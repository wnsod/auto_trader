import os
import sys
import time
import sqlite3
import pandas as pd
import json
import traceback
from datetime import datetime, timedelta
from collections import defaultdict
from typing import List, Dict, Any, Optional

# ê²½ë¡œ ì„¤ì • (trade.core.databaseì—ì„œ ì¤‘ì•™í™”ëœ ì„¤ì • ë¡œë“œ)
try:
    from trade.core.database import TRADING_SYSTEM_DB_PATH, STRATEGY_DB_PATH, CANDLES_DB_PATH, get_db_connection
except ImportError:
    # í•˜ìœ„ í˜¸í™˜ì„± ë° ëŒ€ì²´ ë¡œì§
    current_dir = os.path.dirname(os.path.abspath(__file__))
    workspace_dir = os.path.dirname(current_dir)
    sys.path.insert(0, workspace_dir)
    sys.path.insert(0, current_dir)
    _DEFAULT_DB_DIR = os.path.join(workspace_dir, 'market', 'coin_market', 'data_storage')
    TRADING_SYSTEM_DB_PATH = os.path.join(_DEFAULT_DB_DIR, 'trading_system.db')
    STRATEGY_DB_PATH = os.path.join(_DEFAULT_DB_DIR, 'learning_strategies', 'common_strategies.db')
    CANDLES_DB_PATH = os.path.join(_DEFAULT_DB_DIR, 'trade_candles.db')
    def get_db_connection(db_path, read_only=True, **kwargs):
        timeout = kwargs.get('timeout', 60.0)
        conn = sqlite3.connect(db_path, timeout=timeout)
        conn.row_factory = sqlite3.Row
        return conn

from trade.trade_executor import get_market_context
from trade.core.thompson import ThompsonSamplingLearner
from trade.core.thresholds import get_thresholds
from trade.core.learner.realtime import RealTimeLearner
from trade.core.learner.transfer import TransferLearner
from trade.core.learner.analyzer import PatternAnalyzer
from trade.core.learner.insight import MarketInsightMiner
from trade.core.learner.evaluator import PostTradeEvaluator
from trade.core.learner.evolution import EvolutionEngine

# ğŸ†• ì „ëµ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from trade.core.strategies import (
        update_strategy_feedback, get_strategy_success_rate,
        get_market_strategy_preference, create_strategy_feedback_table,
        STRATEGY_EXIT_RULES, get_strategy_description,
        get_regime_adjustment, get_strategy_regime_compatibility  # ğŸ†• ë ˆì§ ì¡°ì • í•¨ìˆ˜
    )
    STRATEGY_SYSTEM_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ì „ëµ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    STRATEGY_SYSTEM_AVAILABLE = False

# ğŸ§¬ ì „ëµ ì§„í™” ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from trade.core.strategy_evolution import (
        get_evolution_manager, update_evolution_stats, get_strategy_level,
        EvolutionLevel, print_evolution_status
    )
    EVOLUTION_SYSTEM_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ì „ëµ ì§„í™” ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    EVOLUTION_SYSTEM_AVAILABLE = False


# ============================================================================
# ğŸ†• ì†ì‹¤ ì›ì¸ ë¶„ì„ + ê³¼ì‰ íšŒí”¼ ë°©ì§€ í†µí•© ì‹œìŠ¤í…œ
# ============================================================================
class LossCause:
    """ì†ì‹¤ ì›ì¸ ë¶„ë¥˜ (í™•ì • ì†ì‹¤)"""
    ENTRY_TIMING = "entry_timing"      # ì§„ì… íƒ€ì´ë° ì‹¤íŒ¨ (ë§¤ìˆ˜ ì§í›„ í•˜ë½)
    EXIT_TIMING = "exit_timing"        # ì²­ì‚° íƒ€ì´ë° ì‹¤íŒ¨ (ìˆ˜ìµâ†’ì†ì‹¤ ì „í™˜)
    STRATEGY_MISMATCH = "strategy_mismatch"  # ì „ëµ-ë ˆì§ ë¶€ì¡°í™”
    MARKET_SHOCK = "market_shock"      # ì‹œì¥ ê¸‰ë³€ (ì˜ˆìƒì¹˜ ëª»í•œ ê¸‰ë½)
    OVERHOLD = "overhold"              # ë³´ìœ  ê¸°ê°„ ì´ˆê³¼
    UNKNOWN = "unknown"                # ì›ì¸ ë¶ˆëª…


class DrawdownAnalysis:
    """
    ğŸ†• ë¯¸ì‹¤í˜„ ì†ì‹¤(Drawdown) ë¶„ì„
    
    ë³´ìœ  ì¤‘ í° í•˜ë½ì„ ê²ªì—ˆì§€ë§Œ íšŒë³µí•œ ì¼€ì´ìŠ¤ ë¶„ì„
    - í™•ì • ì†ì‹¤ ë¶„ì„ê³¼ ë³„ë„ë¡œ "ë‚´ì„±" í•™ìŠµì— í™œìš©
    """
    
    MIN_DRAWDOWN_PCT = 5.0  # 5% ì´ìƒ í•˜ë½ë§Œ ë¶„ì„
    
    @staticmethod
    def analyze_drawdown(
        entry_price: float,
        exit_price: float,
        min_price_during_hold: float,
        final_profit_pct: float
    ) -> dict:
        """
        ë³´ìœ  ì¤‘ ìµœëŒ€ í•˜ë½(MAE) ë¶„ì„
        
        Returns:
            {
                'max_drawdown_pct': ë³´ìœ  ì¤‘ ìµœëŒ€ í•˜ë½ë¥ ,
                'recovered': íšŒë³µ ì—¬ë¶€ (ìµœì¢… ì†ìµ >= 0),
                'recovery_pct': ì €ì  ëŒ€ë¹„ íšŒë³µë¥ ,
                'analysis_type': 'deep_drawdown_recovered' | 'deep_drawdown_loss' | 'shallow_drawdown'
            }
        """
        if entry_price <= 0 or min_price_during_hold <= 0:
            return {}
        
        # MAE (Maximum Adverse Excursion) ê³„ì‚°
        max_drawdown_pct = ((entry_price - min_price_during_hold) / entry_price) * 100
        
        result = {
            'max_drawdown_pct': round(max_drawdown_pct, 2),
            'final_profit_pct': round(final_profit_pct, 2),
            'recovered': final_profit_pct >= 0,
            'recovery_pct': 0.0,
            'analysis_type': 'shallow_drawdown'
        }
        
        # 5% ì´ìƒ í•˜ë½ì¸ ê²½ìš°ë§Œ ìƒì„¸ ë¶„ì„
        if max_drawdown_pct >= DrawdownAnalysis.MIN_DRAWDOWN_PCT:
            # ì €ì  ëŒ€ë¹„ íšŒë³µë¥  ê³„ì‚°
            if min_price_during_hold > 0:
                result['recovery_pct'] = round(
                    ((exit_price - min_price_during_hold) / min_price_during_hold) * 100, 2
                )
            
            if final_profit_pct >= 0:
                result['analysis_type'] = 'deep_drawdown_recovered'  # ğŸ‰ ë²„í…¨ì„œ íšŒë³µ
            else:
                result['analysis_type'] = 'deep_drawdown_loss'  # ğŸ˜¢ ëª» ë²„í‹°ê³  ì†ì ˆ
        
        return result
    
    @staticmethod
    def get_learning_weight_for_drawdown(analysis: dict) -> float:
        """
        ë¯¸ì‹¤í˜„ ì†ì‹¤ ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ í•™ìŠµ ê°€ì¤‘ì¹˜
        
        - ë²„í…¨ì„œ íšŒë³µí•œ ì¼€ì´ìŠ¤: ê¸ì •ì  í•™ìŠµ (ì¸ë‚´ì‹¬ ê°•í™”)
        - ëª» ë²„í…¨ì„œ ì†ì ˆí•œ ì¼€ì´ìŠ¤: ì´ë¯¸ í™•ì • ì†ì‹¤ë¡œ í•™ìŠµë¨ (ì¤‘ë³µ ë°©ì§€)
        """
        analysis_type = analysis.get('analysis_type', 'shallow_drawdown')
        
        if analysis_type == 'deep_drawdown_recovered':
            # ğŸ‰ ë²„í…¨ì„œ íšŒë³µ â†’ ì¸ë‚´ì‹¬ í•™ìŠµ ê°€ì¤‘ì¹˜
            max_dd = analysis.get('max_drawdown_pct', 0)
            # ë” ê¹Šì€ í•˜ë½ì—ì„œ íšŒë³µí• ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜
            if max_dd >= 10:
                return 1.5  # 10%+ í•˜ë½ì—ì„œ íšŒë³µ â†’ ë†’ì€ í•™ìŠµ ê°€ì¹˜
            elif max_dd >= 7:
                return 1.3
            else:
                return 1.1
        
        elif analysis_type == 'deep_drawdown_loss':
            # í™•ì • ì†ì‹¤ë¡œ ì´ë¯¸ í•™ìŠµë˜ë¯€ë¡œ ì¤‘ë³µ í•™ìŠµ ë°©ì§€
            return 0.0  # í•™ìŠµí•˜ì§€ ì•ŠìŒ
        
        return 0.0  # shallowëŠ” í•™ìŠµ ëŒ€ìƒ ì•„ë‹˜


class BalancedLearningGuard:
    """
    ê³¼ì‰ íšŒí”¼ ë°©ì§€ + ê· í˜• í•™ìŠµ ê´€ë¦¬ì
    
    ì†ì‹¤ í•™ìŠµì´ ê³¼ë„í•´ì ¸ì„œ ë§¤ìˆ˜ë¥¼ êº¼ë ¤í•˜ëŠ” í˜„ìƒì„ ë°©ì§€
    """
    
    # ì„¤ì •ê°’
    MIN_BUY_PROBABILITY = 0.15         # ìµœì†Œ ë§¤ìˆ˜ í™•ë¥  (15% ì´í•˜ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ)
    MAX_LOSS_WEIGHT = 2.0              # ì†ì‹¤ í•™ìŠµ ê°€ì¤‘ì¹˜ ìƒí•œì„ 
    TIME_DECAY_DAYS = 14               # ì‹œê°„ ê°ì‡  ê¸°ì¤€ì¼ (14ì¼ í›„ 50% ê°ì‡ )
    REGIME_CHANGE_DECAY = 0.7          # ë ˆì§ ë³€ê²½ ì‹œ ê³¼ê±° í•™ìŠµ ê°ì‡  (30% ê°ì†Œ)
    
    # ğŸ†• ì†ì‹¤ ë¶„ì„ ê¸°ì¤€
    MIN_LOSS_PCT_FOR_ANALYSIS = 5.0    # 5% ì´ìƒ ì†ì‹¤ë§Œ ì›ì¸ ë¶„ì„ (ì¦ì€ ë¶„ì„/ê³¼ì‰ íšŒí”¼ ë°©ì§€)
    
    @staticmethod
    def apply_time_decay(weight: float, trade_timestamp: int) -> float:
        """
        ì‹œê°„ ê°ì‡  ì ìš©: ì˜¤ë˜ëœ ì†ì‹¤ì¼ìˆ˜ë¡ ì˜í–¥ë ¥ ê°ì†Œ
        
        - ë‹¹ì¼: 100%
        - 1ì£¼ì¼: ~75%
        - 2ì£¼ì¼: ~50%
        - 1ê°œì›”: ~25%
        """
        now = int(time.time())
        age_days = (now - trade_timestamp) / 86400  # ì¼ ë‹¨ìœ„
        
        if age_days <= 0:
            return weight
        
        # ì§€ìˆ˜ ê°ì‡ : weight * e^(-age/decay_constant)
        decay_constant = BalancedLearningGuard.TIME_DECAY_DAYS
        decay_factor = pow(0.5, age_days / decay_constant)
        
        return weight * max(0.1, decay_factor)  # ìµœì†Œ 10%ëŠ” ìœ ì§€
    
    @staticmethod
    def cap_loss_weight(weight: float, is_loss: bool) -> float:
        """
        ì†ì‹¤ í•™ìŠµ ê°€ì¤‘ì¹˜ ìƒí•œì„  ì ìš©
        
        ì†ì‹¤ì— ëŒ€í•œ ê³¼ë„í•œ í˜ë„í‹° ë°©ì§€
        """
        if is_loss:
            return min(weight, BalancedLearningGuard.MAX_LOSS_WEIGHT)
        return weight
    
    @staticmethod
    def ensure_minimum_probability(thompson_score: float, pattern: str = None) -> float:
        """
        ìµœì†Œ ë§¤ìˆ˜ í™•ë¥  ë³´ì¥
        
        ì•„ë¬´ë¦¬ ì†ì‹¤ì´ ë§ì•„ë„ ì™„ì „íˆ ë§¤ìˆ˜ë¥¼ ê±°ë¶€í•˜ì§€ ì•Šë„ë¡ í•¨
        """
        return max(thompson_score, BalancedLearningGuard.MIN_BUY_PROBABILITY)
    
    @staticmethod
    def calculate_balanced_weight(
        base_weight: float,
        is_loss: bool,
        trade_timestamp: int,
        loss_cause: str = None,
        regime_changed: bool = False
    ) -> float:
        """
        ê· í˜• ì¡íŒ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì†ì‹¤ ë¶„ì„ + ê³¼ì‰ íšŒí”¼ ë°©ì§€ í†µí•©)
        
        Args:
            base_weight: ê¸°ë³¸ ê°€ì¤‘ì¹˜
            is_loss: ì†ì‹¤ ì—¬ë¶€
            trade_timestamp: ê±°ë˜ ì‹œê°
            loss_cause: ì†ì‹¤ ì›ì¸ (LossCause)
            regime_changed: ë ˆì§ ë³€ê²½ ì—¬ë¶€
            
        Returns:
            ì¡°ì •ëœ ê°€ì¤‘ì¹˜
        """
        weight = base_weight
        
        # 1. ì‹œê°„ ê°ì‡  ì ìš©
        weight = BalancedLearningGuard.apply_time_decay(weight, trade_timestamp)
        
        # 2. ì†ì‹¤ì¸ ê²½ìš° ì›ì¸ë³„ ê°€ì¤‘ì¹˜ ì¡°ì •
        if is_loss and loss_cause:
            if loss_cause == LossCause.MARKET_SHOCK:
                # ì‹œì¥ ê¸‰ë³€ì€ ì˜ˆì¸¡ ë¶ˆê°€ â†’ ê°€ì¤‘ì¹˜ ë‚®ì¶¤ (ê³¼í•™ìŠµ ë°©ì§€)
                weight *= 0.5
            elif loss_cause == LossCause.STRATEGY_MISMATCH:
                # ì „ëµ-ë ˆì§ ë¶€ì¡°í™”ëŠ” ì¤‘ìš”í•œ í•™ìŠµ í¬ì¸íŠ¸
                weight *= 1.2
            elif loss_cause == LossCause.ENTRY_TIMING:
                # ì§„ì… íƒ€ì´ë° ì‹¤íŒ¨ëŠ” ë³´í†µ ê°€ì¤‘ì¹˜
                weight *= 1.0
            elif loss_cause == LossCause.EXIT_TIMING:
                # ì²­ì‚° íƒ€ì´ë° ì‹¤íŒ¨ (ìˆ˜ìµ â†’ ì†ì‹¤) ì¤‘ìš”ë„ ë†’ìŒ
                weight *= 1.3
            elif loss_cause == LossCause.OVERHOLD:
                # ë³´ìœ  ê¸°ê°„ ì´ˆê³¼ëŠ” í•™ìŠµ í•„ìš”
                weight *= 1.1
        
        # 3. ë ˆì§ ë³€ê²½ ì‹œ ê³¼ê±° í•™ìŠµ ì˜í–¥ë ¥ ê°ì†Œ
        if regime_changed:
            weight *= BalancedLearningGuard.REGIME_CHANGE_DECAY
        
        # 4. ì†ì‹¤ ê°€ì¤‘ì¹˜ ìƒí•œì„  ì ìš©
        weight = BalancedLearningGuard.cap_loss_weight(weight, is_loss)
        
        return round(weight, 3)


def get_balanced_thompson_score(thompson_sampler, pattern: str) -> float:
    """
    Thompson ì ìˆ˜ ì¡°íšŒ ì‹œ ìµœì†Œ ë§¤ìˆ˜ í™•ë¥  ë³´ì¥
    
    ì†ì‹¤ í•™ìŠµì´ ê³¼ë„í•´ë„ ì™„ì „íˆ ë§¤ìˆ˜ë¥¼ ê±°ë¶€í•˜ì§€ ì•Šë„ë¡ í•¨
    """
    try:
        raw_score = thompson_sampler.get_success_probability(pattern)
        return BalancedLearningGuard.ensure_minimum_probability(raw_score, pattern)
    except Exception:
        return BalancedLearningGuard.MIN_BUY_PROBABILITY


def analyze_loss_cause(
    entry_price: float,
    exit_price: float,
    entry_timestamp: int,
    exit_timestamp: int,
    max_profit_pct: float,
    profit_loss_pct: float,
    strategy_type: str,
    market_regime: str,
    candle_data: pd.DataFrame = None
) -> tuple:
    """
    ì†ì‹¤ ì›ì¸ ë¶„ì„ (ğŸ†• 5% ì´ìƒ ì†ì‹¤ë§Œ ë¶„ì„)
    
    Args:
        entry_price: ì§„ì…ê°€
        exit_price: ì²­ì‚°ê°€
        entry_timestamp: ì§„ì… ì‹œê°
        exit_timestamp: ì²­ì‚° ì‹œê°
        max_profit_pct: ë³´ìœ  ì¤‘ ìµœëŒ€ ìˆ˜ìµë¥ 
        profit_loss_pct: ìµœì¢… ì†ìµë¥ 
        strategy_type: ì „ëµ íƒ€ì…
        market_regime: ì‹œì¥ ë ˆì§
        candle_data: ìº”ë“¤ ë°ì´í„° (ì˜µì…˜)
        
    Returns:
        (loss_cause: str, details: dict)
        - ì†ì‹¤ì´ ì•„ë‹ˆê±°ë‚˜ 5% ë¯¸ë§Œì´ë©´ (None, {}) ë°˜í™˜
    """
    # ğŸ†• ì†ì‹¤ì´ ì•„ë‹ˆê±°ë‚˜ ê¸°ì¤€ ë¯¸ë§Œì´ë©´ ë¶„ì„í•˜ì§€ ì•ŠìŒ
    if profit_loss_pct >= 0:
        return None, {}  # ì†ì‹¤ì´ ì•„ë‹˜
    
    if abs(profit_loss_pct) < BalancedLearningGuard.MIN_LOSS_PCT_FOR_ANALYSIS:
        return None, {}  # ğŸ†• 5% ë¯¸ë§Œ ì†ì‹¤ì€ ë¶„ì„í•˜ì§€ ì•ŠìŒ (ê³¼ì‰ íšŒí”¼ ë°©ì§€)
    
    details = {
        'entry_price': entry_price,
        'exit_price': exit_price,
        'profit_loss_pct': profit_loss_pct,
        'max_profit_pct': max_profit_pct
    }
    
    holding_hours = (exit_timestamp - entry_timestamp) / 3600
    details['holding_hours'] = holding_hours
    
    # 1. ìˆ˜ìµ â†’ ì†ì‹¤ ì „í™˜ (ì²­ì‚° íƒ€ì´ë° ì‹¤íŒ¨)
    if max_profit_pct and max_profit_pct > 1.0 and profit_loss_pct < 0:
        details['missed_profit'] = max_profit_pct - profit_loss_pct
        return LossCause.EXIT_TIMING, details
    
    # 2. ì§„ì… ì§í›„ ê¸‰ë½ (ì§„ì… íƒ€ì´ë° ì‹¤íŒ¨)
    # ìº”ë“¤ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì§„ì… í›„ 1ì‹œê°„ ë‚´ ìµœì €ê°€ í™•ì¸
    if candle_data is not None and len(candle_data) > 0:
        try:
            early_candles = candle_data[
                (candle_data['timestamp'] >= entry_timestamp) & 
                (candle_data['timestamp'] <= entry_timestamp + 3600)
            ]
            if len(early_candles) > 0:
                min_low = early_candles['low'].min()
                early_drop = ((entry_price - min_low) / entry_price) * 100
                if early_drop > 2.0:  # 1ì‹œê°„ ë‚´ 2% ì´ìƒ í•˜ë½
                    details['early_drop_pct'] = early_drop
                    return LossCause.ENTRY_TIMING, details
        except Exception:
            pass
    
    # 3. ì „ëµ-ë ˆì§ ë¶€ì¡°í™” ì²´í¬
    if STRATEGY_SYSTEM_AVAILABLE and strategy_type and market_regime:
        try:
            compatibility, _ = get_strategy_regime_compatibility(strategy_type, market_regime)
            if compatibility < 0.6:  # í˜¸í™˜ì„± ë‚®ìŒ
                details['compatibility'] = compatibility
                details['strategy'] = strategy_type
                details['regime'] = market_regime
                return LossCause.STRATEGY_MISMATCH, details
        except Exception:
            pass
    
    # 4. ê¸‰ê²©í•œ ì†ì‹¤ (ì‹œì¥ ê¸‰ë³€)
    if profit_loss_pct < -5.0 and holding_hours < 2:  # 2ì‹œê°„ ë‚´ 5% ì´ìƒ ì†ì‹¤
        details['rapid_loss'] = True
        return LossCause.MARKET_SHOCK, details
    
    # 5. ë³´ìœ  ê¸°ê°„ ì´ˆê³¼
    if holding_hours > 48:  # 48ì‹œê°„ ì´ìƒ ë³´ìœ 
        details['overhold_hours'] = holding_hours
        return LossCause.OVERHOLD, details
    
    # 6. ì›ì¸ ë¶ˆëª…
    return LossCause.UNKNOWN, details

class VirtualTradingLearner:
    """ê°€ìƒë§¤ë§¤ ê²°ê³¼ì™€ ì‹œê·¸ë„ì„ ëŒ€ì¡°í•˜ì—¬ ì‹œìŠ¤í…œì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§„í™”ì‹œí‚¤ëŠ” ì—”ì§„"""
    
    def __init__(self):
        print("ğŸš€ ì§„í™”í˜• í•™ìŠµ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        self.db_path = TRADING_SYSTEM_DB_PATH
        self.thompson_sampler = ThompsonSamplingLearner(db_path=STRATEGY_DB_PATH)
        self.realtime_learner = RealTimeLearner(self.thompson_sampler)
        self.transfer_learner = TransferLearner(STRATEGY_DB_PATH, self.db_path, self.thompson_sampler)
        self.pattern_analyzer = PatternAnalyzer()
        self.market_miner = MarketInsightMiner(self)
        self.evaluator = PostTradeEvaluator(STRATEGY_DB_PATH)
        self.evolution_engine = EvolutionEngine(STRATEGY_DB_PATH)
        self.processed_trade_ids = set()

    # Note: ì‹œê·¸ë„ ì˜ˆì¸¡ ê²€ì¦ (_finalize_forecast_accuracy)ì€ 
    # strategy_signal_generator.pyì˜ validate_signals_incremental()ë¡œ ì´ì „ë¨

    def _execute_real_time_learning(self):
        """ê°€ìƒë§¤ë§¤ í”¼ë“œë°± ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ í•™ìŠµ ì‹¤í–‰ (ì“°ê¸° ëª¨ë“œ ì•ˆì •ì„± ê°•í™”)
        ğŸš€ [ì„±ëŠ¥] iterrows â†’ to_dict('records') ìµœì í™”
        ğŸ†• [ê· í˜• í•™ìŠµ] ì†ì‹¤ ì›ì¸ ë¶„ì„ + ê³¼ì‰ íšŒí”¼ ë°©ì§€ í†µí•©
        """
        try:
            with get_db_connection(self.db_path, read_only=False) as conn:
                # 1. ë¯¸í•™ìŠµ í”¼ë“œë°± ë¡œë“œ - ğŸš€ ë™ì  ì»¬ëŸ¼ ì¡°íšŒ (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
                # ë¨¼ì € í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ í™•ì¸
                cursor = conn.execute("PRAGMA table_info(virtual_trade_feedback)")
                existing_cols = {row[1] for row in cursor.fetchall()}
                
                # ê¸°ë³¸ í•„ìˆ˜ ì»¬ëŸ¼
                base_cols = ['id', 'coin', 'signal_pattern', 'profit_loss_pct', 'exit_price', 'entry_price', 'market_conditions']
                # ì„ íƒì  ì»¬ëŸ¼ (ìˆìœ¼ë©´ í¬í•¨, ì—†ìœ¼ë©´ ì œì™¸)
                optional_cols = ['strategy_type', 'holding_duration', 'entry_timestamp', 'exit_timestamp', 'max_profit_pct', 'max_loss_pct']
                
                select_cols = base_cols + [col for col in optional_cols if col in existing_cols]
                
                query = f"SELECT {', '.join(select_cols)} FROM virtual_trade_feedback WHERE is_learned = 0"
                feedback_df = pd.read_sql(query, conn)
                
                if feedback_df.empty:
                    return 0
                
                print(f"ğŸ“– {len(feedback_df)}ê±´ì˜ ê°€ìƒë§¤ë§¤ í”¼ë“œë°± í•™ìŠµ ì¤‘...")
                
                # ğŸ†• ì†ì‹¤ ì›ì¸ë³„ í†µê³„ ìˆ˜ì§‘
                loss_cause_stats = defaultdict(lambda: {'count': 0, 'total_loss': 0.0})
                # ğŸ†• ë¯¸ì‹¤í˜„ ì†ì‹¤(Drawdown) í†µê³„ ìˆ˜ì§‘
                drawdown_stats = {
                    'deep_recovered': {'count': 0, 'avg_drawdown': 0.0, 'avg_recovery': 0.0},
                    'deep_loss': {'count': 0, 'avg_drawdown': 0.0}
                }
                
                # ğŸš€ [ì„±ëŠ¥] iterrows ëŒ€ì‹  to_dict('records') ì‚¬ìš© (2~5ë°° ë¹ ë¦„)
                learned_ids = []  # ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš©
                for row in feedback_df.to_dict('records'):
                    # 2. í†°ìŠ¨ ìƒ˜í”Œë§ ì§€ì‹ ì—…ë°ì´íŠ¸
                    pattern = row['signal_pattern']
                    profit_pct = row['profit_loss_pct']
                    success = profit_pct > 0
                    is_loss = profit_pct < 0
                    
                    # ğŸ†• [í†µí•©] ì‹œê·¸ë„ ì ìˆ˜ì™€ í•™ìŠµ ë°ì´í„° í†µí•©
                    signal_score = row.get('signal_score', 0.0) or 0.0
                    
                    # ğŸ†• í˜¸ê°€ ì •ë°€ë„ ì¸ì‹ (Tick-Aware Learning)
                    from trade.trade_manager import get_bithumb_tick_size
                    current_price = row.get('exit_price', 0) or row.get('entry_price', 0)
                    tick_size = get_bithumb_tick_size(current_price)
                    
                    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
                    weight = 1.0
                    
                    if tick_size > 0 and current_price > 0:
                        price_diff = abs(profit_pct / 100 * current_price)
                        ticks_moved = price_diff / tick_size
                        if ticks_moved < 3.0:
                            weight *= 0.5
                    
                    # ì‹œì¥ ìƒí™© íŒŒì‹±
                    market_cond = json.loads(row['market_conditions']) if row['market_conditions'] else {}
                    current_regime = market_cond.get('regime', 'neutral')
                    strategy_type = row.get('strategy_type', 'trend')
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸ†• [ì†ì‹¤ ì›ì¸ ë¶„ì„ + ê³¼ì‰ íšŒí”¼ ë°©ì§€] í†µí•© ì‹œìŠ¤í…œ
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    loss_cause = None
                    loss_details = {}
                    
                    if is_loss:
                        # ì†ì‹¤ ì›ì¸ ë¶„ì„
                        loss_cause, loss_details = analyze_loss_cause(
                            entry_price=row.get('entry_price', 0) or 0,
                            exit_price=row.get('exit_price', 0) or 0,
                            entry_timestamp=row.get('entry_timestamp', 0) or 0,
                            exit_timestamp=row.get('exit_timestamp', 0) or 0,
                            max_profit_pct=row.get('max_profit_pct', 0) or 0,
                            profit_loss_pct=profit_pct,
                            strategy_type=strategy_type,
                            market_regime=current_regime
                        )
                        
                        # ì†ì‹¤ ì›ì¸ë³„ í†µê³„ ìˆ˜ì§‘
                        if loss_cause:
                            loss_cause_stats[loss_cause]['count'] += 1
                            loss_cause_stats[loss_cause]['total_loss'] += abs(profit_pct)
                        
                        # ğŸ†• ê· í˜• í•™ìŠµ ê°€ì¤‘ì¹˜ ê³„ì‚° (ê³¼ì‰ íšŒí”¼ ë°©ì§€)
                        entry_ts = row.get('entry_timestamp', 0) or int(time.time())
                        weight = BalancedLearningGuard.calculate_balanced_weight(
                            base_weight=weight,
                            is_loss=True,
                            trade_timestamp=entry_ts,
                            loss_cause=loss_cause,
                            regime_changed=False  # TODO: ë ˆì§ ë³€ê²½ ê°ì§€ ì—°ë™
                        )
                        
                        # ğŸ†• ì†ì‹¤ ì›ì¸ë³„ íŒ¨í„´ í•™ìŠµ (ì„¸ë¶„í™”ëœ í•™ìŠµ)
                        if loss_cause and loss_cause != LossCause.UNKNOWN:
                            cause_pattern = f"{pattern}_loss_{loss_cause}"
                            self.thompson_sampler.update_distribution(
                                cause_pattern, False, profit_pct=profit_pct, weight=weight * 0.8
                            )
                    else:
                        # ì„±ê³µì¸ ê²½ìš°ë„ ì‹œê°„ ê°ì‡  ì ìš©
                        entry_ts = row.get('entry_timestamp', 0) or int(time.time())
                        weight = BalancedLearningGuard.apply_time_decay(weight, entry_ts)
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸ†• [ë¯¸ì‹¤í˜„ ì†ì‹¤ ë¶„ì„] ë³´ìœ  ì¤‘ í° í•˜ë½ í›„ íšŒë³µ ì¼€ì´ìŠ¤ í•™ìŠµ
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    entry_price = row.get('entry_price', 0) or 0
                    exit_price = row.get('exit_price', 0) or 0
                    max_loss_pct = row.get('max_loss_pct', None)  # ë³´ìœ  ì¤‘ ìµœëŒ€ ì†ì‹¤ë¥  (ìˆìœ¼ë©´)
                    
                    if entry_price > 0 and exit_price > 0:
                        # max_loss_pctê°€ ì—†ìœ¼ë©´ max_profit_pctë¡œ ì¶”ì • (ê°„ì ‘ ê³„ì‚°)
                        if max_loss_pct is None:
                            # ìµœëŒ€ ì†ì‹¤ì€ ë³´í†µ ìµœëŒ€ ìˆ˜ìµì˜ ë°˜ëŒ€ ë°©í–¥ ë³€ë™ì´ë¯€ë¡œ ì¶”ì •
                            # (ì •í™•í•œ ê°’ì€ ìº”ë“¤ ë¶„ì„ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ê°„ì†Œí™”)
                            max_profit = row.get('max_profit_pct', 0) or 0
                            # ìˆ˜ìµìœ¼ë¡œ ëë‚¬ì§€ë§Œ ì¤‘ê°„ì— í•˜ë½ì´ ìˆì—ˆì„ ê°€ëŠ¥ì„±
                            if success and max_profit > profit_pct:
                                # ìˆ˜ìµì¸ë° ìµœëŒ€ ìˆ˜ìµë³´ë‹¤ ë‚®ê²Œ ëë‚¨ â†’ ì¤‘ê°„ì— í•˜ë½ ìˆì—ˆìŒ
                                estimated_drawdown = max(0, -profit_pct + 2)  # ëŒ€ëµì  ì¶”ì •
                            else:
                                estimated_drawdown = abs(min(0, profit_pct))
                            min_price_during_hold = entry_price * (1 - estimated_drawdown / 100)
                        else:
                            min_price_during_hold = entry_price * (1 - abs(max_loss_pct) / 100)
                        
                        # Drawdown ë¶„ì„
                        dd_analysis = DrawdownAnalysis.analyze_drawdown(
                            entry_price=entry_price,
                            exit_price=exit_price,
                            min_price_during_hold=min_price_during_hold,
                            final_profit_pct=profit_pct
                        )
                        
                        # ğŸ‰ ë²„í…¨ì„œ íšŒë³µí•œ ì¼€ì´ìŠ¤ â†’ ê¸ì •ì  í•™ìŠµ
                        if dd_analysis.get('analysis_type') == 'deep_drawdown_recovered':
                            dd_weight = DrawdownAnalysis.get_learning_weight_for_drawdown(dd_analysis)
                            if dd_weight > 0:
                                # "ì¸ë‚´ì‹¬" íŒ¨í„´ í•™ìŠµ (ë²„í…¨ì„œ íšŒë³µí•˜ë©´ ì¢‹ë‹¤)
                                patience_pattern = f"{pattern}_patience_recovered"
                                self.thompson_sampler.update_distribution(
                                    patience_pattern, True, profit_pct=profit_pct, weight=dd_weight
                                )
                                
                                # í†µê³„ ìˆ˜ì§‘
                                drawdown_stats['deep_recovered']['count'] += 1
                                drawdown_stats['deep_recovered']['avg_drawdown'] += dd_analysis['max_drawdown_pct']
                                drawdown_stats['deep_recovered']['avg_recovery'] += dd_analysis['recovery_pct']
                        
                        # ğŸ˜¢ ê¹Šì€ í•˜ë½ í›„ ì†ì ˆ ì¼€ì´ìŠ¤ (í™•ì • ì†ì‹¤ë¡œ ì´ë¯¸ í•™ìŠµë˜ë¯€ë¡œ í†µê³„ë§Œ)
                        elif dd_analysis.get('analysis_type') == 'deep_drawdown_loss':
                            drawdown_stats['deep_loss']['count'] += 1
                            drawdown_stats['deep_loss']['avg_drawdown'] += dd_analysis['max_drawdown_pct']
                    
                    # ğŸ†• [í†µí•©] ì‹œê·¸ë„ ì ìˆ˜ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
                    t = get_thresholds()
                    if abs(signal_score) > t.strong_buy:
                        if success:
                            weight *= 1.3
                        else:
                            weight *= 1.2  # ğŸ†• ì†ì‹¤ ì‹œ ê°€ì¤‘ì¹˜ ì¶•ì†Œ (1.5 â†’ 1.2, ê³¼ì‰ í•™ìŠµ ë°©ì§€)
                    elif abs(signal_score) > t.buy:
                        if success:
                            weight *= 1.1
                        else:
                            weight *= 1.0  # ğŸ†• ì†ì‹¤ ì‹œ ê°€ì¤‘ì¹˜ ì¶•ì†Œ (1.2 â†’ 1.0)
                    
                    # ğŸ†• [ë ˆì§ ê¸°ë°˜ í•™ìŠµ] ì „ëµ+ë ˆì§ í˜¸í™˜ì„±ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì¡°ì •
                    if STRATEGY_SYSTEM_AVAILABLE and strategy_type and strategy_type != 'None':
                        try:
                            compatibility, compat_desc = get_strategy_regime_compatibility(strategy_type, current_regime)
                            
                            if compatibility >= 1.2:  # ì¢‹ì€ ì¡°í•©
                                if success:
                                    weight *= 1.3
                                else:
                                    weight *= 1.2  # ğŸ†• ì¶•ì†Œ (1.5 â†’ 1.2)
                            elif compatibility <= 0.6:  # ë‚˜ìœ ì¡°í•©
                                if success:
                                    weight *= 1.4  # ì˜ˆì™¸ í•™ìŠµ ì¤‘ìš”
                                else:
                                    weight *= 0.5  # ğŸ†• ì˜ˆìƒëœ ì‹¤íŒ¨ â†’ ë” ë‚®ì€ ê°€ì¤‘ì¹˜ (0.7 â†’ 0.5)
                        except Exception:
                            if current_regime == 'neutral':
                                weight *= 1.2 if success else 1.0
                    else:
                        if current_regime == 'neutral':
                            weight *= 1.2 if success else 1.0
                    
                    # ğŸ†• ìµœì¢… ê°€ì¤‘ì¹˜ ìƒí•œì„  ì ìš© (ê³¼ì‰ í•™ìŠµ ë°©ì§€)
                    weight = BalancedLearningGuard.cap_loss_weight(weight, is_loss)
                    
                    # ğŸ†• [í†µí•©] ì‹œê·¸ë„ ì ìˆ˜ + ë ˆì§ ì •ë³´ë¥¼ íŒ¨í„´ì— í¬í•¨í•˜ì—¬ í•™ìŠµ
                    enhanced_pattern = f"{pattern}_sig{abs(signal_score):.2f}"
                    regime_pattern = f"{pattern}_{current_regime}"
                    
                    self.thompson_sampler.update_distribution(enhanced_pattern, success, profit_pct=profit_pct, weight=weight)
                    self.thompson_sampler.update_distribution(pattern, success, profit_pct=profit_pct, weight=weight * 0.8)
                    self.thompson_sampler.update_distribution(regime_pattern, success, profit_pct=profit_pct, weight=weight * 0.6)
                    
                    # 3. ì‹¤ì‹œê°„ í•™ìŠµê¸°ì— ì „ë‹¬
                    self.realtime_learner.learn_from_trade(pattern, row['profit_loss_pct'])
                    
                    # ğŸ†• [ì „ëµ ì‹œìŠ¤í…œ] ì „ëµë³„ + ë ˆì§ë³„ í•™ìŠµ í”¼ë“œë°± ì €ì¥
                    if STRATEGY_SYSTEM_AVAILABLE:
                        if strategy_type and strategy_type != 'None':
                            holding_hours = row.get('holding_duration', 0) / 3600.0
                            
                            try:
                                # ê¸°ë³¸ ì „ëµ í”¼ë“œë°±
                                update_strategy_feedback(
                                    db_path=self.db_path,
                                    strategy_type=strategy_type,
                                    market_condition=current_regime,  # ğŸ†• ë ˆì§ ì •ë³´ ì „ë‹¬
                                    signal_pattern=pattern,
                                    success=success,
                                    profit_pct=row['profit_loss_pct'],
                                    holding_hours=holding_hours
                                )
                                
                                # ğŸ†• ì „ëµ+ë ˆì§ ì¡°í•© í”¼ë“œë°± (ë” ì„¸ë¶„í™”ëœ í•™ìŠµ)
                                strategy_regime_key = f"{strategy_type}_{current_regime}"
                                update_strategy_feedback(
                                    db_path=self.db_path,
                                    strategy_type=strategy_regime_key,
                                    market_condition=current_regime,
                                    signal_pattern=pattern,
                                    success=success,
                                    profit_pct=row['profit_loss_pct'],
                                    holding_hours=holding_hours
                                )
                            except Exception as strat_err:
                                # ì „ëµ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ ë¬´ì‹œ
                                pass
                    
                    # 4. í•™ìŠµ ì™„ë£Œ ID ìˆ˜ì§‘ (ğŸš€ ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš©)
                    learned_ids.append(row['id'])
                    self.processed_trade_ids.add(row['id'])
                
                # ğŸš€ [ì„±ëŠ¥] ë°°ì¹˜ UPDATE (ê°œë³„ UPDATE ëŒ€ì‹  í•œ ë²ˆì— ì‹¤í–‰)
                if learned_ids:
                    placeholders = ','.join('?' * len(learned_ids))
                    conn.execute(f"UPDATE virtual_trade_feedback SET is_learned = 1 WHERE id IN ({placeholders})", learned_ids)
                
                conn.commit()
                
                # ğŸ†• [ì†ì‹¤ ì›ì¸ ë¶„ì„] í†µê³„ ì¶œë ¥ (5% ì´ìƒ ì†ì‹¤ë§Œ)
                if loss_cause_stats:
                    total_losses = sum(s['count'] for s in loss_cause_stats.values())
                    if total_losses > 0:
                        print(f"\n   ğŸ“Š [ì†ì‹¤ ì›ì¸ ë¶„ì„] {total_losses}ê±´ ì£¼ìš” ì†ì‹¤(â‰¥{BalancedLearningGuard.MIN_LOSS_PCT_FOR_ANALYSIS}%) ë¶„ì„:")
                        cause_names = {
                            LossCause.ENTRY_TIMING: "ì§„ì… íƒ€ì´ë° â°",
                            LossCause.EXIT_TIMING: "ì²­ì‚° íƒ€ì´ë° ğŸ“‰",
                            LossCause.STRATEGY_MISMATCH: "ì „ëµ-ë ˆì§ ë¶€ì¡°í™” âš–ï¸",
                            LossCause.MARKET_SHOCK: "ì‹œì¥ ê¸‰ë³€ âš¡",
                            LossCause.OVERHOLD: "ë³´ìœ  ê¸°ê°„ ì´ˆê³¼ â³",
                            LossCause.UNKNOWN: "ì›ì¸ ë¶ˆëª… â“"
                        }
                        for cause, stats in sorted(loss_cause_stats.items(), key=lambda x: x[1]['count'], reverse=True):
                            pct = (stats['count'] / total_losses) * 100
                            avg_loss = stats['total_loss'] / stats['count'] if stats['count'] > 0 else 0
                            cause_name = cause_names.get(cause, cause)
                            print(f"      - {cause_name}: {stats['count']}ê±´ ({pct:.0f}%), í‰ê·  -{avg_loss:.2f}%")
                        
                        # ğŸ†• ê°€ì¥ ë¹ˆë²ˆí•œ ì†ì‹¤ ì›ì¸ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
                        top_cause = max(loss_cause_stats.items(), key=lambda x: x[1]['count'])[0]
                        if top_cause == LossCause.ENTRY_TIMING:
                            print(f"      ğŸ’¡ ê¶Œì¥: ì§„ì… ì§€ì—° ë˜ëŠ” ë¶„í•  ë§¤ìˆ˜ ê³ ë ¤")
                        elif top_cause == LossCause.EXIT_TIMING:
                            print(f"      ğŸ’¡ ê¶Œì¥: íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë˜ëŠ” ë¶€ë¶„ ìµì ˆ í™œìš©")
                        elif top_cause == LossCause.STRATEGY_MISMATCH:
                            print(f"      ğŸ’¡ ê¶Œì¥: í˜„ì¬ ë ˆì§ì— ë§ëŠ” ì „ëµìœ¼ë¡œ ì „í™˜ í•„ìš”")
                        elif top_cause == LossCause.MARKET_SHOCK:
                            print(f"      ğŸ’¡ ê¶Œì¥: ì‹œì¥ ê¸‰ë³€ì€ ì˜ˆì¸¡ ë¶ˆê°€ - ê³¼í•™ìŠµ ì£¼ì˜ (ê°€ì¤‘ì¹˜ ë‚®ì¶¤)")
                        elif top_cause == LossCause.OVERHOLD:
                            print(f"      ğŸ’¡ ê¶Œì¥: ë³´ìœ  ê¸°ê°„ ëª©í‘œ ë‹¨ì¶• ë˜ëŠ” ì‹œê°„ ê¸°ë°˜ ì²­ì‚° ê·œì¹™ ì¶”ê°€")
                
                # ğŸ†• [ë¯¸ì‹¤í˜„ ì†ì‹¤ ë¶„ì„] Drawdown í†µê³„ ì¶œë ¥
                recovered_count = drawdown_stats['deep_recovered']['count']
                loss_count = drawdown_stats['deep_loss']['count']
                if recovered_count > 0 or loss_count > 0:
                    print(f"\n   ğŸ“‰ [ë¯¸ì‹¤í˜„ ì†ì‹¤ ë¶„ì„] ë³´ìœ  ì¤‘ {DrawdownAnalysis.MIN_DRAWDOWN_PCT}%+ í•˜ë½ ì¼€ì´ìŠ¤:")
                    
                    if recovered_count > 0:
                        avg_dd = drawdown_stats['deep_recovered']['avg_drawdown'] / recovered_count
                        avg_rec = drawdown_stats['deep_recovered']['avg_recovery'] / recovered_count
                        print(f"      ğŸ‰ ë²„í…¨ì„œ íšŒë³µ: {recovered_count}ê±´ (í‰ê·  -{avg_dd:.1f}% â†’ +{avg_rec:.1f}% íšŒë³µ)")
                        print(f"         â†’ 'ì¸ë‚´ì‹¬' íŒ¨í„´ ê¸ì • í•™ìŠµ ì™„ë£Œ")
                    
                    if loss_count > 0:
                        avg_dd_loss = drawdown_stats['deep_loss']['avg_drawdown'] / loss_count
                        print(f"      ğŸ˜¢ ëª» ë²„í‹°ê³  ì†ì ˆ: {loss_count}ê±´ (í‰ê·  -{avg_dd_loss:.1f}% í•˜ë½)")
                        print(f"         â†’ í™•ì • ì†ì‹¤ë¡œ ì´ë¯¸ í•™ìŠµë¨ (ì¤‘ë³µ í•™ìŠµ ë°©ì§€)")
                    
                    # íšŒë³µë¥  ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
                    if recovered_count > 0 and loss_count > 0:
                        recovery_rate = recovered_count / (recovered_count + loss_count) * 100
                        if recovery_rate >= 60:
                            print(f"      ğŸ’ª íšŒë³µë¥  {recovery_rate:.0f}% - ì¸ë‚´ì‹¬ì´ ìˆ˜ìµìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½í–¥")
                        elif recovery_rate <= 30:
                            print(f"      âš ï¸ íšŒë³µë¥  {recovery_rate:.0f}% - ì†ì ˆ ê¸°ì¤€ ì¬ê²€í†  í•„ìš”")
                
                return len(feedback_df)
                
        except Exception as e:
            # ğŸ”‡ DB ì ‘ê·¼ ì˜¤ë¥˜ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì‹¤ì‹œê°„ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return 0

    def _run_post_trade_evaluation(self) -> int:
        """ğŸ†• ë§¤ë„ í›„ ê°€ê²© ì¶”ì  ë° MFE/MAE í‰ê°€ ì‹¤í–‰ (ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ë³µê¸° í¬í•¨)"""
        completed_count = 0
        try:
            # ğŸš€ [Fix] ì‹œìŠ¤í…œ ì‹œê°„ì´ ì•„ë‹Œ DBì˜ ê°€ì¥ ìµœì‹  ìº”ë“¤ ì‹œê°„ ê¸°ì¤€
            from trade.core.database import CANDLES_DB_PATH
            with get_db_connection(CANDLES_DB_PATH, read_only=True) as c_conn:
                max_ts_row = c_conn.execute("SELECT MAX(timestamp) FROM candles").fetchone()
                if not max_ts_row or not max_ts_row[0]:
                    print("âš ï¸ ìº”ë“¤ ë°ì´í„°ê°€ ì—†ì–´ ë³µê¸° ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return 0
                
                latest_db_ts = max_ts_row[0]
                cutoff_ts = latest_db_ts - (24 * 3600)
                
                from datetime import datetime
                dt_str = datetime.fromtimestamp(latest_db_ts).strftime('%m-%d %H:%M')
                print(f"ğŸ“Š [ì •ë°€ ë¶„ì„] ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ë³µê¸° ì‹œì‘... (ë°ì´í„° ì‹œê°: ~{dt_str})")
                
                # ìµœê·¼ 24ì‹œê°„ ë‚´ ì½”ì¸ë³„ ì‹œê°€/ì¢…ê°€ ê°€ì ¸ì˜¤ê¸°
                # ğŸš€ [Fix] ì‚¬ìš© ê°€ëŠ¥í•œ interval ë™ì  í™•ì¸ (1hê°€ ì—†ìœ¼ë©´ 240m ë˜ëŠ” 1d ì‚¬ìš©)
                # ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ interval í™•ì¸
                available_intervals = pd.read_sql("""
                    SELECT DISTINCT interval FROM candles 
                    WHERE timestamp > ? 
                    ORDER BY 
                        CASE interval
                            WHEN '15m' THEN 1
                            WHEN '30m' THEN 2
                            WHEN '240m' THEN 3
                            WHEN '1d' THEN 4
                            ELSE 5
                        END
                """, c_conn, params=(cutoff_ts,))
                
                # ìš°ì„ ìˆœìœ„: 240m(4h) > 1d > 30m > 15m
                target_interval = None
                for preferred in ['240m', '1d', '30m', '15m']:
                    if preferred in available_intervals['interval'].values:
                        target_interval = preferred
                        break
                
                if target_interval is None:
                    # ì‚¬ìš© ê°€ëŠ¥í•œ intervalì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê²ƒ ì‚¬ìš©
                    if not available_intervals.empty:
                        target_interval = available_intervals['interval'].iloc[0]
                    else:
                        print("   âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ìº”ë“¤ intervalì´ ì—†ìŠµë‹ˆë‹¤.")
                        target_interval = '240m'  # ê¸°ë³¸ê°’
                
                # ğŸš€ [Fix] FIRST_VALUE/LAST_VALUEë¥¼ í™œìš©í•˜ì—¬ 24ì‹œê°„ ë³€ë™í­ ê³„ì‚°
                vol_df = pd.read_sql("""
                    SELECT DISTINCT symbol, 
                           FIRST_VALUE(close) OVER (PARTITION BY symbol ORDER BY timestamp ASC) as open_p,
                           LAST_VALUE(close) OVER (PARTITION BY symbol ORDER BY timestamp ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) as close_p
                    FROM candles 
                    WHERE interval = ? AND timestamp > ?
                """, c_conn, params=(target_interval, cutoff_ts))
                
                if target_interval != '1h':
                    print(f"   â„¹ï¸ 1h ìº”ë“¤ ì—†ìŒ -> {target_interval} ìº”ë“¤ ì‚¬ìš© (24ì‹œê°„ ë³€ë™í­ ê³„ì‚°)")
                
                if not vol_df.empty:
                    vol_df['change'] = (vol_df['close_p'] - vol_df['open_p']) / vol_df['open_p'] * 100
                    big_movers = vol_df[vol_df['change'].abs() >= 5.0] # 5% ê¸‰ë“±ë½ ê¸°ì¤€
                    
                    if not big_movers.empty:
                        print(f"   ğŸ“ˆ ìµœê·¼ 24ì‹œê°„ 5% ì´ìƒ ë³€ë™ ì½”ì¸ {len(big_movers)}ê°œ ê°ì§€ (ë³µê¸° ë¶„ì„ ì¤‘...)")
                        for _, row in big_movers.sort_values('change', ascending=False).head(5).iterrows():
                            print(f"      - {row['symbol']}: {row['change']:+.2f}% ë³€ë™")
                    else:
                        print("   â„¹ï¸ ìµœê·¼ 24ì‹œê°„ ë‚´ Â±5% ì´ìƒ ë³€ë™í•œ ì½”ì¸ ì—†ìŒ")

            # ê¸°ì¡´ ë§¤ë„ í’ˆì§ˆ í‰ê°€ ë¡œì§ ê³„ì† ì§„í–‰ (trading_system.db ì—°ê²° í•„ìš”)
            with get_db_connection(self.db_path, read_only=True) as conn:
                trades_df = pd.read_sql("""
                    SELECT coin, entry_price, exit_price, entry_timestamp, exit_timestamp,
                           profit_loss_pct, signal_pattern,
                           entry_strategy, exit_strategy, strategy_switch_count, switch_success
                    FROM virtual_trade_feedback 
                    WHERE exit_timestamp > ? AND is_learned = 1
                    ORDER BY exit_timestamp DESC
                    LIMIT 100
                """, conn, params=(cutoff_ts,))
            
            if trades_df.empty:
                return 0
            
            # 2. ê° ê±°ë˜ë¥¼ evaluatorì— ì¶”ê°€ (ì•„ì§ ì¶”ì  ì¤‘ì´ ì•„ë‹Œ ê²ƒë§Œ)
            for _, trade in trades_df.iterrows():
                trade_id = f"{trade['coin']}_{trade['entry_timestamp']}"
                if trade_id not in self.evaluator.tracked_trades:
                    self.evaluator.add_trade({
                        'coin': trade['coin'],
                        'entry_price': trade['entry_price'],
                        'exit_price': trade['exit_price'],
                        'entry_timestamp': trade['entry_timestamp'],
                        'exit_timestamp': trade['exit_timestamp'],
                        'profit_loss_pct': trade['profit_loss_pct'],
                        'max_profit_pct': 0.0,  # ğŸ†• ê¸°ë³¸ê°’ ì‚¬ìš©
                        'signal_pattern': trade.get('signal_pattern', 'unknown'),
                    })
            
            # 3. í˜„ì¬ ê°€ê²© ì¡°íšŒ
            current_prices = self._get_current_prices()
            
            # 4. í‰ê°€ ì‹¤í–‰
            if current_prices:
                completed_ids = self.evaluator.check_evaluations(current_prices)
                completed_count = len(completed_ids)
            
            # 5. í‰ê°€ ê²°ê³¼ë¥¼ Thompson Samplingì— ë°˜ì˜
            feedbacks = self.evaluator.get_pending_feedback()
            for fb in feedbacks:
                pattern = fb.get('signal_pattern', 'unknown')
                adjustment = fb.get('adjustment_weight', 0.0)
                
                if fb.get('is_panic_sell'):
                    # íŒ¨ë‹‰ ì…€: ë§¤ë„ ê¸°ì¤€ì„ ë” ë†’ì´ë„ë¡ í•™ìŠµ
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_sell_quality",
                        success=False,
                        profit_pct=-abs(fb.get('mfe', 0)),
                        weight=1.5
                    )
                elif fb.get('is_perfect_exit'):
                    # ì™„ë²½í•œ ë§¤ë„: ì´ íŒ¨í„´ì˜ ì‹ ë¢°ë„ ìƒìŠ¹
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_sell_quality",
                        success=True,
                        profit_pct=abs(fb.get('mae', 0)),
                        weight=1.5
                    )
            
            # ğŸ†• [ì „ëµ ë¶„ë¦¬ í•™ìŠµ] ì§„ì…/ì²­ì‚°/ì „í™˜ ì„±ê³µë¥  ê°ê° í•™ìŠµ
            self._learn_strategy_separated(trades_df)
            
            return completed_count
            
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ë§¤ë„ í’ˆì§ˆ í‰ê°€ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return 0
    
    def _get_current_prices(self) -> Dict[str, float]:
        """í˜„ì¬ ì½”ì¸ ê°€ê²© ì¡°íšŒ (ìº”ë“¤ DBì˜ ìµœì‹  ë°ì´í„° ê¸°ì¤€)"""
        prices = {}
        try:
            from trade.core.database import CANDLES_DB_PATH
            with get_db_connection(CANDLES_DB_PATH, read_only=True) as conn:
                # ğŸš€ [Fix] ì „ì²´ DB ê¸°ì¤€ ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ë¨¼ì € í™•ë³´
                max_ts = conn.execute("SELECT MAX(timestamp) FROM candles").fetchone()[0]
                if not max_ts: return {}
                
                # ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ì— í•´ë‹¹í•˜ëŠ” ê°€ê²©ë“¤ë§Œ ì¡°íšŒ
                df = pd.read_sql("""
                    SELECT symbol, close 
                    FROM candles 
                    WHERE timestamp = ?
                """, conn, params=(max_ts,))
                
                for _, row in df.iterrows():
                    prices[row['symbol']] = float(row['close'])
        except:
            pass
        return prices

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• [ì „ëµ ë¶„ë¦¬ í•™ìŠµ] ì§„ì…/ì²­ì‚°/ì „í™˜ ì„±ê³µë¥  ê°ê° í•™ìŠµ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _learn_strategy_separated(self, trades_df: pd.DataFrame) -> int:
        """
        ì „ëµë³„ ë¶„ë¦¬ í•™ìŠµ:
        1. ì§„ì… ì „ëµ ì •í™•ë„ (entry_strategy)
        2. ì²­ì‚° ì „ëµ ì •í™•ë„ (exit_strategy)
        3. ì „ëµ ì „í™˜ ì„±ê³µë¥  (scalp_to_swing ë“±)
        4. ğŸ†• ì „ëµ+ë ˆì§ ì¡°í•©ë³„ í•™ìŠµ
        ğŸš€ [ì„±ëŠ¥] iterrows â†’ to_dict('records') ìµœì í™”
        """
        if trades_df.empty:
            return 0
        
        learned_count = 0
        regime_stats = defaultdict(lambda: {'success': 0, 'total': 0, 'profit_sum': 0.0})
        
        try:
            from trade.core.strategies import update_strategy_feedback, create_strategy_feedback_table
            from trade.core.database import STRATEGY_DB_PATH
            
            # ğŸ”§ í…Œì´ë¸”ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¨¼ì € ìƒì„± (IF NOT EXISTS)
            try:
                create_strategy_feedback_table(STRATEGY_DB_PATH)
            except Exception:
                pass  # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ
            
            # ğŸš€ [ì„±ëŠ¥] iterrows ëŒ€ì‹  to_dict('records') ì‚¬ìš©
            for trade in trades_df.to_dict('records'):
                entry_strategy = trade.get('entry_strategy', 'trend')
                exit_strategy = trade.get('exit_strategy', entry_strategy)
                switch_count = trade.get('strategy_switch_count', 0) or 0
                switch_success = trade.get('switch_success', -1)
                profit_pct = trade.get('profit_loss_pct', 0.0) or 0.0
                pattern = trade.get('signal_pattern', 'unknown')
                
                # ì„±ê³µ ì—¬ë¶€
                success = profit_pct > 0
                
                # ë³´ìœ  ì‹œê°„ ê³„ì‚°
                entry_ts = trade.get('entry_timestamp', 0) or 0
                exit_ts = trade.get('exit_timestamp', 0) or 0
                holding_hours = (exit_ts - entry_ts) / 3600.0 if exit_ts > entry_ts else 0
                
                # ğŸ†• ì‹œì¥ ë ˆì§ ì¶”ì¶œ (market_conditionsì—ì„œ)
                market_regime = 'neutral'
                market_cond_str = trade.get('market_conditions', '')
                if market_cond_str:
                    try:
                        market_cond = json.loads(market_cond_str) if isinstance(market_cond_str, str) else market_cond_str
                        market_regime = market_cond.get('regime', 'neutral')
                    except:
                        pass
                
                # 1ï¸âƒ£ ì§„ì… ì „ëµ í•™ìŠµ
                if entry_strategy and entry_strategy != 'None':
                    update_strategy_feedback(
                        db_path=STRATEGY_DB_PATH,
                        strategy_type=entry_strategy,
                        market_condition=market_regime,  # ğŸ†• ë ˆì§ ì „ë‹¬
                        signal_pattern=pattern,
                        success=success,
                        profit_pct=profit_pct,
                        holding_hours=holding_hours,
                        feedback_type='entry'
                    )
                    learned_count += 1
                    
                    # ğŸ†• ì „ëµ+ë ˆì§ ì¡°í•© í†µê³„ ìˆ˜ì§‘
                    strategy_regime_key = f"{entry_strategy}_{market_regime}"
                    regime_stats[strategy_regime_key]['total'] += 1
                    if success:
                        regime_stats[strategy_regime_key]['success'] += 1
                    regime_stats[strategy_regime_key]['profit_sum'] += profit_pct
                    
                    # ğŸ†• ì „ëµ+ë ˆì§ ì¡°í•© í”¼ë“œë°±ë„ ì €ì¥
                    update_strategy_feedback(
                        db_path=STRATEGY_DB_PATH,
                        strategy_type=strategy_regime_key,
                        market_condition=market_regime,
                        signal_pattern=pattern,
                        success=success,
                        profit_pct=profit_pct,
                        holding_hours=holding_hours,
                        feedback_type='entry_regime'
                    )
                
                # 2ï¸âƒ£ ì²­ì‚° ì „ëµ í•™ìŠµ (ì „í™˜ëœ ê²½ìš°ë§Œ)
                if switch_count > 0 and exit_strategy != entry_strategy:
                    update_strategy_feedback(
                        db_path=STRATEGY_DB_PATH,
                        strategy_type=exit_strategy,
                        market_condition=market_regime,  # ğŸ†• ë ˆì§ ì „ë‹¬
                        signal_pattern=pattern,
                        success=success,
                        profit_pct=profit_pct,
                        holding_hours=holding_hours,
                        feedback_type='exit'
                    )
                    learned_count += 1
                    
                    # 3ï¸âƒ£ ì „ëµ ì „í™˜ ì„±ê³µë¥  í•™ìŠµ (ë ˆì§ë³„)
                    switch_key = f"{entry_strategy}_to_{exit_strategy}"
                    switch_regime_key = f"{switch_key}_{market_regime}"  # ğŸ†• ë ˆì§ë³„ ì „í™˜ í•™ìŠµ
                    
                    update_strategy_feedback(
                        db_path=STRATEGY_DB_PATH,
                        strategy_type=switch_key,
                        market_condition=market_regime,
                        signal_pattern=pattern,
                        success=(switch_success == 1) if switch_success >= 0 else success,
                        profit_pct=profit_pct,
                        holding_hours=holding_hours,
                        feedback_type='switch'
                    )
                    
                    # ğŸ†• ë ˆì§ë³„ ì „í™˜ í•™ìŠµ
                    update_strategy_feedback(
                        db_path=STRATEGY_DB_PATH,
                        strategy_type=switch_regime_key,
                        market_condition=market_regime,
                        signal_pattern=pattern,
                        success=(switch_success == 1) if switch_success >= 0 else success,
                        profit_pct=profit_pct,
                        holding_hours=holding_hours,
                        feedback_type='switch_regime'
                    )
                    learned_count += 1
            
            if learned_count > 0:
                print(f"   ğŸ“š [ì „ëµ ë¶„ë¦¬ í•™ìŠµ] {learned_count}ê±´ í•™ìŠµ ì™„ë£Œ (ì§„ì…/ì²­ì‚°/ì „í™˜ + ë ˆì§ë³„)")
                
                # ğŸ†• ë ˆì§ë³„ ì„±ê³¼ ìš”ì•½ ì¶œë ¥
                if regime_stats:
                    print("   ğŸ“Š [ì „ëµ+ë ˆì§ ì¡°í•© ì„±ê³¼]")
                    sorted_stats = sorted(regime_stats.items(), 
                                         key=lambda x: x[1]['total'], reverse=True)[:5]
                    for key, stats in sorted_stats:
                        if stats['total'] >= 3:  # ìµœì†Œ 3ê±´ ì´ìƒë§Œ ì¶œë ¥
                            success_rate = stats['success'] / stats['total'] * 100
                            avg_profit = stats['profit_sum'] / stats['total']
                            print(f"      - {key}: ì„±ê³µë¥  {success_rate:.0f}% ({stats['success']}/{stats['total']}), í‰ê· ìˆ˜ìµ {avg_profit:+.2f}%")
                
                # ğŸ§¬ [ì§„í™” ì‹œìŠ¤í…œ] ì§„í™” í†µê³„ ì—…ë°ì´íŠ¸
                if EVOLUTION_SYSTEM_AVAILABLE and regime_stats:
                    try:
                        evolution_updated = 0
                        for key, stats in regime_stats.items():
                            if stats['total'] < 2:
                                continue
                            
                            # key = "strategy_regime" í˜•íƒœ
                            parts = key.rsplit('_', 1)
                            if len(parts) == 2:
                                strategy, regime = parts[0], parts[1]
                            else:
                                strategy, regime = key, 'neutral'
                            
                            # ì§„í™” í†µê³„ì— ê° ê±°ë˜ ê²°ê³¼ ë°˜ì˜
                            for _ in range(stats['total']):
                                success = stats['success'] > stats['total'] // 2
                                avg_profit = stats['profit_sum'] / stats['total']
                                
                                update_evolution_stats(
                                    strategy=strategy,
                                    regime=regime,
                                    success=success,
                                    profit_pct=avg_profit,
                                    is_switch=('_to_' in strategy),
                                    switch_from=strategy.split('_to_')[0] if '_to_' in strategy else None
                                )
                                evolution_updated += 1
                                break  # ë°°ì¹˜ ë‹¨ìœ„ë¡œ 1íšŒë§Œ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ ë°©ì§€)
                        
                        if evolution_updated > 0:
                            print(f"   ğŸ§¬ [ì§„í™” ì‹œìŠ¤í…œ] {evolution_updated}ê°œ ì „ëµÃ—ë ˆì§ ì¡°í•© ì§„í™” í†µê³„ ì—…ë°ì´íŠ¸")
                    except Exception as evo_err:
                        print(f"âš ï¸ ì§„í™” í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {evo_err}")
                
        except ImportError:
            pass  # ì „ëµ ëª¨ë“ˆ ì—†ìœ¼ë©´ ë¬´ì‹œ
        except Exception as e:
            print(f"âš ï¸ ì „ëµ ë¶„ë¦¬ í•™ìŠµ ì˜¤ë¥˜: {e}")
        
        return learned_count

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• [1] ì§„ì… íƒ€ì´ë° ìµœì í™” í•™ìŠµ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _learn_entry_timing_optimization(self) -> Dict[str, Any]:
        """ë§¤ìˆ˜ í›„ Në¶„ ë™ì•ˆ ë” ë‚®ì€ ê°€ê²©ì´ ìˆì—ˆëŠ”ì§€ ë¶„ì„í•˜ì—¬ ìµœì  ì§„ì… ì§€ì—° ì‹œê°„ í•™ìŠµ"""
        results = {'analyzed': 0, 'could_be_better': 0, 'avg_missed_pct': 0.0, 'optimal_delay_minutes': 0}
        
        try:
            from trade.core.database import CANDLES_DB_PATH
            
            # ìµœê·¼ ê±°ë˜ ë‚´ì—­ ë¡œë“œ
            with get_db_connection(self.db_path, read_only=True) as conn:
                trades_df = pd.read_sql("""
                    SELECT coin, entry_price, entry_timestamp, signal_pattern, profit_loss_pct
                    FROM virtual_trade_feedback 
                    WHERE entry_timestamp > 0 AND entry_price > 0
                    ORDER BY entry_timestamp DESC
                    LIMIT 200
                """, conn)
            
            if trades_df.empty:
                return results
            
            delay_stats = defaultdict(lambda: {'better_count': 0, 'total': 0, 'saved_pct_sum': 0.0})
            missed_pcts = []
            
            # ğŸš€ [ì„±ëŠ¥] ì¼ê´„ ìº”ë“¤ ë¡œë“œ + ë©”ëª¨ë¦¬ í•„í„°ë§ (ê°œë³„ ì¿¼ë¦¬ NíšŒ â†’ 1íšŒ)
            with get_db_connection(CANDLES_DB_PATH, read_only=True) as c_conn:
                # 1. í•„ìš”í•œ ì½”ì¸ ëª©ë¡ê³¼ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
                unique_coins = trades_df['coin'].unique().tolist()
                min_ts = int(trades_df['entry_timestamp'].min())
                max_ts = int(trades_df['entry_timestamp'].max()) + (120 * 60)  # 2ì‹œê°„ ìœˆë„ìš°
                
                # 2. ëª¨ë“  ê´€ë ¨ ìº”ë“¤ì„ í•œ ë²ˆì— ë¡œë“œ
                placeholders = ','.join('?' * len(unique_coins))
                all_candles = pd.read_sql(f"""
                    SELECT symbol, timestamp, low, close
                    FROM candles 
                    WHERE symbol IN ({placeholders}) AND interval = '15m'
                    AND timestamp >= ? AND timestamp <= ?
                    ORDER BY symbol, timestamp ASC
                """, c_conn, params=unique_coins + [min_ts, max_ts])
                
                # 3. ì½”ì¸ë³„ë¡œ ì¸ë±ì‹± (ë¹ ë¥¸ ì¡°íšŒìš©)
                candle_cache = {coin: group.set_index('timestamp') 
                               for coin, group in all_candles.groupby('symbol', sort=False)}
                
                # 4. ê° ê±°ë˜ ë¶„ì„ (ğŸš€ iterrows â†’ to_dict)
                for trade in trades_df.to_dict('records'):
                    coin = trade['coin']
                    entry_ts = int(trade['entry_timestamp'])
                    entry_price = float(trade['entry_price'])
                    
                    if coin not in candle_cache:
                        continue
                    
                    # ë©”ëª¨ë¦¬ì—ì„œ í•„í„°ë§ (DB ì¿¼ë¦¬ ëŒ€ì‹ )
                    coin_candles = candle_cache[coin]
                    window_end = entry_ts + (120 * 60)
                    candles = coin_candles[(coin_candles.index >= entry_ts) & (coin_candles.index <= window_end)]
                    
                    if candles.empty:
                        continue
                    
                    results['analyzed'] += 1
                    
                    # ê° ì‹œê°„ëŒ€ë³„ë¡œ ë” ë‚®ì€ ê°€ê²©ì´ ìˆì—ˆëŠ”ì§€ í™•ì¸
                    for delay_min in [15, 30, 45, 60, 90, 120]:
                        delay_ts = entry_ts + (delay_min * 60)
                        window = candles[candles.index <= delay_ts]
                        
                        if not window.empty:
                            min_low = window['low'].min()
                            if min_low < entry_price:
                                saved_pct = ((entry_price - min_low) / entry_price) * 100
                                delay_stats[delay_min]['better_count'] += 1
                                delay_stats[delay_min]['saved_pct_sum'] += saved_pct
                            delay_stats[delay_min]['total'] += 1
                    
                    # ì „ì²´ ìœˆë„ìš°ì—ì„œ ìµœì €ê°€ í™•ì¸
                    overall_min = candles['low'].min()
                    if overall_min < entry_price:
                        missed_pct = ((entry_price - overall_min) / entry_price) * 100
                        missed_pcts.append(missed_pct)
                        results['could_be_better'] += 1
            
            # ìµœì  ì§€ì—° ì‹œê°„ ê³„ì‚°
            if delay_stats:
                best_delay = 0
                best_score = 0
                
                for delay_min, stats in delay_stats.items():
                    if stats['total'] > 0:
                        hit_rate = stats['better_count'] / stats['total']
                        avg_saved = stats['saved_pct_sum'] / max(1, stats['better_count'])
                        # ì ìˆ˜ = ì ì¤‘ë¥  * í‰ê·  ì ˆê°ë¥  (ì§€ì—° ì‹œê°„ì— ëŒ€í•œ í˜ë„í‹° ì ìš©)
                        score = hit_rate * avg_saved * (1 - delay_min / 300)
                        
                        if score > best_score:
                            best_score = score
                            best_delay = delay_min
                
                results['optimal_delay_minutes'] = best_delay
            
            if missed_pcts:
                results['avg_missed_pct'] = sum(missed_pcts) / len(missed_pcts)
            
            # Thompson Samplingì— í•™ìŠµ ê²°ê³¼ ë°˜ì˜
            if results['analyzed'] > 10:
                improvement_rate = results['could_be_better'] / results['analyzed']
                self.thompson_sampler.update_distribution(
                    pattern="entry_timing_optimization",
                    success=improvement_rate < 0.3,  # 30% ë¯¸ë§Œì´ë©´ íƒ€ì´ë°ì´ ì¢‹ì•˜ë‹¤
                    profit_pct=results['avg_missed_pct'],
                    weight=1.0
                )
            
            return results
            
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì§„ì… íƒ€ì´ë° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• [2] ë³´ìœ  ê¸°ê°„ ìµœì í™” í•™ìŠµ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _learn_optimal_holding_period(self) -> Dict[str, Any]:
        """íŒ¨í„´ë³„ ìµœì  ë³´ìœ  ê¸°ê°„ ë¶„ì„ ë° í•™ìŠµ"""
        results = {'patterns_analyzed': 0, 'recommendations': {}}
        
        try:
            from trade.core.database import CANDLES_DB_PATH
            
            with get_db_connection(self.db_path, read_only=True) as conn:
                # ğŸ”§ max_profit_pctëŠ” í…Œì´ë¸”ì— ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œì™¸ (ìº”ë“¤ì—ì„œ ì§ì ‘ ê³„ì‚°)
                trades_df = pd.read_sql("""
                    SELECT coin, entry_price, exit_price, entry_timestamp, exit_timestamp,
                           profit_loss_pct, signal_pattern
                    FROM virtual_trade_feedback 
                    WHERE entry_timestamp > 0 AND exit_timestamp > 0
                    ORDER BY exit_timestamp DESC
                    LIMIT 300
                """, conn)
            
            if trades_df.empty:
                return results
            
            # íŒ¨í„´ë³„ ë³´ìœ  ê¸°ê°„ê³¼ ìˆ˜ìµë¥  ë¶„ì„
            pattern_stats = defaultdict(lambda: {
                'holding_periods': [],
                'profits': [],
                'max_profits': [],
                'optimal_periods': []
            })
            
            # ğŸš€ [ì„±ëŠ¥] ì¼ê´„ ìº”ë“¤ ë¡œë“œ + ë©”ëª¨ë¦¬ í•„í„°ë§ (ê°œë³„ ì¿¼ë¦¬ NíšŒ â†’ 1íšŒ)
            with get_db_connection(CANDLES_DB_PATH, read_only=True) as c_conn:
                # 1. í•„ìš”í•œ ë°ì´í„° ë²”ìœ„ ê³„ì‚°
                unique_coins = trades_df['coin'].unique().tolist()
                min_ts = int(trades_df['entry_timestamp'].min())
                max_ts = int(trades_df['exit_timestamp'].max()) + 7200  # ë§¤ë„ í›„ 2ì‹œê°„ ì¶”ì 
                
                # 2. ëª¨ë“  ê´€ë ¨ ìº”ë“¤ ì¼ê´„ ë¡œë“œ
                placeholders = ','.join('?' * len(unique_coins))
                all_candles = pd.read_sql(f"""
                    SELECT symbol, timestamp, high, low, close
                    FROM candles 
                    WHERE symbol IN ({placeholders}) AND interval = '15m'
                    AND timestamp >= ? AND timestamp <= ?
                    ORDER BY symbol, timestamp ASC
                """, c_conn, params=unique_coins + [min_ts, max_ts])
                
                # 3. ì½”ì¸ë³„ ì¸ë±ì‹±
                candle_cache = {coin: group.set_index('timestamp')
                               for coin, group in all_candles.groupby('symbol', sort=False)}
                
                # 4. ê±°ë˜ ë¶„ì„ (ğŸš€ iterrows â†’ to_dict)
                for trade in trades_df.to_dict('records'):
                    pattern = trade.get('signal_pattern', 'unknown')
                    if not pattern or pattern == 'unknown':
                        continue
                    
                    coin = trade['coin']
                    entry_ts = int(trade['entry_timestamp'])
                    exit_ts = int(trade['exit_timestamp'])
                    entry_price = float(trade['entry_price'])
                    actual_profit = float(trade.get('profit_loss_pct', 0) or 0)
                    
                    if coin not in candle_cache:
                        continue
                    
                    # ì‹¤ì œ ë³´ìœ  ê¸°ê°„ (ì‹œê°„)
                    actual_holding_hours = (exit_ts - entry_ts) / 3600
                    
                    # ë©”ëª¨ë¦¬ì—ì„œ ìº”ë“¤ í•„í„°ë§
                    coin_candles = candle_cache[coin]
                    candles = coin_candles[(coin_candles.index >= entry_ts) & (coin_candles.index <= exit_ts + 7200)]
                    
                    if candles.empty or len(candles) < 2:
                        continue
                    
                    # ğŸš€ [ì„±ëŠ¥] ë²¡í„° ì—°ì‚°ìœ¼ë¡œ ìµœì  ë§¤ë„ ì‹œì  ì°¾ê¸° (iterrows ì œê±°)
                    profits_series = ((candles['high'] - entry_price) / entry_price) * 100
                    max_profit_idx = profits_series.idxmax()
                    max_profit_pct = profits_series.max()
                    max_profit_time = max_profit_idx  # ì¸ë±ìŠ¤ê°€ timestamp
                    
                    optimal_holding_hours = (max_profit_time - entry_ts) / 3600
                    
                    # ê¸°ë³¸ íŒ¨í„´ (ì²« ë‹¨ì–´ë§Œ ì‚¬ìš©)
                    base_pattern = pattern.split('_')[0] if '_' in pattern else pattern
                    
                    pattern_stats[base_pattern]['holding_periods'].append(actual_holding_hours)
                    pattern_stats[base_pattern]['profits'].append(actual_profit)
                    pattern_stats[base_pattern]['max_profits'].append(max_profit_pct)
                    pattern_stats[base_pattern]['optimal_periods'].append(optimal_holding_hours)
            
            # íŒ¨í„´ë³„ ìµœì  ë³´ìœ  ê¸°ê°„ ê³„ì‚°
            recommendations = {}
            for pattern, stats in pattern_stats.items():
                if len(stats['holding_periods']) < 5:
                    continue
                
                results['patterns_analyzed'] += 1
                
                avg_actual = sum(stats['holding_periods']) / len(stats['holding_periods'])
                avg_optimal = sum(stats['optimal_periods']) / len(stats['optimal_periods'])
                avg_profit = sum(stats['profits']) / len(stats['profits'])
                avg_max_profit = sum(stats['max_profits']) / len(stats['max_profits'])
                
                # ìµœì  ë³´ìœ  ê¸°ê°„ ëŒ€ë¹„ ì‹¤ì œ ë³´ìœ  ê¸°ê°„ ì°¨ì´
                timing_gap = avg_actual - avg_optimal
                missed_profit = avg_max_profit - avg_profit
                
                recommendations[pattern] = {
                    'avg_holding_hours': round(avg_actual, 1),
                    'optimal_holding_hours': round(avg_optimal, 1),
                    'timing_gap_hours': round(timing_gap, 1),
                    'avg_profit_pct': round(avg_profit, 2),
                    'potential_profit_pct': round(avg_max_profit, 2),
                    'missed_profit_pct': round(missed_profit, 2),
                    'sample_count': len(stats['holding_periods'])
                }
                
                # Thompson Samplingì— í•™ìŠµ
                # ë„ˆë¬´ ì˜¤ë˜ ë“¤ê³  ìˆì—ˆìœ¼ë©´ (timing_gap > 2ì‹œê°„) íŒ¨í„´ ìˆ˜ì •
                if timing_gap > 2:
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_holding_too_long",
                        success=False,
                        profit_pct=-missed_profit,
                        weight=1.2
                    )
                elif timing_gap < -1:  # ë„ˆë¬´ ì¼ì° íŒ”ì•˜ìœ¼ë©´
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_holding_too_short",
                        success=False,
                        profit_pct=-missed_profit,
                        weight=1.2
                    )
                else:  # ì ì ˆí•œ íƒ€ì´ë°
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_holding_optimal",
                        success=True,
                        profit_pct=avg_profit,
                        weight=1.0
                    )
            
            results['recommendations'] = recommendations
            return results
            
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ë³´ìœ  ê¸°ê°„ ìµœì í™” ë¶„ì„ ì˜¤ë¥˜: {e}")
            return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• [3] ì†ì ˆ/ìµì ˆ ì„ê³„ê°’ ë™ì  í•™ìŠµ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _learn_dynamic_stop_take_profit(self) -> Dict[str, Any]:
        """íŒ¨í„´ë³„ ìµœì  ì†ì ˆ/ìµì ˆ ë¼ì¸ í•™ìŠµ"""
        results = {'patterns_analyzed': 0, 'stop_loss_adjustments': {}, 'take_profit_adjustments': {}}
        
        try:
            from trade.core.database import CANDLES_DB_PATH
            
            with get_db_connection(self.db_path, read_only=True) as conn:
                trades_df = pd.read_sql("""
                    SELECT coin, entry_price, exit_price, entry_timestamp, exit_timestamp,
                           profit_loss_pct, signal_pattern
                    FROM virtual_trade_feedback 
                    WHERE entry_timestamp > 0 AND exit_timestamp > 0
                    ORDER BY exit_timestamp DESC
                    LIMIT 300
                """, conn)
            
            if trades_df.empty:
                return results
            
            # íŒ¨í„´ë³„ MFE(ìµœëŒ€ ìœ ë¦¬ ë³€ë™)/MAE(ìµœëŒ€ ë¶ˆë¦¬ ë³€ë™) ìˆ˜ì§‘
            pattern_extremes = defaultdict(lambda: {
                'mfe_list': [],  # Maximum Favorable Excursion
                'mae_list': [],  # Maximum Adverse Excursion
                'final_profits': [],
                'stopped_out': 0,  # ì†ì ˆë¡œ ëë‚œ íšŸìˆ˜
                'took_profit': 0   # ìµì ˆë¡œ ëë‚œ íšŸìˆ˜
            })
            
            # ğŸš€ [ì„±ëŠ¥] ì¼ê´„ ìº”ë“¤ ë¡œë“œ (ê°œë³„ ì¿¼ë¦¬ NíšŒ â†’ 1íšŒ)
            with get_db_connection(CANDLES_DB_PATH, read_only=True) as c_conn:
                # 1. í•„ìš”í•œ ë°ì´í„° ë²”ìœ„ ê³„ì‚°
                unique_coins = trades_df['coin'].unique().tolist()
                min_ts = int(trades_df['entry_timestamp'].min())
                max_ts = int(trades_df['exit_timestamp'].max())
                
                # 2. ì¼ê´„ ë¡œë“œ
                placeholders = ','.join('?' * len(unique_coins))
                all_candles = pd.read_sql(f"""
                    SELECT symbol, timestamp, high, low
                    FROM candles 
                    WHERE symbol IN ({placeholders}) AND interval = '15m'
                    AND timestamp >= ? AND timestamp <= ?
                """, c_conn, params=unique_coins + [min_ts, max_ts])
                
                # 3. ì½”ì¸ë³„ ì¸ë±ì‹±
                candle_cache = {coin: group.set_index('timestamp')
                               for coin, group in all_candles.groupby('symbol', sort=False)}
                
                # 4. ê±°ë˜ ë¶„ì„ (ğŸš€ iterrows â†’ to_dict)
                for trade in trades_df.to_dict('records'):
                    pattern = trade.get('signal_pattern', 'unknown')
                    if not pattern or pattern == 'unknown':
                        continue
                    
                    coin = trade['coin']
                    entry_ts = int(trade['entry_timestamp'])
                    exit_ts = int(trade['exit_timestamp'])
                    entry_price = float(trade['entry_price'])
                    final_profit = float(trade.get('profit_loss_pct', 0) or 0)
                    
                    if coin not in candle_cache:
                        continue
                    
                    # ë©”ëª¨ë¦¬ì—ì„œ í•„í„°ë§
                    coin_candles = candle_cache[coin]
                    candles = coin_candles[(coin_candles.index >= entry_ts) & (coin_candles.index <= exit_ts)]
                    
                    if candles.empty:
                        continue
                    
                    # MFE/MAE ê³„ì‚° (ë²¡í„° ì—°ì‚°)
                    max_high = candles['high'].max()
                    min_low = candles['low'].min()
                    
                    mfe = ((max_high - entry_price) / entry_price) * 100  # ìµœëŒ€ ìˆ˜ìµ
                    mae = ((entry_price - min_low) / entry_price) * 100   # ìµœëŒ€ ì†ì‹¤ (ì–‘ìˆ˜ë¡œ í‘œí˜„)
                    
                    base_pattern = pattern.split('_')[0] if '_' in pattern else pattern
                    
                    pattern_extremes[base_pattern]['mfe_list'].append(mfe)
                    pattern_extremes[base_pattern]['mae_list'].append(mae)
                    pattern_extremes[base_pattern]['final_profits'].append(final_profit)
                    
                    if final_profit < -2:  # 2% ì´ìƒ ì†ì‹¤
                        pattern_extremes[base_pattern]['stopped_out'] += 1
                    elif final_profit > 3:  # 3% ì´ìƒ ì´ìµ
                        pattern_extremes[base_pattern]['took_profit'] += 1
            
            # íŒ¨í„´ë³„ ìµœì  ì†ì ˆ/ìµì ˆ ë¼ì¸ ê³„ì‚°
            stop_loss_adj = {}
            take_profit_adj = {}
            
            for pattern, extremes in pattern_extremes.items():
                if len(extremes['mfe_list']) < 5:
                    continue
                
                results['patterns_analyzed'] += 1
                
                # í†µê³„ ê³„ì‚°
                avg_mfe = sum(extremes['mfe_list']) / len(extremes['mfe_list'])
                avg_mae = sum(extremes['mae_list']) / len(extremes['mae_list'])
                avg_profit = sum(extremes['final_profits']) / len(extremes['final_profits'])
                
                # 75ë°±ë¶„ìœ„ìˆ˜ MAE = ëŒ€ë¶€ë¶„ì˜ ê±°ë˜ê°€ ì´ ë²”ìœ„ ë‚´ì—ì„œ ì†ì‹¤
                sorted_mae = sorted(extremes['mae_list'])
                mae_75pct = sorted_mae[int(len(sorted_mae) * 0.75)]
                
                # 50ë°±ë¶„ìœ„ìˆ˜ MFE = ì ˆë°˜ì˜ ê±°ë˜ê°€ ì´ ìˆ˜ìµì— ë„ë‹¬
                sorted_mfe = sorted(extremes['mfe_list'])
                mfe_50pct = sorted_mfe[int(len(sorted_mfe) * 0.5)]
                
                # ìµœì  ì†ì ˆì„ : 75ë°±ë¶„ìœ„ MAE + ì•½ê°„ì˜ ì—¬ìœ  (ë„ˆë¬´ íƒ€ì´íŠ¸í•˜ë©´ ì†ì ˆì´ ì¦ìŒ)
                optimal_stop_loss = -(mae_75pct + 0.5)
                
                # ìµœì  ìµì ˆì„ : 50ë°±ë¶„ìœ„ MFE (ì ˆë°˜ ì´ìƒì´ ë„ë‹¬í•˜ëŠ” ìˆ˜ìµ)
                optimal_take_profit = mfe_50pct * 0.9  # 90%ë§Œ ëª©í‘œ (í™•ì‹¤í•œ ìµì ˆ)
                
                stop_loss_adj[pattern] = {
                    'current_default': -3.0,  # í˜„ì¬ ê¸°ë³¸ ì†ì ˆì„ 
                    'optimal': round(optimal_stop_loss, 2),
                    'avg_mae': round(avg_mae, 2),
                    'mae_75pct': round(mae_75pct, 2),
                    'stop_out_rate': extremes['stopped_out'] / len(extremes['mfe_list'])
                }
                
                take_profit_adj[pattern] = {
                    'current_default': 5.0,  # í˜„ì¬ ê¸°ë³¸ ìµì ˆì„ 
                    'optimal': round(optimal_take_profit, 2),
                    'avg_mfe': round(avg_mfe, 2),
                    'mfe_50pct': round(mfe_50pct, 2),
                    'take_profit_rate': extremes['took_profit'] / len(extremes['mfe_list'])
                }
                
                # Thompson Samplingì— í•™ìŠµ
                # ì†ì ˆì´ ë„ˆë¬´ ì¦ì€ íŒ¨í„´
                if extremes['stopped_out'] / len(extremes['mfe_list']) > 0.4:
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_stop_loss_too_tight",
                        success=False,
                        profit_pct=avg_profit,
                        weight=1.3
                    )
                
                # ìµì ˆì„ ì˜ ëª»í•˜ëŠ” íŒ¨í„´ (MFE ëŒ€ë¹„ ì‹¤í˜„ ìˆ˜ìµì´ ë‚®ìŒ)
                if avg_mfe > 0 and avg_profit < avg_mfe * 0.3:
                    self.thompson_sampler.update_distribution(
                        pattern=f"{pattern}_take_profit_missed",
                        success=False,
                        profit_pct=avg_profit - avg_mfe,
                        weight=1.3
                    )
            
            results['stop_loss_adjustments'] = stop_loss_adj
            results['take_profit_adjustments'] = take_profit_adj
            
            # ê¸€ë¡œë²Œ DBì— ìµœì  ì„ê³„ê°’ ì €ì¥
            global_db = os.environ.get('GLOBAL_STRATEGY_DB_PATH')
            if global_db and (stop_loss_adj or take_profit_adj):
                try:
                    with sqlite3.connect(global_db) as conn:
                        conn.execute("""
                            CREATE TABLE IF NOT EXISTS optimal_thresholds (
                                pattern TEXT PRIMARY KEY,
                                optimal_stop_loss REAL,
                                optimal_take_profit REAL,
                                avg_mae REAL,
                                avg_mfe REAL,
                                sample_count INTEGER,
                                last_updated INTEGER
                            )
                        """)
                        
                        for pattern in stop_loss_adj:
                            conn.execute("""
                                INSERT OR REPLACE INTO optimal_thresholds 
                                (pattern, optimal_stop_loss, optimal_take_profit, avg_mae, avg_mfe, sample_count, last_updated)
                                VALUES (?, ?, ?, ?, ?, ?, ?)
                            """, (
                                pattern,
                                stop_loss_adj[pattern]['optimal'],
                                take_profit_adj.get(pattern, {}).get('optimal', 5.0),
                                stop_loss_adj[pattern]['avg_mae'],
                                take_profit_adj.get(pattern, {}).get('avg_mfe', 0),
                                len(pattern_extremes[pattern]['mfe_list']),
                                int(time.time())
                            ))
                        conn.commit()
                except Exception as db_err:
                    print(f"âš ï¸ ìµœì  ì„ê³„ê°’ ì €ì¥ ì˜¤ë¥˜: {db_err}")
            
            return results
            
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì†ì ˆ/ìµì ˆ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• [4] ì—°ì† ì†ì‹¤ íŒ¨í„´ ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _learn_consecutive_loss_patterns(self) -> Dict[str, Any]:
        """ì—°ì† ì†ì‹¤ ì‹œ ê³µí†µì  ë¶„ì„ ë° íšŒí”¼ í•™ìŠµ"""
        results = {
            'total_streaks': 0,
            'max_streak': 0,
            'common_factors': {},
            'recommendations': []
        }
        
        try:
            with get_db_connection(self.db_path, read_only=True) as conn:
                # ğŸ†• ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ ë¶„ì„ (ì˜¤ë˜ëœ ë¶ˆì™„ì „í•œ ë°ì´í„° ì œì™¸)
                recent_cutoff = int(time.time()) - (7 * 24 * 3600)
                trades_df = pd.read_sql("""
                    SELECT coin, entry_timestamp, exit_timestamp, profit_loss_pct, 
                           signal_pattern, market_conditions
                    FROM virtual_trade_feedback 
                    WHERE exit_timestamp > ? AND market_conditions IS NOT NULL AND market_conditions != ''
                    ORDER BY exit_timestamp ASC
                    LIMIT 500
                """, conn, params=(recent_cutoff,))
            
            if trades_df.empty or len(trades_df) < 10:
                return results
            
            # ì—°ì† ì†ì‹¤ ìŠ¤íŠ¸ë¦­ ì°¾ê¸°
            streaks = []
            current_streak = []
            
            for _, trade in trades_df.iterrows():
                profit = float(trade.get('profit_loss_pct', 0) or 0)
                
                if profit < 0:  # ì†ì‹¤
                    current_streak.append(trade)
                else:
                    if len(current_streak) >= 3:  # 3ì—°íŒ¨ ì´ìƒë§Œ ë¶„ì„
                        streaks.append(current_streak.copy())
                    current_streak = []
            
            # ë§ˆì§€ë§‰ ìŠ¤íŠ¸ë¦­ ì²˜ë¦¬
            if len(current_streak) >= 3:
                streaks.append(current_streak)
            
            if not streaks:
                return results
            
            results['total_streaks'] = len(streaks)
            results['max_streak'] = max(len(s) for s in streaks)
            
            # ì—°ì† ì†ì‹¤ ì‹œ ê³µí†µ ìš”ì¸ ë¶„ì„
            common_factors = {
                'patterns': defaultdict(int),
                'coins': defaultdict(int),
                'market_regimes': defaultdict(int),
                'time_of_day': defaultdict(int),
                'total_loss_pct': 0,
                'avg_loss_per_trade': 0
            }
            
            total_trades_in_streaks = 0
            
            for streak in streaks:
                for trade in streak:
                    total_trades_in_streaks += 1
                    
                    # íŒ¨í„´ ì§‘ê³„
                    pattern = trade.get('signal_pattern', 'unknown')
                    base_pattern = pattern.split('_')[0] if pattern and '_' in pattern else (pattern or 'unknown')
                    common_factors['patterns'][base_pattern] += 1
                    
                    # ì½”ì¸ ì§‘ê³„
                    common_factors['coins'][trade['coin']] += 1
                    
                    # ì‹œì¥ ìƒí™© ì§‘ê³„
                    market_cond = {}
                    if trade.get('market_conditions'):
                        try:
                            market_cond = json.loads(trade['market_conditions'])
                        except:
                            pass
                    regime = market_cond.get('regime', 'unknown')
                    common_factors['market_regimes'][regime] += 1
                    
                    # ì‹œê°„ëŒ€ ì§‘ê³„
                    entry_ts = int(trade.get('entry_timestamp', 0))
                    if entry_ts > 0:
                        hour = datetime.fromtimestamp(entry_ts).hour
                        time_slot = f"{(hour // 4) * 4:02d}-{(hour // 4) * 4 + 4:02d}ì‹œ"
                        common_factors['time_of_day'][time_slot] += 1
                    
                    # ì†ì‹¤ í•©ê³„
                    common_factors['total_loss_pct'] += float(trade.get('profit_loss_pct', 0) or 0)
            
            if total_trades_in_streaks > 0:
                common_factors['avg_loss_per_trade'] = common_factors['total_loss_pct'] / total_trades_in_streaks
            
            # ê°€ì¥ ë¹ˆë²ˆí•œ ìš”ì¸ ì°¾ê¸°
            recommendations = []
            
            # ìœ„í—˜í•œ íŒ¨í„´
            if common_factors['patterns']:
                worst_pattern = max(common_factors['patterns'].items(), key=lambda x: x[1])
                if worst_pattern[1] >= 3:
                    recommendations.append(f"âš ï¸ '{worst_pattern[0]}' íŒ¨í„´ì—ì„œ {worst_pattern[1]}íšŒ ì—°ì† ì†ì‹¤ ë°œìƒ - ì£¼ì˜ í•„ìš”")
                    self.thompson_sampler.update_distribution(
                        pattern=f"{worst_pattern[0]}_consecutive_loss",
                        success=False,
                        profit_pct=common_factors['avg_loss_per_trade'],
                        weight=2.0  # ë†’ì€ ê°€ì¤‘ì¹˜
                    )
            
            # ìœ„í—˜í•œ ì‹œì¥ ìƒí™©
            if common_factors['market_regimes']:
                worst_regime = max(common_factors['market_regimes'].items(), key=lambda x: x[1])
                if worst_regime[1] >= 3:
                    recommendations.append(f"âš ï¸ '{worst_regime[0]}' ì‹œì¥ì—ì„œ {worst_regime[1]}íšŒ ì—°ì† ì†ì‹¤ - ë§¤ë§¤ ìì œ ê¶Œì¥")
                    self.thompson_sampler.update_distribution(
                        pattern=f"regime_{worst_regime[0]}_danger",
                        success=False,
                        profit_pct=common_factors['avg_loss_per_trade'],
                        weight=1.5
                    )
                    
                    # ğŸ†• ë ˆì§+íŒ¨í„´ ì¡°í•© ìœ„í—˜ í•™ìŠµ
                    if common_factors['patterns']:
                        worst_pattern = max(common_factors['patterns'].items(), key=lambda x: x[1])
                        if worst_pattern[1] >= 2:
                            danger_combo = f"{worst_pattern[0]}_{worst_regime[0]}"
                            recommendations.append(f"   â›” íŠ¹íˆ '{danger_combo}' ì¡°í•© ì£¼ì˜ (ë ˆì§+íŒ¨í„´)")
                            self.thompson_sampler.update_distribution(
                                pattern=f"{danger_combo}_consecutive_loss",
                                success=False,
                                profit_pct=common_factors['avg_loss_per_trade'],
                                weight=2.0  # ë†’ì€ ê°€ì¤‘ì¹˜ë¡œ ê°•ë ¥ í•™ìŠµ
                            )
            
            # ìœ„í—˜í•œ ì‹œê°„ëŒ€
            if common_factors['time_of_day']:
                worst_time = max(common_factors['time_of_day'].items(), key=lambda x: x[1])
                if worst_time[1] >= 3:
                    recommendations.append(f"âš ï¸ {worst_time[0]} ì‹œê°„ëŒ€ì— {worst_time[1]}íšŒ ì—°ì† ì†ì‹¤ - í•´ë‹¹ ì‹œê°„ëŒ€ ì£¼ì˜")
            
            # 3ì—°íŒ¨ ì´ìƒ ë°œìƒ ì‹œ íœ´ì‹ ê¶Œì¥
            if results['max_streak'] >= 5:
                recommendations.append(f"ğŸ›‘ ìµœëŒ€ {results['max_streak']}ì—°íŒ¨ ê¸°ë¡ - ì—°ì† ì†ì‹¤ ì‹œ ë§¤ë§¤ ì¼ì‹œ ì¤‘ë‹¨ ê¶Œì¥")
            
            # Dict ë³€í™˜ (defaultdict -> dict)
            results['common_factors'] = {
                'patterns': dict(common_factors['patterns']),
                'coins': dict(common_factors['coins']),
                'market_regimes': dict(common_factors['market_regimes']),
                'time_of_day': dict(common_factors['time_of_day']),
                'total_loss_pct': round(common_factors['total_loss_pct'], 2),
                'avg_loss_per_trade': round(common_factors['avg_loss_per_trade'], 2)
            }
            results['recommendations'] = recommendations
            
            return results
            
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì—°ì† ì†ì‹¤ íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return results

    def run_full_learning(self):
        """ê°€ìƒë§¤ë§¤ ê²°ê³¼ í•™ìŠµ ë° ìê°€ì§„ë‹¨ ì¼ê´„ ì‹¤í–‰
        
        Note: ì‹œê·¸ë„ ì˜ˆì¸¡ ê²€ì¦ì€ strategy_signal_generator.pyì—ì„œ ì²˜ë¦¬
              (validate_signals_incremental í•¨ìˆ˜)
        
        ğŸ†• ê· í˜• í•™ìŠµ ì‹œìŠ¤í…œ (ì†ì‹¤ ë¶„ì„ + ê³¼ì‰ íšŒí”¼ ë°©ì§€):
        - ì†ì‹¤ ì›ì¸ë³„ ë¶„ì„: ì§„ì…/ì²­ì‚° íƒ€ì´ë°, ì „ëµ-ë ˆì§ ë¶€ì¡°í™”, ì‹œì¥ ê¸‰ë³€, ë³´ìœ  ì´ˆê³¼
        - ê³¼ì‰ íšŒí”¼ ë°©ì§€: ì‹œê°„ ê°ì‡ , ê°€ì¤‘ì¹˜ ìƒí•œì„ , ìµœì†Œ ë§¤ìˆ˜ í™•ë¥  ë³´ì¥
        """
        print("\nğŸ“– ê°€ìƒë§¤ë§¤ ê²°ê³¼ í•™ìŠµ ë° ìê°€ì§„ë‹¨ ì‹œì‘...")
        print(f"   âš–ï¸ ê· í˜• í•™ìŠµ í™œì„±í™”: ìµœì†Œ ë§¤ìˆ˜í™•ë¥  {BalancedLearningGuard.MIN_BUY_PROBABILITY*100:.0f}%, ì†ì‹¤ ê°€ì¤‘ì¹˜ ìƒí•œ {BalancedLearningGuard.MAX_LOSS_WEIGHT}x, ì†ì‹¤ ë¶„ì„ ê¸°ì¤€ {BalancedLearningGuard.MIN_LOSS_PCT_FOR_ANALYSIS}%â†‘")
        
        # 0. ì‹œì¥ ë ˆì§ ë¶„ì„
        try:
            market_context = get_market_context()
            print(f"ğŸ“Š ì‹œì¥ ìƒíƒœ: [ì¶”ì„¸] {market_context.get('regime', 'neutral').upper()} | [í™•ì‚°] {market_context.get('breadth', 'neutral').upper()}")
        except Exception as e:
            print(f"âš ï¸ ì‹œì¥ ë ˆì§ ë¶„ì„ ì˜¤ë¥˜: {e}")

        # 1. ì‹¤ì‹œê°„ í•™ìŠµ (ê°€ìƒë§¤ë§¤ ê²°ê³¼ ê¸°ë°˜)
        total_new = 0
        while True:
            new_count = self._execute_real_time_learning()
            if new_count == 0: break
            total_new += new_count
            
        # 2. ì•ŒíŒŒ ê°€ë””ì–¸ ìê°€ ì§„ë‹¨
        try:
            from trade.core.decision import get_ai_decision_engine
            guardian = get_ai_decision_engine(db_path=STRATEGY_DB_PATH)
            
            with get_db_connection(self.db_path) as conn:
                query = "SELECT * FROM virtual_trade_feedback ORDER BY exit_timestamp DESC LIMIT 100"
                feedback_history = pd.read_sql(query, conn).to_dict('records')
                
                if feedback_history:
                    quality = self.evolution_engine.evaluate_decision_quality(feedback_history, guardian)
                    new_bias = self.evolution_engine.update_meta_bias(quality, guardian)
                    guardian.save_meta_bias(new_bias)
                    
                    print(f"\nğŸ›¡ï¸ [ì•ŒíŒŒ ê°€ë””ì–¸ ìê°€ì§„ë‹¨ ë¦¬í¬íŠ¸]")
                    print(f"   ğŸ“ˆ ë§¤ìˆ˜ ì„±ê³µë¥ : {quality.get('buy_accuracy', 0):>6.1%} ({quality.get('profit_count', 0)}/{quality.get('buy_count', 0)}ê±´)")
                    print(f"   âœ¨ ì „ì—­ ì„±ê²© êµì • ì™„ë£Œ: {new_bias.get('buy_threshold_offset', 0):+.2f}")
                else:
                    print(f"\nğŸ›¡ï¸ [ì•ŒíŒŒ ê°€ë””ì–¸] ë¶„ì„í•  í”¼ë“œë°± ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì•ŒíŒŒ ê°€ë””ì–¸ ìê°€ì§„ë‹¨ ì˜¤ë¥˜: {e}")

        # 3. ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ë³µê¸° (ë†“ì¹œ ë§¤ë§¤/ì˜í•œ ê´€ë§ í•™ìŠµ)
        try:
            print("\nğŸ“Š [ì •ë°€ ë¶„ì„] ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ë³µê¸° ì‹œì‘...")
            self.market_miner.mine_insights()
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")

        # 4. ë§¤ë„ í’ˆì§ˆ í‰ê°€ (MFE/MAE ë¶„ì„)
        try:
            print("\nğŸ“ˆ [ë§¤ë„ í’ˆì§ˆ í‰ê°€] ë§¤ë„ í›„ ê°€ê²© ì¶”ì  ë¶„ì„ ì¤‘...")
            completed_evals = self._run_post_trade_evaluation()
            if completed_evals > 0:
                print(f"   âœ… {completed_evals}ê±´ì˜ ë§¤ë„ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ë§¤ë„ í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")

        # 5. ì „ì´ í•™ìŠµ (íŒ¨í„´ ì§€ì‹ ê³µìœ )
        try:
            print("\nğŸ”„ [ì „ì´ í•™ìŠµ] ê¸€ë¡œë²Œ íŒ¨í„´ ì§€ì‹ ê³µìœ  ì‹œì‘...")
            self.transfer_learner.execute_transfer_learning()
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì „ì´ í•™ìŠµ ì˜¤ë¥˜: {e}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ†• ì‹ ê·œ í•™ìŠµ ëª¨ë“ˆ (ì§„ì…/ë³´ìœ /ì†ìµì ˆ/ì—°ì†ì†ì‹¤)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # 6. ì§„ì… íƒ€ì´ë° ìµœì í™” í•™ìŠµ
        try:
            print("\nâ±ï¸ [ì§„ì… íƒ€ì´ë° ìµœì í™”] ë” ì¢‹ì€ ì§„ì… ê¸°íšŒ ë¶„ì„ ì¤‘...")
            entry_results = self._learn_entry_timing_optimization()
            if entry_results['analyzed'] > 0:
                better_rate = (entry_results['could_be_better'] / entry_results['analyzed']) * 100
                print(f"   ğŸ“Š ë¶„ì„ ì™„ë£Œ: {entry_results['analyzed']}ê±´ ì¤‘ {entry_results['could_be_better']}ê±´({better_rate:.1f}%)ì€ ë” ì¢‹ì€ ê°€ê²© ìˆì—ˆìŒ")
                if entry_results['avg_missed_pct'] > 0:
                    print(f"   ğŸ’¡ í‰ê·  {entry_results['avg_missed_pct']:.2f}% ë” ì¢‹ì€ ê°€ê²© ì¡´ì¬")
                if entry_results['optimal_delay_minutes'] > 0:
                    print(f"   â° ê¶Œì¥ ì§„ì… ì§€ì—°: {entry_results['optimal_delay_minutes']}ë¶„")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì§„ì… íƒ€ì´ë° í•™ìŠµ ì˜¤ë¥˜: {e}")

        # 7. ë³´ìœ  ê¸°ê°„ ìµœì í™” í•™ìŠµ
        try:
            print("\nâ³ [ë³´ìœ  ê¸°ê°„ ìµœì í™”] íŒ¨í„´ë³„ ìµœì  ë³´ìœ  ì‹œê°„ ë¶„ì„ ì¤‘...")
            holding_results = self._learn_optimal_holding_period()
            if holding_results['patterns_analyzed'] > 0:
                print(f"   ğŸ“Š {holding_results['patterns_analyzed']}ê°œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
                # ìƒìœ„ 3ê°œ íŒ¨í„´ë§Œ ì¶œë ¥
                for pattern, rec in list(holding_results['recommendations'].items())[:3]:
                    gap = rec['timing_gap_hours']
                    if abs(gap) > 1:
                        direction = "ë„ˆë¬´ ì˜¤ë˜" if gap > 0 else "ë„ˆë¬´ ë¹¨ë¦¬"
                        print(f"   ğŸ’¡ '{pattern}': {direction} ë³´ìœ  (ì‹¤ì œ {rec['avg_holding_hours']:.1f}h vs ìµœì  {rec['optimal_holding_hours']:.1f}h)")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ë³´ìœ  ê¸°ê°„ í•™ìŠµ ì˜¤ë¥˜: {e}")

        # 8. ì†ì ˆ/ìµì ˆ ì„ê³„ê°’ ë™ì  í•™ìŠµ
        try:
            print("\nğŸ“‰ [ì†ì ˆ/ìµì ˆ ìµœì í™”] íŒ¨í„´ë³„ ìµœì  ì„ê³„ê°’ ë¶„ì„ ì¤‘...")
            threshold_results = self._learn_dynamic_stop_take_profit()
            if threshold_results['patterns_analyzed'] > 0:
                print(f"   ğŸ“Š {threshold_results['patterns_analyzed']}ê°œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
                # ì£¼ìš” ì¡°ì • í•„ìš” íŒ¨í„´ ì¶œë ¥
                for pattern, adj in list(threshold_results['stop_loss_adjustments'].items())[:3]:
                    if abs(adj['optimal'] - adj['current_default']) > 1:
                        print(f"   ğŸ›‘ '{pattern}' ì†ì ˆ: {adj['current_default']}% â†’ {adj['optimal']}% ê¶Œì¥")
                for pattern, adj in list(threshold_results['take_profit_adjustments'].items())[:3]:
                    if abs(adj['optimal'] - adj['current_default']) > 1:
                        print(f"   âœ… '{pattern}' ìµì ˆ: {adj['current_default']}% â†’ {adj['optimal']}% ê¶Œì¥")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì†ì ˆ/ìµì ˆ í•™ìŠµ ì˜¤ë¥˜: {e}")

        # 9. ì—°ì† ì†ì‹¤ íŒ¨í„´ ë¶„ì„
        try:
            print("\nğŸ”´ [ì—°ì† ì†ì‹¤ ë¶„ì„] ì—°íŒ¨ íŒ¨í„´ ë° íšŒí”¼ ì „ëµ ë¶„ì„ ì¤‘...")
            streak_results = self._learn_consecutive_loss_patterns()
            if streak_results['total_streaks'] > 0:
                print(f"   ğŸ“Š {streak_results['total_streaks']}íšŒì˜ 3ì—°íŒ¨ ì´ìƒ ë°œìƒ (ìµœëŒ€ {streak_results['max_streak']}ì—°íŒ¨)")
                if streak_results['common_factors'].get('avg_loss_per_trade', 0) < 0:
                    print(f"   ğŸ’¸ ì—°íŒ¨ ì‹œ í‰ê·  ì†ì‹¤: {streak_results['common_factors']['avg_loss_per_trade']:.2f}%/ê±´")
                for rec in streak_results['recommendations']:
                    print(f"   {rec}")
            else:
                print("   âœ… ìµœê·¼ 3ì—°íŒ¨ ì´ìƒ ê¸°ë¡ ì—†ìŒ - ì–‘í˜¸")
        except Exception as e:
            if "unable to open" not in str(e).lower() and "locked" not in str(e).lower():
                print(f"âš ï¸ ì—°ì† ì†ì‹¤ ë¶„ì„ ì˜¤ë¥˜: {e}")

        # ğŸ§¬ 10. ì „ëµ ì§„í™” ìƒíƒœ ì¶œë ¥
        if EVOLUTION_SYSTEM_AVAILABLE:
            try:
                print("\n" + "=" * 60)
                print_evolution_status()
            except Exception as e:
                print(f"âš ï¸ ì§„í™” ìƒíƒœ ì¶œë ¥ ì˜¤ë¥˜: {e}")

        print(f"\nâœ… ìµœì¢… ì™„ë£Œ: {total_new}ê±´ì˜ ìƒˆë¡œìš´ ì§€ì‹ ìŠµë“ ì™„ë£Œ")

if __name__ == "__main__":
    learner = VirtualTradingLearner()
    learner.run_full_learning()
