import sys
sys.path.insert(0, '/workspace/')  # ì ˆëŒ€ ê²½ë¡œ ì¶”ê°€

import sqlite3
import asyncio
import aiohttp
import pandas as pd
import os
import time
from datetime import datetime, timedelta, timezone
from threading import Thread
from queue import Queue
from collections import defaultdict

DB_PATH = '/workspace/data_storage/realtime_candles.db'
INTERVALS = ['15m', '30m', '240m', '1d']
REQUEST_COUNT = {'15m': 100, '30m': 100, '240m': 100, '1d': 100}

# ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì½”ì¸ ëª©ë¡ (Noneì´ë©´ ì „ì²´ ì½”ì¸ ìˆ˜ì§‘, ë¦¬ìŠ¤íŠ¸ë©´ ì§€ì •ëœ ì½”ì¸ë§Œ ìˆ˜ì§‘)
TEST_COINS = ['BTC', 'ETH', 'XRP', 'DOGE', 'SOL', 'ADA', 'DOT', 'LINK', 'AVAX', 'BNB']  # ë©”ì´ì € ì½”ì¸ 10ê°œ

# ğŸš€ ìµœì í™”ëœ ë™ì‹œì„± ì œì–´ ì„¤ì •
MAX_CONCURRENT_REQUESTS = 50  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì¦ê°€
REQUEST_TIMEOUT = 15  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
RETRY_ATTEMPTS = 2  # ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 0.5  # ì¬ì‹œë„ ê°„ê²©
RATE_LIMIT_DELAY = 1.0  # 429 ì—ëŸ¬ ì‹œ ëŒ€ê¸° ì‹œê°„
MAX_RATE_LIMIT_RETRIES = 3  # 429 ì—ëŸ¬ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

# ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
save_queue = asyncio.Queue(maxsize=3000)  # í í¬ê¸° ì¦ê°€

# 429 rate limit ë¡œê·¸ ìš”ì•½ìš©
rate_limit_counter = defaultdict(int)
rate_limit_last_print = defaultdict(float)

# ğŸš€ ì‹¤íŒ¨í•œ ìš”ì²­ ì¶”ì ìš©
failed_requests = set()  # (coin, interval) íŠœí”Œë¡œ ì €ì¥
failed_requests_lock = asyncio.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½

# ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
class PerformanceMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        self.total_candles = 0
        self.last_progress_time = time.time()
        self.progress_interval = 5  # 5ì´ˆë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
        
    def log_request(self, success: bool, candle_count: int = 0):
        self.request_count += 1
        if success:
            self.success_count += 1
            self.total_candles += candle_count
        else:
            self.error_count += 1
        
        # ì§„í–‰ë¥  ì¶œë ¥ (ì œê±°ë¨)
        current_time = time.time()
        if current_time - self.last_progress_time >= self.progress_interval:
            # self._print_progress()  # ì œê±°ë¨
            self.last_progress_time = current_time
    
    def _print_progress(self):
        # ì§„í–‰ë¥  ì¶œë ¥ ì œê±°ë¨
        pass
    
    def get_stats(self):
        elapsed = time.time() - self.start_time
        return {
            'elapsed_time': elapsed,
            'requests_per_second': self.request_count / elapsed if elapsed > 0 else 0,
            'success_rate': self.success_count / self.request_count if self.request_count > 0 else 0,
            'total_candles': self.total_candles,
            'candles_per_second': self.total_candles / elapsed if elapsed > 0 else 0
        }

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
performance_monitor = PerformanceMonitor()

# ğŸš€ Rate limitingì„ ìœ„í•œ ë”œë ˆì´ ê´€ë¦¬
class RateLimiter:
    def __init__(self):
        self.last_request_time = 0
        self.min_interval = 0.02  # 20ms ê°„ê²© (ì´ˆë‹¹ 50 ìš”ì²­)
        self.rate_limit_until = 0
    
    async def wait_if_needed(self):
        current_time = time.time()
        
        # Rate limit ëŒ€ê¸°
        if current_time < self.rate_limit_until:
            wait_time = self.rate_limit_until - current_time
            print(f"â³ Rate limit ëŒ€ê¸°: {wait_time:.1f}ì´ˆ")
            await asyncio.sleep(wait_time)
            current_time = time.time()
        
        # ìµœì†Œ ê°„ê²© ëŒ€ê¸°
        time_since_last = current_time - self.last_request_time
        if time_since_last < self.min_interval:
            await asyncio.sleep(self.min_interval - time_since_last)
        
        self.last_request_time = time.time()
    
    def set_rate_limit(self, retry_after=None):
        """429 ì—ëŸ¬ ì‹œ rate limit ì„¤ì •"""
        if retry_after:
            self.rate_limit_until = time.time() + retry_after
        else:
            self.rate_limit_until = time.time() + RATE_LIMIT_DELAY

# ì „ì—­ rate limiter
rate_limiter = RateLimiter()

# í…Œì´ë¸” ìƒì„±
def create_table():
    # ê¸°ì¡´ DB íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
    if os.path.exists(DB_PATH):
        os.remove(DB_PATH)
        # print(f"ğŸ—‘ï¸ ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ: {DB_PATH}")  # ì œê±°ë¨
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„± (ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ)
    cursor.execute("""
    CREATE TABLE candles (
        -- ğŸ·ï¸ ê¸°ë³¸ ì‹ë³„ì (3ê°œ)
        coin TEXT,
        interval TEXT,
        timestamp INTEGER,
        -- ğŸ’° ê¸°ë³¸ OHLCV (4ê°œ)
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        volume REAL,
        -- ğŸ“‰ í•µì‹¬ ì˜¤ì‹¤ë ˆì´í„° (2ê°œ)
        rsi REAL,
        mfi REAL,
        -- ğŸ“Š í•µì‹¬ íŠ¸ë Œë“œ (2ê°œ)
        macd REAL,
        macd_signal REAL,
        -- ğŸŒ í•µì‹¬ ë³¼ë¦°ì €ë°´ë“œ (5ê°œ)
        bb_upper REAL,
        bb_middle REAL,
        bb_lower REAL,
        bb_position REAL,
        bb_width REAL,
        -- ğŸ“ˆ í•µì‹¬ ì¶”ì„¸/ë³€ë™ì„± (3ê°œ)
        atr REAL,
        ma20 REAL,
        adx REAL,
        -- ğŸ“Š í•µì‹¬ ê±°ë˜ëŸ‰ (1ê°œ)
        volume_ratio REAL,
        -- âš ï¸ í•µì‹¬ ë¦¬ìŠ¤í¬ (2ê°œ)
        volatility REAL,
        risk_score REAL,
        -- ğŸ§  í•µì‹¬ íŒŒë™ (2ê°œ)
        wave_phase TEXT,
        confidence REAL,
        -- ğŸ”„ í•µì‹¬ íŒŒë™ ë¶„ì„ (3ê°œ)
        zigzag_direction REAL,
        zigzag_pivot_price REAL,
        wave_progress REAL,
        -- ğŸ¯ í•µì‹¬ íŒ¨í„´ ë¶„ì„ (2ê°œ)
        pattern_type TEXT,
        pattern_confidence REAL,
        -- ğŸ§  í•µì‹¬ í†µí•© ë¶„ì„ (3ê°œ)
        volatility_level TEXT,
        risk_level TEXT,
        integrated_direction TEXT,
        -- ğŸš€ êµ¬ì¡° ì ìˆ˜ (1ê°œ)
        structure_score REAL,
        -- ğŸš€ ì‹¬ë¦¬ë„ ë¶„ì„ (2ê°œ)
        sentiment REAL,
        sentiment_label TEXT,
        -- ğŸš€ ë ˆì§ ë¶„ì„ (4ê°œ)
        regime_stage INTEGER,
        regime_label TEXT,
        regime_confidence REAL,
        regime_transition_prob REAL,
        PRIMARY KEY (coin, interval, timestamp)
    )
    """)
    
    # ğŸš€ ì¸ë±ìŠ¤ ì¶”ê°€ë¡œ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_coin_interval ON candles(coin, interval)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON candles(timestamp)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_coin_timestamp ON candles(coin, timestamp)')
    
    conn.commit()
    conn.close()
    # print("âœ… ìƒˆë¡œìš´ candles í…Œì´ë¸” ìƒì„± ì™„ë£Œ")  # ì œê±°ë¨



# ì½”ì¸ëª… ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸° ë²„ì „)
async def get_all_coins(session: aiohttp.ClientSession):
    url = "https://api.bithumb.com/public/ticker/ALL_KRW"
    
    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    data = await response.json()
                    coins = [coin for coin in data["data"] if coin != "date"]
                    # print(f"âœ… ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ: {len(coins)}ê°œ")  # ì œê±°ë¨
                    return coins
                elif response.status == 429:
                    # Rate limit ì²˜ë¦¬
                    retry_after = None
                    try:
                        retry_after_header = response.headers.get('Retry-After')
                        if retry_after_header:
                            retry_after = int(retry_after_header)
                    except:
                        pass
                    
                    rate_limiter.set_rate_limit(retry_after)
                    # print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ Rate limit (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS})")  # ì œê±°ë¨
                    
                    if attempt < RETRY_ATTEMPTS - 1:
                        backoff_delay = RETRY_DELAY * (2 ** attempt)
                        await asyncio.sleep(backoff_delay)
                        await rate_limiter.wait_if_needed()
                    continue
                else:
                    # print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ (HTTP {response.status})")  # ì œê±°ë¨
                    pass
        except Exception as e:
            # print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS}): {e}")  # ì œê±°ë¨
            if attempt < RETRY_ATTEMPTS - 1:
                backoff_delay = RETRY_DELAY * (2 ** attempt)
                await asyncio.sleep(backoff_delay)
    
    return []

# ìº”ë“¤ ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸° ë²„ì „)
def build_url(interval):
    interval_map = {
        
        "15m": "https://api.bithumb.com/v1/candles/minutes/15",
        "30m": "https://api.bithumb.com/v1/candles/minutes/30",
        "240m": "https://api.bithumb.com/v1/candles/minutes/240",
        "1d": "https://api.bithumb.com/v1/candles/days",
        "1w": "https://api.bithumb.com/v1/candles/weeks"
    }
    return interval_map.get(interval)

async def fetch_candles(session: aiohttp.ClientSession, coin: str, interval: str, count=200, oldest_timestamp=None):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨) - ì¦ë¶„ ì—…ë°ì´íŠ¸ ì§€ì›"""
    url = build_url(interval)
    if not url:
        return []

    params = {
        "market": f"KRW-{coin}",
        "count": count
    }
    
    # ğŸš€ ì¦ë¶„ ì—…ë°ì´íŠ¸: ê¸°ì¡´ ë°ì´í„°ë³´ë‹¤ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•„í„°ë§
    if oldest_timestamp:
        # ê¸°ì¡´ ë°ì´í„°ì˜ ê°€ì¥ ì˜¤ë˜ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì´í›„ì˜ ë°ì´í„°ë§Œ í•„ìš”
        # print(f"ğŸ”„ {coin}/{interval}: ê¸°ì¡´ ë°ì´í„° ì´í›„ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ê¸°ì¡´ ìµœê³ : {datetime.fromtimestamp(oldest_timestamp)})")  # ì œê±°ë¨
        pass

    key = f"{coin}/{interval}"

    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, params=params, timeout=timeout) as response:
                if response.status == 429:
                    rate_limit_counter[key] += 1
                    now = time.time()
                    if rate_limit_counter[key] % 10 == 1 or now - rate_limit_last_print[key] > 10:
                        # print(f"âš ï¸ HTTP 429 (rate limit) for {key}, ìµœê·¼ {rate_limit_counter[key]}íšŒ ë°˜ë³µ ì¤‘...")  # ì œê±°ë¨
                        rate_limit_last_print[key] = now
                    # Rate Limit ëŒ€ì‘: ë” ê¸´ ëŒ€ê¸° ì‹œê°„ ì ìš©
                    wait_time = min(3.0, rate_limit_counter[key] * 1.5)  # ìµœëŒ€ 3ì´ˆê¹Œì§€ ì¦ê°€
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    rate_limit_counter[key] = 0  # ì •ìƒ ì‘ë‹µì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
                
                if response.status == 200:
                    data = await response.json()
                    if not isinstance(data, list):
                        performance_monitor.log_request(False)
                        return []

                    candles = []
                    seen_timestamps = set()
                    
                    for candle in data:
                        try:
                            timestamp = candle.get('candle_date_time_kst')
                            if timestamp in seen_timestamps or not timestamp:
                                continue  # ì¤‘ë³µ ë˜ëŠ” ì˜ëª»ëœ íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì œì™¸
                            seen_timestamps.add(timestamp)

                            candles.append({
                                'timestamp': timestamp,
                                'open': float(candle.get('opening_price', 0)),
                                'high': float(candle.get('high_price', 0)),
                                'low': float(candle.get('low_price', 0)),
                                'close': float(candle.get('trade_price', 0)),
                                'volume': round(float(candle.get('candle_acc_trade_price', 0)), 4)
                            })
                        except (ValueError, KeyError) as e:
                            continue

                    performance_monitor.log_request(True, len(candles))
                    return candles
                else:
                    # print(f"âš ï¸ ìº”ë“¤ ì¡°íšŒ ì‹¤íŒ¨ {coin}-{interval} (HTTP {response.status})")  # ì œê±°ë¨
                    pass
                    
        except asyncio.TimeoutError:
            # print(f"âš ï¸ ìº”ë“¤ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ {coin}-{interval} (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS})")  # ì œê±°ë¨
            pass
        except Exception as e:
            # print(f"âš ï¸ ìº”ë“¤ ì¡°íšŒ ì˜¤ë¥˜ {coin}-{interval} (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS}): {e}")  # ì œê±°ë¨
            pass
        
        if attempt < RETRY_ATTEMPTS - 1:
            # ì§€ìˆ˜ ë°±ì˜¤í”„
            backoff_delay = RETRY_DELAY * (2 ** attempt)
            await asyncio.sleep(backoff_delay)
    
    performance_monitor.log_request(False)
    
    # ì‹¤íŒ¨í•œ ìš”ì²­ ê¸°ë¡
    async with failed_requests_lock:
        failed_requests.add((coin, interval))
    
    return []

# ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ (ë¹„ë™ê¸° ë²„ì „) - ìµœê·¼ 100ê°œë§Œ ìœ ì§€
async def candle_saver_worker(save_queue):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ - ìµœê·¼ 100ê°œë§Œ ìœ ì§€"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    total_saved = 0
    batch_data = []
    batch_size = 1000  # ë°°ì¹˜ í¬ê¸° ì¦ê°€

    while True:
        try:
            item = await save_queue.get()
            if item is None:
                # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
                if batch_data:
                    cursor.executemany('''
                        INSERT OR REPLACE INTO candles (
                            coin, interval, timestamp, open, high, low, close, volume
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    ''', batch_data)
                    conn.commit()
                    total_saved += len(batch_data)
                # print(f"ğŸ’¾ ì´ ì €ì¥ëœ ìº”ë“¤: {total_saved:,}ê°œ")  # ì œê±°ë¨
                break

            coin, interval, candles = item

            # ë°°ì¹˜ ë°ì´í„° ì¶”ê°€
            for c in candles:
                # Unix timestampë¡œ ë³€í™˜
                timestamp = int(pd.to_datetime(c['timestamp'], format='%Y-%m-%dT%H:%M:%S').timestamp())
                
                batch_data.append((
                    coin, interval, timestamp,
                    c['open'], c['high'], c['low'], c['close'], c['volume']
                ))

            # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ DBì— ì €ì¥
            if len(batch_data) >= batch_size:
                cursor.executemany('''
                    INSERT OR REPLACE INTO candles (
                        coin, interval, timestamp, open, high, low, close, volume
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', batch_data)
                conn.commit()
                total_saved += len(batch_data)
                batch_data.clear()

        except Exception as e:
            # print(f"âš ï¸ ì €ì¥ ì›Œì»¤ ì˜¤ë¥˜: {e}")  # ì œê±°ë¨
            continue

    conn.close()

# ğŸš€ ì¸í„°ë²Œë³„ ìº”ë“¤ ì •ë¦¬ í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™”)
def cleanup_candles_by_interval():
    """ğŸš€ ì¸í„°ë²Œë³„ë¡œ ë‹¤ë¥¸ ì •ë¦¬ ì •ì±… ì ìš©"""
    # print("ğŸ§¹ ì¸í„°ë²Œë³„ ìº”ë“¤ ë°ì´í„° ì •ë¦¬ ì‹œì‘...")  # ì œê±°ë¨
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        # ì‚­ì œ ì „ ì „ì²´ ìº”ë“¤ ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM candles")
        total_before = cursor.fetchone()[0]
        
        total_deleted = 0
        
        # 1. ë‹¨ê¸° ì¸í„°ë²Œ (15m, 30m): 7ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ
        short_intervals = ['15m', '30m']
        current_timestamp = int(datetime.now().timestamp())
        cutoff_timestamp = current_timestamp - (7 * 24 * 3600)  # 7ì¼
        
        for interval in short_intervals:
            cursor.execute("""
                DELETE FROM candles 
                WHERE interval = ? AND timestamp < ?
            """, (interval, cutoff_timestamp))
            
            deleted_count = cursor.rowcount
            total_deleted += deleted_count
            
            if deleted_count > 0:
                # print(f"  ğŸ§¹ {interval}: {deleted_count:,}ê°œ ì‚­ì œ (7ì¼ ì´ì „)")  # ì œê±°ë¨
                pass
        
        # 2. ì¥ê¸° ì¸í„°ë²Œ (240m, 1d, 1w): ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        long_intervals = ['240m', '1d', '1w']
        
        for interval in long_intervals:
            # ê° ì½”ì¸ë³„ë¡œ ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            cursor.execute("SELECT DISTINCT coin FROM candles WHERE interval = ?", (interval,))
            coins = cursor.fetchall()
            
            for (coin,) in coins:
                cursor.execute("""
                    DELETE FROM candles 
                    WHERE coin = ? AND interval = ? 
                    AND timestamp NOT IN (
                        SELECT timestamp FROM candles 
                        WHERE coin = ? AND interval = ?
                        ORDER BY timestamp DESC 
                        LIMIT 100
                    )
                """, (coin, interval, coin, interval))
                
                deleted_count = cursor.rowcount
                total_deleted += deleted_count
                
                if deleted_count > 0:
                    # print(f"  ğŸ§¹ {coin}/{interval}: {deleted_count:,}ê°œ ì‚­ì œ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)")  # ì œê±°ë¨
                    pass
        
        # ì‚­ì œ í›„ ì „ì²´ ìº”ë“¤ ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM candles")
        total_after = cursor.fetchone()[0]
        
        conn.commit()
        
        # print(f"âœ… ì •ë¦¬ ì™„ë£Œ: ì´ {total_deleted:,}ê°œ ìº”ë“¤ ì‚­ì œ")  # ì œê±°ë¨
        # print(f"ğŸ“Š DB í¬ê¸°: {total_before:,}ê°œ â†’ {total_after:,}ê°œ ìº”ë“¤")  # ì œê±°ë¨
        
        # ì¸í„°ë²Œë³„ ìº”ë“¤ ìˆ˜ í†µê³„
        cursor.execute("""
            SELECT interval, COUNT(*) as count 
            FROM candles 
            GROUP BY interval 
            ORDER BY count DESC
        """)
        
        interval_stats = cursor.fetchall()
        if interval_stats:
            # print(f"ğŸ“ˆ ì¸í„°ë²Œë³„ ìº”ë“¤ ìˆ˜:")  # ì œê±°ë¨
            # for interval, count in interval_stats:
            #     print(f"  â° {interval}: {count:,}ê°œ")  # ì œê±°ë¨
            pass
        
    except Exception as e:
        # print(f"âš ï¸ ìº”ë“¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")  # ì œê±°ë¨
        pass
    finally:
        conn.close()



# ğŸš€ ìµœì í™”ëœ ì œí•œëœ í˜ì¹˜ (ì„¸ë§ˆí¬ì–´ ì œì–´)
async def limited_fetch(session: aiohttp.ClientSession, coin: str, interval: str, save_queue):
    """ğŸš€ ìµœì í™”ëœ ì œí•œëœ í˜ì¹˜ (ì„¸ë§ˆí¬ì–´ ì œì–´)"""
    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        candles = await fetch_candles(session, coin, interval, REQUEST_COUNT[interval])
        await asyncio.sleep(0.1)  # ì§€ì—° ì‹œê°„ ì¶”ê°€ (Rate Limit ëŒ€ì‘)
        if candles:
            await save_queue.put((coin, interval, candles))
        return candles

# ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
async def fetch_all(save_queue):
    """ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
    # print("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")  # ì œê±°ë¨

    connector = aiohttp.TCPConnector(
        limit=MAX_CONCURRENT_REQUESTS * 3,
        limit_per_host=MAX_CONCURRENT_REQUESTS * 2,
        ttl_dns_cache=300,
        use_dns_cache=True,
        keepalive_timeout=30,
        enable_cleanup_closed=True
    )

    timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={'User-Agent': 'Mozilla/5.0 (compatible; TradingBot/2.0)'}
    ) as session:
        coins = await get_all_coins(session)
        if not coins:
            # print("âŒ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")  # ì œê±°ë¨
            return

        # ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì½”ì¸ í•„í„°ë§
        if TEST_COINS is not None:
            # TEST_COINSì— ì§€ì •ëœ ì½”ì¸ë§Œ í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
            coins_dict = {coin.upper(): coin for coin in coins}  # ì›ë³¸ ì½”ì¸ëª… ìœ ì§€
            filtered_coins = []
            not_found = []
            
            for test_coin in TEST_COINS:
                test_coin_upper = test_coin.upper()
                if test_coin_upper in coins_dict:
                    filtered_coins.append(coins_dict[test_coin_upper])
                else:
                    not_found.append(test_coin)
            
            coins = filtered_coins
            if not_found:
                print(f"âš ï¸ ë‹¤ìŒ ì½”ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(not_found)}")
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì§€ì •ëœ ì½”ì¸ {len(coins)}ê°œë§Œ ìˆ˜ì§‘ ({', '.join(coins)})")
        elif len(coins) > 10:
            # TEST_COINSê°€ Noneì´ê³  ì½”ì¸ì´ ë§ìœ¼ë©´ ì²˜ìŒ 10ê°œë§Œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            coins = coins[:10]
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì½”ì¸ 10ê°œë¡œ ì œí•œ ({', '.join(coins)})")

        # print(f"ğŸ“Š ìˆ˜ì§‘ ëŒ€ìƒ: {len(coins)}ê°œ ì½”ì¸")  # ì œê±°ë¨

        total_tasks = 0

        for interval in INTERVALS:
            # print(f"\nâ° {interval} ìº”ë“¤ ìˆ˜ì§‘ ì¤‘...")  # ì œê±°ë¨

            interval_tasks = []
            for coin in coins:
                task = limited_fetch(session, coin, interval, save_queue)
                interval_tasks.append(task)

            total_tasks += len(interval_tasks)
            # print(f"ğŸ“‹ {interval}: {len(interval_tasks):,}ê°œ íƒœìŠ¤í¬ ìƒì„±")  # ì œê±°ë¨

            batch_size = 200  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            completed_tasks = 0

            for i in range(0, len(interval_tasks), batch_size):
                batch = interval_tasks[i:i + batch_size]
                results = await asyncio.gather(*batch, return_exceptions=True)

                for result in results:
                    if isinstance(result, Exception):
                        print(f"âš ï¸ íƒœìŠ¤í¬ ì‹¤í–‰ ì˜¤ë¥˜: {result}")

                completed_tasks += len(batch)
                if completed_tasks % (batch_size * 2) == 0:
                    # print(f"ğŸ“ˆ {interval} ì§„í–‰ë¥ : {completed_tasks:,}/{len(interval_tasks):,} ({completed_tasks/len(interval_tasks)*100:.1f}%)")  # ì œê±°ë¨
                    pass

        # print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ (ì´ {total_tasks:,}ê°œ íƒœìŠ¤í¬)")  # ì œê±°ë¨

        # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ì¶œë ¥
        if failed_requests:
            # print(f"\nâš ï¸ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ({len(failed_requests)}ê°œ):")  # ì œê±°ë¨
            # for coin, interval in sorted(failed_requests):
            #     print(f"  - {coin}-{interval}")  # ì œê±°ë¨
            
            # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
            failed_file = os.path.join(os.path.dirname(DB_PATH), 'failed_requests_realtime.txt')
            with open(failed_file, 'w', encoding='utf-8') as f:
                for coin, interval in sorted(failed_requests):
                    f.write(f"{coin},{interval}\n")
            # print(f"ğŸ“ ì‹¤íŒ¨í•œ ìš”ì²­ ëª©ë¡ ì €ì¥: {failed_file}")  # ì œê±°ë¨
        else:
            # print(f"\nâœ… ëª¨ë“  ìš”ì²­ ì„±ê³µ!")  # ì œê±°ë¨
            pass

        stats = performance_monitor.get_stats()
        # print(f"\nğŸ“Š ì„±ëŠ¥ í†µê³„:")  # ì œê±°ë¨
        # print(f"- ì´ ìš”ì²­ ìˆ˜: {performance_monitor.request_count:,}")  # ì œê±°ë¨
        # print(f"- ì„±ê³µë¥ : {stats['success_rate']:.1%}")  # ì œê±°ë¨
        # print(f"- ì´ˆë‹¹ ìš”ì²­ ìˆ˜: {stats['requests_per_second']:.1f}")  # ì œê±°ë¨
        # print(f"- ì´ ìº”ë“¤ ìˆ˜: {stats['total_candles']:,}")  # ì œê±°ë¨
        # print(f"- ì´ˆë‹¹ ìº”ë“¤ ìˆ˜: {stats['candles_per_second']:.1f}")  # ì œê±°ë¨
        # print(f"- ì†Œìš” ì‹œê°„: {stats['elapsed_time']:.1f}ì´ˆ")  # ì œê±°ë¨

        # ğŸš€ ì„±ëŠ¥ í‰ê°€
        if stats['requests_per_second'] > 20:
            # print(f"ğŸš€ ìš°ìˆ˜í•œ ì„±ëŠ¥! ì´ˆë‹¹ {stats['requests_per_second']:.1f} ìš”ì²­")  # ì œê±°ë¨
            pass
        elif stats['requests_per_second'] > 15:
            # print(f"âœ… ì¢‹ì€ ì„±ëŠ¥! ì´ˆë‹¹ {stats['requests_per_second']:.1f} ìš”ì²­")  # ì œê±°ë¨
            pass
        else:
            # print(f"âš ï¸ ê°œì„  í•„ìš”: ì´ˆë‹¹ {stats['requests_per_second']:.1f} ìš”ì²­")  # ì œê±°ë¨
            pass

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë¹„ë™ê¸° ë²„ì „)
async def main():
    # print("ğŸš€ ì‹¤ì‹œê°„ ìº”ë“¤ ìˆ˜ì§‘ê¸° ì‹œì‘")  # ì œê±°ë¨
    
    # í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)
    create_table()
    
    # print(f"ğŸš€ ìµœì í™” ì„¤ì •:")  # ì œê±°ë¨
    # print(f"- ìµœëŒ€ ë™ì‹œ ìš”ì²­: {MAX_CONCURRENT_REQUESTS}")  # ì œê±°ë¨
    # print(f"- ìš”ì²­ íƒ€ì„ì•„ì›ƒ: {REQUEST_TIMEOUT}ì´ˆ")  # ì œê±°ë¨
    # print(f"- ì¬ì‹œë„ íšŸìˆ˜: {RETRY_ATTEMPTS}")  # ì œê±°ë¨
    # print(f"- ë‹¨ê¸° ì¸í„°ë²Œ(15m,30m): 7ì¼ ë³´ê´€")  # ì œê±°ë¨
    # print(f"- ì¥ê¸° ì¸í„°ë²Œ(240m,1d,1w): ìµœê·¼ 100ê°œ ë³´ê´€")  # ì œê±°ë¨
    
    # ğŸš€ ì„±ëŠ¥ ì˜ˆì¸¡
    estimated_coins = 400  # ì˜ˆìƒ ì½”ì¸ ìˆ˜
    estimated_requests = estimated_coins * len(INTERVALS)  # 6ê°œ ì¸í„°ë²Œ
    estimated_time = estimated_requests / 20  # ì´ˆë‹¹ 20 ìš”ì²­ ê°€ì •
    # print(f"\nğŸ“Š ì„±ëŠ¥ ì˜ˆì¸¡:")  # ì œê±°ë¨
    # print(f"- ì˜ˆìƒ ìš”ì²­ ìˆ˜: {estimated_requests:,}ê°œ")  # ì œê±°ë¨
    # print(f"- ì˜ˆìƒ ì†Œìš” ì‹œê°„: {estimated_time/60:.1f}ë¶„")  # ì œê±°ë¨
    # print(f"- ëª©í‘œ ì´ˆë‹¹ ìš”ì²­: 20+ req/s")  # ì œê±°ë¨
    # print(f"- Rate limit ë°©ì§€: 40ms ê°„ê²©, ìµœëŒ€ 25 ë™ì‹œ ìš”ì²­")  # ì œê±°ë¨
    # print(f"- ë°ì´í„° ë³´ê´€: ì¸í„°ë²Œë³„ ìµœì í™” ì •ì±…")  # ì œê±°ë¨

    # ğŸ§ª ì´ë²¤íŠ¸ ë£¨í”„ì— ë°”ì¸ë”©ëœ save_queue ìƒì„±
    save_queue = asyncio.Queue(maxsize=3000)

    # ğŸš€ ì €ì¥ ì›Œì»¤ ì‹œì‘
    worker = asyncio.create_task(candle_saver_worker(save_queue))

    try:
        # ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        await fetch_all(save_queue)
    except KeyboardInterrupt:
        # print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")  # ì œê±°ë¨
        pass
    except Exception as e:
        # print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")  # ì œê±°ë¨
        pass

    # ğŸš€ ì›Œì»¤ ì¢…ë£Œ ì‹ í˜¸
    await save_queue.put(None)
    await worker

    # ğŸ§¹ ì¸í„°ë²Œë³„ ìº”ë“¤ ë°ì´í„° ì •ë¦¬
    cleanup_candles_by_interval()

    # print("\nâœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")  # ì œê±°ë¨

if __name__ == "__main__":
    asyncio.run(main())