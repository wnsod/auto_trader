"""
cache ê´€ë ¨ Mixin í´ë˜ìŠ¤
SignalSelectorì˜ cache ê¸°ëŠ¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""



# === ê³µí†µ import ===
import os
import sys
import logging
import traceback
import time
import json
import math
import sqlite3
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, deque
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass
from contextlib import contextmanager

import numpy as np
import pandas as pd

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# signal_selector ë‚´ë¶€ ëª¨ë“ˆ
try:
    from signal_selector.core.types import SignalInfo, SignalAction
    from signal_selector.config import (
        CANDLES_DB_PATH, STRATEGIES_DB_PATH, TRADING_SYSTEM_DB_PATH,
        DB_PATH, CACHE_SIZE, USE_GPU_ACCELERATION, AI_MODEL_AVAILABLE,
        SYNERGY_LEARNING_AVAILABLE, PERFORMANCE_CONFIG, CROSS_COIN_AVAILABLE,
        ENABLE_CROSS_COIN_LEARNING, workspace_dir
    )
    from signal_selector.utils import (
        safe_float, safe_str, TECHNICAL_INDICATORS_CONFIG,
        STATE_DISCRETIZATION_CONFIG, discretize_value, process_technical_indicators,
        get_optimized_db_connection, safe_db_write, safe_db_read,
        OptimizedCache, DatabasePool
    )
    from signal_selector.evaluators import (
        OffPolicyEvaluator, ConfidenceCalibrator, MetaCorrector
    )
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ê²½ë¡œ ì¶”ê°€
    _current = os.path.dirname(os.path.abspath(__file__))
    _signal_selector = os.path.dirname(_current)
    _trade = os.path.dirname(_signal_selector)
    sys.path.insert(0, _trade)
    from signal_selector.core.types import SignalInfo, SignalAction
    from signal_selector.config import (
        CANDLES_DB_PATH, STRATEGIES_DB_PATH, TRADING_SYSTEM_DB_PATH,
        DB_PATH, CACHE_SIZE, USE_GPU_ACCELERATION, AI_MODEL_AVAILABLE,
        SYNERGY_LEARNING_AVAILABLE, PERFORMANCE_CONFIG, CROSS_COIN_AVAILABLE,
        ENABLE_CROSS_COIN_LEARNING, workspace_dir
    )
    from signal_selector.utils import (
        safe_float, safe_str, TECHNICAL_INDICATORS_CONFIG,
        STATE_DISCRETIZATION_CONFIG, discretize_value, process_technical_indicators,
        get_optimized_db_connection, safe_db_write, safe_db_read,
        OptimizedCache, DatabasePool
    )
    from signal_selector.evaluators import (
        OffPolicyEvaluator, ConfidenceCalibrator, MetaCorrector
    )

# í—¬í¼ í´ë˜ìŠ¤ import (coreì—ì„œë§Œ í•„ìš”)
try:
    from signal_selector.helpers import (
        ContextualBandit, RegimeChangeDetector, ExponentialDecayWeight,
        BayesianSmoothing, ActionSpecificScorer, ContextFeatureExtractor,
        OutlierGuardrail, EvolutionEngine, ContextMemory, RealTimeLearner,
        SignalTradeConnector
    )
except ImportError:
    pass  # í—¬í¼ê°€ í•„ìš”ì—†ëŠ” Mixinì—ì„œëŠ” ë¬´ì‹œ


class CacheMixin:
    """
    CacheMixin - cache ê¸°ëŠ¥

    ì´ Mixinì€ SignalSelector í´ë˜ìŠ¤ì—ì„œ ìƒì†ë°›ì•„ ì‚¬ìš©ë©ë‹ˆë‹¤.
    """

    def _get_cached_market_condition(self, coin: str, interval: str) -> str:
        """ğŸš€ ìºì‹œëœ ì‹œì¥ ìƒí™© ë°˜í™˜ (ë¹ ë¥¸ íŒë‹¨)"""
        try:
            cache_key = f"market_condition_{coin}_{interval}"
            cached_data = self.get_cached_data(cache_key, max_age=300)  # 5ë¶„ ìºì‹œ
            
            if cached_data:
                return cached_data
            
            # ìºì‹œê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‹œì¥ ìƒí™© íŒë‹¨
            market_condition = self._detect_simple_market_condition(coin, interval)
            
            # ìºì‹œì— ì €ì¥
            self.set_cached_data(cache_key, market_condition)
            
            return market_condition
            
        except Exception as e:
            return 'neutral'  # ê¸°ë³¸ê°’
    
    def _cleanup_cache(self):
        """ğŸš€ ê³ ì„±ëŠ¥ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        try:
            current_time = time.time()
            expired_keys = []

            # OptimizedCacheì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ìºì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            with self.cache.lock:
                cache_items = list(self.cache.cache.items())
                cache_timestamps = dict(self.cache.timestamps)

            # ğŸš€ ìºì‹œ í¬ê¸° ì œí•œ ì ìš©
            if len(cache_items) > self.max_cache_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ë¶€í„° ì œê±°
                sorted_items = sorted(cache_timestamps.items(), key=lambda x: x[1])
                items_to_remove = len(cache_items) - self.max_cache_size + 1000  # ì—¬ìœ  ê³µê°„ í™•ë³´
                expired_keys.extend([key for key, _ in sorted_items[:items_to_remove]])

            # ê¸°ì¡´ ë§Œë£Œ ì‹œê°„ ê¸°ë°˜ ì •ë¦¬
            for key, timestamp in cache_timestamps.items():
                if current_time - timestamp > 600:  # 10ë¶„ ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì€ í•­ëª©
                    expired_keys.append(key)

            # ì¤‘ë³µ ì œê±°
            expired_keys = list(set(expired_keys))

            # ë§Œë£Œëœ í•­ëª© ì‚­ì œ
            for key in expired_keys:
                try:
                    del self.cache[key]
                    self._cache_stats['evictions'] += 1
                except:
                    pass

            if expired_keys:
                print(f"ğŸ§¹ ê³ ì„±ëŠ¥ ìºì‹œ ì •ë¦¬: {len(expired_keys)}ê°œ í•­ëª© ì œê±° (ìºì‹œ í¬ê¸°: {len(self.cache):,})")

            self._signal_stats['last_cleanup'] = current_time
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")

    def get_cached_data(self, key: str, max_age: int = 300) -> Optional[Any]:
        """ğŸš€ ìµœì í™”ëœ ìºì‹œ ë°ì´í„° ì¡°íšŒ"""
        return self.cache.get(key, max_age)

    def set_cached_data(self, key: str, data: Any):
        """ğŸš€ ìµœì í™”ëœ ìºì‹œ ë°ì´í„° ì €ì¥"""
        self.cache.set(key, data)

    def cleanup_old_signals(self, max_hours: int = 24):
        """ì˜¤ë˜ëœ ì‹œê·¸ë„ ì •ë¦¬ (ì„±ëŠ¥ ìµœì í™”)"""
        try:
            current_timestamp = int(datetime.now().timestamp())
            cutoff_timestamp = current_timestamp - (max_hours * 3600)
            
            with sqlite3.connect(DB_PATH) as conn:
                # ì˜¤ë˜ëœ ì‹œê·¸ë„ ì‚­ì œ
                deleted_count = conn.execute("""
                    DELETE FROM signals 
                    WHERE timestamp < ?
                """, (cutoff_timestamp,)).rowcount
                
                conn.commit()
                
                if deleted_count > 0:
                    print(f"ğŸ§¹ ì˜¤ë˜ëœ ì‹œê·¸ë„ ì •ë¦¬: {deleted_count}ê°œ ì‚­ì œ (>{max_hours}ì‹œê°„ ì „)")
                else:
                    print(f"â„¹ï¸ ì •ë¦¬í•  ì˜¤ë˜ëœ ì‹œê·¸ë„ ì—†ìŒ (>{max_hours}ì‹œê°„ ì „)")
                    
        except Exception as e:
            print(f"âš ï¸ ì‹œê·¸ë„ ì •ë¦¬ ì˜¤ë¥˜: {e}")
    

