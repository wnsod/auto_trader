"""
Label-Based Reward System - Phase 3
ë¼ë²¨ë§ í†µê³„ë¥¼ RL ë³´ìƒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œ
"""
import sys
import os
import logging
from typing import Dict, Optional, Tuple
from dataclasses import dataclass
import numpy as np

# ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from rl_pipeline.db.connection_pool import get_strategy_db_pool

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class RewardWeights:
    """ë³´ìƒ ê°€ì¤‘ì¹˜ ì„¤ì •"""
    w_pf: float = 0.3          # Profit Factor
    w_rmax: float = 0.25       # í‰ê·  ìµœëŒ€ìˆ˜ìµ
    w_rmin: float = 0.2        # í‰ê·  ìµœëŒ€ì†ì‹¤ (í˜ë„í‹°)
    w_win_rate: float = 0.15   # ìŠ¹ë¥ 
    w_latency: float = 0.05    # ì§€ì—° ì‹œê°„ (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
    w_sample: float = 0.05     # í‘œë³¸ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì‹ ë¢°)

@dataclass
class StrategyReward:
    """ì „ëµ ë³´ìƒ ì •ë³´"""
    strategy_id: str
    coin: str
    interval: str
    regime_tag: str

    # ë³´ìƒ êµ¬ì„±ìš”ì†Œ
    pf_reward: float
    rmax_reward: float
    rmin_penalty: float
    win_rate_reward: float
    latency_penalty: float
    sample_bonus: float

    # ìµœì¢… ë³´ìƒ
    total_reward: float
    normalized_reward: float  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”

    # ì¶”ê°€ ì •ë³´
    grade: str
    confidence: float

class LabelRewardSystem:
    """ë¼ë²¨ ê¸°ë°˜ ë³´ìƒ ì‹œìŠ¤í…œ"""

    def __init__(self, weights: Optional[RewardWeights] = None):
        self.weights = weights or RewardWeights()

        # ì •ê·œí™” íŒŒë¼ë¯¸í„° (ê²½í—˜ì  ê°’)
        self.norm_params = {
            'pf_max': 3.0,        # PF 3.0 ì´ìƒì€ ìµœëŒ€ ë³´ìƒ
            'rmax_max': 0.15,     # 15% ì´ìƒì€ ìµœëŒ€ ë³´ìƒ
            'rmin_max': 0.05,     # 5% ì†ì‹¤ê¹Œì§€ëŠ” í˜ë„í‹° ì¤‘ê°„
            'kmax_ref': 20,       # 20ìº”ë“¤ì´ ê¸°ì¤€
            'n_ref': 100          # 100ê°œ ìƒ˜í”Œì´ ê¸°ì¤€
        }

    def calculate_reward(self,
                        coin: str,
                        interval: str,
                        regime_tag: str,
                        strategy_id: str) -> Optional[StrategyReward]:
        """
        ì „ëµì˜ ë³´ìƒ ê³„ì‚°

        Args:
            coin: ì½”ì¸ëª…
            interval: ì¸í„°ë²Œ
            regime_tag: ë ˆì§ íƒœê·¸
            strategy_id: ì „ëµ ID

        Returns:
            StrategyReward ë˜ëŠ” None (í†µê³„ ì—†ìŒ)
        """
        pool = get_strategy_db_pool()
        with pool.get_connection() as conn:
            cursor = conn.cursor()

            # í†µê³„ ì¡°íšŒ
            cursor.execute("""
                SELECT rmax_mean, rmin_mean, kmax_mean, pf, win_rate, n_signals
                FROM strategy_label_stats
                WHERE coin = ? AND interval = ? AND regime_tag = ? AND strategy_id = ?
            """, (coin, interval, regime_tag, strategy_id))

            stats_row = cursor.fetchone()

            if not stats_row:
                return None

            rmax_mean, rmin_mean, kmax_mean, pf, win_rate, n_signals = stats_row

            # ë“±ê¸‰ ì¡°íšŒ
            cursor.execute("""
                SELECT grade, grade_score
                FROM strategy_grades
                WHERE strategy_id = ? AND interval = ? AND regime_tag = ?
            """, (strategy_id, interval, regime_tag))

            grade_row = cursor.fetchone()
            grade = grade_row[0] if grade_row else 'F'
            grade_score = grade_row[1] if grade_row else 0.0

        # 1. PF ë³´ìƒ (1.0 ì´ìƒì´ ì¢‹ìŒ)
        pf_reward = self._calculate_pf_reward(pf)

        # 2. r_max ë³´ìƒ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        rmax_reward = self._calculate_rmax_reward(rmax_mean)

        # 3. r_min í˜ë„í‹° (ì†ì‹¤ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
        rmin_penalty = self._calculate_rmin_penalty(rmin_mean)

        # 4. Win rate ë³´ìƒ
        win_rate_reward = self._calculate_win_rate_reward(win_rate)

        # 5. Latency í˜ë„í‹° (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
        latency_penalty = self._calculate_latency_penalty(kmax_mean)

        # 6. Sample ë³´ë„ˆìŠ¤ (ë§ì„ìˆ˜ë¡ ì‹ ë¢°)
        sample_bonus = self._calculate_sample_bonus(n_signals)

        # ì´ ë³´ìƒ ê³„ì‚°
        total_reward = (
            self.weights.w_pf * pf_reward +
            self.weights.w_rmax * rmax_reward -
            self.weights.w_rmin * rmin_penalty +
            self.weights.w_win_rate * win_rate_reward -
            self.weights.w_latency * latency_penalty +
            self.weights.w_sample * sample_bonus
        )

        # ì •ê·œí™” (0~1 ë²”ìœ„)
        # total_rewardëŠ” ëŒ€ëµ -0.5 ~ 1.5 ë²”ìœ„
        normalized_reward = (total_reward + 0.5) / 2.0
        normalized_reward = max(0.0, min(1.0, normalized_reward))

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(n_signals, grade)

        return StrategyReward(
            strategy_id=strategy_id,
            coin=coin,
            interval=interval,
            regime_tag=regime_tag,
            pf_reward=pf_reward,
            rmax_reward=rmax_reward,
            rmin_penalty=rmin_penalty,
            win_rate_reward=win_rate_reward,
            latency_penalty=latency_penalty,
            sample_bonus=sample_bonus,
            total_reward=total_reward,
            normalized_reward=normalized_reward,
            grade=grade,
            confidence=confidence
        )

    def _calculate_pf_reward(self, pf: float) -> float:
        """PF ë³´ìƒ ê³„ì‚°"""
        # PF 1.0 = 0 ë³´ìƒ, 3.0+ = 1.0 ë³´ìƒ
        return min((pf - 1.0) / (self.norm_params['pf_max'] - 1.0), 1.0)

    def _calculate_rmax_reward(self, rmax_mean: float) -> float:
        """r_max ë³´ìƒ ê³„ì‚°"""
        # 0% = 0 ë³´ìƒ, 15%+ = 1.0 ë³´ìƒ
        return min(rmax_mean / self.norm_params['rmax_max'], 1.0)

    def _calculate_rmin_penalty(self, rmin_mean: float) -> float:
        """r_min í˜ë„í‹° ê³„ì‚°"""
        # rminì€ ìŒìˆ˜, ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡ í˜ë„í‹°
        # 0% = 0 í˜ë„í‹°, 5%+ = 1.0 í˜ë„í‹°
        return min(abs(rmin_mean) / self.norm_params['rmin_max'], 1.0)

    def _calculate_win_rate_reward(self, win_rate: float) -> float:
        """ìŠ¹ë¥  ë³´ìƒ ê³„ì‚°"""
        # 50% = 0 ë³´ìƒ, 100% = 1.0 ë³´ìƒ
        return max((win_rate - 0.5) / 0.5, 0.0)

    def _calculate_latency_penalty(self, kmax_mean: float) -> float:
        """ì§€ì—° í˜ë„í‹° ê³„ì‚°"""
        # ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ
        # 0ìº”ë“¤ = 0 í˜ë„í‹°, 20ìº”ë“¤+ = 1.0 í˜ë„í‹°
        return min(kmax_mean / self.norm_params['kmax_ref'], 1.0)

    def _calculate_sample_bonus(self, n_signals: int) -> float:
        """í‘œë³¸ ë³´ë„ˆìŠ¤ ê³„ì‚°"""
        # ë§ì„ìˆ˜ë¡ ì‹ ë¢°
        # 0ê°œ = 0 ë³´ë„ˆìŠ¤, 100ê°œ+ = 1.0 ë³´ë„ˆìŠ¤
        return min(n_signals / self.norm_params['n_ref'], 1.0)

    def _calculate_confidence(self, n_signals: int, grade: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        # í‘œë³¸ ìˆ˜ ê¸°ë°˜
        n_score = min(n_signals / 200.0, 1.0)

        # ë“±ê¸‰ ê¸°ë°˜
        grade_scores = {'S': 1.0, 'A': 0.9, 'B': 0.8, 'C': 0.7, 'D': 0.5, 'F': 0.3}
        grade_score = grade_scores.get(grade, 0.5)

        # ê°€ì¤‘ í‰ê· 
        confidence = 0.6 * n_score + 0.4 * grade_score

        return confidence

    def calculate_batch_rewards(self,
                                strategies: list[Tuple[str, str, str, str]]
                               ) -> Dict[str, StrategyReward]:
        """
        ì—¬ëŸ¬ ì „ëµì˜ ë³´ìƒ ì¼ê´„ ê³„ì‚°

        Args:
            strategies: [(coin, interval, regime_tag, strategy_id), ...]

        Returns:
            {strategy_id: StrategyReward, ...}
        """
        results = {}

        for coin, interval, regime_tag, strategy_id in strategies:
            reward = self.calculate_reward(coin, interval, regime_tag, strategy_id)
            if reward:
                results[strategy_id] = reward

        return results

def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ Label-Based Reward System í…ŒìŠ¤íŠ¸\n")

    reward_system = LabelRewardSystem()

    # ìƒìœ„ ë“±ê¸‰ ì „ëµìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    pool = get_strategy_db_pool()
    with pool.get_connection() as conn:
        cursor = conn.cursor()

        cursor.execute("""
            SELECT DISTINCT s.coin, s.interval, s.regime_tag, s.strategy_id, g.grade
            FROM strategy_label_stats s
            JOIN strategy_grades g
                ON s.strategy_id = g.strategy_id
                AND s.interval = g.interval
                AND s.regime_tag = g.regime_tag
            WHERE g.grade IN ('S', 'A', 'B', 'C')
            ORDER BY g.grade_score DESC
            LIMIT 10
        """)

        test_strategies = cursor.fetchall()

    logger.info(f"âœ… {len(test_strategies)}ê°œ ì „ëµ í…ŒìŠ¤íŠ¸\n")

    for coin, interval, regime_tag, strategy_id, grade in test_strategies:
        reward = reward_system.calculate_reward(coin, interval, regime_tag, strategy_id)

        if reward:
            logger.info(f"ğŸ“Š [{grade}] {coin} {interval} {regime_tag}")
            logger.info(f"   ì „ëµ: {strategy_id[:50]}...")
            logger.info(f"   ë³´ìƒ êµ¬ì„±:")
            logger.info(f"     PF: {reward.pf_reward:.3f}")
            logger.info(f"     R_max: {reward.rmax_reward:.3f}")
            logger.info(f"     R_min penalty: {reward.rmin_penalty:.3f}")
            logger.info(f"     Win rate: {reward.win_rate_reward:.3f}")
            logger.info(f"     Latency penalty: {reward.latency_penalty:.3f}")
            logger.info(f"     Sample bonus: {reward.sample_bonus:.3f}")
            logger.info(f"   âœ… Total Reward: {reward.total_reward:.3f}")
            logger.info(f"   âœ… Normalized: {reward.normalized_reward:.3f}")
            logger.info(f"   âœ… Confidence: {reward.confidence:.1%}\n")

    logger.info("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
