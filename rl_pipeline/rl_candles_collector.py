import sys
sys.path.insert(0, '/workspace/')  # ì ˆëŒ€ ê²½ë¡œ ì¶”ê°€

import sqlite3
import asyncio
import aiohttp
import pandas as pd
import os
import time
from datetime import datetime, timedelta, timezone
from threading import Thread
from queue import Queue
from collections import defaultdict

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì • (envì—ì„œ ê°€ì ¸ì˜¤ê¸°)
from rl_pipeline.core.env import config
DB_PATH = config.RL_DB  # CANDLES_DB_PATH
INTERVALS = ['15m', '30m', '240m', '1d']
KST = timezone(timedelta(hours=9))

# ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì½”ì¸ ëª©ë¡ (Noneì´ë©´ ì „ì²´ ì½”ì¸ ìˆ˜ì§‘, ë¦¬ìŠ¤íŠ¸ë©´ ì§€ì •ëœ ì½”ì¸ë§Œ ìˆ˜ì§‘)
TEST_COINS = ['BTC', 'ETH', 'XRP', 'DOGE', 'SOL', 'ADA', 'DOT', 'LINK', 'AVAX', 'BNB']  # ë©”ì´ì € ì½”ì¸ 10ê°œ

# ğŸš€ ìµœì í™”ëœ ë™ì‹œì„± ì œì–´ ì„¤ì •
MAX_CONCURRENT_REQUESTS = 50  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì¦ê°€
REQUEST_TIMEOUT = 15  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
RETRY_ATTEMPTS = 2  # ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 0.5  # ì¬ì‹œë„ ê°„ê²©
RATE_LIMIT_DELAY = 1.0  # 429 ì—ëŸ¬ ì‹œ ëŒ€ê¸° ì‹œê°„
MAX_RATE_LIMIT_RETRIES = 3  # 429 ì—ëŸ¬ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

# ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
save_queue = asyncio.Queue(maxsize=3000)  # í í¬ê¸° ì¦ê°€

# 429 rate limit ë¡œê·¸ ìš”ì•½ìš©
rate_limit_counter = defaultdict(int)
rate_limit_last_print = defaultdict(float)

# ğŸš€ ì‹¤íŒ¨í•œ ìš”ì²­ ì¶”ì ìš© (ê°„ì†Œí™”)
failed_requests = set()  # (coin, interval) íŠœí”Œë¡œ ì €ì¥
failed_requests_lock = asyncio.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½

# ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
class PerformanceMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        self.total_candles = 0
        self.last_progress_time = time.time()
        self.progress_interval = 10  # 10ì´ˆë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
        
    def log_request(self, success: bool, candle_count: int = 0):
        self.request_count += 1
        if success:
            self.success_count += 1
            self.total_candles += candle_count
        else:
            self.error_count += 1
        
        # ì§„í–‰ë¥  ì¶œë ¥
        current_time = time.time()
        if current_time - self.last_progress_time >= self.progress_interval:
            self._print_progress()
            self.last_progress_time = current_time
    
    def _print_progress(self):
        elapsed = time.time() - self.start_time
        if elapsed > 0:
            rps = self.request_count / elapsed
            cps = self.total_candles / elapsed
            success_rate = self.success_count / self.request_count if self.request_count > 0 else 0
            print(f"ğŸ“ˆ ì§„í–‰ë¥ : {self.request_count:,} ìš”ì²­, {self.total_candles:,} ìº”ë“¤, "
                  f"{rps:.1f} req/s, {cps:.0f} ìº”ë“¤/s, ì„±ê³µë¥ : {success_rate:.1%}")
    
    def get_stats(self):
        elapsed = time.time() - self.start_time
        return {
            'elapsed_time': elapsed,
            'requests_per_second': self.request_count / elapsed if elapsed > 0 else 0,
            'success_rate': self.success_count / self.request_count if self.request_count > 0 else 0,
            'total_candles': self.total_candles,
            'candles_per_second': self.total_candles / elapsed if elapsed > 0 else 0
        }

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
performance_monitor = PerformanceMonitor()

# ğŸš€ Rate limitingì„ ìœ„í•œ ë”œë ˆì´ ê´€ë¦¬
class RateLimiter:
    def __init__(self):
        self.last_request_time = 0
        self.min_interval = 0.02  # 20ms ê°„ê²© (ì´ˆë‹¹ 50 ìš”ì²­) - ìµœì í™”ë¨
        self.rate_limit_until = 0
    
    async def wait_if_needed(self):
        current_time = time.time()
        
        # Rate limit ëŒ€ê¸°
        if current_time < self.rate_limit_until:
            wait_time = self.rate_limit_until - current_time
            print(f"â³ Rate limit ëŒ€ê¸°: {wait_time:.1f}ì´ˆ")
            await asyncio.sleep(wait_time)
            current_time = time.time()
        
        # ìµœì†Œ ê°„ê²© ëŒ€ê¸°
        time_since_last = current_time - self.last_request_time
        if time_since_last < self.min_interval:
            await asyncio.sleep(self.min_interval - time_since_last)
        
        self.last_request_time = time.time()
    
    def set_rate_limit(self, retry_after=None):
        """429 ì—ëŸ¬ ì‹œ rate limit ì„¤ì •"""
        if retry_after:
            self.rate_limit_until = time.time() + retry_after
        else:
            self.rate_limit_until = time.time() + RATE_LIMIT_DELAY

# ì „ì—­ rate limiter
rate_limiter = RateLimiter()

# í…Œì´ë¸” ìƒì„±
def create_table():
    # ê¸°ì¡´ DB íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
    if os.path.exists(DB_PATH):
        os.remove(DB_PATH)
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„± (ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ)
    cursor.execute("""
    CREATE TABLE candles (
        -- ğŸ·ï¸ ê¸°ë³¸ ì‹ë³„ì (3ê°œ)
        coin TEXT,
        interval TEXT,
        timestamp INTEGER,
        -- ğŸ’° ê¸°ë³¸ OHLCV (4ê°œ)
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        volume REAL,
        -- ğŸ“‰ í•µì‹¬ ì˜¤ì‹¤ë ˆì´í„° (2ê°œ)
        rsi REAL,
        mfi REAL,
        -- ğŸ“Š í•µì‹¬ íŠ¸ë Œë“œ (2ê°œ)
        macd REAL,
        macd_signal REAL,
        -- ğŸŒ í•µì‹¬ ë³¼ë¦°ì €ë°´ë“œ (5ê°œ)
        bb_upper REAL,
        bb_middle REAL,
        bb_lower REAL,
        bb_position REAL,
        bb_width REAL,
        -- ğŸ“ˆ í•µì‹¬ ì¶”ì„¸/ë³€ë™ì„± (3ê°œ)
        atr REAL,
        ma20 REAL,
        adx REAL,
        -- ğŸ“Š í•µì‹¬ ê±°ë˜ëŸ‰ (1ê°œ)
        volume_ratio REAL,
        -- âš ï¸ í•µì‹¬ ë¦¬ìŠ¤í¬ (1ê°œ)
        risk_score REAL,
        -- ğŸ§  í•µì‹¬ íŒŒë™ (2ê°œ)
        wave_phase TEXT,
        confidence REAL,
        -- ğŸ”„ í•µì‹¬ íŒŒë™ ë¶„ì„ (3ê°œ)
        zigzag_direction REAL,
        zigzag_pivot_price REAL,
        wave_progress REAL,
        -- ğŸ¯ í•µì‹¬ íŒ¨í„´ ë¶„ì„ (2ê°œ)
        pattern_type TEXT,
        pattern_confidence REAL,
        -- ğŸ§  í•µì‹¬ í†µí•© ë¶„ì„ (3ê°œ)
        volatility_level TEXT,
        risk_level TEXT,
        integrated_direction TEXT,
        -- ğŸš€ êµ¬ì¡° ì ìˆ˜ (1ê°œ)
        structure_score REAL,
        -- ğŸš€ ì‹¬ë¦¬ë„ ë¶„ì„ (2ê°œ)
        sentiment REAL,
        sentiment_label TEXT,
        PRIMARY KEY (coin, interval, timestamp)
    )
    """)
    
    # ğŸš€ ì¸ë±ìŠ¤ ì¶”ê°€ë¡œ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_coin_interval ON candles(coin, interval)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON candles(timestamp)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_coin_timestamp ON candles(coin, timestamp)')
    
    conn.commit()
    conn.close()

# ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ (ë¹„ë™ê¸° ë²„ì „) - ìµœê·¼ 100ê°œë§Œ ìœ ì§€
async def candle_saver_worker(save_queue):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ - ìµœê·¼ 100ê°œë§Œ ìœ ì§€"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    total_saved = 0
    batch_data = []
    batch_size = 1000  # ë°°ì¹˜ í¬ê¸° ì¦ê°€

    while True:
        try:
            item = await save_queue.get()
            if item is None:
                # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
                if batch_data:
                    cursor.executemany('''
                        INSERT OR REPLACE INTO candles (
                            coin, interval, timestamp, open, high, low, close, volume
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    ''', batch_data)
                    conn.commit()
                    total_saved += len(batch_data)
                print(f"ğŸ’¾ ì´ ì €ì¥ëœ ìº”ë“¤: {total_saved:,}ê°œ")
                break

            coin, interval, candles = item

            # ë°°ì¹˜ ë°ì´í„° ì¶”ê°€
            for c in candles:
                # Unix timestampë¡œ ë³€í™˜
                timestamp = int(pd.to_datetime(c['timestamp'], format='%Y-%m-%dT%H:%M:%S').timestamp())
                
                batch_data.append((
                    coin, interval, timestamp,
                    c['open'], c['high'], c['low'], c['close'], c['volume']
                ))

            # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ DBì— ì €ì¥
            if len(batch_data) >= batch_size:
                cursor.executemany('''
                    INSERT OR REPLACE INTO candles (
                        coin, interval, timestamp, open, high, low, close, volume
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', batch_data)
                conn.commit()
                total_saved += len(batch_data)
                batch_data.clear()

        except Exception as e:
            print(f"âš ï¸ ì €ì¥ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            continue

    conn.close()
    
def build_url(interval):
    interval_map = {
        "15m": "https://api.bithumb.com/v1/candles/minutes/15",
        "30m": "https://api.bithumb.com/v1/candles/minutes/30",
        "240m": "https://api.bithumb.com/v1/candles/minutes/240",
        "1d": "https://api.bithumb.com/v1/candles/days"
    }
    return interval_map.get(interval)

async def get_all_coins(session: aiohttp.ClientSession):
    """ğŸš€ ìµœì í™”ëœ ì½”ì¸ ëª©ë¡ ì¡°íšŒ"""
    url = "https://api.bithumb.com/public/ticker/ALL_KRW"
    
    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    data = await response.json()
                    coins = [coin for coin in data["data"] if coin != "date"]
                    print(f"âœ… ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ: {len(coins)}ê°œ")
                    return coins
                elif response.status == 429:
                    # Rate limit ì²˜ë¦¬
                    retry_after = None
                    try:
                        retry_after_header = response.headers.get('Retry-After')
                        if retry_after_header:
                            retry_after = int(retry_after_header)
                    except:
                        pass
                    
                    rate_limiter.set_rate_limit(retry_after)
                    print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ Rate limit (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS})")
                    
                    if attempt < RETRY_ATTEMPTS - 1:
                        backoff_delay = RETRY_DELAY * (2 ** attempt)
                        await asyncio.sleep(backoff_delay)
                        await rate_limiter.wait_if_needed()
                    continue
                else:
                    print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ (HTTP {response.status})")
        except Exception as e:
            print(f"âš ï¸ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS}): {e}")
            if attempt < RETRY_ATTEMPTS - 1:
                backoff_delay = RETRY_DELAY * (2 ** attempt)
                await asyncio.sleep(backoff_delay)
    
    return []

async def fetch_candles(session: aiohttp.ClientSession, coin: str, interval: str, from_ts: int, to_ts: int):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨) - ê³¼ê±° ìˆ˜ì§‘ ì§€ì›"""
    url = build_url(interval)
    if not url:
        return []

    to_dt = datetime.fromtimestamp(to_ts, tz=KST)
    params = {
        "market": f"KRW-{coin}",
        "count": 200,
        "to": to_dt.strftime("%Y-%m-%dT%H:%M:%S")
    }
    
    key = f"{coin}/{interval}"

    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, params=params, timeout=timeout) as response:
                if response.status == 429:
                    rate_limit_counter[key] += 1
                    now = time.time()
                    if rate_limit_counter[key] % 10 == 1 or now - rate_limit_last_print[key] > 10:
                        rate_limit_last_print[key] = now
                    # Rate Limit ëŒ€ì‘: ë” ê¸´ ëŒ€ê¸° ì‹œê°„ ì ìš©
                    wait_time = min(3.0, rate_limit_counter[key] * 1.5)  # ìµœëŒ€ 3ì´ˆê¹Œì§€ ì¦ê°€
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    rate_limit_counter[key] = 0  # ì •ìƒ ì‘ë‹µì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
                
                if response.status == 200:
                    data = await response.json()
                    if not isinstance(data, list):
                        performance_monitor.log_request(False)
                        return []

                    candles = []
                    seen_timestamps = set()
                    
                    for candle in data:
                        try:
                            timestamp = candle.get('candle_date_time_kst')
                            if timestamp in seen_timestamps or not timestamp:
                                continue  # ì¤‘ë³µ ë˜ëŠ” ì˜ëª»ëœ íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì œì™¸
                            seen_timestamps.add(timestamp)

                            candles.append({
                                'timestamp': timestamp,
                                'open': float(candle.get('opening_price', 0)),
                                'high': float(candle.get('high_price', 0)),
                                'low': float(candle.get('low_price', 0)),
                                'close': float(candle.get('trade_price', 0)),
                                'volume': round(float(candle.get('candle_acc_trade_price', 0)), 4)
                            })
                        except (ValueError, KeyError) as e:
                            continue

                    performance_monitor.log_request(True, len(candles))
                    return candles
                else:
                    pass
                    
        except asyncio.TimeoutError:
            pass
        except Exception as e:
            pass
        
        if attempt < RETRY_ATTEMPTS - 1:
            # ì§€ìˆ˜ ë°±ì˜¤í”„
            backoff_delay = RETRY_DELAY * (2 ** attempt)
            await asyncio.sleep(backoff_delay)
    
    performance_monitor.log_request(False)
    
    # ì‹¤íŒ¨í•œ ìš”ì²­ ê¸°ë¡
    async with failed_requests_lock:
        failed_requests.add((coin, interval))
    
    return []

interval_minutes = {'15m': 15, '30m': 30, '240m': 240, '1d': 1440}

def split_into_chunks(from_ts, to_ts, gap_sec):
    chunks = []
    while to_ts > from_ts:
        end = to_ts
        start = max(from_ts, to_ts - gap_sec * 200)
        chunks.append((start, end))
        to_ts = start - gap_sec
    return chunks

# ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
async def fetch_all(save_queue):
    """ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""

    connector = aiohttp.TCPConnector(
        limit=MAX_CONCURRENT_REQUESTS * 3,
        limit_per_host=MAX_CONCURRENT_REQUESTS * 2,
        ttl_dns_cache=300,
        use_dns_cache=True,
        keepalive_timeout=30,
        enable_cleanup_closed=True
    )

    timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={'User-Agent': 'Mozilla/5.0 (compatible; TradingBot/2.0)'}
    ) as session:
        coins = await get_all_coins(session)
        if not coins:
            return
        
        # ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì½”ì¸ í•„í„°ë§
        if TEST_COINS is not None:
            # TEST_COINSì— ì§€ì •ëœ ì½”ì¸ë§Œ í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
            coins_dict = {coin.upper(): coin for coin in coins}  # ì›ë³¸ ì½”ì¸ëª… ìœ ì§€
            filtered_coins = []
            not_found = []
            
            for test_coin in TEST_COINS:
                test_coin_upper = test_coin.upper()
                if test_coin_upper in coins_dict:
                    filtered_coins.append(coins_dict[test_coin_upper])
                else:
                    not_found.append(test_coin)
            
            coins = filtered_coins
            if not_found:
                print(f"âš ï¸ ë‹¤ìŒ ì½”ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(not_found)}")
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì§€ì •ëœ ì½”ì¸ {len(coins)}ê°œë§Œ ìˆ˜ì§‘ ({', '.join(coins)})")
        elif len(coins) > 10:
            # TEST_COINSê°€ Noneì´ê³  ì½”ì¸ì´ ë§ìœ¼ë©´ ì²˜ìŒ 10ê°œë§Œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            coins = coins[:10]
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì½”ì¸ 10ê°œë¡œ ì œí•œ ({', '.join(coins)})")


        # ê³¼ê±° ìˆ˜ì§‘ ê¸°ê°„ì€ ì¸í„°ë²Œë³„ë¡œ ìƒì´: 15m/30m/240m â†’ 45ì¼, 1d â†’ 60ì¼
        total_tasks = 0

        end_time_global = datetime.now(KST)
        for interval in INTERVALS:
            gap_sec = interval_minutes[interval] * 60
            print(f"\nâ° {interval} ìº”ë“¤ ìˆ˜ì§‘ ì¤‘...")

            interval_tasks = []
            # ì¸í„°ë²Œë³„ ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •
            days_back = 60 if interval == '1d' else 45
            start_time = end_time_global - timedelta(days=days_back)
            start_ts = int(start_time.timestamp())
            end_ts = int(end_time_global.timestamp()) - 300
            for coin in coins:
                chunks = split_into_chunks(start_ts, end_ts, gap_sec)
                
                for start, end in chunks:
                    task = limited_fetch(session, coin, interval, start, end, save_queue)
                    interval_tasks.append(task)

            total_tasks += len(interval_tasks)
            print(f"ğŸ“‹ {interval}: {len(interval_tasks):,}ê°œ íƒœìŠ¤í¬ ìƒì„±")

            # ğŸš€ ë” í° ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹¤í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            batch_size = 200  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            completed_tasks = 0

            for i in range(0, len(interval_tasks), batch_size):
                batch = interval_tasks[i:i + batch_size]
                results = await asyncio.gather(*batch, return_exceptions=True)

                # ê²°ê³¼ ì²˜ë¦¬
                for result in results:
                    if isinstance(result, Exception):
                        print(f"âš ï¸ íƒœìŠ¤í¬ ì‹¤í–‰ ì˜¤ë¥˜: {result}")
                    elif result:
                        pass  # ì„±ê³µí•œ ê²½ìš° (ì´ë¯¸ íì— ì¶”ê°€ë¨)

                completed_tasks += len(batch)
                if completed_tasks % (batch_size * 5) == 0:  # 5ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
                    print(f"ğŸ“ˆ {interval} ì§„í–‰ë¥ : {completed_tasks:,}/{len(interval_tasks):,} ({completed_tasks/len(interval_tasks)*100:.1f}%)")


        # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ì²˜ë¦¬ (íŒŒì¼ ì €ì¥ ì œê±°)
        if failed_requests:
            logger.warning(f"âš ï¸ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ({len(failed_requests)}ê°œ): {failed_requests}")
        else:
            logger.info("âœ… ëª¨ë“  ìš”ì²­ ì„±ê³µ!")

        stats = performance_monitor.get_stats()

        # ğŸš€ ì„±ëŠ¥ í‰ê°€
        if stats['requests_per_second'] > 50:
            pass
        elif stats['requests_per_second'] > 35:
            pass
        else:
            pass
            
async def limited_fetch(session: aiohttp.ClientSession, coin: str, interval: str, start_ts: int, end_ts: int, save_queue):
    """ğŸš€ ìµœì í™”ëœ ì œí•œëœ í˜ì¹˜ (ì„¸ë§ˆí¬ì–´ ì œì–´)"""
    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        candles = await fetch_candles(session, coin, interval, start_ts, end_ts)
        await asyncio.sleep(0.02)  # ìµœì†Œ ì§€ì—° ì‹œê°„ (50 ë™ì‹œ ìš”ì²­ ëŒ€ì‘)
        if candles:
            await save_queue.put((coin, interval, candles))
        return candles

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë¹„ë™ê¸° ë²„ì „)
async def main():
    
    # í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)
    create_table()
    
    
    # ğŸš€ ì„±ëŠ¥ ì˜ˆì¸¡
    estimated_coins = 400  # ì˜ˆìƒ ì½”ì¸ ìˆ˜
    estimated_requests = estimated_coins * len(INTERVALS) * 8  # 4ê°œ ì¸í„°ë²Œ Ã— 8íšŒ ìš”ì²­/ì½”ì¸
    estimated_time = estimated_requests / 50  # ì´ˆë‹¹ 50 ìš”ì²­ ê°€ì •

    # ğŸ§ª ì´ë²¤íŠ¸ ë£¨í”„ì— ë°”ì¸ë”©ëœ save_queue ìƒì„±
    save_queue = asyncio.Queue(maxsize=3000)

    # ğŸš€ ì €ì¥ ì›Œì»¤ ì‹œì‘
    worker = asyncio.create_task(candle_saver_worker(save_queue))

    try:
        # ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        await fetch_all(save_queue)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        pass

    # ğŸš€ ì›Œì»¤ ì¢…ë£Œ ì‹ í˜¸
    await save_queue.put(None)
    await worker

if __name__ == "__main__":
    asyncio.run(main())