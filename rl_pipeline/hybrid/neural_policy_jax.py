"""
JAX ê¸°ë°˜ ì‹ ê²½ë§ ì •ì±… ë„¤íŠ¸ì›Œí¬
PPOìš© ì •ì±… ë° ê°€ì¹˜ ë„¤íŠ¸ì›Œí¬
"""

import logging
import os
import pickle
import struct
import warnings
from typing import Dict, Tuple, Optional
import numpy as np

logger = logging.getLogger(__name__)

# TensorFlow Protobuf ê²½ê³  ìˆ¨ê¹€ (JAX ë¡œë“œ ì‹œ ë°œìƒí•˜ëŠ” ê²½ê³ , ê¸°ëŠ¥ ì˜í–¥ ì—†ìŒ)
warnings.filterwarnings('ignore', message='.*Protobuf gencode version.*', category=UserWarning)
warnings.filterwarnings('ignore', message='.*Sharding info not provided.*', category=UserWarning)

# JAX ê°€ìš©ì„± í™•ì¸ ë° CUDA ë°±ì—”ë“œ ì´ˆê¸°í™”
try:
    import logging as std_logging
    
    # ğŸ”¥ JAX ë¡œë“œ ì „ì— í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (CUDA ìš°ì„ , ì‹¤íŒ¨ ì‹œ CPU ìë™ ì „í™˜)
    # JAX_PLATFORMSì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œë¥¼ ì„ íƒ
    if 'JAX_PLATFORMS' not in os.environ:
        os.environ['JAX_PLATFORMS'] = ''  # ìë™ ë°±ì—”ë“œ ì„ íƒ (CUDAê°€ ìˆìœ¼ë©´ CUDA, ì—†ìœ¼ë©´ CPU)
    
    # JAX TPU ë°±ì—”ë“œ ê²½ê³  ë¡œê±° ë ˆë²¨ ì¡°ì • (ê²½ê³  ìˆ¨ê¹€)
    jax_logger = std_logging.getLogger('jax._src.xla_bridge')
    jax_logger.setLevel(std_logging.CRITICAL)  # TPU ê´€ë ¨ ë©”ì‹œì§€ ìˆ¨ê¹€
    
    import jax
    import jax.numpy as jnp
    from flax import linen as nn
    from flax.training import checkpoints
    
    # ğŸ”¥ CUDA ë°±ì—”ë“œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    try:
        # JAX í”Œë«í¼ ì´ˆê¸°í™” ì‹œë„ (ì¡°ìš©íˆ)
        devices = jax.devices()
        available_backends = jax.devices()[0].platform if devices else 'unknown'
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        cuda_available = any('gpu' in str(d).lower() or 'cuda' in str(d).lower() for d in devices)
        
        if cuda_available:
            logger.info(f"âœ… JAX CUDA ë°±ì—”ë“œ ì‚¬ìš© ê°€ëŠ¥: {devices}")
            # CUDA ì‚¬ìš© ê°•ì œ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                jax.config.update('jax_platform_name', 'cuda')
                logger.info("âœ… JAX CUDA í”Œë«í¼ ì„¤ì • ì™„ë£Œ")
            except Exception as config_err:
                logger.debug(f"âš ï¸ JAX CUDA í”Œë«í¼ ê°•ì œ ì„¤ì • ì‹¤íŒ¨, ìë™ ì„ íƒ ì‚¬ìš©: {config_err}")
        else:
            logger.info(f"ğŸ’» JAX CPU ë°±ì—”ë“œ ì‚¬ìš©: {devices} (CUDA ì‚¬ìš© ë¶ˆê°€)")
            # CPUë¡œ ëª…ì‹œì  ì„¤ì •
            try:
                jax.config.update('jax_platform_name', 'cpu')
            except:
                pass
    except Exception as device_check_err:
        logger.debug(f"ğŸ’» JAX ë””ë°”ì´ìŠ¤ í™•ì¸ ì‹¤íŒ¨, CPU ëª¨ë“œë¡œ ì§„í–‰: {device_check_err}")
        try:
            jax.config.update('jax_platform_name', 'cpu')
        except:
            pass
    
    # ğŸ”§ Orbax ì²´í¬í¬ì¸íŠ¸ ë¡œê±° ë ˆë²¨ ì¡°ì • (ê³¼ë„í•œ INFO ë©”ì‹œì§€ ìˆ¨ê¹€)
    orbax_loggers = [
        'orbax.checkpoint',
        'orbax.checkpoint.checkpoint_handler',
        'orbax.checkpoint.checkpoints',
        'jax.checkpoint',  # JAX checkpoint ëª¨ë“ˆ
        'flax.training.checkpoints'  # Flax checkpoints
    ]
    for logger_name in orbax_loggers:
        orbax_logger = std_logging.getLogger(logger_name)
        orbax_logger.setLevel(std_logging.WARNING)  # WARNING ì´ìƒë§Œ í‘œì‹œ (INFO ìˆ¨ê¹€)
    
    JAX_AVAILABLE = True
except ImportError:
    JAX_AVAILABLE = False
    jax = None
    jnp = None
    nn = None
    logger.warning("âš ï¸ JAX/Flaxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install jax[cuda12] ë˜ëŠ” jax[cuda11] (RTX 5090ìš©)")
except Exception as e:
    # JAX ì´ˆê¸°í™” ì¤‘ ë‹¤ë¥¸ ì—ëŸ¬ ë°œìƒ ì‹œ CPU ëª¨ë“œë¡œ í´ë°±
    logger.warning(f"âš ï¸ JAX ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}, CPU ëª¨ë“œë¡œ ì§„í–‰")
    try:
        os.environ['JAX_PLATFORMS'] = 'cpu'
        import jax
        import jax.numpy as jnp
        from flax import linen as nn
        from flax.training import checkpoints
        jax.config.update('jax_platform_name', 'cpu')
        JAX_AVAILABLE = True
        logger.info("ğŸ’» JAX CPU ëª¨ë“œë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
    except:
        JAX_AVAILABLE = False
        jax = None
        jnp = None
        nn = None


if JAX_AVAILABLE:
    class PolicyNetwork(nn.Module):
        """ì •ì±… ë„¤íŠ¸ì›Œí¬ (PPOìš©)"""
        
        hidden_dim: int = 128
        action_dim: int = 3  # HOLD, BUY, SELL
        
        @nn.compact
        def __call__(self, x):
            """
            ìˆœì „íŒŒ

            Args:
                x: ìƒíƒœ ë²¡í„° (batch_size, obs_dim)

            Returns:
                action_logits: (batch_size, action_dim) - ë°©í–¥ ì˜ˆì¸¡ (UP/DOWN/NEUTRAL)
                value: (batch_size, 1) - ìƒíƒœ ê°€ì¹˜
                price_change: (batch_size, 1) - ë³€ë™ë¥  ì˜ˆì¸¡ (%)
                horizon: (batch_size, 1) - íƒ€ì´ë° ì˜ˆì¸¡ (ìº”ë“¤ ìˆ˜)
            """
            # ğŸ”¥ í•™ìŠµ ì„±ëŠ¥ ê°œì„ : ì´ˆê¸°í™” ê°œì„  (Xavier/Glorot ì´ˆê¸°í™”)
            # kernel_init: Xavier uniform ì´ˆê¸°í™” (ë” ì•ˆì •ì ì¸ í•™ìŠµ)
            kernel_init = nn.initializers.xavier_uniform()
            bias_init = nn.initializers.zeros_init()

            # ê³µìœ  ë ˆì´ì–´
            x = nn.Dense(
                self.hidden_dim,
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)
            x = nn.relu(x)
            x = nn.Dense(
                self.hidden_dim,
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)
            x = nn.relu(x)

            # ë¶„ê¸°: 4ê°œì˜ í—¤ë“œ
            # ğŸ”¥ Action head: ë°©í–¥ ë¶„ë¥˜ (UP/DOWN/NEUTRAL)
            action_kernel_init = nn.initializers.xavier_uniform()
            action_logits = nn.Dense(
                self.action_dim,
                name='action_head',
                kernel_init=action_kernel_init,
                bias_init=bias_init
            )(x)

            # Value head: ìƒíƒœ ê°€ì¹˜
            value = nn.Dense(
                1,
                name='value_head',
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)

            # ğŸ†• Price change head: ë³€ë™ë¥  ì˜ˆì¸¡ (íšŒê·€)
            # ë²”ìœ„: -10% ~ +10% ì •ë„ ì˜ˆìƒ
            price_change = nn.Dense(
                1,
                name='price_change_head',
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)
            # tanhë¡œ ë²”ìœ„ ì œí•œ í›„ ìŠ¤ì¼€ì¼ë§: -0.1 ~ +0.1 (Â±10%)
            price_change = jnp.tanh(price_change) * 0.1

            # ğŸ†• Horizon head: íƒ€ì´ë° ì˜ˆì¸¡ (íšŒê·€)
            # ë²”ìœ„: 1 ~ 20 ìº”ë“¤ ì •ë„ ì˜ˆìƒ
            horizon = nn.Dense(
                1,
                name='horizon_head',
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)
            # sigmoidë¡œ 0~1 ë²”ìœ„ë¡œ ë§Œë“  í›„ 1~20ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
            horizon = nn.sigmoid(horizon) * 19 + 1

            # ğŸ†• Analysis head: ë¶„ì„ ì ìˆ˜ ì˜ˆì¸¡ (íšŒê·€)
            # ë²”ìœ„: 0 ~ 100 (ë¶„ì„ ì ìˆ˜ëŠ” 0~100 ì‚¬ì´)
            analysis_score = nn.Dense(
                1,
                name='analysis_head',
                kernel_init=kernel_init,
                bias_init=bias_init
            )(x)
            # sigmoidë¡œ 0~1 ë²”ìœ„ë¡œ ë§Œë“  í›„ 100ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
            analysis_score = nn.sigmoid(analysis_score) * 100.0

            return action_logits, value, price_change, horizon, analysis_score
else:
    # JAX ì—†ì„ ë•Œ í´ë°± í´ë˜ìŠ¤
    class PolicyNetwork:
        """í´ë°± ì •ì±… ë„¤íŠ¸ì›Œí¬ (JAX ë¯¸ì„¤ì¹˜ ì‹œ - ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±)"""
        pass


def init_model(
    rng_key,
    obs_dim: int = 25,  # ğŸ”¥ í™•ì¥ ì§€í‘œ í¬í•¨ ê¸°ë³¸ê°’ (20 â†’ 25)
    action_dim: int = 3,
    hidden_dim: int = 128
) -> Dict:
    """
    ëª¨ë¸ ì´ˆê¸°í™”
    
    Args:
        rng_key: JAX ëœë¤ í‚¤
        obs_dim: ê´€ì¸¡ ì°¨ì› (ê¸°ë³¸ 25: í™•ì¥ ì§€í‘œ í¬í•¨)
        action_dim: ì•¡ì…˜ ì°¨ì› (ê¸°ë³¸ 3: HOLD/BUY/SELL)
        hidden_dim: ì€ë‹‰ì¸µ ì°¨ì› (ê¸°ë³¸ 128)
    
    Returns:
        {
            'params': Flax params,
            'model_def': PolicyNetwork,
            'obs_dim': int,
            'action_dim': int,
            'hidden_dim': int
        }
    """
    if not JAX_AVAILABLE:
        raise ImportError("JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install jax flax")
    
    model = PolicyNetwork(hidden_dim=hidden_dim, action_dim=action_dim)
    
    # ëª¨ë¸ ì´ˆê¸°í™”ìš© ìƒ˜í”Œ ì…ë ¥ ìƒì„±
    sample_input = jnp.ones((1, obs_dim))
    params = model.init(rng_key, sample_input)
    
    logger.info(f"âœ… ì •ì±… ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™” ì™„ë£Œ: obs_dim={obs_dim}, action_dim={action_dim}, hidden_dim={hidden_dim}")
    
    return {
        'params': params,
        'model_def': model,
        'obs_dim': obs_dim,
        'action_dim': action_dim,
        'hidden_dim': hidden_dim
    }


def apply(
    params: Dict,
    state_vec: np.ndarray,
    rng_key,
    deterministic: bool = False
) -> Dict:
    """
    ìˆœì „íŒŒ: state_vector â†’ action_logits, value
    
    Args:
        params: ëª¨ë¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        state_vec: ìƒíƒœ ë²¡í„° (obs_dim,) ë˜ëŠ” (batch_size, obs_dim)
        rng_key: JAX ëœë¤ í‚¤
        deterministic: Trueë©´ ìµœëŒ€ í™•ë¥  ì•¡ì…˜, Falseë©´ ìƒ˜í”Œë§
    
    Returns:
        {
            'action_logits': np.ndarray,  # (action_dim,)
            'value': float,
            'action_probs': np.ndarray,  # (action_dim,)
            'action': int,  # 0: HOLD, 1: BUY, 2: SELL
            'action_name': str,
            'confidence': float  # ìµœëŒ€ í™•ë¥ 
        }
    """
    if not JAX_AVAILABLE:
        raise ImportError("JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    model = params['model_def']
    
    # ì…ë ¥ í˜•íƒœ í™•ì¸ ë° ë³€í™˜
    state_vec = np.asarray(state_vec, dtype=np.float32)
    if state_vec.ndim == 1:
        state_vec = state_vec.reshape(1, -1)
    
    state_vec_jax = jnp.array(state_vec)
    
    # ìˆœì „íŒŒ
    action_logits, value, price_change, horizon, analysis_score = model.apply(params['params'], state_vec_jax)

    # ğŸ”¥ ì•¡ì…˜ ìƒ˜í”Œë§ ê°œì„ : Temperature ê¸°ë°˜ íƒí—˜ ê°•í™”
    # deterministic=Falseì¼ ë•Œ temperatureë¥¼ ì ìš©í•˜ì—¬ íƒí—˜ ì¦ê°€
    temperature = 1.5 if not deterministic else 1.0  # íƒí—˜ ëª¨ë“œì—ì„œëŠ” 1.5ë°° ì˜¨ë„ ì ìš©

    # Temperature-scaled logits (ë†’ì€ ì˜¨ë„ = ë” ê· ë“±í•œ ë¶„í¬ = ë” ë§ì€ íƒí—˜)
    scaled_logits = action_logits[0] / temperature

    # Softmaxë¡œ í™•ë¥  ê³„ì‚°
    action_probs = jax.nn.softmax(scaled_logits)

    # ì•¡ì…˜ ê²°ì •
    if deterministic:
        # ìµœëŒ€ í™•ë¥  ì•¡ì…˜ ì„ íƒ
        action_idx = int(jnp.argmax(action_probs))
    else:
        # Temperature-scaled ìƒ˜í”Œë§ (ë” ë§ì€ íƒí—˜)
        action_idx = int(jax.random.categorical(rng_key, scaled_logits))

    # Action ì´ë¦„ ë§¤í•‘
    action_map = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
    action_name = action_map.get(action_idx, 'HOLD')

    return {
        'action_logits': np.array(action_logits[0]),
        'value': round(float(value[0, 0]), 4),  # ì†Œìˆ«ì  4ìë¦¬
        'action_probs': np.array(action_probs),
        'action': int(action_idx),
        'action_name': action_name,
        'confidence': round(float(jnp.max(action_probs)), 2),  # ì†Œìˆ«ì  2ìë¦¬
        'price_change_pct': round(float(price_change[0, 0]), 4),  # ğŸ†• ë³€ë™ë¥  ì˜ˆì¸¡ (ì†Œìˆ«ì  4ìë¦¬)
        'horizon_k': int(jnp.round(horizon[0, 0])),  # ğŸ†• íƒ€ì´ë° ì˜ˆì¸¡ (ì •ìˆ˜)
        'predicted_analysis_score': round(float(analysis_score[0, 0]), 2)  # ğŸ†• ë¶„ì„ ì ìˆ˜ ì˜ˆì¸¡ (ì†Œìˆ«ì  2ìë¦¬)
    }


def save_ckpt(params: Dict, path: str) -> None:
    """
    ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    
    Args:
        params: ëª¨ë¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        path: ì €ì¥ ê²½ë¡œ
    """
    if not JAX_AVAILABLE:
        raise ImportError("JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        # Flax ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        checkpoint_dir = os.path.dirname(path)
        checkpoint_name = os.path.basename(path).replace('.ckpt', '')
        
        # ğŸ”§ Orbax ë¡œê±° ë ˆë²¨ ì„ì‹œ ì¡°ì • (ì €ì¥ ì¤‘ ìƒì„¸ ë©”ì‹œì§€ ìˆ¨ê¹€)
        import logging as std_logging
        orbax_loggers = [
            'orbax.checkpoint',
            'jax.checkpoint',
            'flax.training.checkpoints'
        ]
        original_levels = {}
        for logger_name in orbax_loggers:
            orbax_logger = std_logging.getLogger(logger_name)
            original_levels[logger_name] = orbax_logger.level
            orbax_logger.setLevel(std_logging.WARNING)
        
        try:
            # Flax checkpoints.save() ì‚¬ìš©
            checkpoints.save_checkpoint(
                checkpoint_dir,
                target=params['params'],
                step=0,
                prefix=checkpoint_name,
                keep=1
            )
        finally:
            # ì›ë˜ ë¡œê±° ë ˆë²¨ ë³µì›
            for logger_name, original_level in original_levels.items():
                std_logging.getLogger(logger_name).setLevel(original_level)
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata_path = path + '.meta'
        with open(metadata_path, 'wb') as f:
            pickle.dump({
                'obs_dim': params['obs_dim'],
                'action_dim': params['action_dim'],
                'hidden_dim': params['hidden_dim'],
                'model_class': 'PolicyNetwork'
            }, f)
        
        logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {path}")
        
    except Exception as e:
        logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def load_ckpt(path: str, rng_key=None) -> Dict:
    """
    ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    
    Args:
        path: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        rng_key: JAX ëœë¤ í‚¤ (í•„ìš” ì‹œ)
    
    Returns:
        ëª¨ë¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
    """
    if not JAX_AVAILABLE:
        raise ImportError("JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒë¼ë¯¸í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¡œë“œ
    restored_params = None
    metadata = {
        'obs_dim': 15,
        'action_dim': 3,
        'hidden_dim': 128
    }
    
    try:
        checkpoint_dir = os.path.dirname(path)
        checkpoint_name = os.path.basename(path).replace('.ckpt', '')
        
        # ğŸ”§ Orbax í˜•ì‹ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸
        # OrbaxëŠ” `{prefix}0` ë””ë ‰í† ë¦¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨ (ì˜ˆ: ppo_20251031_154621_0c18d72b0)
        orbax_checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name + '0')
        
        # ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        actual_checkpoint_path = None
        if os.path.exists(orbax_checkpoint_path) and os.path.isdir(orbax_checkpoint_path):
            actual_checkpoint_path = orbax_checkpoint_path
            logger.debug(f"âœ… Orbax ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {actual_checkpoint_path}")
        else:
            # prefixë¡œ ê²€ìƒ‰ ì‹œë„ (ë””ë ‰í† ë¦¬ ëª©ë¡ì—ì„œ ì°¾ê¸°)
            logger.debug(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²€ìƒ‰: {checkpoint_dir}, prefix: {checkpoint_name}")
            try:
                for item in os.listdir(checkpoint_dir):
                    item_path = os.path.join(checkpoint_dir, item)
                    # {prefix}0 í˜•ì‹ì˜ ë””ë ‰í† ë¦¬ ì°¾ê¸° (.meta íŒŒì¼ ì œì™¸)
                    if (item.startswith(checkpoint_name) and 
                        item.endswith('0') and 
                        os.path.isdir(item_path) and
                        '.meta' not in item):
                        actual_checkpoint_path = item_path
                        logger.debug(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {actual_checkpoint_path}")
                        break
            except OSError as list_err:
                logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {list_err}")
        
        if actual_checkpoint_path is None:
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_dir}, prefix: {checkpoint_name}, ì‹œë„í•œ ê²½ë¡œ: {orbax_checkpoint_path}")
        
        # ğŸ”§ Orbax ë¡œê±° ë ˆë²¨ ì„ì‹œ ì¡°ì • (ë¡œë“œ ì¤‘ ìƒì„¸ ë©”ì‹œì§€ ìˆ¨ê¹€)
        import logging as std_logging
        orbax_loggers = [
            'orbax.checkpoint',
            'jax.checkpoint',
            'flax.training.checkpoints'
        ]
        original_levels = {}
        for logger_name in orbax_loggers:
            orbax_logger = std_logging.getLogger(logger_name)
            original_levels[logger_name] = orbax_logger.level
            orbax_logger.setLevel(std_logging.WARNING)
        
        try:
            # ğŸ”¥ ê°œì„ : Orbax ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ê°€ í™•ì¸ë˜ë©´ prefix ë°©ì‹ì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì§ì ‘ ë¡œë“œ
            # Legacy checkpoint í˜•ì‹ ì˜¤ë¥˜ ë°©ì§€ (unpack(b) received extra data)
            if actual_checkpoint_path and os.path.isdir(actual_checkpoint_path):
                # Orbax ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì§ì ‘ ë¡œë“œ (prefix ë°©ì‹ìœ¼ë¡œ ì¸í•œ legacy í˜•ì‹ ì‹œë„ ë°©ì§€)
                logger.info(f"Restoring orbax checkpoint from {actual_checkpoint_path}")
                try:
                    restored_params = checkpoints.restore_checkpoint(
                        actual_checkpoint_path,
                        target=None
                    )
                except (struct.error, pickle.UnpicklingError, EOFError, ValueError) as restore_err:
                    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ë˜ëŠ” í˜•ì‹ ë¶ˆì¼ì¹˜ ì‹œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
                    error_msg = str(restore_err)
                    if "unpack" in error_msg.lower() or "extra data" in error_msg.lower():
                        logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ê°ì§€ (ë‹¤ë¥¸ ë°©ë²• ì‹œë„): {error_msg}")
                    else:
                        logger.debug(f"âš ï¸ Orbax ì²´í¬í¬ì¸íŠ¸ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨ (ë‹¤ë¥¸ ë°©ë²• ì‹œë„): {restore_err}")
                    restored_params = None
            else:
                # Orbax ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ prefix ë°©ì‹ ì‹œë„
                logger.debug(f"ğŸ” Orbax ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì—†ìŒ, prefix ë°©ì‹ ì‹œë„: {checkpoint_name}")
                try:
                    restored_params = checkpoints.restore_checkpoint(
                        checkpoint_dir,
                        target=None,
                        prefix=checkpoint_name,
                        step=None  # Noneì´ë©´ ìµœì‹  ì²´í¬í¬ì¸íŠ¸
                    )
                except (struct.error, pickle.UnpicklingError, EOFError, ValueError) as restore_err:
                    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ë˜ëŠ” í˜•ì‹ ë¶ˆì¼ì¹˜ ì‹œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
                    error_msg = str(restore_err)
                    if "unpack" in error_msg.lower() or "extra data" in error_msg.lower():
                        logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ê°ì§€ (ë‹¤ë¥¸ ë°©ë²• ì‹œë„): {error_msg}")
                    else:
                        logger.debug(f"âš ï¸ prefix ë°©ì‹ ì‹¤íŒ¨ (ë‹¤ë¥¸ ë°©ë²• ì‹œë„): {restore_err}")
                    restored_params = None
            
            if restored_params is None:
                # ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì¬ì‹œë„
                logger.debug(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì¬ì‹œë„: {checkpoint_dir}")
                # ë””ë ‰í† ë¦¬ ë‚´ë¶€ì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì°¾ê¸°
                if actual_checkpoint_path and os.path.isdir(actual_checkpoint_path):
                    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ë¶€ì—ì„œ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
                    checkpoint_files = []
                    try:
                        for item in os.listdir(actual_checkpoint_path):
                            if item.startswith('checkpoint_') or item == 'checkpoint':
                                item_path = os.path.join(actual_checkpoint_path, item)
                                if os.path.isfile(item_path) or os.path.isdir(item_path):
                                    checkpoint_files.append(item_path)
                    except OSError as list_err:
                        logger.debug(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {list_err}")
                    
                    if checkpoint_files:
                        # ìµœì‹  íŒŒì¼ ì„ íƒ
                        latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)
                        logger.debug(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë°œê²¬: {latest_checkpoint}")
                        # FlaxëŠ” ë””ë ‰í† ë¦¬ ë‹¨ìœ„ë¡œ ë¡œë“œí•˜ë¯€ë¡œ, ë””ë ‰í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
                        try:
                            restored_params = checkpoints.restore_checkpoint(
                                actual_checkpoint_path,
                                target=None
                            )
                        except (struct.error, pickle.UnpicklingError, EOFError, ValueError) as restore_err2:
                            logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨ (íŒŒì¼ ì†ìƒ ê°€ëŠ¥): {restore_err2}")
                            restored_params = None
                    else:
                        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìì²´ë¥¼ ë¡œë“œ
                        try:
                            restored_params = checkpoints.restore_checkpoint(
                                actual_checkpoint_path,
                                target=None
                            )
                        except (struct.error, pickle.UnpicklingError, EOFError, ValueError) as restore_err3:
                            logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨ (íŒŒì¼ ì†ìƒ ê°€ëŠ¥): {restore_err3}")
                            restored_params = None
            
            if restored_params is not None:
                logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ: {actual_checkpoint_path or checkpoint_dir}")
            else:
                raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì†ìƒë¨: {actual_checkpoint_path or checkpoint_dir}")
        finally:
            # ì›ë˜ ë¡œê±° ë ˆë²¨ ë³µì›
            for logger_name, original_level in original_levels.items():
                std_logging.getLogger(logger_name).setLevel(original_level)
        
        if restored_params is None:
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        
    except FileNotFoundError:
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ëŠ” ëª…í™•í•œ ì—ëŸ¬
        raise
    except (struct.error, pickle.UnpicklingError, EOFError, ValueError) as unpickle_err:
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ë˜ëŠ” í˜•ì‹ ë¶ˆì¼ì¹˜
        error_msg = str(unpickle_err)
        logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨ (íŒŒì¼ ì†ìƒ ë˜ëŠ” í˜•ì‹ ë¶ˆì¼ì¹˜): {error_msg}")
        logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ë¡œ ìƒˆ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤")
        raise
    except Exception as e:
        # ì²´í¬í¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨ (ê¸°íƒ€ ì—ëŸ¬)
        error_msg = str(e)
        logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
        raise
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©, ì „ì²´ ë¡œë“œ ì‹¤íŒ¨í•˜ì§€ ì•ŠìŒ)
    metadata_path = path + '.meta'
    if os.path.exists(metadata_path):
        try:
            with open(metadata_path, 'rb') as f:
                # ğŸ”§ pickle ë¡œë“œ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ ê°œì„  (unpack ì—ëŸ¬ ë°©ì§€)
                try:
                    loaded_metadata = pickle.load(f)
                except (pickle.UnpicklingError, EOFError, ValueError, struct.error) as unpickle_err:
                    # pickle ë¡œë“œ ì‹¤íŒ¨ ì‹œ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    # struct.errorëŠ” "unpack(b) received extra data" í¬í•¨
                    logger.debug(f"âš ï¸ ë©”íƒ€ë°ì´í„° pickle ë¡œë“œ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {unpickle_err}")
                    loaded_metadata = None
                
                if loaded_metadata is not None:
                    # ê²€ì¦: ë”•ì…”ë„ˆë¦¬ì´ê³  í•„ìˆ˜ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if isinstance(loaded_metadata, dict):
                        if 'obs_dim' in loaded_metadata and 'action_dim' in loaded_metadata and 'hidden_dim' in loaded_metadata:
                            metadata = loaded_metadata
                            logger.debug(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ: {metadata_path}")
                        else:
                            logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜, ê¸°ë³¸ê°’ ì‚¬ìš©: {metadata_path}")
                    else:
                        logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜, ê¸°ë³¸ê°’ ì‚¬ìš©: {metadata_path}")
                else:
                    logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ê²°ê³¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {metadata_path}")
        except Exception as meta_err:
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ê°’ìœ¼ë¡œ ê³„ì† ì§„í–‰ (ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ)
            error_msg = str(meta_err)
            if "unpack" in error_msg.lower() or "extra data" in error_msg.lower():
                logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ë¬¸ì œ (ê¸°ë³¸ê°’ìœ¼ë¡œ ê³„ì† ì§„í–‰): {error_msg}")
            else:
                logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {meta_err}")
    else:
        logger.debug(f"â„¹ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {metadata_path}")
    
    # ëª¨ë¸ ì¬êµ¬ì„±
    try:
        if rng_key is None:
            rng_key = jax.random.PRNGKey(42)
        
        model = PolicyNetwork(
            hidden_dim=metadata['hidden_dim'],
            action_dim=metadata['action_dim']
        )
        
        logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {path}")
        
        return {
            'params': restored_params,
            'model_def': model,
            'obs_dim': metadata['obs_dim'],
            'action_dim': metadata['action_dim'],
            'hidden_dim': metadata['hidden_dim']
        }
    except Exception as e:
        # ëª¨ë¸ ì¬êµ¬ì„± ì‹¤íŒ¨
        logger.error(f"âŒ ëª¨ë¸ ì¬êµ¬ì„± ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ëª¨ë¸ ì¬êµ¬ì„± ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
        raise

