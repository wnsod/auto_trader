"""
ì¦ë¶„ í•™ìŠµ (Incremental Learning) íŠ¸ë ˆì´ë„ˆ

ìœ ì‚¬ë„ ê¸°ë°˜ ì „ëµ ë¶„ë¥˜ì— ë”°ë¼ ì°¨ë“±ì ì¸ í•™ìŠµ ì „ëµ ì ìš©:
- duplicate: í•™ìŠµ ê±´ë„ˆëœ€ (ì´ë¯¸ creatorì—ì„œ ì œê±°ë¨)
- copy: ë¶€ëª¨ ì •ì±… ë³µì‚¬ (3 ì—í”¼ì†Œë“œ)
- finetune: ë¶€ëª¨ ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì • (7-12 ì—í”¼ì†Œë“œ)
- novel: ì „ì²´ í•™ìŠµ (20 ì—í”¼ì†Œë“œ)
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

logger = logging.getLogger(__name__)


def save_training_history(
    strategy_id: str,
    training_episodes: int,
    avg_accuracy: float,
    parent_strategy_id: Optional[str] = None,
    similarity_score: float = 0.0,
    training_source: str = 'trained',
    policy_data: Optional[Dict[str, Any]] = None
) -> bool:
    """
    ì „ëµ í•™ìŠµ ì´ë ¥ì„ DBì— ì €ì¥

    Args:
        strategy_id: ì „ëµ ID
        training_episodes: í•™ìŠµì— ì‚¬ìš©ëœ ì—í”¼ì†Œë“œ ìˆ˜
        avg_accuracy: í‰ê·  ì •í™•ë„
        parent_strategy_id: ë¶€ëª¨ ì „ëµ ID (ìˆìœ¼ë©´)
        similarity_score: ìœ ì‚¬ë„ ì ìˆ˜
        training_source: 'trained', 'copied', 'finetuned'
        policy_data: ì •ì±… ë°ì´í„° (ë³µì‚¬ëœ ê²½ìš°)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        import time
        import random
        from rl_pipeline.db.connection_pool import get_strategy_db_pool

        # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
        max_retries = 5
        
        for attempt in range(max_retries):
            try:
                pool = get_strategy_db_pool()
                with pool.get_connection() as conn:
                    cursor = conn.cursor()

                    # ê¸°ì¡´ ì´ë ¥ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
                    cursor.execute("""
                        INSERT OR REPLACE INTO strategy_training_history (
                            strategy_id,
                            trained_at,
                            training_episodes,
                            avg_accuracy,
                            parent_strategy_id,
                            similarity_score,
                            training_source,
                            policy_data,
                            created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                    """, (
                        strategy_id,
                        datetime.now().isoformat(),
                        training_episodes,
                        avg_accuracy,
                        parent_strategy_id,
                        similarity_score,
                        training_source,
                        json.dumps(policy_data) if policy_data else None
                    ))

                    conn.commit()
                    logger.info(f"âœ… í•™ìŠµ ì´ë ¥ ì €ì¥: {strategy_id} ({training_source}, {training_episodes}ep, acc={avg_accuracy:.3f})")
                    return True
            
            except Exception as e:
                is_locked = "database is locked" in str(e) or "disk I/O error" in str(e) or "malformed" in str(e)
                if is_locked and attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(0.1, 1.0)
                    logger.warning(f"âš ï¸ í•™ìŠµ ì´ë ¥ ì €ì¥ ì¼ì‹œì  ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„: {strategy_id} - {e}")
                    time.sleep(wait_time)
                else:
                    if attempt == max_retries - 1:
                        logger.error(f"âŒ í•™ìŠµ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨ (ìµœì¢…): {strategy_id} - {e}")
                    raise e

    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨: {strategy_id} - {e}")
        return False


def _has_parent_policy_data(parent_strategy_id: str) -> bool:
    """
    ë¶€ëª¨ ì „ëµì— ì •ì±… ë°ì´í„°ê°€ ìˆëŠ”ì§€ ì‚¬ì „ ê²€ì¦
    
    Args:
        parent_strategy_id: ë¶€ëª¨ ì „ëµ ID
        
    Returns:
        policy_data ì¡´ì¬ ì—¬ë¶€
    """
    try:
        from rl_pipeline.db.connection_pool import get_strategy_db_pool

        pool = get_strategy_db_pool()
        with pool.get_connection() as conn:
            cursor = conn.cursor()

            # ë¶€ëª¨ ì „ëµì˜ policy_data ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
            cursor.execute("""
                SELECT policy_data
                FROM strategy_training_history
                WHERE strategy_id = ? AND policy_data IS NOT NULL
                ORDER BY trained_at DESC
                LIMIT 1
            """, (parent_strategy_id,))

            row = cursor.fetchone()
            return row is not None and row[0] is not None

    except Exception as e:
        logger.debug(f"ë¶€ëª¨ ì •ì±… ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {parent_strategy_id} - {e}")
        return False


def load_parent_policy(parent_strategy_id: str) -> Optional[Dict[str, Any]]:
    """
    ë¶€ëª¨ ì „ëµì˜ í•™ìŠµëœ ì •ì±… ë¡œë“œ

    Args:
        parent_strategy_id: ë¶€ëª¨ ì „ëµ ID

    Returns:
        ì •ì±… ë°ì´í„° (dict) ë˜ëŠ” None
    """
    try:
        from rl_pipeline.db.connection_pool import get_strategy_db_pool

        pool = get_strategy_db_pool()
        with pool.get_connection() as conn:
            cursor = conn.cursor()

            # ë¶€ëª¨ ì „ëµì˜ ì •ì±… ë°ì´í„° ì¡°íšŒ
            cursor.execute("""
                SELECT policy_data
                FROM strategy_training_history
                WHERE strategy_id = ? AND policy_data IS NOT NULL
                ORDER BY trained_at DESC
                LIMIT 1
            """, (parent_strategy_id,))

            row = cursor.fetchone()
            if row and row[0]:
                policy_data = json.loads(row[0])
                logger.debug(f"âœ… ë¶€ëª¨ ì •ì±… ë¡œë“œ: {parent_strategy_id}")
                return policy_data
            else:
                logger.debug(f"â„¹ï¸ ë¶€ëª¨ ì •ì±… ë°ì´í„° ì—†ìŒ: {parent_strategy_id} (ì •ìƒ: novelë¡œ ì²˜ë¦¬)")
                return None

    except Exception as e:
        logger.error(f"âŒ ë¶€ëª¨ ì •ì±… ë¡œë“œ ì‹¤íŒ¨: {parent_strategy_id} - {e}")
        return None


def copy_parent_policy(strategy: Dict[str, Any]) -> bool:
    """
    ë¶€ëª¨ ì „ëµì˜ ì •ì±…ì„ í˜„ì¬ ì „ëµìœ¼ë¡œ ë³µì‚¬

    Args:
        strategy: ì „ëµ (similarity_classification='copy')

    Returns:
        ì„±ê³µ ì—¬ë¶€ (ì‹¤íŒ¨ ì‹œ strategyë¥¼ novelë¡œ ì¬ë¶„ë¥˜)
    """
    try:
        strategy_id = strategy.get('id')
        if not strategy_id:
            logger.error(f"âŒ ì „ëµ ID ì—†ìŒ, ì •ì±… ë³µì‚¬ ë¶ˆê°€")
            return False

        parent_id = strategy.get('parent_strategy_id')
        similarity_score = strategy.get('similarity_score', 0.0)

        if not parent_id:
            logger.debug(f"â„¹ï¸ {strategy_id}: ë¶€ëª¨ ID ì—†ìŒ, novelë¡œ ì¬ë¶„ë¥˜")
            # copy â†’ novelë¡œ ì¬ë¶„ë¥˜
            strategy['similarity_classification'] = 'novel'
            strategy['parent_strategy_id'] = None
            return False

        # ğŸ”¥ ì‚¬ì „ ê²€ì¦: ë¶€ëª¨ ì „ëµì˜ policy_data ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not _has_parent_policy_data(parent_id):
            logger.debug(f"â„¹ï¸ {strategy_id}: ë¶€ëª¨ ì •ì±… ë°ì´í„° ì—†ìŒ (ë¶€ëª¨: {parent_id}), novelë¡œ ì¬ë¶„ë¥˜")
            # copy â†’ novelë¡œ ì¬ë¶„ë¥˜
            strategy['similarity_classification'] = 'novel'
            strategy['parent_strategy_id'] = None
            return False

        # ë¶€ëª¨ ì •ì±… ë¡œë“œ
        parent_policy = load_parent_policy(parent_id)

        if not parent_policy:
            logger.debug(f"â„¹ï¸ {strategy_id}: ë¶€ëª¨ ì •ì±… ë¡œë“œ ì‹¤íŒ¨, novelë¡œ ì¬ë¶„ë¥˜")
            # copy â†’ novelë¡œ ì¬ë¶„ë¥˜
            strategy['similarity_classification'] = 'novel'
            strategy['parent_strategy_id'] = None
            return False

        # í•™ìŠµ ì´ë ¥ ì €ì¥ (ë³µì‚¬)
        save_training_history(
            strategy_id=strategy_id,
            training_episodes=3,  # ë³µì‚¬ëŠ” 3 ì—í”¼ì†Œë“œë¡œ ê¸°ë¡
            avg_accuracy=0.95,  # ë¶€ëª¨ì™€ ê±°ì˜ ë™ì¼í•˜ë‹¤ê³  ê°€ì •
            parent_strategy_id=parent_id,
            similarity_score=similarity_score,
            training_source='copied',
            policy_data=parent_policy
        )

        logger.info(f"âœ… {strategy_id}: ë¶€ëª¨ ì •ì±… ë³µì‚¬ ì™„ë£Œ (ë¶€ëª¨: {parent_id}, ìœ ì‚¬ë„: {similarity_score:.3f})")
        return True

    except Exception as e:
        logger.error(f"âŒ ì •ì±… ë³µì‚¬ ì‹¤íŒ¨: {strategy.get('id')} - {e}")
        # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ novelë¡œ ì¬ë¶„ë¥˜
        strategy['similarity_classification'] = 'novel'
        strategy['parent_strategy_id'] = None
        return False


def train_strategies_incremental(
    strategies: List[Dict[str, Any]],
    episodes_data: List[Dict[str, Any]],
    trainer,
    db_path: Optional[str] = None,
    analysis_data: Optional[Dict[str, Any]] = None
) -> Optional[str]:
    """
    ì¦ë¶„ í•™ìŠµ: ìœ ì‚¬ë„ ë¶„ë¥˜ì— ë”°ë¼ ì°¨ë“± í•™ìŠµ

    Args:
        strategies: ì „ëµ ë¦¬ìŠ¤íŠ¸ (similarity_classification ë©”íƒ€ë°ì´í„° í¬í•¨)
        episodes_data: Self-play ì—í”¼ì†Œë“œ ë°ì´í„°
        trainer: PPOTrainer ì¸ìŠ¤í„´ìŠ¤
        db_path: DB ê²½ë¡œ
        analysis_data: í†µí•© ë¶„ì„ ë°ì´í„°

    Returns:
        ëª¨ë¸ ID (ì„±ê³µ ì‹œ) ë˜ëŠ” None
    """
    try:
        # ì „ëµ ë¶„ë¥˜ë³„ ì¹´ìš´íŠ¸
        copy_count = sum(1 for s in strategies if s.get('similarity_classification') == 'copy')
        finetune_count = sum(1 for s in strategies if s.get('similarity_classification') == 'finetune')
        novel_count = sum(1 for s in strategies if s.get('similarity_classification') == 'novel')

        logger.info(f"ğŸ”„ ì¦ë¶„ í•™ìŠµ ì‹œì‘:")
        logger.info(f"  - ì •ì±… ë³µì‚¬(copy): {copy_count}ê°œ")
        logger.info(f"  - ë¯¸ì„¸ ì¡°ì •(finetune): {finetune_count}ê°œ")
        logger.info(f"  - ì‹ ê·œ í•™ìŠµ(novel): {novel_count}ê°œ")

        # 1. ì •ì±… ë³µì‚¬ ì „ëµ ì²˜ë¦¬
        copied_strategies = []
        reclassified_to_novel = []
        
        for strategy in strategies:
            if strategy.get('similarity_classification') == 'copy':
                if copy_parent_policy(strategy):
                    copied_strategies.append(strategy)
                else:
                    # copy ì‹¤íŒ¨ ì‹œ novelë¡œ ì¬ë¶„ë¥˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if strategy.get('similarity_classification') == 'novel':
                        reclassified_to_novel.append(strategy)

        if copied_strategies:
            logger.info(f"âœ… ì •ì±… ë³µì‚¬ ì™„ë£Œ: {len(copied_strategies)}ê°œ")
        
        if reclassified_to_novel:
            logger.debug(f"â„¹ï¸ ë¶€ëª¨ ì •ì±… ì—†ìŒìœ¼ë¡œ novelë¡œ ì¬ë¶„ë¥˜: {len(reclassified_to_novel)}ê°œ")
            # ì¬ë¶„ë¥˜ëœ ì „ëµì„ novel ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            novel_count += len(reclassified_to_novel)

        # 2. ë¯¸ì„¸ ì¡°ì • ì „ëµ ì²˜ë¦¬ (episode ë°ì´í„°ë¥¼ ì¤„ì—¬ì„œ í•™ìŠµ)
        finetune_strategies = [s for s in strategies if s.get('similarity_classification') == 'finetune']

        if finetune_strategies:
            logger.info(f"ğŸ”¥ ë¯¸ì„¸ ì¡°ì • í•™ìŠµ ì‹œì‘: {finetune_strategies}ê°œ ì „ëµ")

            # ì—í”¼ì†Œë“œ ë°ì´í„°ë¥¼ finetune ì „ëµì— ë§ê²Œ í•„í„°ë§
            # TODO: ì‹¤ì œë¡œëŠ” ì „ëµë³„ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•´ì•¼ í•˜ì§€ë§Œ, ì¼ë‹¨ ëª¨ë“  ë°ì´í„° ì‚¬ìš©
            # ëŒ€ì‹  epochsë¥¼ ì¤„ì—¬ì„œ í•™ìŠµ ì‹œê°„ ë‹¨ì¶•

            # epochsë¥¼ ê¸°ë³¸ì˜ 40%ë¡œ ì¤„ì„ (30 â†’ 12)
            original_epochs = trainer.train_config.get('epochs', 30)
            trainer.train_config['epochs'] = int(original_epochs * 0.4)

            try:
                model_id = trainer.train_from_selfplay_data(
                    episodes_data,
                    db_path=db_path,
                    analysis_data=analysis_data
                )

                if model_id:
                    # í•™ìŠµ ì´ë ¥ ì €ì¥
                    for strategy in finetune_strategies:
                        save_training_history(
                            strategy_id=strategy.get('id'),
                            training_episodes=int(original_epochs * 0.4),
                            avg_accuracy=0.85,  # ì„ì‹œê°’, ì‹¤ì œë¡œëŠ” í•™ìŠµ ê²°ê³¼ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
                            parent_strategy_id=strategy.get('parent_strategy_id'),
                            similarity_score=strategy.get('similarity_score', 0.0),
                            training_source='finetuned'
                        )

                    logger.info(f"âœ… ë¯¸ì„¸ ì¡°ì • ì™„ë£Œ: {len(finetune_strategies)}ê°œ ì „ëµ")

            finally:
                # epochs ë³µì›
                trainer.train_config['epochs'] = original_epochs

        # 3. ì‹ ê·œ ì „ëµ ì „ì²´ í•™ìŠµ (ì¬ë¶„ë¥˜ëœ ì „ëµ í¬í•¨)
        novel_strategies = [s for s in strategies if s.get('similarity_classification') == 'novel']

        if novel_strategies:
            if reclassified_to_novel:
                logger.info(f"ğŸ”¥ ì‹ ê·œ ì „ëµ ì „ì²´ í•™ìŠµ ì‹œì‘: {len(novel_strategies)}ê°œ ì „ëµ (ì¬ë¶„ë¥˜ í¬í•¨: {len(reclassified_to_novel)}ê°œ)")
            else:
                logger.info(f"ğŸ”¥ ì‹ ê·œ ì „ëµ ì „ì²´ í•™ìŠµ ì‹œì‘: {len(novel_strategies)}ê°œ ì „ëµ")

            model_id = trainer.train_from_selfplay_data(
                episodes_data,
                db_path=db_path,
                analysis_data=analysis_data
            )

            if model_id:
                # í•™ìŠµ ì´ë ¥ ì €ì¥
                for strategy in novel_strategies:
                    save_training_history(
                        strategy_id=strategy.get('id'),
                        training_episodes=trainer.train_config.get('epochs', 30),
                        avg_accuracy=0.75,  # ì„ì‹œê°’, ì‹¤ì œë¡œëŠ” í•™ìŠµ ê²°ê³¼ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
                        parent_strategy_id=None,
                        similarity_score=0.0,
                        training_source='trained'
                    )

                logger.info(f"âœ… ì‹ ê·œ ì „ëµ í•™ìŠµ ì™„ë£Œ: {len(novel_strategies)}ê°œ")
                return model_id

        logger.info(f"âœ… ì¦ë¶„ í•™ìŠµ ì™„ë£Œ: copy={len(copied_strategies)}, finetune={len(finetune_strategies)}, novel={len(novel_strategies)}")
        return None

    except Exception as e:
        logger.error(f"âŒ ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return None
