"""
ìë™ í•™ìŠµ ë° ê²€ì¦ ëª¨ë“ˆ
Self-play ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ìë™ìœ¼ë¡œ í•™ìŠµ ë° í‰ê°€
"""

import logging
import os
import json
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

from rl_pipeline.hybrid.trainer_jax import PPOTrainer
from rl_pipeline.hybrid.evaluator import (
    evaluate_ab,
    walk_forward_validation,
    multi_period_validation
)
from rl_pipeline.hybrid.validation_checker import (
    evaluate_validation_results,
    should_retrain,
    get_retrain_suggestions
)
from rl_pipeline.db.connection_pool import get_strategy_db_pool
from rl_pipeline.db.connection_pool import get_optimized_db_connection

# ì¦ë¶„ í•™ìŠµ
from rl_pipeline.hybrid.incremental_trainer import (
    save_training_history,
    copy_parent_policy,
    train_strategies_incremental
)


def _create_adjusted_config(
    config_path: Optional[str],
    suggestions: Dict[str, Any],
    previous_attempts: int
) -> Optional[str]:
    """
    ì¬í•™ìŠµ ì œì•ˆì— ë”°ë¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•œ ì„ì‹œ ì„¤ì • íŒŒì¼ ìƒì„±
    
    Args:
        config_path: ì›ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        suggestions: ì¬í•™ìŠµ ì œì•ˆ ë”•ì…”ë„ˆë¦¬
        previous_attempts: ì¬ì‹œë„ íšŸìˆ˜
    
    Returns:
        ì¡°ì •ëœ ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        # ì›ë³¸ ì„¤ì • ë¡œë“œ
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config = json.load(f)
        else:
            # ê¸°ë³¸ ì„¤ì •
            config = {
                'train': {
                    'epochs': 30,
                    'batch_size': 4096,
                    'lr': 0.0003,
                    'hidden_dim': 128
                },
                'paths': {
                    'checkpoints': '/workspace/rl_pipeline/artifacts/checkpoints',
                    'db': '/workspace/data_storage/rl_strategies.db'
                }
            }
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
        train_config = config.setdefault('train', {})
        
        # ğŸ”¥ ê±°ë˜ 0íšŒ ë¬¸ì œ í•´ê²°: í•™ìŠµë¥  ë° íƒí—˜ ì¦ê°€
        if suggestions.get('adjust_learning_rate'):
            # ì¬ì‹œë„ íšŸìˆ˜ì— ë”°ë¼ í•™ìŠµë¥  ì¡°ì • (ë” ë§ì€ ì¬ì‹œë„ = ë” ì‘ì€ í•™ìŠµë¥ )
            base_lr = train_config.get('lr', 0.0003)
            if previous_attempts == 1:
                # ì²« ì¬ì‹œë„: í•™ìŠµë¥  ì•½ê°„ ì¦ê°€ (íƒí—˜ ì¦ê°€)
                adjusted_lr = base_lr * 1.5  # 0.0003 â†’ 0.00045
            elif previous_attempts == 2:
                # ë‘ ë²ˆì§¸ ì¬ì‹œë„: í•™ìŠµë¥  ë” ì¦ê°€
                adjusted_lr = base_lr * 2.0  # 0.0003 â†’ 0.0006
            else:
                # ì„¸ ë²ˆì§¸ ì´ìƒ: í•™ìŠµë¥  ê°ì†Œ (ì•ˆì •ì„± ìš°ì„ )
                adjusted_lr = base_lr * 0.5  # 0.0003 â†’ 0.00015
            
            train_config['lr'] = adjusted_lr
            logger.info(f"ğŸ”§ í•™ìŠµë¥  ì¡°ì •: {base_lr:.6f} â†’ {adjusted_lr:.6f} (ì¬ì‹œë„: {previous_attempts}íšŒ)")
        
        # ğŸ”¥ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •: ì—í¬í¬ ìˆ˜ ì¦ê°€ (ë” ë§ì€ í•™ìŠµ)
        if suggestions.get('adjust_hyperparameters'):
            base_epochs = train_config.get('epochs', 30)
            # ì¬ì‹œë„ íšŸìˆ˜ì— ë”°ë¼ ì—í¬í¬ ìˆ˜ ì¦ê°€
            adjusted_epochs = base_epochs + (previous_attempts * 10)  # ì¬ì‹œë„ë§ˆë‹¤ 10 ì—í¬í¬ ì¶”ê°€
            train_config['epochs'] = adjusted_epochs
            logger.info(f"ğŸ”§ ì—í¬í¬ ìˆ˜ ì¡°ì •: {base_epochs} â†’ {adjusted_epochs} (ì¬ì‹œë„: {previous_attempts}íšŒ)")
        
        # ì„ì‹œ ì„¤ì • íŒŒì¼ ì €ì¥
        import tempfile
        temp_dir = tempfile.gettempdir()
        temp_config_path = os.path.join(
            temp_dir,
            f"hybrid_config_adjusted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        
        with open(temp_config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        return temp_config_path
        
    except Exception as e:
        logger.warning(f"âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ì‹¤íŒ¨ (ì›ë³¸ ì„¤ì • ì‚¬ìš©): {e}")
        return None


def collect_selfplay_data_for_training(
    coin: str,
    interval: str,
    selfplay_result: Dict[str, Any],
    min_episodes: int = 10
) -> List[Dict[str, Any]]:
    """
    Self-play ê²°ê³¼ì—ì„œ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        selfplay_result: Self-play ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        min_episodes: ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜
    
    Returns:
        í•™ìŠµìš© ì—í”¼ì†Œë“œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    try:
        episodes_data = []
        
        # cycle_resultsì—ì„œ ë°ì´í„° ì¶”ì¶œ
        cycle_results = selfplay_result.get("cycle_results", [])
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì¸¡ ì‹¤í˜„ Self-play ë° ì˜¨ë¼ì¸ Self-play ê²°ê³¼ë„ ë³€í™˜í•˜ì—¬ í¬í•¨
        if not cycle_results or len(cycle_results) == 0:
            # 1ìˆœìœ„: ì˜¨ë¼ì¸ Self-play ê²°ê³¼ í™•ì¸
            try:
                from rl_pipeline.hybrid.online_data_converter import (
                    extract_online_selfplay_result,
                    convert_online_segments_to_cycle_results
                )
                
                online_segments = extract_online_selfplay_result(selfplay_result)
                if online_segments:
                    logger.info(f"ğŸ“Š {coin}-{interval}: ì˜¨ë¼ì¸ Self-play ì„¸ê·¸ë¨¼íŠ¸ {len(online_segments)}ê°œ ë°œê²¬, ë³€í™˜ ì¤‘...")
                    converted_cycles = convert_online_segments_to_cycle_results(online_segments)
                    if converted_cycles:
                        cycle_results = converted_cycles
                        logger.info(f"âœ… {coin}-{interval}: ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ ({len(converted_cycles)}ê°œ cycle)")
            except ImportError:
                logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ ì—†ìŒ (ë¬´ì‹œ)")
            except Exception as e:
                logger.warning(f"âš ï¸ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            # 2ìˆœìœ„: ì˜ˆì¸¡ ì‹¤í˜„ ì—í”¼ì†Œë“œ í™•ì¸ (ì˜¨ë¼ì¸ ê²°ê³¼ê°€ ì—†ì„ ë•Œ)
            if not cycle_results:
                try:
                    from rl_pipeline.hybrid.predictive_data_converter import (
                        extract_predictive_episodes_from_selfplay_result,
                        convert_predictive_episodes_to_cycle_results
                    )
                    
                    predictive_episodes = extract_predictive_episodes_from_selfplay_result(selfplay_result)
                    if predictive_episodes:
                        logger.info(f"ğŸ“Š {coin}-{interval}: ì˜ˆì¸¡ ì‹¤í˜„ ì—í”¼ì†Œë“œ {len(predictive_episodes)}ê°œ ë°œê²¬, ë³€í™˜ ì¤‘...")
                        converted_cycles = convert_predictive_episodes_to_cycle_results(predictive_episodes)
                        if converted_cycles:
                            cycle_results = converted_cycles
                            logger.info(f"âœ… {coin}-{interval}: ì˜ˆì¸¡ ì‹¤í˜„ ê²°ê³¼ ë³€í™˜ ì™„ë£Œ ({len(converted_cycles)}ê°œ cycle)")
                except ImportError:
                    logger.debug(f"âš ï¸ ì˜ˆì¸¡ ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ ì—†ìŒ (ë¬´ì‹œ)")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì˜ˆì¸¡ ì‹¤í˜„ ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        if not cycle_results:
            logger.warning(f"âš ï¸ {coin}-{interval}: cycle_resultsê°€ ì—†ì–´ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ë¶ˆê°€")
            logger.warning(f"   selfplay_result íƒ€ì…: {type(selfplay_result)}")
            logger.warning(f"   selfplay_result keys: {list(selfplay_result.keys()) if isinstance(selfplay_result, dict) else 'N/A'}")
            # ğŸ”¥ ì¶”ê°€ ë””ë²„ê¹…: status í™•ì¸
            if isinstance(selfplay_result, dict):
                logger.warning(f"   status: {selfplay_result.get('status', 'N/A')}")
                logger.warning(f"   episodes: {selfplay_result.get('episodes', 'N/A')}")
            return []
        
        logger.debug(f"ğŸ“Š {coin}-{interval}: cycle_results {len(cycle_results)}ê°œ ë°œê²¬")
        
        # ğŸ”¥ í•™ìŠµ ì„±ëŠ¥ ê°œì„ : ëª¨ë“  ì•¡ì…˜(BUY/SELL/HOLD) í¬í•¨
        # HOLDë„ ì¤‘ìš”í•œ ì•¡ì…˜ì´ë¯€ë¡œ ë°°ì œí•˜ì§€ ì•ŠìŒ
        actions_check = {'BUY': 0, 'SELL': 0, 'HOLD': 0}
        skipped_no_results = 0
        skipped_no_trades = 0  # ì•¡ì…˜ê³¼ trades ëª¨ë‘ ì—†ëŠ” ê²½ìš°ë§Œ ì œì™¸
        
        # ğŸ”¥ ë””ë²„ê¹…: ì²« ë²ˆì§¸ cycle ìƒì„¸ í™•ì¸
        if cycle_results:
            first_cycle = cycle_results[0]
            logger.warning(f"  ğŸ” {coin}-{interval}: ì²« ë²ˆì§¸ cycle ë””ë²„ê¹…:")
            logger.warning(f"     episode: {first_cycle.get('episode', 'N/A')}")
            logger.warning(f"     results íƒ€ì…: {type(first_cycle.get('results', {}))}")
            results_raw = first_cycle.get('results', {})
            logger.warning(f"     results ê°’ ìì²´: {results_raw}")
            logger.warning(f"     results í‚¤ ê°œìˆ˜: {len(results_raw) if isinstance(results_raw, dict) else 'N/A'}")
            if isinstance(results_raw, dict) and results_raw:
                first_agent_id = list(results_raw.keys())[0]
                first_agent_result = results_raw[first_agent_id]
                logger.warning(f"     ì²« ë²ˆì§¸ agent_id: {first_agent_id}")
                logger.warning(f"     ì²« ë²ˆì§¸ agent ê²°ê³¼ íƒ€ì…: {type(first_agent_result)}")
                logger.warning(f"     ì²« ë²ˆì§¸ agent ê²°ê³¼ keys: {list(first_agent_result.keys()) if isinstance(first_agent_result, dict) else 'N/A'}")
                if isinstance(first_agent_result, dict):
                    logger.warning(f"     total_pnl: {first_agent_result.get('total_pnl', 'N/A')}")
                    logger.warning(f"     win_rate: {first_agent_result.get('win_rate', 'N/A')}")
                    logger.warning(f"     trades íƒ€ì…: {type(first_agent_result.get('trades', []))}")
                    logger.warning(f"     trades ê°œìˆ˜: {len(first_agent_result.get('trades', []))}")
            elif not results_raw:
                logger.warning(f"     âš ï¸ resultsê°€ ë¹„ì–´ìˆê±°ë‚˜ Noneì…ë‹ˆë‹¤!")
        
        for cycle in cycle_results:
            episode_num = cycle.get("episode", 0)
            results = cycle.get("results", {})
            
            if not results:
                skipped_no_results += 1
                # ğŸ”¥ ë””ë²„ê¹…: ì™œ resultsê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if skipped_no_results == 1:  # ì²« ë²ˆì§¸ë§Œ ë¡œê·¸
                    logger.warning(f"  ğŸ” {coin}-{interval}: episode {episode_num}ì˜ resultsê°€ ë¹„ì–´ìˆìŒ")
                    logger.warning(f"     cycle keys: {list(cycle.keys())}")
                    logger.warning(f"     results ê°’: {results}")
                continue
            
            # ì—í”¼ì†Œë“œ ë‚´ ì•¡ì…˜ ë‹¤ì–‘ì„± ì²´í¬
            episode_actions = {'BUY': 0, 'SELL': 0, 'HOLD': 0}
            has_any_trades = False
            has_performance_data = False  # ğŸ”¥ ì„±ê³¼ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            
            for agent_id, agent_result in results.items():
                # ğŸ”¥ ì„±ê³¼ ë°ì´í„° í™•ì¸ (total_pnl, win_rate ë“±ì´ ìˆìœ¼ë©´ í¬í•¨)
                if isinstance(agent_result, dict):
                    if 'total_pnl' in agent_result or 'win_rate' in agent_result or 'total_return' in agent_result:
                        has_performance_data = True
                
                # ğŸ”¥ ì „ëµ ë°©í–¥ í™•ì¸ (ë§¤ìˆ˜/ë§¤ë„ ì „ëµ êµ¬ë¶„)
                strategy_direction = agent_result.get('strategy_direction', 'neutral') if isinstance(agent_result, dict) else 'neutral'
                
                trades = agent_result.get('trades', [])
                if trades:
                    has_any_trades = True
                    for trade in trades:
                        direction = trade.get('direction', 'HOLD')
                        episode_actions[direction] = episode_actions.get(direction, 0) + 1
                        actions_check[direction] = actions_check.get(direction, 0) + 1
                        
                        # ğŸ”¥ ì „ëµ ë°©í–¥ê³¼ ì˜ˆì¸¡ ë°©í–¥ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸ (ë§¤ìˆ˜ ì „ëµì€ BUYë§Œ, ë§¤ë„ ì „ëµì€ SELLë§Œ)
                        if strategy_direction == 'buy' and direction != 'BUY':
                            logger.debug(f"  âš ï¸ {coin}-{interval}: ë§¤ìˆ˜ ì „ëµ {agent_id}ê°€ {direction} ì˜ˆì¸¡ ìƒì„± (BUY ì˜ˆìƒ)")
                        elif strategy_direction == 'sell' and direction != 'SELL':
                            logger.debug(f"  âš ï¸ {coin}-{interval}: ë§¤ë„ ì „ëµ {agent_id}ê°€ {direction} ì˜ˆì¸¡ ìƒì„± (SELL ì˜ˆìƒ)")
            
            # ğŸ”¥ HOLDë„ ì¤‘ìš”í•œ ì•¡ì…˜ì´ë¯€ë¡œ ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì—í”¼ì†Œë“œ í¬í•¨
            # ë‹¤ë§Œ BUY/SELLì´ ìˆëŠ” ì—í”¼ì†Œë“œë¥¼ ìš°ì„ ì‹œí•˜ê³ , HOLDë§Œ ìˆëŠ” ì—í”¼ì†Œë“œë„ í¬í•¨
            total_episode_actions = sum(episode_actions.values())
            has_buy_sell = (episode_actions.get('BUY', 0) > 0 or 
                          episode_actions.get('SELL', 0) > 0)
            only_hold = (total_episode_actions > 0 and 
                        episode_actions.get('BUY', 0) == 0 and 
                        episode_actions.get('SELL', 0) == 0)
            
            # ğŸ”¥ í•„í„°ë§ ë¡œì§: ëª¨ë“  ì—í”¼ì†Œë“œ ê¸°ë³¸ í¬í•¨, HOLDë§Œ ìˆëŠ” ê²ƒë„ í¬í•¨
            # BUY/SELLì´ ìˆìœ¼ë©´ ìš°ì„  í¬í•¨, HOLDë§Œ ìˆì–´ë„ í¬í•¨ (HOLDëŠ” ìœ íš¨í•œ ì•¡ì…˜)
            # ë‹¤ë§Œ, ì—í”¼ì†Œë“œì— ì•¡ì…˜ ë°ì´í„°ë„ ì—†ê³  tradesë„ ì—†ëŠ” ê²½ìš°ë§Œ ì œì™¸
            # ğŸ”¥ ê°œì„ : resultsê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ í¬í•¨ (ì„±ê³¼ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•™ìŠµ ê°€ëŠ¥)
            should_include = True  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë‘ í¬í•¨
            
            # resultsê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ í¬í•¨ (ì„±ê³¼ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•™ìŠµ ê°€ëŠ¥)
            # total_episode_actions == 0 and not has_any_trades and not has_performance_dataì¸ ê²½ìš°ë§Œ ì œì™¸
            if total_episode_actions == 0 and not has_any_trades and not has_performance_data:
                # ğŸ”¥ ë””ë²„ê¹…: ì™œ ì œì™¸ë˜ëŠ”ì§€ í™•ì¸
                if skipped_no_trades == 0:  # ì²« ë²ˆì§¸ë§Œ ë¡œê·¸
                    logger.warning(f"  ğŸ” {coin}-{interval}: episode {episode_num} ì œì™¸ - ì•¡ì…˜ ì—†ìŒ, trades ì—†ìŒ, ì„±ê³¼ ë°ì´í„° ì—†ìŒ")
                    logger.warning(f"     results í‚¤ ê°œìˆ˜: {len(results)}")
                    if results:
                        first_agent_id = list(results.keys())[0]
                        first_agent_result = results[first_agent_id]
                        logger.warning(f"     ì²« ë²ˆì§¸ agent_id: {first_agent_id}")
                        logger.warning(f"     ì²« ë²ˆì§¸ agent keys: {list(first_agent_result.keys()) if isinstance(first_agent_result, dict) else 'N/A'}")
                        logger.warning(f"     total_pnl: {first_agent_result.get('total_pnl', 'N/A') if isinstance(first_agent_result, dict) else 'N/A'}")
                skipped_no_trades += 1
                should_include = False
            elif has_performance_data and not has_any_trades:
                # ğŸ”¥ ì„±ê³¼ ë°ì´í„°ëŠ” ìˆì§€ë§Œ tradesëŠ” ì—†ëŠ” ê²½ìš° í¬í•¨ (ì„±ê³¼ ê¸°ë°˜ í•™ìŠµ)
                logger.debug(f"  ğŸ“Š {coin}-{interval}: episode {episode_num} í¬í•¨ - ì„±ê³¼ ë°ì´í„° ìˆìŒ (trades ì—†ìŒ)")
            
            if should_include:
                # ğŸ”¥ ì „ëµ ë°©í–¥ë³„ ë¶„ë¥˜ (ë§¤ìˆ˜/ë§¤ë„ ì „ëµ êµ¬ë¶„)
                buy_strategies = {}
                sell_strategies = {}
                neutral_strategies = {}
                
                for agent_id, agent_result in results.items():
                    strategy_direction = agent_result.get('strategy_direction', 'neutral') if isinstance(agent_result, dict) else 'neutral'
                    if strategy_direction == 'buy':
                        buy_strategies[agent_id] = agent_result
                    elif strategy_direction == 'sell':
                        sell_strategies[agent_id] = agent_result
                    else:
                        neutral_strategies[agent_id] = agent_result
                
                episode_data = {
                    'episode': episode_num,
                    'coin': coin,
                    'interval': interval,
                    'results': results,
                    'timestamp': datetime.now().isoformat(),
                    'action_counts': episode_actions,  # ì•¡ì…˜ ë¶„í¬ ì €ì¥
                    'strategy_directions': {  # ğŸ”¥ ì „ëµ ë°©í–¥ë³„ ë¶„ë¥˜ ì¶”ê°€
                        'buy': buy_strategies,
                        'sell': sell_strategies,
                        'neutral': neutral_strategies
                    }
                }
                episodes_data.append(episode_data)
                
                # ğŸ”¥ HOLDë§Œ ìˆëŠ” ì—í”¼ì†Œë“œì— ëŒ€í•œ ì •ë³´ ë¡œê¹… (ê²½ê³  ì•„ë‹˜)
                if only_hold:
                    logger.debug(f"  ğŸ“Š {coin}-{interval}: ì—í”¼ì†Œë“œ {episode_num}ì€ HOLDë§Œ í¬í•¨ (ì •ìƒì ì¸ ì•¡ì…˜)")
        
        # ìƒì„¸ ë¡œê¹…
        total_actions = sum(actions_check.values())
        if total_actions > 0:
            action_dist = {k: v/total_actions for k, v in actions_check.items()}
            logger.info(f"ğŸ“Š {coin}-{interval}: ì•¡ì…˜ ë¶„í¬ - BUY: {action_dist.get('BUY', 0):.1%}, "
                       f"SELL: {action_dist.get('SELL', 0):.1%}, HOLD: {action_dist.get('HOLD', 0):.1%}")
            
            # ğŸ”¥ HOLD ë¹„ìœ¨ì´ ë†’ì•„ë„ ì •ìƒì ì¼ ìˆ˜ ìˆìŒ (ì‹œì¥ ìƒí™©ì— ë”°ë¼)
            # ê²½ê³  ëŒ€ì‹  ì •ë³´ ë¡œê¹…ìœ¼ë¡œ ë³€ê²½
            if action_dist.get('HOLD', 0) > 0.9:
                logger.info(f"ğŸ“Š {coin}-{interval}: HOLD ë¹„ìœ¨ì´ ë†’ìŒ ({action_dist.get('HOLD', 0):.1%}) - "
                          f"ì‹œì¥ ìƒí™©ì— ë”°ë¼ ì •ìƒì ì¸ ì•¡ì…˜ ì„ íƒì¼ ìˆ˜ ìˆìŒ")
            elif action_dist.get('HOLD', 0) > 0.7:
                logger.debug(f"ğŸ“Š {coin}-{interval}: HOLD ë¹„ìœ¨ì´ ë‹¤ì†Œ ë†’ìŒ ({action_dist.get('HOLD', 0):.1%})")
        else:
            # ì•¡ì…˜ ë°ì´í„°ê°€ ì—†ì§€ë§Œ ì—í”¼ì†Œë“œëŠ” í¬í•¨ë¨ (ì„±ê³¼ ê¸°ë°˜ í•™ìŠµ)
            logger.debug(f"ğŸ“Š {coin}-{interval}: ì•¡ì…˜ ë°ì´í„° ì—†ìŒ (ì„±ê³¼ ê¸°ë°˜ í•™ìŠµ ë°ì´í„°ë¡œ í¬í•¨)")
        
        # ìˆ˜ì§‘ ìƒì„¸ ì •ë³´ ë¡œê¹…
        logger.info(f"âœ… {coin}-{interval}: {len(episodes_data)}ê°œ ì—í”¼ì†Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        if skipped_no_results > 0 or skipped_no_trades > 0:
            logger.debug(f"   ğŸ“Š ì œì™¸ëœ ì—í”¼ì†Œë“œ: results ì—†ìŒ={skipped_no_results}, "
                        f"ì•¡ì…˜/trades ëª¨ë‘ ì—†ìŒ={skipped_no_trades}")
        
        # ğŸ”¥ min_episodes ì²´í¬ëŠ” í•¨ìˆ˜ ëì—ì„œ (ìˆ˜ì§‘ í›„)
        if min_episodes > 0 and len(episodes_data) < min_episodes:
            logger.info(f"ğŸ“Š {coin}-{interval}: ìˆ˜ì§‘ëœ ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({len(episodes_data)} < {min_episodes}), ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return []
        
        return episodes_data
        
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return []


def auto_train_from_selfplay(
    coin: str,
    interval: str,
    selfplay_result: Dict[str, Any],
    config_path: Optional[str] = None,
    min_episodes: int = 10,
    previous_attempts: int = 0  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
) -> Optional[str]:
    """
    Self-play ê²°ê³¼ë¡œ ìë™ í•™ìŠµ
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        selfplay_result: Self-play ê²°ê³¼
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’)
        min_episodes: ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜
    
    Returns:
        í•™ìŠµëœ ëª¨ë¸ ID (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        # JAX ê°€ìš©ì„± í™•ì¸ (ë” ìì„¸í•œ ì²´í¬)
        try:
            import jax
            import jax.numpy as jnp
            from flax import linen as nn
            logger.debug("âœ… JAX/Flax ì„í¬íŠ¸ ì„±ê³µ")
        except ImportError as import_err:
            logger.warning(f"âš ï¸ JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤: {import_err}")
            return None
        
        # neural_policy_jax ëª¨ë“ˆì˜ JAX_AVAILABLEë„ í™•ì¸
        try:
            from rl_pipeline.hybrid.neural_policy_jax import JAX_AVAILABLE as NEURAL_JAX_AVAILABLE
            if not NEURAL_JAX_AVAILABLE:
                logger.warning("âš ï¸ neural_policy_jax ëª¨ë“ˆì—ì„œ JAX ì‚¬ìš© ë¶ˆê°€, í•™ìŠµ ê±´ë„ˆëœë‹ˆë‹¤")
                return None
        except ImportError as import_err:
            logger.warning(f"âš ï¸ neural_policy_jax ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {import_err}")
            return None
        
        # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
        episodes_data = collect_selfplay_data_for_training(
            coin, interval, selfplay_result, min_episodes
        )
        
        if not episodes_data:
            logger.info(f"ğŸ“Š {coin}-{interval}: í•™ìŠµ ë°ì´í„° ì—†ìŒ, í•™ìŠµ ê±´ë„ˆëœ€")
            return None
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            config_path = os.getenv(
                'HYBRID_CONFIG_PATH',
                '/workspace/rl_pipeline/hybrid/config_hybrid.json'
            )
        
        if not os.path.exists(config_path):
            logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            config = {
                'train': {
                    'epochs': 20,
                    'batch_size': 2048,
                    'lr': 0.0003,
                    'hidden_dim': 128
                },
                'paths': {
                    'checkpoints': '/workspace/rl_pipeline/artifacts/checkpoints',
                    'db': '/workspace/data_storage/rl_strategies.db'
                }
            }
        else:
            with open(config_path, 'r') as f:
                config = json.load(f)
        
        # Trainer ì´ˆê¸°í™” ë° í•™ìŠµ
        logger.info(f"ğŸš€ {coin}-{interval}: ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘ ({len(episodes_data)}ê°œ ì—í”¼ì†Œë“œ)")
        
        try:
            trainer = PPOTrainer(config)
        except ImportError as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨ (JAX ê´€ë ¨): {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"ì´ˆê¸°í™” ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
            return None

        try:
            # ğŸ†• ì¦ë¶„ í•™ìŠµ: episodes_dataì—ì„œ ì „ëµ ì •ë³´ ì¶”ì¶œ
            from rl_pipeline.db.reads import load_strategies_pool

            # ìµœê·¼ ìƒì„±ëœ ì „ëµë“¤ ë¡œë“œ (similarity_classification ë©”íƒ€ë°ì´í„° í¬í•¨)
            strategies = load_strategies_pool(
                coin=coin,
                interval=interval,
                limit=100,  # ìµœê·¼ 100ê°œë§Œ
                order_by="created_at DESC",
                include_unknown=True
            )

            # ğŸ”¥ ì¦ë¶„ í•™ìŠµ ì ìš© ì—¬ë¶€ í™•ì¸
            has_incremental_metadata = any(
                s.get('similarity_classification') in ['copy', 'finetune', 'novel']
                for s in strategies
            )

            if has_incremental_metadata and len(strategies) > 0:
                logger.info(f"ğŸ”„ {coin}-{interval}: ì¦ë¶„ í•™ìŠµ ëª¨ë“œ í™œì„±í™”")
                model_id = train_strategies_incremental(
                    strategies=strategies,
                    episodes_data=episodes_data,
                    trainer=trainer,
                    db_path=config.get('paths', {}).get('db'),
                    analysis_data=None
                )
            else:
                logger.info(f"ğŸ“Š {coin}-{interval}: ì¼ë°˜ í•™ìŠµ ëª¨ë“œ (ë©”íƒ€ë°ì´í„° ì—†ìŒ)")
                model_id = trainer.train_from_selfplay_data(
                    episodes_data,
                    db_path=config.get('paths', {}).get('db')
                )
            
            if model_id:
                logger.info(f"âœ… {coin}-{interval}: ì‹ ê²½ë§ í•™ìŠµ ì™„ë£Œ: {model_id}")
                
                # ğŸ”¥ ìë™ í‰ê°€ ì‹¤í–‰ (í™˜ê²½ë³€ìˆ˜ ì²´í¬)
                if should_auto_evaluate(model_id):
                    try:
                        # í‰ê°€ì— í•„ìš”í•œ ë°ì´í„° ì¤€ë¹„
                        from rl_pipeline.data.candles_loader import load_candles
                        
                        # ìº”ë“¤ ë°ì´í„° ë¡œë“œ (ìµœê·¼ 30ì¼)
                        candle_data = load_candles(coin, interval, days=30)
                        
                        if candle_data is not None and len(candle_data) > 0:
                            # ì „ëµ íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (DBì—ì„œ ë˜ëŠ” selfplay_resultì—ì„œ)
                            strategy_params_list = []
                            if selfplay_result and 'cycle_results' in selfplay_result:
                                # cycle_resultsì—ì„œ ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                                for cycle in selfplay_result['cycle_results']:
                                    results = cycle.get('results', {})
                                    for agent_id, perf in results.items():
                                        if 'strategy_params' in perf:
                                            strategy_params_list.append(perf['strategy_params'])
                            
                            # ì¤‘ë³µ ì œê±°
                            if strategy_params_list:
                                seen = set()
                                unique_params = []
                                for params in strategy_params_list:
                                    params_str = str(sorted(params.items()))
                                    if params_str not in seen:
                                        seen.add(params_str)
                                        unique_params.append(params)
                                strategy_params_list = unique_params[:10]  # ìµœëŒ€ 10ê°œ
                            
                            # ê¸°ë³¸ ì „ëµ íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ê¸°ë³¸ê°’ ì‚¬ìš©
                            if not strategy_params_list:
                                strategy_params_list = [{
                                    'rsi_min': 30.0, 'rsi_max': 70.0,
                                    'volume_ratio_min': 1.0, 'volume_ratio_max': 2.0,
                                    'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01,
                                    'stop_loss_pct': 0.02, 'take_profit_pct': 0.05
                                }]
                            
                            # ìë™ í‰ê°€ ì‹¤í–‰
                            eval_result = auto_evaluate_model(
                                model_id=model_id,
                                coin=coin,
                                interval=interval,
                                candle_data=candle_data,
                                strategy_params_list=strategy_params_list,
                                config=config
                            )
                            
                            if eval_result:
                                logger.info(f"âœ… {coin}-{interval}: ìë™ í‰ê°€ ì™„ë£Œ")
                                
                                # ğŸ”¥ ê²€ì¦ ê²°ê³¼ í‰ê°€ ë° ì¬í•™ìŠµ íŒë‹¨
                                passed, reason, details = evaluate_validation_results(eval_result)
                                
                                if passed:
                                    logger.info(f"âœ… {coin}-{interval}: ê²€ì¦ í•©ê²© - ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
                                    if details.get('warnings'):
                                        logger.info(f"   âš ï¸ ê²½ê³  {len(details['warnings'])}ê°œ: {', '.join(details['warnings'][:2])}")
                                else:
                                    logger.warning(f"âš ï¸ {coin}-{interval}: ê²€ì¦ ë¶ˆí•©ê²© - {reason}")
                                    
                                    # ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ í™•ì¸ (ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì )
                                    needs_retrain, retrain_reason = should_retrain(eval_result, previous_attempts=previous_attempts)
                                    
                                    if needs_retrain:
                                        logger.warning(f"ğŸ”„ {coin}-{interval}: ì¬í•™ìŠµ ê¶Œì¥ - {retrain_reason} (ì¬ì‹œë„: {previous_attempts}íšŒ)")
                                        
                                        # ì¬í•™ìŠµ ì œì•ˆ ê°€ì ¸ì˜¤ê¸°
                                        suggestions = get_retrain_suggestions(eval_result)
                                        logger.info(f"ğŸ’¡ ì¬í•™ìŠµ ì œì•ˆ: {suggestions.get('reason', '')}")
                                        
                                        # ğŸ”¥ ìë™ ì¬í•™ìŠµ ì—¬ë¶€ í™•ì¸ (í™˜ê²½ë³€ìˆ˜)
                                        auto_retrain_enabled = os.getenv('ENABLE_AUTO_RETRAIN', 'false').lower() == 'true'
                                        
                                        if auto_retrain_enabled:
                                            logger.info(f"ğŸ”„ {coin}-{interval}: ìë™ ì¬í•™ìŠµ ì‹œì‘ (í™˜ê²½ë³€ìˆ˜ í™œì„±í™”ë¨, ì¬ì‹œë„: {previous_attempts + 1}íšŒ)")
                                            # ì¬í•™ìŠµ ì‹¤í–‰ (ì¬ê·€ í˜¸ì¶œ, ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€)
                                            retrain_model_id = auto_train_from_selfplay(
                                                coin=coin,
                                                interval=interval,
                                                selfplay_result=selfplay_result,
                                                config_path=config_path,
                                                min_episodes=min_episodes,
                                                previous_attempts=previous_attempts + 1  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
                                            )
                                            if retrain_model_id:
                                                logger.info(f"âœ… {coin}-{interval}: ì¬í•™ìŠµ ì™„ë£Œ: {retrain_model_id}")
                                                return retrain_model_id
                                            else:
                                                logger.warning(f"âš ï¸ {coin}-{interval}: ì¬í•™ìŠµ ì‹¤íŒ¨")
                                        else:
                                            logger.info(f"ğŸ’¡ ìë™ ì¬í•™ìŠµ ë¹„í™œì„±í™” (ENABLE_AUTO_RETRAIN=false), ìˆ˜ë™ ì¬í•™ìŠµ ê¶Œì¥")
                                    else:
                                        logger.info(f"ğŸ“Š {coin}-{interval}: ì¬í•™ìŠµ ë¶ˆí•„ìš” ë˜ëŠ” ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                            else:
                                logger.warning(f"âš ï¸ {coin}-{interval}: ìë™ í‰ê°€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
                        else:
                            logger.warning(f"âš ï¸ {coin}-{interval}: í‰ê°€ìš© ìº”ë“¤ ë°ì´í„° ì—†ìŒ, í‰ê°€ ê±´ë„ˆëœ€")
                    except Exception as eval_err:
                        logger.warning(f"âš ï¸ {coin}-{interval}: ìë™ í‰ê°€ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {eval_err}")
            else:
                logger.warning(f"âš ï¸ {coin}-{interval}: í•™ìŠµ ì™„ë£Œí–ˆì§€ë§Œ ëª¨ë¸ IDê°€ ì—†ìŒ")
            
            return model_id
        except Exception as train_err:
            logger.error(f"âŒ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {train_err}")
            import traceback
            logger.debug(f"í•™ìŠµ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ ìë™ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ìë™ í•™ìŠµ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
        return None


def auto_train_from_integrated_analysis(
    coin: str,
    all_interval_selfplay: Dict[str, Dict[str, Any]],  # {interval: selfplay_result}
    analysis_result: Any,  # CoinSignalScore ë˜ëŠ” dict
    config_path: Optional[str] = None,
    min_episodes: int = 10,
    previous_attempts: int = 0  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
) -> Optional[str]:
    """
    í†µí•© ë¶„ì„ ë‹¨ê³„ì—ì„œ ìë™ í•™ìŠµ (ëª¨ë“  ì¸í„°ë²Œ self-play + ë¶„ì„ ê²°ê³¼ í™œìš©)
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        all_interval_selfplay: ëª¨ë“  ì¸í„°ë²Œì˜ self-play ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            {
                '15m': {...selfplay_result...},
                '30m': {...selfplay_result...},
                ...
            }
        analysis_result: í†µí•© ë¶„ì„ ê²°ê³¼ (CoinSignalScore ë˜ëŠ” dict)
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’)
        min_episodes: ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ (ì¸í„°ë²Œë³„)
    
    Returns:
        í•™ìŠµëœ ëª¨ë¸ ID (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        logger.info(f"ğŸš€ {coin}: í†µí•© í•™ìŠµ ì‹œì‘ (ì¸í„°ë²Œ ìˆ˜: {len(all_interval_selfplay)})")
        logger.info(f"ğŸ“Š í•™ìŠµ ëŒ€ìƒ ì¸í„°ë²Œ: {list(all_interval_selfplay.keys())}")
        
        # JAX ê°€ìš©ì„± í™•ì¸
        try:
            import jax
            import jax.numpy as jnp
            from flax import linen as nn
            logger.debug("âœ… JAX/Flax ì„í¬íŠ¸ ì„±ê³µ")
        except ImportError as import_err:
            logger.warning(f"âš ï¸ JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤: {import_err}")
            return None
        
        # neural_policy_jax ëª¨ë“ˆ í™•ì¸
        try:
            from rl_pipeline.hybrid.neural_policy_jax import JAX_AVAILABLE as NEURAL_JAX_AVAILABLE
            if not NEURAL_JAX_AVAILABLE:
                logger.warning("âš ï¸ neural_policy_jax ëª¨ë“ˆì—ì„œ JAX ì‚¬ìš© ë¶ˆê°€, í•™ìŠµ ê±´ë„ˆëœë‹ˆë‹¤")
                return None
        except ImportError as import_err:
            logger.warning(f"âš ï¸ neural_policy_jax ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {import_err}")
            return None
        
        # í†µí•© ë¶„ì„ ê²°ê³¼ì—ì„œ ë¶„ì„ ì ìˆ˜ ì¶”ì¶œ
        if hasattr(analysis_result, 'fractal_score'):
            # CoinSignalScore ê°ì²´ì¸ ê²½ìš°
            analysis_data = {
                'fractal_score': analysis_result.fractal_score,
                'multi_timeframe_score': analysis_result.multi_timeframe_score,
                'indicator_cross_score': analysis_result.indicator_cross_score,
                'ensemble_score': analysis_result.ensemble_score,
                'ensemble_confidence': analysis_result.ensemble_confidence
            }
            logger.debug(f"âœ… ë¶„ì„ ê²°ê³¼: CoinSignalScore ê°ì²´ì—ì„œ ì¶”ì¶œ")
        elif isinstance(analysis_result, dict):
            # dictì¸ ê²½ìš°
            analysis_data = {
                'fractal_score': analysis_result.get('fractal_score', 0.5),
                'multi_timeframe_score': analysis_result.get('multi_timeframe_score', 0.5),
                'indicator_cross_score': analysis_result.get('indicator_cross_score', 0.5),
                'ensemble_score': analysis_result.get('ensemble_score', 0.5),
                'ensemble_confidence': analysis_result.get('ensemble_confidence', 0.5)
            }
            logger.debug(f"âœ… ë¶„ì„ ê²°ê³¼: dictì—ì„œ ì¶”ì¶œ")
        elif hasattr(analysis_result, 'signal_score') or hasattr(analysis_result, 'signal_action'):
            # PipelineResult ê°ì²´ì¸ ê²½ìš° (ë¶„ì„ ì ìˆ˜ëŠ” ì—†ì§€ë§Œ signal_scoreëŠ” ìˆìŒ)
            # DBì—ì„œ ìµœì‹  í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹œë„
            logger.debug(f"â„¹ï¸ ë¶„ì„ ê²°ê³¼: PipelineResult ê°ì²´ ê°ì§€ (íƒ€ì…: {type(analysis_result).__name__}), DBì—ì„œ ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹œë„")
            try:
                from rl_pipeline.db.reads import fetch_integrated_analysis
                from rl_pipeline.db.connection_pool import get_strategy_db_pool
                
                pool = get_strategy_db_pool()
                with pool.get_connection() as conn:
                    # ìµœì‹  í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
                    latest_analysis = fetch_integrated_analysis(conn, coin, 'all_intervals')
                    if latest_analysis and isinstance(latest_analysis, dict):
                        # fetch_integrated_analysis ë°˜í™˜ í˜•ì‹: multi_tf_score (multi_timeframe_score ì•„ë‹˜)
                        analysis_data = {
                            'fractal_score': latest_analysis.get('fractal_score', 0.5),
                            'multi_timeframe_score': latest_analysis.get('multi_tf_score', latest_analysis.get('multi_timeframe_score', 0.5)),
                            'indicator_cross_score': latest_analysis.get('indicator_cross_score', 0.5),
                            'ensemble_score': latest_analysis.get('score', latest_analysis.get('ensemble_score', 0.5)),
                            'ensemble_confidence': latest_analysis.get('confidence', latest_analysis.get('signal_confidence', 0.5))
                        }
                        logger.info(f"âœ… ë¶„ì„ ê²°ê³¼: DBì—ì„œ ìµœì‹  í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì„±ê³µ (í”„ë™íƒˆ={analysis_data['fractal_score']:.3f}, ë©€í‹°TF={analysis_data['multi_timeframe_score']:.3f}, ì•™ìƒë¸”={analysis_data['ensemble_score']:.3f})")
                    else:
                        # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                        analysis_data = {
                            'fractal_score': 0.5,
                            'multi_timeframe_score': 0.5,
                            'indicator_cross_score': 0.5,
                            'ensemble_score': 0.5,
                            'ensemble_confidence': 0.5
                        }
                        logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼: PipelineResult ê°ì²´ì´ì§€ë§Œ DBì—ì„œ ë¶„ì„ ì ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (coin={coin}, interval=all_intervals), ê¸°ë³¸ê°’ ì‚¬ìš©")
            except Exception as db_err:
                # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                analysis_data = {
                    'fractal_score': 0.5,
                    'multi_timeframe_score': 0.5,
                    'indicator_cross_score': 0.5,
                    'ensemble_score': 0.5,
                    'ensemble_confidence': 0.5
                }
                logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼: PipelineResult ê°ì²´ì´ì§€ë§Œ DB ì¡°íšŒ ì‹¤íŒ¨ ({type(db_err).__name__}: {str(db_err)[:100]}), ê¸°ë³¸ê°’ ì‚¬ìš©")
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹
            result_type = type(analysis_result).__name__
            result_str = str(analysis_result)[:200] if analysis_result is not None else "None"
            logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„ (íƒ€ì…: {result_type}), ê¸°ë³¸ê°’ ì‚¬ìš©")
            logger.debug(f"   ë¶„ì„ ê²°ê³¼ ë‚´ìš©: {result_str}")
            analysis_data = {
                'fractal_score': 0.5,
                'multi_timeframe_score': 0.5,
                'indicator_cross_score': 0.5,
                'ensemble_score': 0.5,
                'ensemble_confidence': 0.5
            }
        
        logger.info(f"ğŸ“Š ë¶„ì„ ì ìˆ˜: í”„ë™íƒˆ={analysis_data['fractal_score']:.3f}, "
                   f"ë©€í‹°TF={analysis_data['multi_timeframe_score']:.3f}, "
                   f"ì§€í‘œêµì°¨={analysis_data['indicator_cross_score']:.3f}")
        
        # ëª¨ë“  ì¸í„°ë²Œì˜ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ë° ê²°í•©
        all_episodes_data = []
        total_episodes = 0
        
        for interval, selfplay_result in all_interval_selfplay.items():
            if not selfplay_result:
                logger.debug(f"  âš ï¸ {coin}-{interval}: selfplay_resultê°€ ë¹„ì–´ìˆìŒ, ìŠ¤í‚µ")
                continue
            
            # ğŸ”¥ ë””ë²„ê¹…: selfplay_result êµ¬ì¡° í™•ì¸
            logger.info(f"  ğŸ“Š {coin}-{interval}: selfplay_result íƒ€ì…={type(selfplay_result)}, keys={list(selfplay_result.keys()) if isinstance(selfplay_result, dict) else 'N/A'}")
            
            # ğŸ”¥ cycle_results í™•ì¸ (ë””ë²„ê¹…)
            if isinstance(selfplay_result, dict):
                cycle_results = selfplay_result.get("cycle_results", [])
                logger.info(f"  ğŸ“Š {coin}-{interval}: cycle_results ì¡´ì¬={cycle_results is not None}, ê¸¸ì´={len(cycle_results) if cycle_results else 0}")
                if cycle_results and len(cycle_results) > 0:
                    first_cycle = cycle_results[0] if cycle_results else {}
                    logger.info(f"  ğŸ“Š {coin}-{interval}: ì²« ë²ˆì§¸ cycle íƒ€ì…={type(first_cycle)}, keys={list(first_cycle.keys()) if isinstance(first_cycle, dict) else 'N/A'}")
            
            episodes_data = collect_selfplay_data_for_training(
                coin, interval, selfplay_result, min_episodes=0  # ìµœì†Œ ì—í”¼ì†Œë“œ ì²´í¬ëŠ” ì „ì²´ì—ì„œ
            )
            
            if episodes_data:
                all_episodes_data.extend(episodes_data)
                total_episodes += len(episodes_data)
                logger.info(f"  âœ… {interval}: {len(episodes_data)}ê°œ ì—í”¼ì†Œë“œ ì¶”ê°€")
            else:
                logger.warning(f"  âš ï¸ {coin}-{interval}: ì—í”¼ì†Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ (0ê°œ)")
                # ğŸ”¥ ë””ë²„ê¹…: ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸
                if isinstance(selfplay_result, dict):
                    cycle_results = selfplay_result.get("cycle_results", [])
                    logger.warning(f"    cycle_results: {len(cycle_results)}ê°œ")
                    if cycle_results:
                        first_cycle = cycle_results[0] if cycle_results else {}
                        logger.warning(f"    ì²« ë²ˆì§¸ cycle keys: {list(first_cycle.keys()) if isinstance(first_cycle, dict) else 'N/A'}")
        
        # ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ ì²´í¬ (ì „ì²´ ê¸°ì¤€)
        if total_episodes < min_episodes:
            logger.info(f"ğŸ“Š {coin}: ì´ ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({total_episodes} < {min_episodes}), í•™ìŠµ ê±´ë„ˆëœ€")
            return None
        
        # ğŸ”¥ ê°œì„ : ì¤‘ë³µ ì—í”¼ì†Œë“œ ì²´í¬ ë° ì œê±° (ì™„í™”ëœ ê¸°ì¤€)
        try:
            seen_episodes = set()
            unique_episodes = []
            duplicate_count = 0
            
            for episode in all_episodes_data:
                # ğŸ”¥ ì™„í™”ëœ ê³ ìœ ì„± íŒë‹¨: (coin, interval, episode_num, timestamp)
                # states/actions í•´ì‹œëŠ” ë„ˆë¬´ ì—„ê²©í•˜ì—¬ ê±°ì˜ ëª¨ë“  ì—í”¼ì†Œë“œê°€ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ë¨
                # episode_numê³¼ timestampë¡œ ì¶©ë¶„íˆ êµ¬ë¶„ ê°€ëŠ¥
                episode_num = episode.get('episode', 0)
                timestamp = episode.get('timestamp', '')
                interval_key = episode.get('interval', interval)
                
                # ğŸ”¥ resultsì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë„ í¬í•¨ (ë” ì •í™•í•œ êµ¬ë¶„)
                results = episode.get('results', {})
                first_agent_id = list(results.keys())[0] if results else ''
                first_result = results.get(first_agent_id, {}) if first_agent_id else {}
                total_pnl = first_result.get('total_pnl', 0.0)
                total_trades = first_result.get('total_trades', 0)
                
                # ğŸ”¥ ì™„í™”ëœ í‚¤: episode_num + interval + total_trades + timestamp (ì²˜ìŒ 10ìë§Œ)
                # ê°™ì€ ì—í”¼ì†Œë“œ ë²ˆí˜¸ë¼ë„ ë‹¤ë¥¸ intervalì´ë‚˜ ì„±ê³¼ë©´ ë‹¤ë¥¸ ì—í”¼ì†Œë“œë¡œ ê°„ì£¼
                episode_key = (
                    coin,
                    interval_key,
                    episode_num,
                    total_trades,  # ê±°ë˜ ìˆ˜ë¡œ êµ¬ë¶„
                    round(total_pnl, 2),  # ìˆ˜ìµì„ ì†Œìˆ˜ì  2ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼í•˜ì—¬ êµ¬ë¶„
                    timestamp[:10] if timestamp else ''  # íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ìŒ 10ì
                )
                
                if episode_key not in seen_episodes:
                    seen_episodes.add(episode_key)
                    unique_episodes.append(episode)
                else:
                    duplicate_count += 1
            
            if duplicate_count > 0:
                logger.info(f"ğŸ“Š {coin}: ì¤‘ë³µ ì—í”¼ì†Œë“œ {duplicate_count}ê°œ ì œê±°, {len(unique_episodes)}ê°œ ê³ ìœ  ì—í”¼ì†Œë“œ ì‚¬ìš©")
                all_episodes_data = unique_episodes
                total_episodes = len(unique_episodes)
        except Exception as e:
            logger.warning(f"âš ï¸ ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        # ğŸ”¥ ê°œì„ : í•™ìŠµ ë¹ˆë„ ì œí•œ ì²´í¬ (ìµœê·¼ Nì‹œê°„ ë‚´ í•™ìŠµí–ˆìœ¼ë©´ ìŠ¤í‚µ)
        try:
            from rl_pipeline.db.connection_pool import get_optimized_db_connection
            min_training_interval_hours = int(os.getenv('MIN_TRAINING_INTERVAL_HOURS', '6'))  # ê¸°ë³¸ 6ì‹œê°„
            
            with get_optimized_db_connection("strategies") as conn:
                cursor = conn.cursor()
                # ìµœê·¼ í•™ìŠµ ê¸°ë¡ ì¡°íšŒ
                cursor.execute("""
                    SELECT MAX(created_at) as last_training
                    FROM hybrid_models
                    WHERE coin = ? AND status = 'completed'
                """, (coin,))
                
                result = cursor.fetchone()
                if result and result[0]:
                    from datetime import datetime, timedelta
                    last_training_str = result[0]
                    if isinstance(last_training_str, str):
                        last_training = datetime.fromisoformat(last_training_str.replace('Z', '+00:00'))
                    else:
                        last_training = result[0]
                    
                    time_since_last = datetime.now() - (last_training.replace(tzinfo=None) if last_training.tzinfo else last_training)
                    
                    if time_since_last.total_seconds() < min_training_interval_hours * 3600:
                        hours_remaining = (min_training_interval_hours * 3600 - time_since_last.total_seconds()) / 3600
                        logger.info(f"ğŸ“Š {coin}: ìµœê·¼ í•™ìŠµ í›„ {time_since_last.total_seconds()/3600:.1f}ì‹œê°„ ê²½ê³¼, "
                                  f"ìµœì†Œ ê°„ê²©({min_training_interval_hours}ì‹œê°„) ë¯¸ë‹¬ë¡œ í•™ìŠµ ê±´ë„ˆëœ€ "
                                  f"(ë‚¨ì€ ì‹œê°„: {hours_remaining:.1f}ì‹œê°„)")
                        return None
        except Exception as e:
            logger.debug(f"âš ï¸ í•™ìŠµ ë¹ˆë„ ì²´í¬ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        
        logger.info(f"âœ… {coin}: ì´ {total_episodes}ê°œ ê³ ìœ  ì—í”¼ì†Œë“œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            config_path = os.getenv(
                'HYBRID_CONFIG_PATH',
                '/workspace/rl_pipeline/hybrid/config_hybrid.json'
            )
        
        if not os.path.exists(config_path):
            logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            config = {
                'train': {
                    'epochs': 30,
                    'batch_size': 4096,
                    'lr': 0.0003,
                    'hidden_dim': 128
                },
                'paths': {
                    'checkpoints': '/workspace/rl_pipeline/artifacts/checkpoints',
                    'db': '/workspace/data_storage/rl_strategies.db'
                }
            }
        else:
            with open(config_path, 'r') as f:
                config = json.load(f)
        
        # Trainer ì´ˆê¸°í™” ë° í•™ìŠµ
        logger.info(f"ğŸš€ {coin}: í†µí•© ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘")
        logger.info(f"   ğŸ“Š ì—í”¼ì†Œë“œ: {total_episodes}ê°œ")
        logger.info(f"   ğŸ”¥ ë¶„ì„ ë°ì´í„° í¬í•¨: 25ì°¨ì› ìƒíƒœ ë²¡í„° ì‚¬ìš© (í™•ì¥ ì§€í‘œ í¬í•¨)")
        logger.info(f"   ğŸ“ˆ ë¶„ì„ ì ìˆ˜: í”„ë™íƒˆ={analysis_data['fractal_score']:.3f}, "
                   f"ë©€í‹°TF={analysis_data['multi_timeframe_score']:.3f}, "
                   f"ì§€í‘œêµì°¨={analysis_data['indicator_cross_score']:.3f}")
        
        try:
            trainer = PPOTrainer(config)
        except ImportError as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨ (JAX ê´€ë ¨): {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"ì´ˆê¸°í™” ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
            return None

        try:
            # ğŸ†• ì¦ë¶„ í•™ìŠµ: í†µí•© í•™ìŠµì—ë„ ì ìš©
            from rl_pipeline.db.reads import load_strategies_pool

            # ëª¨ë“  ì¸í„°ë²Œì˜ ìµœê·¼ ì „ëµ ë¡œë“œ
            all_strategies = []
            for interval in all_interval_selfplay.keys():
                strategies = load_strategies_pool(
                    coin=coin,
                    interval=interval,
                    limit=50,  # ì¸í„°ë²Œë‹¹ 50ê°œì”©
                    order_by="created_at DESC",
                    include_unknown=True
                )
                all_strategies.extend(strategies)

            # ì¦ë¶„ í•™ìŠµ ì ìš© ì—¬ë¶€ í™•ì¸
            has_incremental_metadata = any(
                s.get('similarity_classification') in ['copy', 'finetune', 'novel']
                for s in all_strategies
            )

            if has_incremental_metadata and len(all_strategies) > 0:
                logger.info(f"ğŸ”„ {coin}: í†µí•© í•™ìŠµ - ì¦ë¶„ í•™ìŠµ ëª¨ë“œ í™œì„±í™” ({len(all_strategies)}ê°œ ì „ëµ)")
                model_id = train_strategies_incremental(
                    strategies=all_strategies,
                    episodes_data=all_episodes_data,
                    trainer=trainer,
                    db_path=config.get('paths', {}).get('db'),
                    analysis_data=analysis_data
                )
            else:
                logger.info(f"ğŸ“Š {coin}: í†µí•© í•™ìŠµ - ì¼ë°˜ í•™ìŠµ ëª¨ë“œ")
                model_id = trainer.train_from_selfplay_data(
                    all_episodes_data,
                    db_path=config.get('paths', {}).get('db'),
                    analysis_data=analysis_data  # ğŸ”¥ ë¶„ì„ ë°ì´í„° ì „ë‹¬
                )
            
            if model_id:
                logger.info(f"âœ… {coin}: í†µí•© ì‹ ê²½ë§ í•™ìŠµ ì™„ë£Œ: {model_id}")
                
                # ğŸ”¥ ìë™ í‰ê°€ ì‹¤í–‰ (í™˜ê²½ë³€ìˆ˜ ì²´í¬)
                if should_auto_evaluate(model_id):
                    try:
                        # í‰ê°€ëŠ” ì²« ë²ˆì§¸ ì¸í„°ë²Œë¡œ ì‹¤í–‰ (ëŒ€í‘œì„±)
                        first_interval = list(all_interval_selfplay.keys())[0] if all_interval_selfplay else None
                        if first_interval:
                            from rl_pipeline.data.candles_loader import load_candles
                            
                            # ìº”ë“¤ ë°ì´í„° ë¡œë“œ
                            candle_data = load_candles(coin, first_interval, days=30)
                            
                            if candle_data is not None and len(candle_data) > 0:
                                # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                                strategy_params_list = []
                                first_selfplay = all_interval_selfplay.get(first_interval, {})
                                if first_selfplay and 'cycle_results' in first_selfplay:
                                    for cycle in first_selfplay['cycle_results']:
                                        results = cycle.get('results', {})
                                        for agent_id, perf in results.items():
                                            if 'strategy_params' in perf:
                                                strategy_params_list.append(perf['strategy_params'])
                                
                                # ì¤‘ë³µ ì œê±°
                                if strategy_params_list:
                                    seen = set()
                                    unique_params = []
                                    for params in strategy_params_list:
                                        params_str = str(sorted(params.items()))
                                        if params_str not in seen:
                                            seen.add(params_str)
                                            unique_params.append(params)
                                    strategy_params_list = unique_params[:10]
                                
                                if not strategy_params_list:
                                    strategy_params_list = [{
                                        'rsi_min': 30.0, 'rsi_max': 70.0,
                                        'volume_ratio_min': 1.0, 'volume_ratio_max': 2.0,
                                        'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01,
                                        'stop_loss_pct': 0.02, 'take_profit_pct': 0.05
                                    }]
                                
                                # ìë™ í‰ê°€ ì‹¤í–‰
                                eval_result = auto_evaluate_model(
                                    model_id=model_id,
                                    coin=coin,
                                    interval=first_interval,
                                    candle_data=candle_data,
                                    strategy_params_list=strategy_params_list,
                                    config=config
                                )
                                
                                if eval_result:
                                    logger.info(f"âœ… {coin}-{first_interval}: í†µí•© í•™ìŠµ ìë™ í‰ê°€ ì™„ë£Œ")
                                    
                                    # ğŸ”¥ ê²€ì¦ ê²°ê³¼ í‰ê°€ ë° ì¬í•™ìŠµ íŒë‹¨
                                    passed, reason, details = evaluate_validation_results(eval_result)
                                    
                                    if passed:
                                        logger.info(f"âœ… {coin}-{first_interval}: ê²€ì¦ í•©ê²© - ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
                                        if details.get('warnings'):
                                            logger.info(f"   âš ï¸ ê²½ê³  {len(details['warnings'])}ê°œ: {', '.join(details['warnings'][:2])}")
                                    else:
                                        logger.warning(f"âš ï¸ {coin}-{first_interval}: ê²€ì¦ ë¶ˆí•©ê²© - {reason}")
                                        
                                        # ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ í™•ì¸ (ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì )
                                        needs_retrain, retrain_reason = should_retrain(eval_result, previous_attempts=previous_attempts)
                                        
                                        if needs_retrain:
                                            logger.warning(f"ğŸ”„ {coin}-{first_interval}: ì¬í•™ìŠµ ê¶Œì¥ - {retrain_reason} (ì¬ì‹œë„: {previous_attempts}íšŒ)")
                                            
                                            # ì¬í•™ìŠµ ì œì•ˆ ê°€ì ¸ì˜¤ê¸°
                                            suggestions = get_retrain_suggestions(eval_result)
                                            logger.info(f"ğŸ’¡ ì¬í•™ìŠµ ì œì•ˆ: {suggestions.get('reason', '')}")
                                            
                                            # ğŸ”¥ ìë™ ì¬í•™ìŠµ ì—¬ë¶€ í™•ì¸ (í™˜ê²½ë³€ìˆ˜)
                                            auto_retrain_enabled = os.getenv('ENABLE_AUTO_RETRAIN', 'false').lower() == 'true'
                                            
                                            if auto_retrain_enabled:
                                                logger.info(f"ğŸ”„ {coin}-{first_interval}: ìë™ ì¬í•™ìŠµ ì‹œì‘ (í™˜ê²½ë³€ìˆ˜ í™œì„±í™”ë¨, ì¬ì‹œë„: {previous_attempts + 1}íšŒ)")
                                                
                                                # ğŸ”¥ ì¬í•™ìŠµ ì‹œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ì ìš©
                                                adjusted_config_path = None
                                                if suggestions.get('adjust_learning_rate') or suggestions.get('adjust_entropy_coef'):
                                                    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° ì„ì‹œ ì„¤ì • íŒŒì¼ ìƒì„±
                                                    adjusted_config_path = _create_adjusted_config(
                                                        config_path=config_path,
                                                        suggestions=suggestions,
                                                        previous_attempts=previous_attempts + 1
                                                    )
                                                    logger.info(f"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ì ìš©: {adjusted_config_path}")
                                                
                                                # ì¬í•™ìŠµ ì‹¤í–‰ (ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€, ì¡°ì •ëœ ì„¤ì • ì‚¬ìš©)
                                                retrain_model_id = auto_train_from_integrated_analysis(
                                                    coin=coin,
                                                    all_interval_selfplay=all_interval_selfplay,
                                                    analysis_result=analysis_result,
                                                    config_path=adjusted_config_path or config_path,  # ğŸ”¥ ì¡°ì •ëœ ì„¤ì • ì‚¬ìš©
                                                    min_episodes=min_episodes,
                                                    previous_attempts=previous_attempts + 1  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
                                                )
                                                if retrain_model_id:
                                                    logger.info(f"âœ… {coin}-{first_interval}: ì¬í•™ìŠµ ì™„ë£Œ: {retrain_model_id}")
                                                    return retrain_model_id
                                                else:
                                                    logger.warning(f"âš ï¸ {coin}-{first_interval}: ì¬í•™ìŠµ ì‹¤íŒ¨")
                                            else:
                                                logger.info(f"ğŸ’¡ ìë™ ì¬í•™ìŠµ ë¹„í™œì„±í™” (ENABLE_AUTO_RETRAIN=false), ìˆ˜ë™ ì¬í•™ìŠµ ê¶Œì¥")
                                        else:
                                            logger.info(f"ğŸ“Š {coin}-{first_interval}: ì¬í•™ìŠµ ë¶ˆí•„ìš” ë˜ëŠ” ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                                else:
                                    logger.warning(f"âš ï¸ {coin}-{first_interval}: í†µí•© í•™ìŠµ ìë™ í‰ê°€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
                    except Exception as eval_err:
                        logger.warning(f"âš ï¸ {coin}: í†µí•© í•™ìŠµ ìë™ í‰ê°€ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {eval_err}")
            else:
                logger.warning(f"âš ï¸ {coin}: í•™ìŠµ ì™„ë£Œí–ˆì§€ë§Œ ëª¨ë¸ IDê°€ ì—†ìŒ")
            
            return model_id
        except Exception as train_err:
            logger.error(f"âŒ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {train_err}")
            import traceback
            logger.error(f"í•™ìŠµ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© ìë™ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"í†µí•© ìë™ í•™ìŠµ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
        return None


def auto_train_from_global_strategies(
    all_coin_selfplay: Dict[str, Dict[str, Dict[str, Any]]],  # {coin: {interval: selfplay_result}}
    all_coin_analysis: Dict[str, Any],  # {coin: analysis_result} ë˜ëŠ” ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼
    config_path: Optional[str] = None,
    min_episodes: int = 20,  # ê¸€ë¡œë²Œ í•™ìŠµì€ ë” ë§ì€ ë°ì´í„° í•„ìš”
    previous_attempts: int = 0,  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
    session_id: Optional[str] = None  # ë””ë²„ê·¸ ì„¸ì…˜ ID
) -> Optional[str]:
    """
    ê¸€ë¡œë²Œ ì „ëµ ìƒì„± ë‹¨ê³„ì—ì„œ ìë™ í•™ìŠµ (ëª¨ë“  ì½”ì¸ self-play + ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼ í™œìš©)
    
    Args:
        all_coin_selfplay: ëª¨ë“  ì½”ì¸ì˜ self-play ê²°ê³¼
            {
                'BTC': {
                    '15m': {...selfplay_result...},
                    '30m': {...selfplay_result...},
                    ...
                },
                'ETH': {...},
                ...
            }
        all_coin_analysis: ëª¨ë“  ì½”ì¸ì˜ í†µí•© ë¶„ì„ ê²°ê³¼ ë˜ëŠ” ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼
            - ì˜µì…˜ 1: {coin: analysis_result}
            - ì˜µì…˜ 2: ê¸€ë¡œë²Œ í†µí•© ë¶„ì„ ê²°ê³¼ (ë‹¨ì¼ dict)
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’)
        min_episodes: ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ (ëª¨ë“  ì½”ì¸ í•©ì‚°)
    
    Returns:
        í•™ìŠµëœ ëª¨ë¸ ID (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        logger.info(f"ğŸŒ ê¸€ë¡œë²Œ í•™ìŠµ ì‹œì‘ (ì½”ì¸ ìˆ˜: {len(all_coin_selfplay)})")
        
        # JAX ê°€ìš©ì„± í™•ì¸
        try:
            import jax
            import jax.numpy as jnp
            from flax import linen as nn
            logger.debug("âœ… JAX/Flax ì„í¬íŠ¸ ì„±ê³µ")
        except ImportError as import_err:
            logger.warning(f"âš ï¸ JAXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤: {import_err}")
            return None
        
        # neural_policy_jax ëª¨ë“ˆ í™•ì¸
        try:
            from rl_pipeline.hybrid.neural_policy_jax import JAX_AVAILABLE as NEURAL_JAX_AVAILABLE
            if not NEURAL_JAX_AVAILABLE:
                logger.warning("âš ï¸ neural_policy_jax ëª¨ë“ˆì—ì„œ JAX ì‚¬ìš© ë¶ˆê°€, í•™ìŠµ ê±´ë„ˆëœë‹ˆë‹¤")
                return None
        except ImportError as import_err:
            logger.warning(f"âš ï¸ neural_policy_jax ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {import_err}")
            return None
        
        # ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼ì—ì„œ ë¶„ì„ ì ìˆ˜ ì¶”ì¶œ
        if isinstance(all_coin_analysis, dict):
            # ì½”ì¸ë³„ ë¶„ì„ ê²°ê³¼ì¸ì§€ ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼ì¸ì§€ íŒë‹¨
            if 'fractal_score' in all_coin_analysis or 'overall_score' in all_coin_analysis:
                # ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼ (ë‹¨ì¼ dict)
                if 'fractal_score' in all_coin_analysis:
                    # ê°œë³„ ì½”ì¸ ë¶„ì„ ê²°ê³¼ì™€ ë™ì¼í•œ í˜•ì‹
                    analysis_data = {
                        'fractal_score': all_coin_analysis.get('fractal_score', 0.5),
                        'multi_timeframe_score': all_coin_analysis.get('multi_timeframe_score', 0.5),
                        'indicator_cross_score': all_coin_analysis.get('indicator_cross_score', 0.5),
                        'ensemble_score': all_coin_analysis.get('ensemble_score', 0.5),
                        'ensemble_confidence': all_coin_analysis.get('ensemble_confidence', 0.5)
                    }
                else:
                    # GlobalSignalScore í˜•ì‹ (overall_score í¬í•¨)
                    analysis_data = {
                        'fractal_score': all_coin_analysis.get('overall_score', 0.5),
                        'multi_timeframe_score': all_coin_analysis.get('overall_score', 0.5),
                        'indicator_cross_score': all_coin_analysis.get('overall_score', 0.5),
                        'ensemble_score': all_coin_analysis.get('overall_score', 0.5),
                        'ensemble_confidence': all_coin_analysis.get('overall_confidence', 0.5)
                    }
            else:
                # ì½”ì¸ë³„ ë¶„ì„ ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° (í‰ê·  ê³„ì‚°)
                all_fractal_scores = []
                all_multi_tf_scores = []
                all_indicator_scores = []
                all_ensemble_scores = []
                all_confidence_scores = []
                
                for coin, analysis_result in all_coin_analysis.items():
                    if hasattr(analysis_result, 'fractal_score'):
                        all_fractal_scores.append(analysis_result.fractal_score)
                        all_multi_tf_scores.append(analysis_result.multi_timeframe_score)
                        all_indicator_scores.append(analysis_result.indicator_cross_score)
                        all_ensemble_scores.append(analysis_result.ensemble_score)
                        all_confidence_scores.append(analysis_result.ensemble_confidence)
                    elif isinstance(analysis_result, dict):
                        all_fractal_scores.append(analysis_result.get('fractal_score', 0.5))
                        all_multi_tf_scores.append(analysis_result.get('multi_timeframe_score', 0.5))
                        all_indicator_scores.append(analysis_result.get('indicator_cross_score', 0.5))
                        all_ensemble_scores.append(analysis_result.get('ensemble_score', 0.5))
                        all_confidence_scores.append(analysis_result.get('ensemble_confidence', 0.5))
                
                # í‰ê·  ê³„ì‚°
                analysis_data = {
                    'fractal_score': sum(all_fractal_scores) / len(all_fractal_scores) if all_fractal_scores else 0.5,
                    'multi_timeframe_score': sum(all_multi_tf_scores) / len(all_multi_tf_scores) if all_multi_tf_scores else 0.5,
                    'indicator_cross_score': sum(all_indicator_scores) / len(all_indicator_scores) if all_indicator_scores else 0.5,
                    'ensemble_score': sum(all_ensemble_scores) / len(all_ensemble_scores) if all_ensemble_scores else 0.5,
                    'ensemble_confidence': sum(all_confidence_scores) / len(all_confidence_scores) if all_confidence_scores else 0.5
                }
        else:
            logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ ë¶„ì„ ê²°ê³¼ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„, ê¸°ë³¸ê°’ ì‚¬ìš©")
            analysis_data = {
                'fractal_score': 0.5,
                'multi_timeframe_score': 0.5,
                'indicator_cross_score': 0.5,
                'ensemble_score': 0.5,
                'ensemble_confidence': 0.5
            }
        
        logger.info(f"ğŸ“Š ê¸€ë¡œë²Œ ë¶„ì„ ì ìˆ˜: í”„ë™íƒˆ={analysis_data['fractal_score']:.3f}, "
                   f"ë©€í‹°TF={analysis_data['multi_timeframe_score']:.3f}, "
                   f"ì§€í‘œêµì°¨={analysis_data['indicator_cross_score']:.3f}")
        
        # ëª¨ë“  ì½”ì¸-ì¸í„°ë²Œì˜ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ë° ê²°í•©
        all_episodes_data = []
        total_episodes = 0
        coins_processed = 0
        intervals_processed = 0
        
        for coin, coin_selfplay in all_coin_selfplay.items():
            if not coin_selfplay:
                continue
            
            for interval, selfplay_result in coin_selfplay.items():
                if not selfplay_result:
                    continue
                
                episodes_data = collect_selfplay_data_for_training(
                    coin, interval, selfplay_result, min_episodes=0
                )
                
                if episodes_data:
                    all_episodes_data.extend(episodes_data)
                    total_episodes += len(episodes_data)
                    intervals_processed += 1
                    logger.debug(f"  âœ… {coin}-{interval}: {len(episodes_data)}ê°œ ì—í”¼ì†Œë“œ ì¶”ê°€")
            
            if coin_selfplay:
                coins_processed += 1
        
        # ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ ì²´í¬ (ì „ì²´ ê¸°ì¤€)
        if total_episodes < min_episodes:
            logger.info(f"ğŸ“Š ê¸€ë¡œë²Œ: ì´ ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({total_episodes} < {min_episodes}), í•™ìŠµ ê±´ë„ˆëœ€")
            return None
        
        logger.info(f"âœ… ê¸€ë¡œë²Œ: {coins_processed}ê°œ ì½”ì¸, {intervals_processed}ê°œ ì¸í„°ë²Œ, ì´ {total_episodes}ê°œ ì—í”¼ì†Œë“œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            config_path = os.getenv(
                'HYBRID_CONFIG_PATH',
                '/workspace/rl_pipeline/hybrid/config_hybrid.json'
            )
        
        if not os.path.exists(config_path):
            logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            config = {
                'train': {
                    'epochs': 50,  # ê¸€ë¡œë²Œ í•™ìŠµì€ ë” ë§ì€ ì—í¬í¬
                    'batch_size': 8192,  # ë” í° ë°°ì¹˜ í¬ê¸°
                    'lr': 0.0003,
                    'hidden_dim': 128
                },
                'paths': {
                    'checkpoints': '/workspace/rl_pipeline/artifacts/checkpoints',
                    'db': '/workspace/data_storage/rl_strategies.db'
                }
            }
        else:
            with open(config_path, 'r') as f:
                config = json.load(f)
            # ê¸€ë¡œë²Œ í•™ìŠµìš© ì„¤ì • ì¡°ì •
            if 'train' in config:
                config['train']['epochs'] = config['train'].get('epochs', 30) * 2  # ê¸€ë¡œë²Œì€ 2ë°°
                config['train']['batch_size'] = config['train'].get('batch_size', 2048) * 2  # 2ë°°
        
        # Trainer ì´ˆê¸°í™” ë° í•™ìŠµ
        logger.info(f"ğŸŒ ê¸€ë¡œë²Œ ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘ ({total_episodes}ê°œ ì—í”¼ì†Œë“œ, {coins_processed}ê°œ ì½”ì¸, ê¸€ë¡œë²Œ ë¶„ì„ ë°ì´í„° í¬í•¨)")

        try:
            trainer = PPOTrainer(config, session_id=session_id)
        except ImportError as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨ (JAX ê´€ë ¨): {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ PPOTrainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"ì´ˆê¸°í™” ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
            return None
        
        try:
            model_id = trainer.train_from_selfplay_data(
                all_episodes_data,
                db_path=config.get('paths', {}).get('db'),
                analysis_data=analysis_data  # ğŸ”¥ ê¸€ë¡œë²Œ ë¶„ì„ ë°ì´í„° ì „ë‹¬
            )
            
            if model_id:
                logger.info(f"ğŸŒ ê¸€ë¡œë²Œ ì‹ ê²½ë§ í•™ìŠµ ì™„ë£Œ: {model_id}")
                
                # ğŸ”¥ ìë™ í‰ê°€ ì‹¤í–‰ (í™˜ê²½ë³€ìˆ˜ ì²´í¬)
                if should_auto_evaluate(model_id):
                    try:
                        # í‰ê°€ëŠ” ì²« ë²ˆì§¸ ì½”ì¸-ì¸í„°ë²Œ ì¡°í•©ìœ¼ë¡œ ì‹¤í–‰
                        first_coin = list(all_coin_selfplay.keys())[0] if all_coin_selfplay else None
                        if first_coin:
                            first_coin_data = all_coin_selfplay[first_coin]
                            first_interval = list(first_coin_data.keys())[0] if first_coin_data else None
                            
                            if first_interval:
                                from rl_pipeline.data.candles_loader import load_candles
                                
                                # ìº”ë“¤ ë°ì´í„° ë¡œë“œ
                                candle_data = load_candles(first_coin, first_interval, days=30)
                                
                                if candle_data is not None and len(candle_data) > 0:
                                    # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                                    strategy_params_list = []
                                    first_selfplay = first_coin_data.get(first_interval, {})
                                    if first_selfplay and 'cycle_results' in first_selfplay:
                                        for cycle in first_selfplay['cycle_results']:
                                            results = cycle.get('results', {})
                                            for agent_id, perf in results.items():
                                                if 'strategy_params' in perf:
                                                    strategy_params_list.append(perf['strategy_params'])
                                    
                                    # ì¤‘ë³µ ì œê±°
                                    if strategy_params_list:
                                        seen = set()
                                        unique_params = []
                                        for params in strategy_params_list:
                                            params_str = str(sorted(params.items()))
                                            if params_str not in seen:
                                                seen.add(params_str)
                                                unique_params.append(params)
                                        strategy_params_list = unique_params[:10]
                                    
                                    if not strategy_params_list:
                                        strategy_params_list = [{
                                            'rsi_min': 30.0, 'rsi_max': 70.0,
                                            'volume_ratio_min': 1.0, 'volume_ratio_max': 2.0,
                                            'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01,
                                            'stop_loss_pct': 0.02, 'take_profit_pct': 0.05
                                        }]
                                    
                                    # ìë™ í‰ê°€ ì‹¤í–‰
                                    eval_result = auto_evaluate_model(
                                        model_id=model_id,
                                        coin=first_coin,
                                        interval=first_interval,
                                        candle_data=candle_data,
                                        strategy_params_list=strategy_params_list,
                                        config=config
                                    )
                                    
                                    if eval_result:
                                        logger.info(f"âœ… {first_coin}-{first_interval}: ê¸€ë¡œë²Œ í•™ìŠµ ìë™ í‰ê°€ ì™„ë£Œ")
                                        
                                        # ğŸ”¥ ê²€ì¦ ê²°ê³¼ í‰ê°€ ë° ì¬í•™ìŠµ íŒë‹¨
                                        passed, reason, details = evaluate_validation_results(eval_result)
                                        
                                        if passed:
                                            logger.info(f"âœ… {first_coin}-{first_interval}: ê²€ì¦ í•©ê²© - ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
                                            if details.get('warnings'):
                                                logger.info(f"   âš ï¸ ê²½ê³  {len(details['warnings'])}ê°œ: {', '.join(details['warnings'][:2])}")
                                        else:
                                            logger.warning(f"âš ï¸ {first_coin}-{first_interval}: ê²€ì¦ ë¶ˆí•©ê²© - {reason}")
                                            
                                            # ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ í™•ì¸ (ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì )
                                            needs_retrain, retrain_reason = should_retrain(eval_result, previous_attempts=previous_attempts)
                                            
                                            if needs_retrain:
                                                logger.warning(f"ğŸ”„ {first_coin}-{first_interval}: ì¬í•™ìŠµ ê¶Œì¥ - {retrain_reason} (ì¬ì‹œë„: {previous_attempts}íšŒ)")
                                                
                                                # ì¬í•™ìŠµ ì œì•ˆ ê°€ì ¸ì˜¤ê¸°
                                                suggestions = get_retrain_suggestions(eval_result)
                                                logger.info(f"ğŸ’¡ ì¬í•™ìŠµ ì œì•ˆ: {suggestions.get('reason', '')}")
                                                
                                                # ğŸ”¥ ìë™ ì¬í•™ìŠµ ì—¬ë¶€ í™•ì¸ (í™˜ê²½ë³€ìˆ˜)
                                                auto_retrain_enabled = os.getenv('ENABLE_AUTO_RETRAIN', 'false').lower() == 'true'
                                                
                                                if auto_retrain_enabled:
                                                    logger.info(f"ğŸ”„ {first_coin}-{first_interval}: ìë™ ì¬í•™ìŠµ ì‹œì‘ (í™˜ê²½ë³€ìˆ˜ í™œì„±í™”ë¨, ì¬ì‹œë„: {previous_attempts + 1}íšŒ)")
                                                    # ì¬í•™ìŠµ ì‹¤í–‰ (ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€)
                                                    retrain_model_id = auto_train_from_global_strategies(
                                                        all_coin_selfplay=all_coin_selfplay,
                                                        all_coin_analysis=all_coin_analysis,
                                                        config_path=config_path,
                                                        min_episodes=min_episodes,
                                                        previous_attempts=previous_attempts + 1  # ğŸ”¥ ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
                                                    )
                                                    if retrain_model_id:
                                                        logger.info(f"âœ… {first_coin}-{first_interval}: ì¬í•™ìŠµ ì™„ë£Œ: {retrain_model_id}")
                                                        return retrain_model_id
                                                    else:
                                                        logger.warning(f"âš ï¸ {first_coin}-{first_interval}: ì¬í•™ìŠµ ì‹¤íŒ¨")
                                                else:
                                                    logger.info(f"ğŸ’¡ ìë™ ì¬í•™ìŠµ ë¹„í™œì„±í™” (ENABLE_AUTO_RETRAIN=false), ìˆ˜ë™ ì¬í•™ìŠµ ê¶Œì¥")
                                            else:
                                                logger.info(f"ğŸ“Š {first_coin}-{first_interval}: ì¬í•™ìŠµ ë¶ˆí•„ìš” ë˜ëŠ” ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                                    else:
                                        logger.warning(f"âš ï¸ {first_coin}-{first_interval}: ê¸€ë¡œë²Œ í•™ìŠµ ìë™ í‰ê°€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
                    except Exception as eval_err:
                        logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ: í•™ìŠµ ìë™ í‰ê°€ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {eval_err}")
            else:
                logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ: í•™ìŠµ ì™„ë£Œí–ˆì§€ë§Œ ëª¨ë¸ IDê°€ ì—†ìŒ")
            
            return model_id
        except Exception as train_err:
            logger.error(f"âŒ ê¸€ë¡œë²Œ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {train_err}")
            import traceback
            logger.debug(f"ê¸€ë¡œë²Œ í•™ìŠµ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ìë™ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ê¸€ë¡œë²Œ ìë™ í•™ìŠµ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
        return None


def auto_evaluate_model(
    model_id: str,
    coin: str,
    interval: str,
    candle_data: Any,  # pd.DataFrame
    strategy_params_list: List[Dict[str, Any]],
    config: Optional[Dict[str, Any]] = None
) -> Optional[Dict[str, Any]]:
    """
    í•™ìŠµëœ ëª¨ë¸ ìë™ í‰ê°€ (A/B í…ŒìŠ¤íŠ¸)
    
    Args:
        model_id: ëª¨ë¸ ID
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        candle_data: ìº”ë“¤ ë°ì´í„°
        strategy_params_list: ì „ëµ íŒŒë¼ë¯¸í„° ë¦¬ìŠ¤íŠ¸
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
    
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ì‹¤íŒ¨ ì‹œ None)
    """
    try:
        logger.info(f"ğŸ” {coin}-{interval}: ëª¨ë¸ í‰ê°€ ì‹œì‘: {model_id}")
        
        # ì„¤ì • ë¡œë“œ
        if config is None:
            config_path = os.getenv(
                'HYBRID_CONFIG_PATH',
                '/workspace/rl_pipeline/hybrid/config_hybrid.json'
            )
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    config = json.load(f)
            else:
                config = {}
        
        db_path = config.get('paths', {}).get('db', '/workspace/data_storage/rl_strategies.db')
        
        # A/B í‰ê°€ ì‹¤í–‰
        result = evaluate_ab(
            model_id=model_id,
            mode='HYBRID',
            coin=coin,
            interval=interval,
            candle_data=candle_data,
            strategy_params_list=strategy_params_list,
            db_path=db_path,
            config=config
        )
        
        # ê·œì¹™ ê¸°ë°˜ë„ í‰ê°€ (ë¹„êµìš©)
        rule_result = None
        try:
            rule_result = evaluate_ab(
                model_id=None,
                mode='RULE',
                coin=coin,
                interval=interval,
                candle_data=candle_data,
                strategy_params_list=strategy_params_list,
                db_path=db_path,
                config=config
            )
            
            # ë¹„êµ ê²°ê³¼ ê³„ì‚°
            improvement = {
                'profit_factor_improvement': (
                    result['profit_factor'] - rule_result['profit_factor']
                ) / rule_result['profit_factor'] if rule_result['profit_factor'] > 0 else 0.0,
                'return_improvement': (
                    result['total_return'] - rule_result['total_return']
                ) / abs(rule_result['total_return']) if rule_result['total_return'] != 0 else 0.0,
                'win_rate_improvement': result['win_rate'] - rule_result['win_rate']
            }
            
            logger.info(f"âœ… {coin}-{interval}: A/B í‰ê°€ ì™„ë£Œ")
            logger.info(f"   ğŸ“Š Profit Factor: {rule_result['profit_factor']:.2f} â†’ {result['profit_factor']:.2f} ({improvement['profit_factor_improvement']:+.1%})")
            logger.info(f"   ğŸ“Š Return: {rule_result['total_return']:.2%} â†’ {result['total_return']:.2%} ({improvement['return_improvement']:+.1%})")
            logger.info(f"   ğŸ“Š Win Rate: {rule_result['win_rate']:.2%} â†’ {result['win_rate']:.2%} ({improvement['win_rate_improvement']:+.1%})")
            
            result['comparison'] = {
                'rule': rule_result,
                'hybrid': result,
                'improvement': improvement
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê·œì¹™ ê¸°ë°˜ í‰ê°€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # ğŸ”¥ Walk-Forward ê²€ì¦ ì‹¤í–‰
        walk_forward_result = None
        try:
            logger.info(f"ğŸ” Walk-Forward ê²€ì¦ ì‹œì‘...")
            walk_forward_result = walk_forward_validation(
                model_id=model_id,
                coin=coin,
                interval=interval,
                candle_data=candle_data,
                strategy_params_list=strategy_params_list,
                train_ratio=0.7,
                db_path=db_path,
                config=config
            )
            
            if walk_forward_result.get('status') == 'success':
                logger.info(f"âœ… Walk-Forward ê²€ì¦ ì™„ë£Œ")
                if walk_forward_result.get('has_overfitting'):
                    logger.warning(f"   âš ï¸ ê³¼ì í•© ê°€ëŠ¥ì„± ê°ì§€")
                else:
                    logger.info(f"   âœ… ê³¼ì í•© ì—†ìŒ í™•ì¸")
            else:
                logger.info(f"   ğŸ“Š Walk-Forward ê²€ì¦ ê±´ë„ˆëœ€: {walk_forward_result.get('reason', 'unknown')}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ Walk-Forward ê²€ì¦ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # ğŸ”¥ ë‹¤ì¤‘ ê¸°ê°„ ê²€ì¦ ì‹¤í–‰
        multi_period_result = None
        try:
            logger.info(f"ğŸ” ë‹¤ì¤‘ ê¸°ê°„ ê²€ì¦ ì‹œì‘...")
            multi_period_result = multi_period_validation(
                model_id=model_id,
                coin=coin,
                interval=interval,
                candle_data=candle_data,
                strategy_params_list=strategy_params_list,
                db_path=db_path,
                config=config
            )
            
            if multi_period_result.get('status') == 'success':
                logger.info(f"âœ… ë‹¤ì¤‘ ê¸°ê°„ ê²€ì¦ ì™„ë£Œ")
                consistency = multi_period_result.get('consistency', 0.0)
                regime_count = multi_period_result.get('regime_count', 0)
                logger.info(f"   ğŸ“Š ì¼ê´€ì„±: {consistency:.1%}, ë ˆì§ ìˆ˜: {regime_count}ê°œ")
            else:
                logger.info(f"   ğŸ“Š ë‹¤ì¤‘ ê¸°ê°„ ê²€ì¦ ê±´ë„ˆëœ€: {multi_period_result.get('reason', 'unknown')}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ ë‹¤ì¤‘ ê¸°ê°„ ê²€ì¦ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # ğŸ”¥ í†µí•© ê²°ê³¼ ë°˜í™˜
        result['walk_forward'] = walk_forward_result
        result['multi_period'] = multi_period_result
        
        logger.info(f"âœ… {coin}-{interval}: ì „ì²´ í‰ê°€ ì™„ë£Œ (A/B + Walk-Forward + ë‹¤ì¤‘ ê¸°ê°„)")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
        return None


def should_auto_train(coin: str, interval: str, selfplay_result: Dict[str, Any], min_episodes: int = 10) -> bool:
    """
    ìë™ í•™ìŠµ ì¡°ê±´ ì²´í¬
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        selfplay_result: Self-play ê²°ê³¼
        min_episodes: ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜
    
    Returns:
        ìë™ í•™ìŠµ ì—¬ë¶€
    """
    try:
        # í™˜ê²½ë³€ìˆ˜ ì²´í¬
        auto_train_enabled = os.getenv('ENABLE_AUTO_TRAINING', 'false').lower() == 'true'
        use_hybrid = os.getenv('USE_HYBRID', 'false').lower() == 'true'
        
        if not auto_train_enabled:
            return False
        if not use_hybrid:
            return False
        
        # Self-play ê²°ê³¼ ì²´í¬
        if not selfplay_result:
            return False
        
        status = selfplay_result.get('status')
        if status != 'success':
            return False
        
        # ì—í”¼ì†Œë“œ ìˆ˜ ì²´í¬
        cycle_results = selfplay_result.get('cycle_results', [])
        if len(cycle_results) < min_episodes:
            return False
        
        # JAX ê°€ìš©ì„± ì²´í¬
        try:
            import jax
            from rl_pipeline.hybrid.neural_policy_jax import JAX_AVAILABLE
            if not JAX_AVAILABLE:
                return False
        except ImportError:
            return False
        
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ ìë™ í•™ìŠµ ì¡°ê±´ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False


def should_auto_evaluate(model_id: str) -> bool:
    """
    ìë™ í‰ê°€ ì¡°ê±´ ì²´í¬
    
    Args:
        model_id: ëª¨ë¸ ID
    
    Returns:
        ìë™ í‰ê°€ ì—¬ë¶€
    """
    try:
        # í™˜ê²½ë³€ìˆ˜ ì²´í¬
        auto_eval_enabled = os.getenv('ENABLE_AUTO_EVALUATION', 'true').lower() == 'true'
        use_hybrid = os.getenv('USE_HYBRID', 'false').lower() == 'true'
        
        if not auto_eval_enabled:
            return False
        if not use_hybrid:
            return False
        
        # ëª¨ë¸ ID ì²´í¬
        if not model_id:
            return False
        
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ ìë™ í‰ê°€ ì¡°ê±´ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False
