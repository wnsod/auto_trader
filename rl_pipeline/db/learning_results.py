"""
Learning Results DB ê´€ë¦¬ ëª¨ë“ˆ
ì´ì œ rl_strategies.dbë¡œ í†µí•©ë¨
"""

import logging
import sqlite3
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from contextlib import contextmanager

logger = logging.getLogger(__name__)

# DB ê²½ë¡œ - learning_results.dbëŠ” ì´ì œ rl_strategies.dbë¡œ í†µí•©ë¨
# configì—ì„œ LEARNING_RESULTS_DB_PATH = STRATEGIES_DBë¡œ ì„¤ì •ë¨
from rl_pipeline.core.env import config
LEARNING_RESULTS_DB_PATH = config.LEARNING_RESULTS_DB_PATH


@contextmanager
def get_learning_db_connection(db_path: str = None):
    """learning_results.db ì—°ê²° ê´€ë¦¬"""
    if db_path is None:
        db_path = LEARNING_RESULTS_DB_PATH
    
    conn = None
    try:
        conn = sqlite3.connect(db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row
        yield conn
    except Exception as e:
        if conn:
            conn.rollback()
        logger.error(f"âŒ rl_strategies.db (learning_results) ì—°ê²° ì‹¤íŒ¨: {e}")
        raise
    finally:
        if conn:
            conn.close()

def create_learning_results_tables(db_path: str = None) -> bool:
    """rl_strategies.dbì— learning_results í…Œì´ë¸” ìƒì„± (í†µí•©ë¨)"""
    try:
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            # 1. Self-play ì§„í™” ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS selfplay_evolution_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    regime TEXT NOT NULL,
                    
                    -- ì§„í™” ì „ëµ ì •ë³´
                    initial_strategy TEXT NOT NULL,
                    evolved_strategy TEXT NOT NULL,
                    evolution_steps INTEGER DEFAULT 0,
                    
                    -- ì§„í™” ì„±ê³¼
                    initial_performance REAL DEFAULT 0.0,
                    evolved_performance REAL DEFAULT 0.0,
                    improvement_rate REAL DEFAULT 0.0,
                    
                    -- ì§„í™” ê³¼ì •
                    evolution_history TEXT DEFAULT '[]',
                    adaptation_patterns TEXT DEFAULT '{}',
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 2. ë ˆì§ ê¸°ë°˜ ë¼ìš°íŒ… ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS regime_routing_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    regime TEXT NOT NULL,
                    
                    -- ë¼ìš°íŒ…ëœ ì „ëµ
                    routed_strategy TEXT NOT NULL,
                    routing_confidence REAL DEFAULT 0.0,
                    routing_score REAL DEFAULT 0.0,
                    
                    -- ë ˆì§ë³„ ì„±ëŠ¥
                    regime_performance REAL DEFAULT 0.0,
                    regime_adaptation REAL DEFAULT 0.0,
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 3. í†µí•©ë¶„ì„ ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS integrated_analysis_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    regime TEXT NOT NULL,
                    
                    -- ë¶„ì„ ê²°ê³¼
                    fractal_score REAL DEFAULT 0.0,
                    multi_timeframe_score REAL DEFAULT 0.0,
                    indicator_cross_score REAL DEFAULT 0.0,
                    
                    -- JAX ì•™ìƒë¸” ê²°ê³¼
                    ensemble_score REAL DEFAULT 0.0,
                    ensemble_confidence REAL DEFAULT 0.0,
                    
                    -- ìµœì¢… ì‹œê·¸ë„ ì ìˆ˜
                    final_signal_score REAL DEFAULT 0.0,
                    signal_confidence REAL DEFAULT 0.0,
                    signal_action TEXT DEFAULT 'hold',
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 4. ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS realtime_learning_feedback (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    signal_id TEXT NOT NULL,
                    
                    -- ì‹œê·¸ë„ ì •ë³´
                    signal_score REAL DEFAULT 0.0,
                    signal_action TEXT NOT NULL,
                    signal_timestamp DATETIME NOT NULL,
                    
                    -- ì‹¤ì œ ê²°ê³¼
                    actual_profit REAL DEFAULT 0.0,
                    actual_success BOOLEAN DEFAULT FALSE,
                    market_condition TEXT DEFAULT 'unknown',
                    
                    -- í•™ìŠµ í”¼ë“œë°±
                    learning_adjustment REAL DEFAULT 0.0,
                    strategy_update TEXT DEFAULT '{}',
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 5. ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS global_strategy_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    
                    -- ê¸€ë¡œë²Œ ì„±ëŠ¥
                    overall_score REAL DEFAULT 0.0,
                    overall_confidence REAL DEFAULT 0.0,
                    policy_improvement REAL DEFAULT 0.0,
                    convergence_rate REAL DEFAULT 0.0,
                    
                    -- ìƒìœ„ ì„±ëŠ¥
                    top_performers TEXT DEFAULT '[]',
                    top_coins TEXT DEFAULT '[]',
                    top_intervals TEXT DEFAULT '[]',
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 6. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS pipeline_execution_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    
                    -- ì‹¤í–‰ í†µê³„
                    strategies_created INTEGER DEFAULT 0,
                    selfplay_episodes INTEGER DEFAULT 0,
                    regime_detected TEXT DEFAULT 'unknown',
                    routing_results INTEGER DEFAULT 0,
                    
                    -- ìµœì¢… ê²°ê³¼
                    signal_score REAL DEFAULT 0.0,
                    signal_action TEXT DEFAULT 'HOLD',
                    execution_time REAL DEFAULT 0.0,
                    status TEXT DEFAULT 'unknown',
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ğŸ†• 7. ì‹œê·¸ë„ ê³„ì‚°ìš© ì „ëµ ìš”ì•½ í…Œì´ë¸” (realtime_signal_selector.py ì „ìš©)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS strategy_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    
                    -- ìµœìƒìœ„ ì „ëµ ìš”ì•½ ì •ë³´
                    top_strategy_id TEXT,
                    top_strategy_params TEXT,  -- JSON: {rsi_min, rsi_max, volume_ratio_min, ...}
                    top_profit REAL DEFAULT 0.0,
                    top_win_rate REAL DEFAULT 0.0,
                    top_quality_grade TEXT,  -- S/A/B/C/D/F
                    
                    -- í‰ê·  ì„±ëŠ¥ ì§€í‘œ
                    avg_profit REAL DEFAULT 0.0,
                    avg_win_rate REAL DEFAULT 0.0,
                    avg_sharpe_ratio REAL DEFAULT 0.0,
                    avg_calmar_ratio REAL DEFAULT 0.0,
                    avg_profit_factor REAL DEFAULT 0.0,
                    
                    -- ì „ëµ í†µê³„
                    total_strategies INTEGER DEFAULT 0,
                    s_grade_count INTEGER DEFAULT 0,
                    a_grade_count INTEGER DEFAULT 0,
                    
                    -- ì—…ë°ì´íŠ¸ ì‹œê°„
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    UNIQUE(coin, interval)
                )
            """)
            
            # ğŸ†• 8. ì‹œê·¸ë„ ê³„ì‚°ìš© DNA ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS dna_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT,
                    interval TEXT,
                    
                    -- DNA ìš”ì•½ ì •ë³´ (ì‹¤ì‹œê°„ ì‹œê·¸ë„ ê³„ì‚°ìš©)
                    profitability_score REAL DEFAULT 0.0,  -- win_rate mean
                    stability_score REAL DEFAULT 0.0,      -- trades_count ê¸°ë°˜
                    scalability_score REAL DEFAULT 0.0,    -- complexity_score mean
                    dna_quality REAL DEFAULT 0.0,          -- total_strategies ê¸°ë°˜
                    
                    -- DNA íŒ¨í„´ ìš”ì•½
                    rsi_pattern TEXT,  -- ìµœë¹ˆ RSI íŒ¨í„´
                    macd_pattern TEXT,  -- ìµœë¹ˆ MACD íŒ¨í„´
                    volume_pattern TEXT,  -- ìµœë¹ˆ Volume íŒ¨í„´
                    
                    -- DNA íˆìŠ¤í† ë¦¬ ìš”ì•½
                    dna_momentum REAL DEFAULT 0.0,  -- ìµœê·¼ ë³€í™”ìœ¨
                    dna_stability REAL DEFAULT 0.0,  -- ì•ˆì •ì„± ì ìˆ˜
                    
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    UNIQUE(coin, interval)
                )
            """)
            
            # ğŸ†• 9. ì‹œê·¸ë„ ê³„ì‚°ìš© ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS global_strategy_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    interval TEXT NOT NULL,
                    
                    -- ìµœìƒìœ„ ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½
                    top_global_strategy_id TEXT,
                    top_global_strategy_params TEXT,  -- JSON
                    top_global_score REAL DEFAULT 0.0,
                    
                    -- í‰ê·  ì„±ëŠ¥
                    avg_global_score REAL DEFAULT 0.0,
                    avg_global_confidence REAL DEFAULT 0.0,
                    
                    -- í†µê³„
                    total_global_strategies INTEGER DEFAULT 0,
                    
                    -- í•™ìŠµ í’ˆì§ˆ ì§€í‘œ
                    learning_quality_score REAL DEFAULT 0.0,
                    reliability_score REAL DEFAULT 0.0,
                    
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    UNIQUE(interval)
                )
            """)
            
            # ğŸ†• 10. ì‹œê·¸ë„ ê³„ì‚°ìš© í”„ë™íƒˆ/ì‹œë„ˆì§€ ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS analysis_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    
                    -- í”„ë™íƒˆ ë¶„ì„ ìš”ì•½
                    fractal_score REAL DEFAULT 0.0,
                    fractal_pattern TEXT,  -- JSON
                    
                    -- ì‹œë„ˆì§€ ë¶„ì„ ìš”ì•½
                    synergy_score REAL DEFAULT 0.0,
                    synergy_patterns TEXT,  -- JSON
                    
                    -- ìµœì  ì¡°ê±´
                    optimal_rsi_min REAL DEFAULT 30.0,
                    optimal_rsi_max REAL DEFAULT 70.0,
                    optimal_volume_ratio REAL DEFAULT 1.0,
                    
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    UNIQUE(coin, interval)
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_selfplay_coin_interval ON selfplay_evolution_results(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_regime_routing_coin_interval ON regime_routing_results(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_analysis_coin_interval ON integrated_analysis_results(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_realtime_feedback_coin_interval ON realtime_learning_feedback(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_pipeline_logs_coin_interval ON pipeline_execution_logs(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_strategy_summary_coin_interval ON strategy_summary_for_signals(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_dna_summary_coin_interval ON dna_summary_for_signals(coin, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_global_strategy_summary_interval ON global_strategy_summary_for_signals(interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_analysis_summary_coin_interval ON analysis_summary_for_signals(coin, interval)")
            
            conn.commit()
            logger.info("âœ… rl_strategies.db learning_results í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ rl_strategies.db learning_results í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def save_selfplay_results(coin: str, interval: str, selfplay_result: Dict[str, Any], db_path: str = None) -> bool:
    """Self-play ê²°ê³¼ë¥¼ rl_strategies.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        # ğŸ”¥ ì›ë³¸ summary ë³´ì¡´ (ì˜¨ë¼ì¸ ê²°ê³¼ë¡œ ë®ì–´ì¨ì§€ì§€ ì•Šë„ë¡)
        original_summary = selfplay_result.get("summary", {})
        summary = original_summary.copy() if original_summary else {}
        cycle_results = selfplay_result.get("cycle_results", [])
        
        # ğŸ”¥ rl_strategies.dbì— selfplay_results í…Œì´ë¸” ìƒì„± ë° ì €ì¥
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # selfplay_results í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS selfplay_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coin TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    episodes INTEGER NOT NULL,
                    results TEXT NOT NULL,
                    summary TEXT,
                    created_at TEXT NOT NULL,
                    UNIQUE(coin, interval, episodes, results)
                )
            """)
            
            saved_count = 0
            
            # ğŸ”¥ cycle_resultsê°€ ì—†ìœ¼ë©´ traditional_resultì—ì„œ ê°€ì ¸ì˜¤ê¸° (dual mode ëŒ€ì‘)
            if not cycle_results and selfplay_result.get('dual_mode'):
                traditional_result = selfplay_result.get('traditional_result')
                if traditional_result:
                    cycle_results = traditional_result.get("cycle_results", [])
            
            # ğŸ”¥ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ì²˜ë¦¬ ì¶”ê°€ (ì˜¨ë¼ì¸ ê²°ê³¼ê°€ ì•„ì§ ë³€í™˜ë˜ì§€ ì•Šì€ ê²½ìš°)
            online_summary = None  # ì˜¨ë¼ì¸ summary ë³„ë„ ì €ì¥ (ì›ë³¸ summary ë³´ì¡´)
            if not cycle_results:
                try:
                    from rl_pipeline.hybrid.online_data_converter import (
                        extract_online_selfplay_result,
                        convert_online_segments_to_cycle_results
                    )
                    
                    online_segments = extract_online_selfplay_result(selfplay_result)
                    if online_segments:
                        cycle_results = convert_online_segments_to_cycle_results(online_segments, summary)
                        logger.debug(f"âœ… ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ ({len(cycle_results)}ê°œ cycle)")
                    # online_resultì— ì§ì ‘ ìˆëŠ” ê²½ìš°
                    elif selfplay_result.get('online_result'):
                        online_result = selfplay_result.get('online_result', {})
                        online_segments = online_result.get('segment_results', [])
                        if online_segments:
                            online_summary = online_result.get('summary', {})  # ë³„ë„ ì €ì¥
                            cycle_results = convert_online_segments_to_cycle_results(online_segments, online_summary)
                            logger.debug(f"âœ… ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ (online_resultì—ì„œ) ({len(cycle_results)}ê°œ cycle)")
                except ImportError:
                    logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ ì—†ìŒ (ë¬´ì‹œ)")
                except Exception as e:
                    logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            # ğŸ”¥ summaryê°€ ë¹„ì–´ìˆê±°ë‚˜ ê°’ì´ 0.0ì´ë©´ cycle_resultsì—ì„œ ì§ì ‘ ê³„ì‚°
            if cycle_results and (not summary or 
                summary.get("avg_win_rate", 0.0) == 0.0 and summary.get("avg_pnl", 0.0) == 0.0):
                try:
                    import numpy as np
                    all_performances = []
                    for result in cycle_results:
                        if "results" in result:
                            for agent_id, performance in result["results"].items():
                                all_performances.append(performance)
                    
                    if all_performances:
                        calculated_summary = {
                            "total_episodes": len(cycle_results),
                            "total_trades": sum(p.get("total_trades", 0) for p in all_performances),
                            "avg_win_rate": float(np.mean([p.get("win_rate", 0) for p in all_performances])),
                            "avg_pnl": float(np.mean([p.get("total_pnl", 0) for p in all_performances])),
                            "avg_sharpe_ratio": float(np.mean([p.get("sharpe_ratio", 0) for p in all_performances])),
                        }
                        # ê¸°ì¡´ summaryì™€ ë³‘í•© (ê³„ì‚°ëœ ê°’ ìš°ì„ )
                        summary.update(calculated_summary)
                        logger.debug(f"âœ… cycle_resultsì—ì„œ summary ê³„ì‚° ì™„ë£Œ: win_rate={summary.get('avg_win_rate', 0):.2%}, pnl={summary.get('avg_pnl', 0):.2f}")
                except Exception as e:
                    logger.warning(f"âš ï¸ cycle_resultsì—ì„œ summary ê³„ì‚° ì‹¤íŒ¨: {e}")
            
            if not cycle_results:
                logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ì €ì¥: cycle_resultsê°€ ì—†ìŠµë‹ˆë‹¤. (dual_mode={selfplay_result.get('dual_mode', False)})")
                logger.info(f"âœ… Self-play ê²°ê³¼ ì €ì¥ ì™„ë£Œ (rl_strategies.db): {coin}-{interval}, {saved_count}ê°œ")
                return False
            
            for cycle in cycle_results:
                episode = cycle.get("episode", 0)
                results = cycle.get("results", {})
                
                if not results:
                    continue
                
                for agent_id, performance in results.items():
                    try:
                        cursor.execute("""
                            INSERT OR REPLACE INTO selfplay_results 
                            (coin, interval, episodes, results, summary, created_at)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (
                            coin,
                            interval,
                            episode,
                            json.dumps({
                                "agent_id": agent_id,
                                "performance": performance
                            }),
                            json.dumps({
                                "total_episodes": len(cycle_results),
                                "episode": episode,
                                "total_trades": summary.get("total_trades", 0),  # ğŸ”¥ ì¶”ê°€
                                "avg_win_rate": summary.get("avg_win_rate", 0.0),
                                "avg_pnl": summary.get("avg_pnl", 0.0),  # ğŸ”¥ ìˆ˜ì • (avg_total_return â†’ avg_pnl)
                                "avg_sharpe_ratio": summary.get("avg_sharpe_ratio", 0.0),  # ğŸ”¥ ì¶”ê°€
                                "avg_total_return": summary.get("avg_total_return", summary.get("avg_pnl", 0.0)),  # í˜¸í™˜ì„± ìœ ì§€ (avg_pnlë¡œ í´ë°±)
                                "regime_performance": summary.get("regime_performance", {}),  # ğŸ”¥ ì¶”ê°€ (ì„ íƒ)
                                "learning_progress": selfplay_result.get("learning_progress", {})
                            }),
                            datetime.now().isoformat()
                        ))
                        saved_count += 1
                    except Exception as e:
                        logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ì¼ë¶€ ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
            
            conn.commit()
            logger.info(f"âœ… Self-play ê²°ê³¼ ì €ì¥ ì™„ë£Œ (rl_strategies.db): {coin}-{interval}, {saved_count}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Self-play ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_pipeline_execution_log(coin: str, interval: str, strategies_created: int,
                               selfplay_episodes: int, regime_detected: str,
                               routing_results: int, signal_score: float,
                               signal_action: str, execution_time: float,
                               status: str, db_path: str = None) -> bool:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥"""
    try:
        # ìŒìˆ˜ execution_time ë°©ì§€
        if execution_time < 0:
            logger.warning(f"âš ï¸ ìŒìˆ˜ execution_time ê°ì§€: {execution_time:.2f}ì´ˆ â†’ 0.0ì´ˆë¡œ ë³€ê²½ ({coin}-{interval})")
            execution_time = 0.0

        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO pipeline_execution_logs
                (coin, interval, strategies_created, selfplay_episodes, regime_detected,
                 routing_results, signal_score, signal_action, execution_time, status)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                coin, interval, strategies_created, selfplay_episodes, regime_detected,
                routing_results, signal_score, signal_action, execution_time, status
            ))
            
            conn.commit()
            logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {coin}-{interval}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_regime_routing_results(coin: str, interval: str, routing_results: List[Any]) -> bool:
    """ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ë¥¼ rl_strategies.dbì— ì €ì¥"""
    try:
        from rl_pipeline.routing.regime_router import RegimeRoutingResult
        import json
        
        if not routing_results:
            logger.debug(f"ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ ì €ì¥ ê±´ë„ˆëœ€: {coin}-{interval}")
            return True
        
        with get_learning_db_connection(LEARNING_RESULTS_DB_PATH) as conn:
            cursor = conn.cursor()
            
            saved_count = 0
            for result in routing_results:
                try:
                    # RegimeRoutingResult ê°ì²´ì¸ì§€ í™•ì¸
                    if hasattr(result, 'routed_strategy'):
                        # ê°ì²´ì¸ ê²½ìš°
                        routed_strategy_json = json.dumps(result.routed_strategy)
                        cursor.execute("""
                            INSERT INTO regime_routing_results 
                            (coin, interval, regime, routed_strategy, routing_confidence, 
                             routing_score, regime_performance, regime_adaptation, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            result.coin,
                            result.interval,
                            result.regime,
                            routed_strategy_json,
                            result.routing_confidence,
                            result.routing_score,
                            result.regime_performance,
                            result.regime_adaptation,
                            result.created_at
                        ))
                        saved_count += 1
                    elif isinstance(result, dict):
                        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ëŒ€ì²´ ì²˜ë¦¬)
                        routed_strategy_json = json.dumps(result.get('routed_strategy', result))
                        cursor.execute("""
                            INSERT INTO regime_routing_results 
                            (coin, interval, regime, routed_strategy, routing_confidence, 
                             routing_score, regime_performance, regime_adaptation, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            result.get('coin', coin),
                            result.get('interval', interval),
                            result.get('regime', 'neutral'),
                            routed_strategy_json,
                            result.get('routing_confidence', 0.5),
                            result.get('routing_score', 0.5),
                            result.get('regime_performance', 0.5),
                            result.get('regime_adaptation', 0.5),
                            result.get('created_at', datetime.now().isoformat())
                        ))
                        saved_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì¼ë¶€ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            conn.commit()
            logger.info(f"âœ… ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {coin}-{interval}, {saved_count}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_regime_routing_to_rl_episodes(coin: str, interval: str, routing_results: List[Any]) -> bool:
    """
    ğŸ”¥ ë ˆì§ ë¼ìš°íŒ… ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ rl_episodes í…Œì´ë¸”ì— ì €ì¥
    Self-play ì—†ì´ë„ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆë„ë¡ í•¨
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        routing_results: ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        from rl_pipeline.routing.regime_router import RegimeRoutingResult
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        import uuid
        import hashlib
        
        if not routing_results:
            logger.debug(f"ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ rl_episodes ì €ì¥ ê±´ë„ˆëœ€: {coin}-{interval}")
            return True
        
        saved_count = 0
        timestamp = int(datetime.now().timestamp())
        
        for result in routing_results:
            try:
                # RegimeRoutingResult ê°ì²´ì¸ì§€ í™•ì¸
                if not hasattr(result, 'routed_strategy'):
                    continue
                
                strategy = result.routed_strategy
                strategy_id = strategy.get('id') or strategy.get('strategy_id') or 'unknown'
                predictive_accuracy = getattr(result, 'predictive_accuracy', 0.0)
                backtest_result = getattr(result, 'backtest_result', None)
                
                # ğŸ”¥ ì €ì¥ ì¡°ê±´ ì™„í™”: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì €ì¥
                # (ì˜ˆì¸¡ ì •í™•ë„ê°€ 0ì´ì–´ë„ ì‹œì¥ ìƒíƒœ ì •ë³´ëŠ” ìœ ìš©)
                if not backtest_result:
                    # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì €ì¥ (ìµœì†Œí•œì˜ ë°ì´í„° ìˆ˜ì§‘)
                    backtest_result = {
                        'trades': 0,
                        'profit': 0.0,
                        'wins': 0,
                        'win_rate': 0.0,
                        'predictive_accuracy': 0.0,
                        'data_points': 0
                    }
                
                # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ê±°ë˜ ì •ë³´ ì¶”ì¶œ
                trades = backtest_result.get('trades', 0)
                
                # ğŸ”¥ ê±°ë˜ê°€ 0íšŒì—¬ë„ ì €ì¥ (ì‹œì¥ ìƒíƒœ ì •ë³´ëŠ” ìœ ìš©)
                # ì˜ˆì¸¡ ì •í™•ë„ê°€ 0ì´ì–´ë„ ì €ì¥ (ë‚˜ì¤‘ì— Paper Tradingì—ì„œ ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
                
                # ğŸ”¥ ê° ê±°ë˜ë¥¼ ì—í”¼ì†Œë“œë¡œ ì €ì¥
                # ê°„ë‹¨í•œ ë°©ì‹: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì—í”¼ì†Œë“œë¡œ ì €ì¥
                # episode_id ìƒì„± (ê³ ìœ ì„± ë³´ì¥)
                episode_id = f"regime_routing_{coin}_{interval}_{strategy_id}_{timestamp}_{saved_count}"
                
                # ì˜ˆì¸¡ ë°©í–¥ ê²°ì • (ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ë§¤ìˆ˜ ì‹ í˜¸ = ìƒìŠ¹ ì˜ˆì¸¡)
                predicted_dir = 1  # ìƒìŠ¹ ì˜ˆì¸¡ (ë§¤ìˆ˜ ì‹ í˜¸)
                predicted_conf = min(predictive_accuracy, 1.0)  # ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í™•ì‹ ë„ë¡œ ì‚¬ìš©
                
                # ì „ëµ íŒŒë¼ë¯¸í„°ì—ì„œ ëª©í‘œ ë³€ë™ë¥  ì¶”ì •
                target_move_pct = strategy.get('take_profit', 0.05)  # ê¸°ë³¸ê°’ 5%
                horizon_k = strategy.get('max_hold_periods', 20)  # ê¸°ë³¸ê°’ 20 ìº”ë“¤
                
                # state_key ìƒì„± (ë ˆì§ ê¸°ë°˜)
                regime = result.regime
                state_key = f"{regime}_{strategy_id}"
                
                # ì§„ì… ê°€ê²© ì¶”ì • (ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ)
                entry_price = 1.0  # ì •ê·œí™”ëœ ê°€ê²© (ë°±í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ìƒëŒ€ì )
                
                # ğŸ”¥ rl_episodesì— ì €ì¥ (strategies DB ì‚¬ìš©)
                try:
                    with get_optimized_db_connection("strategies") as strategies_conn:
                        cursor = strategies_conn.cursor()
                        
                        # rl_episodes í…Œì´ë¸”ì— ì €ì¥
                        cursor.execute("""
                            INSERT OR REPLACE INTO rl_episodes (
                                episode_id, ts_entry, coin, interval, strategy_id, state_key,
                                predicted_dir, predicted_conf, entry_price, target_move_pct, horizon_k
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            episode_id, timestamp, coin, interval, strategy_id, state_key,
                            predicted_dir, predicted_conf, entry_price, target_move_pct, horizon_k
                        ))
                        
                        # rl_episode_summary í…Œì´ë¸”ì— ì €ì¥
                        total_profit = backtest_result.get('profit', 0.0)
                        win_rate = backtest_result.get('win_rate', 0.0)
                        realized_ret_signed = total_profit / trades if trades > 0 else 0.0
                        acc_flag = 1 if predictive_accuracy >= 0.5 else 0
                        ts_exit = timestamp + (horizon_k * 900)  # ëŒ€ëµì ì¸ ì¢…ë£Œ ì‹œê°„
                        
                        cursor.execute("""
                            INSERT OR REPLACE INTO rl_episode_summary (
                                episode_id, ts_exit, first_event, t_hit,
                                realized_ret_signed, total_reward, acc_flag,
                                coin, interval, strategy_id, source_type
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            episode_id, ts_exit, 'expiry', horizon_k,
                            realized_ret_signed, predictive_accuracy, acc_flag,
                            coin, interval, strategy_id, 'regime_routing'
                        ))
                        
                        strategies_conn.commit()
                        logger.debug(f"âœ… rl_episodes ì €ì¥: {episode_id}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ rl_episodes ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
                    continue
                
                saved_count += 1
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì‹¤íŒ¨: {e}")
                continue
        
        if saved_count > 0:
            logger.info(f"âœ… ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì™„ë£Œ: {coin}-{interval}, {saved_count}ê°œ ì—í”¼ì†Œë“œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
        return False

def save_integrated_analysis_results(coin: str, interval: str, regime: str, analysis_result: Any) -> bool:
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ rl_strategies.dbì— ì €ì¥ (integrated_analysis_results í…Œì´ë¸”)

    ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ: id, coin, interval, regime, fractal_score, multi_timeframe_score,
                 indicator_cross_score, ensemble_score, ensemble_confidence,
                 final_signal_score, signal_confidence, signal_action, created_at
    """
    try:
        with get_learning_db_connection(LEARNING_RESULTS_DB_PATH) as conn:
            cursor = conn.cursor()

            # ì•ˆì „í•˜ê²Œ ì†ì„± ì ‘ê·¼
            try:
                result_coin = getattr(analysis_result, 'coin', coin)
                # intervalì€ íŒŒë¼ë¯¸í„° ìš°ì„  ì‚¬ìš© (ê°œë³„ ì¸í„°ë²Œ ì €ì¥ ì‹œ ë®ì–´ì“°ê¸° ê°€ëŠ¥)
                result_interval = interval if interval else getattr(analysis_result, 'interval', 'all_intervals')
                result_regime = getattr(analysis_result, 'regime', regime if regime else 'neutral')

                # ë¶„ì„ ì ìˆ˜ë“¤
                fractal_score = getattr(analysis_result, 'fractal_score', 0.0)
                multi_timeframe_score = getattr(analysis_result, 'multi_timeframe_score', 0.0)
                indicator_cross_score = getattr(analysis_result, 'indicator_cross_score', 0.0)

                # ì•™ìƒë¸” ì ìˆ˜
                ensemble_score = getattr(analysis_result, 'ensemble_score', 0.0)
                ensemble_confidence = getattr(analysis_result, 'ensemble_confidence', 0.0)

                # ìµœì¢… ì‹œê·¸ë„
                final_signal_score = getattr(analysis_result, 'final_signal_score', 0.5)
                signal_confidence = getattr(analysis_result, 'signal_confidence', 0.5)
                signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
                created_at = getattr(analysis_result, 'created_at', datetime.now().isoformat())
            except Exception as e:
                logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ì†ì„± ì ‘ê·¼ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
                result_coin = coin
                result_interval = interval
                result_regime = regime if regime else 'neutral'
                fractal_score = 0.0
                multi_timeframe_score = 0.0
                indicator_cross_score = 0.0
                ensemble_score = 0.0
                ensemble_confidence = 0.0
                final_signal_score = 0.5
                signal_confidence = 0.5
                signal_action = 'HOLD'
                created_at = datetime.now().isoformat()

            # ì™„ì „í•œ ìŠ¤í‚¤ë§ˆì— ë§ì¶˜ INSERT
            cursor.execute("""
                INSERT INTO integrated_analysis_results
                (coin, interval, regime, fractal_score, multi_timeframe_score,
                 indicator_cross_score, ensemble_score, ensemble_confidence,
                 final_signal_score, signal_confidence, signal_action, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                result_coin,
                result_interval,
                result_regime,
                fractal_score,
                multi_timeframe_score,
                indicator_cross_score,
                ensemble_score,
                ensemble_confidence,
                final_signal_score,
                signal_confidence,
                signal_action,
                created_at
            ))

            conn.commit()
            logger.info(f"âœ… í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {coin}-{interval}")

        return True

    except Exception as e:
        logger.error(f"âŒ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_integrated_analysis_results(coin: str, interval: str, db_path: str = None, limit: int = 1) -> Optional[Dict[str, Any]]:
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ rl_strategies.dbì—ì„œ ë¡œë“œ (ê°œë³„ ì½”ì¸ ì „ëµ ë¶„ì„)

    ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ: id, coin, interval, regime, fractal_score, multi_timeframe_score,
                 indicator_cross_score, ensemble_score, ensemble_confidence,
                 final_signal_score, signal_confidence, signal_action, created_at
    """
    try:
        db_path = db_path or LEARNING_RESULTS_DB_PATH

        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()

            # ìµœì‹  í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë°˜ì˜)
            cursor.execute("""
                SELECT
                    coin, interval, regime, fractal_score, multi_timeframe_score,
                    indicator_cross_score, ensemble_score, ensemble_confidence,
                    final_signal_score, signal_confidence, signal_action, created_at
                FROM integrated_analysis_results
                WHERE coin = ? AND interval = ?
                ORDER BY created_at DESC
                LIMIT ?
            """, (coin, interval, limit))

            rows = cursor.fetchall()
            if not rows:
                return None

            # ê°€ì¥ ìµœì‹  ê²°ê³¼ ë°˜í™˜
            row = rows[0]
            result = {
                'coin': row[0],
                'interval': row[1],
                'regime': row[2],
                'fractal_score': row[3],
                'multi_timeframe_score': row[4],
                'indicator_cross_score': row[5],
                'ensemble_score': row[6],
                'ensemble_confidence': row[7],
                'final_signal_score': row[8],
                'signal_confidence': row[9],
                'signal_action': row[10],
                'created_at': row[11]
            }

            return result

    except Exception as e:
        logger.error(f"âŒ í†µí•© ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def save_strategy_summary_for_signals(coin: str, interval: str, db_path: str = None) -> bool:
    """rl_strategies.dbì˜ coin_strategiesë¥¼ ìš”ì•½í•˜ì—¬ rl_strategies.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # rl_strategies.dbì—ì„œ ì „ëµ ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # í•´ë‹¹ ì½”ì¸/ì¸í„°ë²Œì˜ ì „ëµë“¤ ì¡°íšŒ
            cursor.execute("""
                SELECT id, rsi_min, rsi_max, volume_ratio_min, volume_ratio_max,
                       macd_buy_threshold, macd_sell_threshold, profit, win_rate,
                       sharpe_ratio, calmar_ratio, profit_factor, quality_grade
                FROM coin_strategies
                WHERE coin = ? AND interval = ?
                ORDER BY profit DESC, win_rate DESC
                LIMIT 100
            """, (coin, interval))
            
            strategies = cursor.fetchall()
            
            if not strategies:
                logger.warning(f"âš ï¸ {coin}-{interval} ì „ëµ ë°ì´í„° ì—†ìŒ")
                return False
            
            # ìš”ì•½ ì •ë³´ ê³„ì‚°
            top_strategy = strategies[0]
            top_strategy_id = top_strategy[0]
            top_strategy_params = json.dumps({
                'rsi_min': top_strategy[1],
                'rsi_max': top_strategy[2],
                'volume_ratio_min': top_strategy[3],
                'volume_ratio_max': top_strategy[4],
                'macd_buy_threshold': top_strategy[5],
                'macd_sell_threshold': top_strategy[6]
            })
            top_profit = top_strategy[7] or 0.0
            top_win_rate = top_strategy[8] or 0.0
            top_quality_grade = top_strategy[12] or 'F'
            
            # í‰ê·  ê³„ì‚°
            profits = [s[7] or 0.0 for s in strategies]
            win_rates = [s[8] or 0.0 for s in strategies]
            sharpe_ratios = [s[9] or 0.0 for s in strategies]
            calmar_ratios = [s[10] or 0.0 for s in strategies]
            profit_factors = [s[11] or 1.0 for s in strategies]
            
            avg_profit = sum(profits) / len(profits) if profits else 0.0
            avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0.0
            avg_sharpe_ratio = sum(sharpe_ratios) / len(sharpe_ratios) if sharpe_ratios else 0.0
            avg_calmar_ratio = sum(calmar_ratios) / len(calmar_ratios) if calmar_ratios else 0.0
            avg_profit_factor = sum(profit_factors) / len(profit_factors) if profit_factors else 1.0
            
            # ë“±ê¸‰ë³„ ì¹´ìš´íŠ¸
            s_grade_count = sum(1 for s in strategies if s[12] == 'S')
            a_grade_count = sum(1 for s in strategies if s[12] == 'A')
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO strategy_summary_for_signals
                    (coin, interval, top_strategy_id, top_strategy_params, top_profit, top_win_rate,
                     top_quality_grade, avg_profit, avg_win_rate, avg_sharpe_ratio, avg_calmar_ratio,
                     avg_profit_factor, total_strategies, s_grade_count, a_grade_count, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, top_strategy_id, top_strategy_params, top_profit, top_win_rate,
                    top_quality_grade, avg_profit, avg_win_rate, avg_sharpe_ratio, avg_calmar_ratio,
                    avg_profit_factor, len(strategies), s_grade_count, a_grade_count
                ))
                
                conn.commit()
                logger.info(f"âœ… ì „ëµ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin}-{interval} ({len(strategies)}ê°œ ì „ëµ)")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ì „ëµ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def _calculate_global_confidence(strategies: List[tuple]) -> float:
    """ê¸€ë¡œë²Œ ì „ëµ ì‹ ë¢°ë„ ê³„ì‚°"""
    if not strategies:
        return 0.0
    
    try:
        # ë“±ê¸‰ë³„ ê°€ì¤‘ì¹˜
        grade_weights = {
            'S': 1.0, 'A': 0.7, 'B': 0.4, 'C': 0.2, 'D': 0.1, 'F': 0.0,
            'UNKNOWN': 0.0
        }
        
        # ì „ëµ ë°ì´í„° êµ¬ì¡°: (strategy_id, score, ...)
        # strategiesëŠ” íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì •
        grade_scores = []
        strategy_count = len(strategies)
        
        # ê° ì „ëµì˜ ë“±ê¸‰ ì •ë³´ ì¶”ì¶œ (ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
        for strategy in strategies:
            # strategyê°€ íŠœí”Œì¸ ê²½ìš°, ë“±ê¸‰ ì •ë³´ë¥¼ ì¶”ì¶œ
            # ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”
            if isinstance(strategy, tuple) and len(strategy) > 0:
                # ë“±ê¸‰ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: strategy[3]ì— ë“±ê¸‰ì´ ìˆë‹¤ê³  ê°€ì •)
                if len(strategy) > 3:
                    grade = strategy[3] if isinstance(strategy[3], str) else 'UNKNOWN'
                else:
                    grade = 'UNKNOWN'
            else:
                grade = 'UNKNOWN'
            
            grade_scores.append(grade_weights.get(grade, 0.0))
        
        avg_grade_score = sum(grade_scores) / len(grade_scores) if grade_scores else 0.0
        count_score = min(1.0, strategy_count / 100.0)
        
        # ë“±ê¸‰ ì ìˆ˜ 70%, ì „ëµ ìˆ˜ 30% ê°€ì¤‘ì¹˜
        confidence = avg_grade_score * 0.7 + count_score * 0.3
        return round(confidence, 3)
        
    except Exception as e:
        logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        return 0.7

def _extract_rsi_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ RSI íŒ¨í„´ ì¶”ì¶œ"""
    try:
        rsi_mean = dna_data.get('rsi_min', {}).get('mean', 50.0)
        
        if rsi_mean < 30:
            return "oversold_dominant"
        elif rsi_mean > 70:
            return "overbought_dominant"
        elif 40 <= rsi_mean <= 60:
            return "neutral_balanced"
        else:
            return "medium"
    except Exception as e:
        logger.debug(f"âš ï¸ RSI íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "medium"

def _extract_macd_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ MACD íŒ¨í„´ ì¶”ì¶œ"""
    try:
        macd_buy = dna_data.get('macd_buy_threshold', {}).get('mean', 0.0)
        macd_sell = dna_data.get('macd_sell_threshold', {}).get('mean', 0.0)
        
        if macd_buy > 0.01 and macd_sell < -0.01:
            return "strong_trend_following"
        elif abs(macd_buy) < 0.005 and abs(macd_sell) < 0.005:
            return "neutral"
        else:
            return "moderate_trend"
    except Exception as e:
        logger.debug(f"âš ï¸ MACD íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "neutral"

def _extract_volume_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ Volume íŒ¨í„´ ì¶”ì¶œ"""
    try:
        vol_min = dna_data.get('volume_ratio_min', {}).get('mean', 1.0)
        vol_max = dna_data.get('volume_ratio_max', {}).get('mean', 2.0)
        
        if vol_min > 1.5:
            return "high_volume_focus"
        elif vol_max < 1.2:
            return "low_volume_focus"
        else:
            return "normal"
    except Exception as e:
        logger.debug(f"âš ï¸ Volume íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "normal"

def save_dna_summary_for_signals(coin: str, interval: str = None, db_path: str = None) -> bool:
    """rl_strategies.dbì˜ strategy_dnaë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # rl_strategies.dbì—ì„œ DNA ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # DNA ë°ì´í„° ì¡°íšŒ
            if coin:
                cursor.execute("""
                    SELECT dna_data FROM strategy_dna
                    WHERE coin = ? AND (interval = ? OR interval IS NULL)
                    ORDER BY created_at DESC LIMIT 1
                """, (coin, interval))
            else:
                cursor.execute("""
                    SELECT dna_data FROM strategy_dna
                    ORDER BY created_at DESC LIMIT 1
                """)
            
            row = cursor.fetchone()
            if not row:
                logger.warning(f"âš ï¸ DNA ë°ì´í„° ì—†ìŒ: {coin}")
                return False
            
            dna_data = json.loads(row[0])
            
            # ìš”ì•½ ì •ë³´ ê³„ì‚°
            profitability_score = dna_data.get('win_rate', {}).get('mean', 0.0)
            stability_score = min(1.0, dna_data.get('trades_count', {}).get('mean', 0) / 100.0)
            scalability_score = dna_data.get('complexity_score', {}).get('mean', 0.5)
            dna_quality = min(1.0, dna_data.get('analysis_info', {}).get('total_strategies', 0) / 1000.0)
            
            # ğŸ”¥ ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ íŒ¨í„´ ì¶”ì¶œ
            rsi_pattern = _extract_rsi_pattern(dna_data)
            macd_pattern = _extract_macd_pattern(dna_data)
            volume_pattern = _extract_volume_pattern(dna_data)
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO dna_summary_for_signals
                    (coin, interval, profitability_score, stability_score, scalability_score,
                     dna_quality, rsi_pattern, macd_pattern, volume_pattern, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, profitability_score, stability_score, scalability_score,
                    dna_quality, rsi_pattern, macd_pattern, volume_pattern
                ))
                
                conn.commit()
                logger.info(f"âœ… DNA ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin or 'ì „ì²´'}")
                return True
                
    except Exception as e:
        logger.error(f"âŒ DNA ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_global_strategy_summary_for_signals(interval: str, db_path: str = None) -> bool:
    """rl_strategies.dbì˜ global_strategiesë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # rl_strategies.dbì—ì„œ ê¸€ë¡œë²Œ ì „ëµ ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # ê¸€ë¡œë²Œ ì „ëµ ì¡°íšŒ
            cursor.execute("""
                SELECT strategy_id, performance_score, global_dna_pattern, 
                       global_fractal_score, global_synergy_score
                FROM global_strategies
                ORDER BY performance_score DESC
                LIMIT 50
            """)
            
            strategies = cursor.fetchall()
            
            if not strategies:
                logger.warning(f"âš ï¸ {interval} ê¸€ë¡œë²Œ ì „ëµ ë°ì´í„° ì—†ìŒ")
                return False
            
            top_strategy = strategies[0]
            top_strategy_id = top_strategy[0]
            top_strategy_params = json.dumps({
                'dna_pattern': top_strategy[2],
                'fractal_score': top_strategy[3],
                'synergy_score': top_strategy[4]
            })
            top_global_score = top_strategy[1] or 0.0
            
            # í‰ê·  ê³„ì‚°
            scores = [s[1] or 0.0 for s in strategies]
            avg_global_score = sum(scores) / len(scores) if scores else 0.0
            # ğŸ”¥ ì‹¤ì œ ì „ëµ ë“±ê¸‰ ê¸°ë°˜ìœ¼ë¡œ ê¸€ë¡œë²Œ ì‹ ë¢°ë„ ê³„ì‚°
            avg_global_confidence = _calculate_global_confidence(strategies)
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO global_strategy_summary_for_signals
                    (interval, top_global_strategy_id, top_global_strategy_params, top_global_score,
                     avg_global_score, avg_global_confidence, total_global_strategies, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    interval, top_strategy_id, top_strategy_params, top_global_score,
                    avg_global_score, avg_global_confidence, len(strategies)
                ))
                
                conn.commit()
                logger.info(f"âœ… ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {interval} ({len(strategies)}ê°œ)")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_analysis_summary_for_signals(coin: str, interval: str, db_path: str = None) -> bool:
    """rl_strategies.dbì˜ fractal_analysis/synergy_analysisë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # rl_strategies.dbì—ì„œ ë¶„ì„ ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # í”„ë™íƒˆ ë¶„ì„
            cursor.execute("""
                SELECT fractal_score, pattern_distribution, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio
                FROM fractal_analysis
                WHERE coin = ? AND interval = ?
                ORDER BY created_at DESC LIMIT 1
            """, (coin, interval))
            
            fractal_row = cursor.fetchone()
            fractal_score = 0.0
            fractal_pattern = "{}"
            optimal_rsi_min = 30.0
            optimal_rsi_max = 70.0
            optimal_volume_ratio = 1.0
            
            if fractal_row:
                fractal_score = fractal_row[0] or 0.0
                fractal_pattern = fractal_row[1] or "{}"
                optimal_rsi_min = fractal_row[2] or 30.0
                optimal_rsi_max = fractal_row[3] or 70.0
                optimal_volume_ratio = fractal_row[4] or 1.0
            
            # ì‹œë„ˆì§€ ë¶„ì„
            cursor.execute("""
                SELECT synergy_score, synergy_patterns
                FROM synergy_analysis
                WHERE coin = ? AND interval = ?
                ORDER BY created_at DESC LIMIT 1
            """, (coin, interval))
            
            synergy_row = cursor.fetchone()
            synergy_score = 0.0
            synergy_patterns = "{}"
            
            if synergy_row:
                synergy_score = synergy_row[0] or 0.0
                synergy_patterns = synergy_row[1] or "{}"
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO analysis_summary_for_signals
                    (coin, interval, fractal_score, fractal_pattern, synergy_score,
                     synergy_patterns, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, fractal_score, fractal_pattern, synergy_score,
                    synergy_patterns, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio
                ))
                
                conn.commit()
                logger.info(f"âœ… ë¶„ì„ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin}-{interval}")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_global_strategy_results(
    overall_score: float,
    overall_confidence: float = 0.5,
    top_performers: List[Dict[str, Any]] = None,
    db_path: str = None
) -> bool:
    """ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ë¥¼ learning_results.dbì— ì €ì¥
    
    Args:
        overall_score: ì „ì²´ ì„±ê³¼ ì ìˆ˜
        overall_confidence: ì „ì²´ ì‹ ë¢°ë„
        top_performers: ìƒìœ„ ì„±ê³¼ì ë¦¬ìŠ¤íŠ¸
        db_path: DB ê²½ë¡œ (ê¸°ë³¸ê°’: LEARNING_RESULTS_DB_PATH)
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        import json
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        if top_performers is None:
            top_performers = []
        
        # ìƒìœ„ ì„±ê³¼ìì—ì„œ ì½”ì¸/ì¸í„°ë²Œ ì¶”ì¶œ
        # ğŸ”¥ íƒ€ì… í™•ì¸: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
        top_coins = []
        top_intervals = []
        for p in top_performers[:10]:
            if isinstance(p, dict):
                coin = p.get('coin', '')
                interval = p.get('interval', '')
                if coin:
                    top_coins.append(coin)
                if interval:
                    top_intervals.append(interval)
        
        top_coins = list(set(top_coins))
        top_intervals = list(set(top_intervals))
        
        # ì´ì „ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ policy_improvement ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
        policy_improvement = 0.0  # ì¶”í›„ ì´ì „ ë°ì´í„°ì™€ ë¹„êµ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO global_strategy_results (
                    overall_score, overall_confidence, policy_improvement, convergence_rate,
                    top_performers, top_coins, top_intervals
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                overall_score,
                overall_confidence,
                policy_improvement,
                0.0,  # convergence_rate (ê³„ì‚° í•„ìš” ì‹œ ì¶”ê°€)
                json.dumps(top_performers),
                json.dumps(top_coins),
                json.dumps(top_intervals)
            ))
            
            conn.commit()
            logger.info(f"âœ… ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ì ìˆ˜ {overall_score:.3f}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        return False

def load_global_strategies_from_db(interval: str = None, db_path: str = None) -> List[Dict[str, Any]]:
    """ê¸€ë¡œë²Œ ì „ëµì„ rl_strategies.dbì—ì„œ ë¡œë“œ"""
    try:
        import json
        from rl_pipeline.core.env import config
        
        db_path = db_path or config.STRATEGIES_DB
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # global_strategies í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='global_strategies'
            """)
            
            if not cursor.fetchone():
                logger.warning("âš ï¸ global_strategies í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê¸€ë¡œë²Œ ì „ëµ ì¡°íšŒ
            if interval:
                cursor.execute("""
                    SELECT id, coin, interval, strategy_type, params, name, description,
                           profit, profit_factor, win_rate, trades_count, quality_grade,
                           market_condition, created_at, updated_at, meta
                    FROM global_strategies
                    WHERE interval = ?
                    ORDER BY created_at DESC
                """, (interval,))
            else:
                cursor.execute("""
                    SELECT id, coin, interval, strategy_type, params, name, description,
                           profit, profit_factor, win_rate, trades_count, quality_grade,
                           market_condition, created_at, updated_at, meta
                    FROM global_strategies
                    ORDER BY created_at DESC
                """)
            
            strategies = []
            for row in cursor.fetchall():
                try:
                    strategy = {
                        'id': row[0],
                        'coin': row[1],
                        'interval': row[2],
                        'strategy_type': row[3],
                        'params': json.loads(row[4]) if row[4] else {},
                        'name': row[5],
                        'description': row[6],
                        'profit': row[7] or 0.0,
                        'profit_factor': row[8] or 0.0,
                        'win_rate': row[9] or 0.5,
                        'trades_count': row[10] or 0,
                        'quality_grade': row[11] or 'A',
                        'market_condition': row[12] or 'neutral',
                        'created_at': row[13],
                        'updated_at': row[14],
                        'meta': json.loads(row[15]) if row[15] else {}
                    }
                    strategies.append(strategy)
                except Exception as e:
                    logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ ì „ëµ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            return strategies
            
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def get_pipeline_performance_summary(days: int = 7, db_path: str = None) -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ìš”ì•½"""
    try:
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            # ìµœê·¼ Nì¼ê°„ì˜ ì‹¤í–‰ ë¡œê·¸ ì¡°íšŒ
            cursor.execute("""
                SELECT * FROM pipeline_execution_logs 
                WHERE created_at >= datetime('now', '-{} days')
                ORDER BY created_at DESC
            """.format(days))
            
            rows = cursor.fetchall()
            
            if not rows:
                return {'error': 'No data found'}
            
            # í†µê³„ ê³„ì‚°
            total_runs = len(rows)
            successful_runs = len([r for r in rows if r['status'] == 'success'])
            failed_runs = total_runs - successful_runs
            
            avg_execution_time = sum(r['execution_time'] for r in rows) / total_runs
            avg_signal_score = sum(r['signal_score'] for r in rows if r['signal_score'] > 0) / successful_runs if successful_runs > 0 else 0
            
            # ì•¡ì…˜ë³„ ë¶„í¬
            action_distribution = {}
            for row in rows:
                action = row['signal_action']
                action_distribution[action] = action_distribution.get(action, 0) + 1
            
            # ë ˆì§ë³„ ë¶„í¬
            regime_distribution = {}
            for row in rows:
                regime = row['regime_detected']
                regime_distribution[regime] = regime_distribution.get(regime, 0) + 1
            
            summary = {
                'period_days': days,
                'total_runs': total_runs,
                'successful_runs': successful_runs,
                'failed_runs': failed_runs,
                'success_rate': successful_runs / total_runs if total_runs > 0 else 0,
                'avg_execution_time': avg_execution_time,
                'avg_signal_score': avg_signal_score,
                'action_distribution': action_distribution,
                'regime_distribution': regime_distribution,
                'created_at': datetime.now().isoformat()
            }
            
            return summary
            
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def save_realtime_feedback(
    coin: str,
    interval: str,
    signal_id: str,
    signal_score: float,
    signal_action: str,
    signal_timestamp: datetime,
    actual_profit: float = 0.0,
    actual_success: bool = False,
    market_condition: str = 'unknown',
    learning_adjustment: float = 0.0,
    strategy_update: Dict[str, Any] = None,
    db_path: str = None
) -> bool:
    """ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°± ì €ì¥ - ì‹¤ì œ ë§¤ë§¤ ê²°ê³¼ë¥¼ í•™ìŠµ ë£¨í”„ë¡œ í”¼ë“œë°±
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        signal_id: ì‹œê·¸ë„ ê³ ìœ  ID
        signal_score: ì‹œê·¸ë„ ì ìˆ˜
        signal_action: ì‹œê·¸ë„ ì•¡ì…˜ (buy/sell/hold)
        signal_timestamp: ì‹œê·¸ë„ ë°œìƒ ì‹œê°
        actual_profit: ì‹¤ì œ ìˆ˜ìµë¥ 
        actual_success: ì„±ê³µ ì—¬ë¶€
        market_condition: ì‹œì¥ ìƒíƒœ
        learning_adjustment: í•™ìŠµ ì¡°ì •ê°’
        strategy_update: ì „ëµ ì—…ë°ì´íŠ¸ ì •ë³´ (JSON)
        db_path: DB ê²½ë¡œ
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        import json
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        if strategy_update is None:
            strategy_update = {}
        
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO realtime_learning_feedback
                (coin, interval, signal_id, signal_score, signal_action, signal_timestamp,
                 actual_profit, actual_success, market_condition, learning_adjustment,
                 strategy_update, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                coin,
                interval,
                signal_id,
                signal_score,
                signal_action,
                signal_timestamp.isoformat() if isinstance(signal_timestamp, datetime) else signal_timestamp,
                actual_profit,
                1 if actual_success else 0,  # SQLiteëŠ” BOOLEANì„ INTEGERë¡œ ì €ì¥
                market_condition,
                learning_adjustment,
                json.dumps(strategy_update),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            logger.info(f"âœ… ì‹¤ì‹œê°„ í”¼ë“œë°± ì €ì¥ ì™„ë£Œ: {coin}-{interval} (signal_id={signal_id}, profit={actual_profit:.2f}%)")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        return False

def get_realtime_feedback_summary(
    coin: str = None,
    interval: str = None,
    days: int = 7,
    db_path: str = None
) -> Dict[str, Any]:
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ìš”ì•½ í†µê³„ ì¡°íšŒ
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼ (Noneì´ë©´ ì „ì²´)
        interval: ì¸í„°ë²Œ (Noneì´ë©´ ì „ì²´)
        days: ì¡°íšŒ ê¸°ê°„ (ì¼)
        db_path: DB ê²½ë¡œ
    
    Returns:
        í”¼ë“œë°± ìš”ì•½ í†µê³„
    """
    try:
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            # WHERE ì¡°ê±´ ë™ì  êµ¬ì„±
            conditions = ["signal_timestamp >= datetime('now', '-{} days')".format(days)]
            params = []
            
            if coin:
                conditions.append("coin = ?")
                params.append(coin)
            
            if interval:
                conditions.append("interval = ?")
                params.append(interval)
            
            where_clause = " AND ".join(conditions)
            
            # í†µê³„ ê³„ì‚°
            cursor.execute(f"""
                SELECT 
                    COUNT(*) as total_feedbacks,
                    SUM(CASE WHEN actual_success = 1 THEN 1 ELSE 0 END) as successful_signals,
                    AVG(actual_profit) as avg_profit,
                    AVG(signal_score) as avg_signal_score,
                    COUNT(DISTINCT coin) as distinct_coins,
                    COUNT(DISTINCT interval) as distinct_intervals
                FROM realtime_learning_feedback
                WHERE {where_clause}
            """, params)
            
            row = cursor.fetchone()
            
            if not row or row[0] == 0:
                return {
                    'total_feedbacks': 0,
                    'success_rate': 0.0,
                    'avg_profit': 0.0,
                    'avg_signal_score': 0.0
                }
            
            total = row[0]
            successful = row[1] or 0
            avg_profit = row[2] or 0.0
            avg_signal_score = row[3] or 0.0
            
            return {
                'total_feedbacks': total,
                'successful_signals': successful,
                'success_rate': successful / total if total > 0 else 0.0,
                'avg_profit': avg_profit,
                'avg_signal_score': avg_signal_score,
                'distinct_coins': row[4] or 0,
                'distinct_intervals': row[5] or 0,
                'period_days': days
            }
            
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

# í¸ì˜ í•¨ìˆ˜ë“¤
