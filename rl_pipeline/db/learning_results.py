"""
Learning Results DB ê´€ë¦¬ ëª¨ë“ˆ
ì´ì œ learning_strategies.dbë¡œ í†µí•©ë¨
"""

import logging
import sqlite3
import json
import os
import time
import random
from datetime import datetime
from typing import Dict, List, Any, Optional
from contextlib import contextmanager

logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ”’ íŒŒì¼ ë½ ìœ í‹¸ë¦¬í‹° (Docker ë³¼ë¥¨ ë§ˆìš´íŠ¸ í™˜ê²½ì—ì„œ ë™ì‹œ ì ‘ê·¼ ë°©ì§€)
# ============================================================================

def _get_lock_path(db_path: str) -> str:
    """ë½ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    return f"{db_path}.process_lock"

def _acquire_file_lock(db_path: str, timeout: int = 60) -> bool:
    """íŒŒì¼ ë½ íšë“ (ê°„ë‹¨í•œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ê¸°ë°˜)"""
    lock_path = _get_lock_path(db_path)
    start_time = time.time()
    pid = os.getpid()
    
    while time.time() - start_time < timeout:
        try:
            # ë½ íŒŒì¼ì´ ìˆìœ¼ë©´ ëŒ€ê¸°
            if os.path.exists(lock_path):
                # ë½ íŒŒì¼ì´ ì˜¤ë˜ëìœ¼ë©´ (60ì´ˆ ì´ìƒ) ê°•ì œ ì‚­ì œ
                try:
                    lock_age = time.time() - os.path.getmtime(lock_path)
                    if lock_age > 60:
                        os.remove(lock_path)
                        logger.debug(f"ğŸ”“ ì˜¤ë˜ëœ ë½ íŒŒì¼ ì‚­ì œ: {lock_path}")
                except:
                    pass
                
                # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                time.sleep(0.5 + random.random())
                continue
            
            # ë½ íŒŒì¼ ìƒì„± ì‹œë„
            with open(lock_path, 'w') as f:
                f.write(f"{pid}:{time.time()}")
            
            # ê²½ìŸ ì¡°ê±´ ë°©ì§€: ì ì‹œ ëŒ€ê¸° í›„ ìì‹ ì˜ ë½ì¸ì§€ í™•ì¸
            time.sleep(0.1)
            try:
                with open(lock_path, 'r') as f:
                    content = f.read()
                    if content.startswith(f"{pid}:"):
                        return True
            except:
                pass
            
        except Exception as e:
            logger.debug(f"âš ï¸ ë½ íšë“ ì¤‘ ì˜¤ë¥˜: {e}")
            time.sleep(0.5)
    
    logger.warning(f"âš ï¸ ë½ íšë“ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ): {db_path}")
    return False

def _release_file_lock(db_path: str):
    """íŒŒì¼ ë½ í•´ì œ"""
    lock_path = _get_lock_path(db_path)
    try:
        if os.path.exists(lock_path):
            os.remove(lock_path)
    except Exception as e:
        logger.debug(f"âš ï¸ ë½ í•´ì œ ì¤‘ ì˜¤ë¥˜: {e}")

# DB ê²½ë¡œ - learning_results.dbëŠ” ì´ì œ learning_strategies.dbë¡œ í†µí•©ë¨
# configì—ì„œ LEARNING_RESULTS_DB_PATH = STRATEGIES_DBë¡œ ì„¤ì •ë¨
from rl_pipeline.core.env import config

def get_learning_results_db_path() -> str:
    """ë™ì ìœ¼ë¡œ í•™ìŠµ ê²°ê³¼ DB ê²½ë¡œ ë°˜í™˜ (ë””ë ‰í† ë¦¬ ëª¨ë“œ ì§€ì›)"""
    # ğŸ”¥ í™˜ê²½ë³€ìˆ˜ ìš°ì„  í™•ì¸ (ì—”ì§„í™”ëœ run_learning.pyì—ì„œ ì„¤ì •)
    env_strategies_path = os.getenv('STRATEGY_DB_PATH') or os.getenv('STRATEGIES_DB_PATH')
    
    if env_strategies_path:
        base_path = env_strategies_path
    else:
        base_path = config.LEARNING_RESULTS_DB_PATH
    
    # ğŸ”§ ë””ë ‰í† ë¦¬ ëª¨ë“œ ì§€ì›: í´ë”ë©´ common_strategies.db ì‚¬ìš©
    if os.path.isdir(base_path) or not base_path.endswith('.db'):
        result = os.path.join(base_path, 'common_strategies.db')
    else:
        result = base_path
    
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    return os.path.abspath(result)

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³€ìˆ˜ (ë™ì  ê²½ë¡œëŠ” get_learning_results_db_path() ì‚¬ìš© ê¶Œì¥)
# ğŸ”¥ ì°¸ê³ : ì´ ë³€ìˆ˜ëŠ” ì„í¬íŠ¸ ì‹œì ì— ê³ ì •ë¨. ëŸ°íƒ€ì„ì—ëŠ” get_learning_results_db_path() ì‚¬ìš©
def _get_initial_db_path():
    try:
        path = get_learning_results_db_path()
        logger.debug(f"ğŸ“‚ learning_results DB ê²½ë¡œ: {path}")
        return path
    except Exception as e:
        logger.warning(f"âš ï¸ learning_results DB ê²½ë¡œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

LEARNING_RESULTS_DB_PATH = _get_initial_db_path()


@contextmanager
def get_learning_db_connection(db_path: str = None):
    """learning_results.db ì—°ê²° ê´€ë¦¬ (íŒŒì¼ ë½ í¬í•¨)"""
    if db_path is None:
        db_path = get_learning_results_db_path()
    
    # ğŸ”§ ë””ë ‰í† ë¦¬ ëª¨ë“œ ì§€ì›: í´ë”ë©´ common_strategies.db ì‚¬ìš©
    if os.path.isdir(db_path) or not db_path.endswith('.db'):
        db_path = os.path.join(db_path, 'common_strategies.db')
    
    # ğŸ”¥ ì ˆëŒ€ ê²½ë¡œ ë³€í™˜ (ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ ë°©ì§€)
    db_path = os.path.abspath(db_path)
    
    # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    db_dir = os.path.dirname(db_path)
    if db_dir and not os.path.exists(db_dir):
        try:
            os.makedirs(db_dir, exist_ok=True)
            logger.info(f"ğŸ“ DB ë””ë ‰í† ë¦¬ ìƒì„±: {db_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ DB ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ({db_dir}): {e}")
    
    # ğŸ”’ íŒŒì¼ ë½ íšë“ (ë™ì‹œ ì ‘ê·¼ ë°©ì§€)
    lock_acquired = _acquire_file_lock(db_path, timeout=120)
    if not lock_acquired:
        logger.warning(f"âš ï¸ íŒŒì¼ ë½ íšë“ ì‹¤íŒ¨, ë½ ì—†ì´ ì§„í–‰: {db_path}")
    
    conn = None
    max_retries = 5
    last_error = None
    
    try:
        # ì—°ê²° ì‹œë„ (ì¬ì‹œë„ ë¡œì§)
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(db_path, timeout=180.0, isolation_level=None)
                # ğŸ”¥ WAL ëª¨ë“œ ì‚¬ìš© (ë™ì‹œ ì ‘ê·¼ ì§€ì›)
                try:
                    conn.execute("PRAGMA journal_mode=WAL")
                except:
                    conn.execute("PRAGMA journal_mode=DELETE")
                conn.execute("PRAGMA mmap_size=0")
                conn.execute("PRAGMA busy_timeout=180000")
                conn.execute("PRAGMA synchronous=NORMAL")
                conn.execute("PRAGMA wal_autocheckpoint=100")
                conn.row_factory = sqlite3.Row
                break
            except Exception as e:
                last_error = e
                if conn:
                    try:
                        conn.close()
                    except:
                        pass
                    conn = None
                
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"âš ï¸ learning_results DB ì—°ê²° ì¬ì‹œë„ ({attempt + 1}/{max_retries}): {db_path}")
                    time.sleep(wait_time)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
        if conn is None:
            logger.error(f"âŒ learning_results DB ì—°ê²° ì‹¤íŒ¨ ({db_path}): {last_error}")
            _release_file_lock(db_path)  # ë½ í•´ì œ
            raise last_error if last_error else Exception(f"DB ì—°ê²° ì‹¤íŒ¨: {db_path}")
        
        try:
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            raise
        finally:
            if conn:
                conn.close()
    finally:
        # ğŸ”“ íŒŒì¼ ë½ í•´ì œ (í•­ìƒ ì‹¤í–‰)
        _release_file_lock(db_path)

def create_learning_results_tables(db_path: str = None) -> bool:
    """learning_strategies.dbì— learning_results í…Œì´ë¸” ìƒì„± (í†µí•©ë¨)

    í•µì‹¬ ì„¤ê³„:
    - coin â†’ symbol ë§¤í•‘
    - market_type, market ì»¬ëŸ¼ ì¶”ê°€
    """
    try:
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()

            # 1. Self-play ì§„í™” ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS selfplay_evolution_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    regime TEXT NOT NULL,

                    -- ì§„í™” ì „ëµ ì •ë³´
                    initial_strategy TEXT NOT NULL,
                    evolved_strategy TEXT NOT NULL,
                    evolution_steps INTEGER DEFAULT 0,

                    -- ì§„í™” ì„±ê³¼
                    initial_performance REAL DEFAULT 0.0,
                    evolved_performance REAL DEFAULT 0.0,
                    improvement_rate REAL DEFAULT 0.0,

                    -- ì§„í™” ê³¼ì •
                    evolution_history TEXT DEFAULT '[]',
                    adaptation_patterns TEXT DEFAULT '{}',

                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 2. ë ˆì§ ê¸°ë°˜ ë¼ìš°íŒ… ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS regime_routing_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    regime TEXT NOT NULL,

                    -- ë¼ìš°íŒ…ëœ ì „ëµ
                    routed_strategy TEXT NOT NULL,
                    routing_confidence REAL DEFAULT 0.0,
                    routing_score REAL DEFAULT 0.0,

                    -- ë ˆì§ë³„ ì„±ëŠ¥
                    regime_performance REAL DEFAULT 0.0,
                    regime_adaptation REAL DEFAULT 0.0,

                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 3. ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS realtime_learning_feedback (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    signal_id TEXT NOT NULL,

                    -- ì‹œê·¸ë„ ì •ë³´
                    signal_score REAL DEFAULT 0.0,
                    signal_action TEXT NOT NULL,
                    signal_timestamp DATETIME NOT NULL,

                    -- ì‹¤ì œ ê²°ê³¼
                    actual_profit REAL DEFAULT 0.0,
                    actual_success BOOLEAN DEFAULT FALSE,
                    market_condition TEXT DEFAULT 'unknown',

                    -- í•™ìŠµ í”¼ë“œë°±
                    learning_adjustment REAL DEFAULT 0.0,
                    strategy_update TEXT DEFAULT '{}',

                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 4. ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS global_strategy_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',

                    -- ê¸€ë¡œë²Œ ì„±ëŠ¥
                    overall_score REAL DEFAULT 0.0,
                    overall_confidence REAL DEFAULT 0.0,
                    policy_improvement REAL DEFAULT 0.0,
                    convergence_rate REAL DEFAULT 0.0,

                    -- ìƒìœ„ ì„±ëŠ¥
                    top_performers TEXT DEFAULT '[]',
                    top_symbols TEXT DEFAULT '[]',
                    top_intervals TEXT DEFAULT '[]',

                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 5. ì‹œê·¸ë„ ê³„ì‚°ìš© ì „ëµ ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS strategy_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,

                    -- ìµœìƒìœ„ ì „ëµ ìš”ì•½ ì •ë³´
                    top_strategy_id TEXT,
                    top_strategy_params TEXT,
                    top_profit REAL DEFAULT 0.0,
                    top_win_rate REAL DEFAULT 0.0,
                    top_quality_grade TEXT,

                    -- í‰ê·  ì„±ëŠ¥ ì§€í‘œ
                    avg_profit REAL DEFAULT 0.0,
                    avg_win_rate REAL DEFAULT 0.0,
                    avg_sharpe_ratio REAL DEFAULT 0.0,
                    avg_calmar_ratio REAL DEFAULT 0.0,
                    avg_profit_factor REAL DEFAULT 0.0,

                    -- ì „ëµ í†µê³„
                    total_strategies INTEGER DEFAULT 0,
                    s_grade_count INTEGER DEFAULT 0,
                    a_grade_count INTEGER DEFAULT 0,

                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                    UNIQUE(market_type, market, symbol, interval)
                )
            """)

            # 6. ì‹œê·¸ë„ ê³„ì‚°ìš© DNA ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS dna_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT,
                    interval TEXT,

                    -- DNA ìš”ì•½ ì •ë³´
                    profitability_score REAL DEFAULT 0.0,
                    stability_score REAL DEFAULT 0.0,
                    scalability_score REAL DEFAULT 0.0,
                    dna_quality REAL DEFAULT 0.0,

                    -- DNA íŒ¨í„´ ìš”ì•½
                    rsi_pattern TEXT,
                    macd_pattern TEXT,
                    volume_pattern TEXT,

                    -- DNA íˆìŠ¤í† ë¦¬ ìš”ì•½
                    dna_momentum REAL DEFAULT 0.0,
                    dna_stability REAL DEFAULT 0.0,

                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                    UNIQUE(market_type, market, symbol, interval)
                )
            """)

            # 7. ì‹œê·¸ë„ ê³„ì‚°ìš© ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS global_strategy_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    interval TEXT NOT NULL,

                    -- ìµœìƒìœ„ ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½
                    top_global_strategy_id TEXT,
                    top_global_strategy_params TEXT,
                    top_global_score REAL DEFAULT 0.0,

                    -- í‰ê·  ì„±ëŠ¥
                    avg_global_score REAL DEFAULT 0.0,
                    avg_global_confidence REAL DEFAULT 0.0,

                    -- í†µê³„
                    total_global_strategies INTEGER DEFAULT 0,

                    -- í•™ìŠµ í’ˆì§ˆ ì§€í‘œ
                    learning_quality_score REAL DEFAULT 0.0,
                    reliability_score REAL DEFAULT 0.0,

                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                    UNIQUE(market_type, interval)
                )
            """)

            # 8. ì‹œê·¸ë„ ê³„ì‚°ìš© í”„ë™íƒˆ/ì‹œë„ˆì§€ ìš”ì•½ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS analysis_summary_for_signals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,

                    -- í”„ë™íƒˆ ë¶„ì„ ìš”ì•½
                    fractal_score REAL DEFAULT 0.0,
                    fractal_pattern TEXT,

                    -- ì‹œë„ˆì§€ ë¶„ì„ ìš”ì•½
                    synergy_score REAL DEFAULT 0.0,
                    synergy_patterns TEXT,

                    -- ìµœì  ì¡°ê±´
                    optimal_rsi_min REAL DEFAULT 30.0,
                    optimal_rsi_max REAL DEFAULT 70.0,
                    optimal_volume_ratio REAL DEFAULT 1.0,

                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                    UNIQUE(market_type, market, symbol, interval)
                )
            """)

            # 9. selfplay_results í…Œì´ë¸” (save_selfplay_resultsì—ì„œ ì‚¬ìš©)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS selfplay_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    episodes INTEGER NOT NULL,
                    results TEXT NOT NULL,
                    summary TEXT,
                    created_at TEXT NOT NULL,
                    UNIQUE(market_type, market, symbol, interval, episodes, results)
                )
            """)

            # 10. Paper Trading ê´€ë ¨ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS paper_trading_sessions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT UNIQUE NOT NULL,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    start_time DATETIME NOT NULL,
                    end_time DATETIME,
                    status TEXT DEFAULT 'active',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS paper_trading_trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    trade_id TEXT UNIQUE NOT NULL,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    action TEXT NOT NULL,
                    entry_price REAL,
                    exit_price REAL,
                    quantity REAL,
                    profit REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES paper_trading_sessions(session_id)
                )
            """)

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS paper_trading_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    market_type TEXT NOT NULL DEFAULT 'COIN',
                    market TEXT NOT NULL DEFAULT 'BITHUMB',
                    symbol TEXT NOT NULL,
                    interval TEXT NOT NULL,
                    total_trades INTEGER DEFAULT 0,
                    winning_trades INTEGER DEFAULT 0,
                    total_profit REAL DEFAULT 0.0,
                    max_drawdown REAL DEFAULT 0.0,
                    sharpe_ratio REAL DEFAULT 0.0,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES paper_trading_sessions(session_id)
                )
            """)

            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_selfplay_symbol_interval ON selfplay_evolution_results(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_regime_routing_symbol_interval ON regime_routing_results(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_realtime_feedback_symbol_interval ON realtime_learning_feedback(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_strategy_summary_symbol_interval ON strategy_summary_for_signals(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_dna_summary_symbol_interval ON dna_summary_for_signals(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_global_strategy_summary_interval ON global_strategy_summary_for_signals(interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_analysis_summary_symbol_interval ON analysis_summary_for_signals(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_selfplay_results_symbol_interval ON selfplay_results(symbol, interval)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_paper_trading_sessions_symbol ON paper_trading_sessions(symbol)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_paper_trading_trades_session ON paper_trading_trades(session_id)")

            conn.commit()
            logger.info("âœ… learning_strategies.db learning_results í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ learning_strategies.db learning_results í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def save_selfplay_results(coin: str, interval: str, selfplay_result: Dict[str, Any], db_path: str = None,
                         market_type: str = "COIN", market: str = "BITHUMB") -> bool:
    """Self-play ê²°ê³¼ë¥¼ learning_strategies.dbì— ì €ì¥

    í•µì‹¬ ì„¤ê³„:
    - coin íŒŒë¼ë¯¸í„°ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ë‚´ë¶€ì ìœ¼ë¡œ symbolë¡œ ì €ì¥)
    - market_type, market ì»¬ëŸ¼ ì¶”ê°€
    """
    try:
        import json
        import time
        import random
        import numpy as np
        from rl_pipeline.db.connection_pool import get_optimized_db_connection

        # coin â†’ symbol ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
        symbol = coin

        # ì›ë³¸ summary ë³´ì¡´ (ì˜¨ë¼ì¸ ê²°ê³¼ë¡œ ë®ì–´ì¨ì§€ì§€ ì•Šë„ë¡)
        original_summary = selfplay_result.get("summary", {})
        summary = original_summary.copy() if original_summary else {}
        cycle_results = selfplay_result.get("cycle_results", [])
        
        # ğŸ”¥ cycle_resultsê°€ ì—†ìœ¼ë©´ traditional_resultì—ì„œ ê°€ì ¸ì˜¤ê¸° (dual mode ëŒ€ì‘)
        if not cycle_results and selfplay_result.get('dual_mode'):
            traditional_result = selfplay_result.get('traditional_result')
            if traditional_result:
                cycle_results = traditional_result.get("cycle_results", [])
        
        # ğŸ”¥ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ì²˜ë¦¬ ì¶”ê°€ (ì˜¨ë¼ì¸ ê²°ê³¼ê°€ ì•„ì§ ë³€í™˜ë˜ì§€ ì•Šì€ ê²½ìš°)
        online_summary = None  # ì˜¨ë¼ì¸ summary ë³„ë„ ì €ì¥ (ì›ë³¸ summary ë³´ì¡´)
        if not cycle_results:
            try:
                from rl_pipeline.hybrid.online_data_converter import (
                    extract_online_selfplay_result,
                    convert_online_segments_to_cycle_results
                )
                
                online_segments = extract_online_selfplay_result(selfplay_result)
                if online_segments:
                    cycle_results = convert_online_segments_to_cycle_results(online_segments, summary)
                    logger.debug(f"âœ… ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ ({len(cycle_results)}ê°œ cycle)")
                # online_resultì— ì§ì ‘ ìˆëŠ” ê²½ìš°
                elif selfplay_result.get('online_result'):
                    online_result = selfplay_result.get('online_result', {})
                    online_segments = online_result.get('segment_results', [])
                    if online_segments:
                        online_summary = online_result.get('summary', {})  # ë³„ë„ ì €ì¥
                        cycle_results = convert_online_segments_to_cycle_results(online_segments, online_summary)
                        logger.debug(f"âœ… ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ (online_resultì—ì„œ) ({len(cycle_results)}ê°œ cycle)")
            except ImportError:
                logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ ì—†ìŒ (ë¬´ì‹œ)")
            except Exception as e:
                logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        # ğŸ”¥ summaryê°€ ë¹„ì–´ìˆê±°ë‚˜ ê°’ì´ 0.0ì´ë©´ cycle_resultsì—ì„œ ì§ì ‘ ê³„ì‚°
        if cycle_results and (not summary or 
            summary.get("avg_win_rate", 0.0) == 0.0 and summary.get("avg_pnl", 0.0) == 0.0):
            try:
                all_performances = []
                for result in cycle_results:
                    if "results" in result:
                        for agent_id, performance in result["results"].items():
                            all_performances.append(performance)
                
                if all_performances:
                    calculated_summary = {
                        "total_episodes": len(cycle_results),
                        "total_trades": sum(p.get("total_trades", 0) for p in all_performances),
                        "avg_win_rate": float(np.mean([p.get("win_rate", 0) for p in all_performances])),
                        "avg_pnl": float(np.mean([p.get("total_pnl", 0) for p in all_performances])),
                        "avg_sharpe_ratio": float(np.mean([p.get("sharpe_ratio", 0) for p in all_performances])),
                    }
                    # ê¸°ì¡´ summaryì™€ ë³‘í•© (ê³„ì‚°ëœ ê°’ ìš°ì„ )
                    summary.update(calculated_summary)
                    logger.debug(f"âœ… cycle_resultsì—ì„œ summary ê³„ì‚° ì™„ë£Œ: win_rate={summary.get('avg_win_rate', 0):.2%}, pnl={summary.get('avg_pnl', 0):.2f}")
            except Exception as e:
                logger.warning(f"âš ï¸ cycle_resultsì—ì„œ summary ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        if not cycle_results:
            logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ì €ì¥: cycle_resultsê°€ ì—†ìŠµë‹ˆë‹¤. (dual_mode={selfplay_result.get('dual_mode', False)})")
            return False

        max_retries = 5
        for attempt in range(max_retries):
            try:
                # learning_strategies.dbì— selfplay_results í…Œì´ë¸” ìƒì„± ë° ì €ì¥
                with get_optimized_db_connection("strategies") as conn:
                    cursor = conn.cursor()

                    # selfplay_results í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„± (symbol ì»¬ëŸ¼ ì‚¬ìš©)
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS selfplay_results (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            market_type TEXT NOT NULL DEFAULT 'COIN',
                            market TEXT NOT NULL DEFAULT 'BITHUMB',
                            symbol TEXT NOT NULL,
                            interval TEXT NOT NULL,
                            episodes INTEGER NOT NULL,
                            results TEXT NOT NULL,
                            summary TEXT,
                            created_at TEXT NOT NULL,
                            UNIQUE(market_type, market, symbol, interval, episodes, results)
                        )
                    """)
                    
                    saved_count = 0

                    for cycle in cycle_results:
                        episode = cycle.get("episode", 0)
                        results = cycle.get("results", {})

                        if not results:
                            continue

                        for agent_id, performance in results.items():
                            try:
                                cursor.execute("""
                                    INSERT OR REPLACE INTO selfplay_results
                                    (market_type, market, symbol, interval, episodes, results, summary, created_at)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                                """, (
                                    market_type,
                                    market,
                                    symbol,
                                    interval,
                                    episode,
                                    json.dumps({
                                        "agent_id": agent_id,
                                        "performance": performance
                                    }),
                                    json.dumps({
                                        "total_episodes": len(cycle_results),
                                        "episode": episode,
                                        "total_trades": summary.get("total_trades", 0),
                                        "avg_win_rate": summary.get("avg_win_rate", 0.0),
                                        "avg_pnl": summary.get("avg_pnl", 0.0),
                                        "avg_sharpe_ratio": summary.get("avg_sharpe_ratio", 0.0),
                                        "avg_total_return": summary.get("avg_total_return", summary.get("avg_pnl", 0.0)),
                                        "regime_performance": summary.get("regime_performance", {}),
                                        "learning_progress": selfplay_result.get("learning_progress", {})
                                    }),
                                    datetime.now().isoformat()
                                ))
                                saved_count += 1
                            except Exception as e:
                                logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ì¼ë¶€ ì €ì¥ ì‹¤íŒ¨: {e}")
                                continue
                    
                    conn.commit()
                    logger.info(f"âœ… Self-play ê²°ê³¼ ì €ì¥ ì™„ë£Œ (learning_strategies.db): {symbol}-{interval}, {saved_count}ê°œ")
                    return True

            except Exception as e:
                is_locked = "database is locked" in str(e) or "disk I/O error" in str(e) or "malformed" in str(e)
                if is_locked and attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(0.1, 1.0)
                    logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ì €ì¥ ì¼ì‹œì  ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                    time.sleep(wait_time)
                else:
                    if attempt == max_retries - 1:
                         logger.error(f"âŒ Self-play ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ (ìµœì¢…): {e}")
                    # continue loop or return False
        
        return False

    except Exception as e:
        logger.error(f"âŒ Self-play ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_pipeline_execution_log(coin: str, interval: str, strategies_created: int,
                               selfplay_episodes: int, regime_detected: str,
                               routing_results: int, signal_score: float,
                               signal_action: str, execution_time: float,
                               status: str, db_path: str = None,
                               market_type: str = "COIN", market: str = "BITHUMB") -> bool:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥

    í•µì‹¬ ì„¤ê³„:
    - coin íŒŒë¼ë¯¸í„°ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ë‚´ë¶€ì ìœ¼ë¡œ symbolë¡œ ì €ì¥)
    - market_type, market ì»¬ëŸ¼ ì¶”ê°€
    """
    try:
        import time
        import random
        
        # coin â†’ symbol ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
        symbol = coin

        # ìŒìˆ˜ execution_time ë°©ì§€
        if execution_time < 0:
            logger.warning(f"âš ï¸ ìŒìˆ˜ execution_time ê°ì§€: {execution_time:.2f}ì´ˆ â†’ 0.0ì´ˆë¡œ ë³€ê²½ ({symbol}-{interval})")
            execution_time = 0.0

        max_retries = 5
        
        for attempt in range(max_retries):
            try:
                with get_learning_db_connection(db_path) as conn:
                    cursor = conn.cursor()

                    cursor.execute("""
                        INSERT INTO pipeline_execution_logs
                        (market_type, market, symbol, interval, strategies_created, selfplay_episodes, regime_detected,
                         routing_results, signal_score, signal_action, execution_time, status)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        market_type, market, symbol, interval, strategies_created, selfplay_episodes, regime_detected,
                        routing_results, signal_score, signal_action, execution_time, status
                    ))

                    conn.commit()
                    logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {symbol}-{interval}")
                    return True
            
            except Exception as e:
                is_locked = "database is locked" in str(e) or "disk I/O error" in str(e) or "malformed" in str(e)
                if is_locked and attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(0.1, 1.0)
                    logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì¼ì‹œì  ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                    time.sleep(wait_time)
                else:
                    if attempt == max_retries - 1:
                        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ (ìµœì¢…): {e}")
                    # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œ ì‹¤íŒ¨í•˜ë©´ return False

        return False

    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_regime_routing_results(coin: str, interval: str, routing_results: List[Any],
                               market_type: str = "COIN", market: str = "BITHUMB") -> bool:
    """ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ë¥¼ learning_strategies.dbì— ì €ì¥

    í•µì‹¬ ì„¤ê³„:
    - coin íŒŒë¼ë¯¸í„°ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ë‚´ë¶€ì ìœ¼ë¡œ symbolë¡œ ì €ì¥)
    - market_type, market ì»¬ëŸ¼ ì¶”ê°€
    """
    try:
        from rl_pipeline.routing.regime_router import RegimeRoutingResult
        import json

        # coin â†’ symbol ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
        symbol = coin

        if not routing_results:
            logger.debug(f"ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ ì €ì¥ ê±´ë„ˆëœ€: {symbol}-{interval}")
            return True
        
        with get_learning_db_connection(LEARNING_RESULTS_DB_PATH) as conn:
            cursor = conn.cursor()
            
            saved_count = 0
            for result in routing_results:
                try:
                    # RegimeRoutingResult ê°ì²´ì¸ì§€ í™•ì¸
                    if hasattr(result, 'routed_strategy'):
                        # ê°ì²´ì¸ ê²½ìš° - symbol ì‚¬ìš© (coin ì†ì„±ì€ symbolë¡œ ë§¤í•‘)
                        result_symbol = getattr(result, 'symbol', getattr(result, 'coin', symbol))
                        routed_strategy_json = json.dumps(result.routed_strategy)
                        cursor.execute("""
                            INSERT INTO regime_routing_results
                            (market_type, market, symbol, interval, regime, routed_strategy, routing_confidence,
                             routing_score, regime_performance, regime_adaptation, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            market_type,
                            market,
                            result_symbol,
                            result.interval,
                            result.regime,
                            routed_strategy_json,
                            result.routing_confidence,
                            result.routing_score,
                            result.regime_performance,
                            result.regime_adaptation,
                            result.created_at
                        ))
                        saved_count += 1
                    elif isinstance(result, dict):
                        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ëŒ€ì²´ ì²˜ë¦¬)
                        result_symbol = result.get('symbol', result.get('coin', symbol))
                        routed_strategy_json = json.dumps(result.get('routed_strategy', result))
                        cursor.execute("""
                            INSERT INTO regime_routing_results
                            (market_type, market, symbol, interval, regime, routed_strategy, routing_confidence,
                             routing_score, regime_performance, regime_adaptation, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            market_type,
                            market,
                            result_symbol,
                            result.get('interval', interval),
                            result.get('regime', 'neutral'),
                            routed_strategy_json,
                            result.get('routing_confidence', 0.5),
                            result.get('routing_score', 0.5),
                            result.get('regime_performance', 0.5),
                            result.get('regime_adaptation', 0.5),
                            result.get('created_at', datetime.now().isoformat())
                        ))
                        saved_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì¼ë¶€ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            conn.commit()
            logger.info(f"âœ… ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {symbol}-{interval}, {saved_count}ê°œ")

        return True

    except Exception as e:
        logger.error(f"âŒ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_regime_routing_to_rl_episodes(coin: str, interval: str, routing_results: List[Any],
                                       market_type: str = "COIN", market: str = "BITHUMB") -> bool:
    """
    ë ˆì§ ë¼ìš°íŒ… ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ rl_episodes í…Œì´ë¸”ì— ì €ì¥
    Self-play ì—†ì´ë„ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆë„ë¡ í•¨

    í•µì‹¬ ì„¤ê³„:
    - coin íŒŒë¼ë¯¸í„°ëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ë‚´ë¶€ì ìœ¼ë¡œ symbolë¡œ ì €ì¥)
    - market_type, market ì»¬ëŸ¼ ì¶”ê°€

    Args:
        coin: ì½”ì¸ ì‹¬ë³¼ (symbolë¡œ ì €ì¥)
        interval: ì¸í„°ë²Œ
        routing_results: ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        market_type: ì‹œì¥ ìœ í˜• (COIN/US_STOCK/KR_STOCK)
        market: ê±°ë˜ì†Œ (BITHUMB/NYSE/KOSPI ë“±)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        from rl_pipeline.routing.regime_router import RegimeRoutingResult
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        import uuid
        import hashlib

        # coin â†’ symbol ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
        symbol = coin

        if not routing_results:
            logger.debug(f"ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ rl_episodes ì €ì¥ ê±´ë„ˆëœ€: {symbol}-{interval}")
            return True

        saved_count = 0
        timestamp = int(datetime.now().timestamp())
        
        for result in routing_results:
            try:
                # RegimeRoutingResult ê°ì²´ì¸ì§€ í™•ì¸
                if not hasattr(result, 'routed_strategy'):
                    continue
                
                strategy = result.routed_strategy
                strategy_id = strategy.get('id') or strategy.get('strategy_id') or 'unknown'
                predictive_accuracy = getattr(result, 'predictive_accuracy', 0.0)
                backtest_result = getattr(result, 'backtest_result', None)
                
                # ğŸ”¥ ì €ì¥ ì¡°ê±´ ì™„í™”: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì €ì¥
                # (ì˜ˆì¸¡ ì •í™•ë„ê°€ 0ì´ì–´ë„ ì‹œì¥ ìƒíƒœ ì •ë³´ëŠ” ìœ ìš©)
                if not backtest_result:
                    # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì €ì¥ (ìµœì†Œí•œì˜ ë°ì´í„° ìˆ˜ì§‘)
                    backtest_result = {
                        'trades': 0,
                        'profit': 0.0,
                        'wins': 0,
                        'win_rate': 0.0,
                        'predictive_accuracy': 0.0,
                        'data_points': 0
                    }
                
                # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ê±°ë˜ ì •ë³´ ì¶”ì¶œ
                trades = backtest_result.get('trades', 0)
                
                # ğŸ”¥ ê±°ë˜ê°€ 0íšŒì—¬ë„ ì €ì¥ (ì‹œì¥ ìƒíƒœ ì •ë³´ëŠ” ìœ ìš©)
                # ì˜ˆì¸¡ ì •í™•ë„ê°€ 0ì´ì–´ë„ ì €ì¥ (ë‚˜ì¤‘ì— Paper Tradingì—ì„œ ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
                
                # ê° ê±°ë˜ë¥¼ ì—í”¼ì†Œë“œë¡œ ì €ì¥
                # ê°„ë‹¨í•œ ë°©ì‹: ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì—í”¼ì†Œë“œë¡œ ì €ì¥
                # episode_id ìƒì„± (ê³ ìœ ì„± ë³´ì¥)
                episode_id = f"regime_routing_{symbol}_{interval}_{strategy_id}_{timestamp}_{saved_count}"

                # ì˜ˆì¸¡ ë°©í–¥ ê²°ì • (ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ë§¤ìˆ˜ ì‹ í˜¸ = ìƒìŠ¹ ì˜ˆì¸¡)
                predicted_dir = 1  # ìƒìŠ¹ ì˜ˆì¸¡ (ë§¤ìˆ˜ ì‹ í˜¸)
                predicted_conf = min(predictive_accuracy, 1.0)  # ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í™•ì‹ ë„ë¡œ ì‚¬ìš©

                # ì „ëµ íŒŒë¼ë¯¸í„°ì—ì„œ ëª©í‘œ ë³€ë™ë¥  ì¶”ì •
                target_move_pct = strategy.get('take_profit', 0.05)  # ê¸°ë³¸ê°’ 5%
                horizon_k = strategy.get('max_hold_periods', 20)  # ê¸°ë³¸ê°’ 20 ìº”ë“¤

                # state_key ìƒì„± (ë ˆì§ ê¸°ë°˜)
                regime = result.regime
                state_key = f"{regime}_{strategy_id}"

                # ì§„ì… ê°€ê²© ì¶”ì • (ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ)
                entry_price = 1.0  # ì •ê·œí™”ëœ ê°€ê²© (ë°±í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ìƒëŒ€ì )

                # rl_episodesì— ì €ì¥ (strategies DB ì‚¬ìš©, symbol ì»¬ëŸ¼ ì‚¬ìš©)
                try:
                    with get_optimized_db_connection("strategies") as strategies_conn:
                        cursor = strategies_conn.cursor()

                        # rl_episodes í…Œì´ë¸”ì— ì €ì¥ (market_type, market, symbol ì‚¬ìš©)
                        cursor.execute("""
                            INSERT OR REPLACE INTO rl_episodes (
                                episode_id, ts_entry, market_type, market, symbol, interval, strategy_id, state_key,
                                predicted_dir, predicted_conf, entry_price, target_move_pct, horizon_k
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            episode_id, timestamp, market_type, market, symbol, interval, strategy_id, state_key,
                            predicted_dir, predicted_conf, entry_price, target_move_pct, horizon_k
                        ))

                        # rl_episode_summary í…Œì´ë¸”ì— ì €ì¥ (market_type, market, symbol ì‚¬ìš©)
                        total_profit = backtest_result.get('profit', 0.0)
                        win_rate = backtest_result.get('win_rate', 0.0)
                        realized_ret_signed = total_profit / trades if trades > 0 else 0.0
                        acc_flag = 1 if predictive_accuracy >= 0.5 else 0
                        ts_exit = timestamp + (horizon_k * 900)  # ëŒ€ëµì ì¸ ì¢…ë£Œ ì‹œê°„

                        cursor.execute("""
                            INSERT OR REPLACE INTO rl_episode_summary (
                                episode_id, ts_exit, market_type, market, symbol, interval,
                                strategy_id, first_event, t_hit,
                                realized_ret_signed, total_reward, acc_flag, source_type
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            episode_id, ts_exit, market_type, market, symbol, interval,
                            strategy_id, 'expiry', horizon_k,
                            realized_ret_signed, predictive_accuracy, acc_flag, 'regime_routing'
                        ))

                        strategies_conn.commit()
                        logger.debug(f"âœ… rl_episodes ì €ì¥: {episode_id}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ rl_episodes ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
                    continue
                
                saved_count += 1
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì‹¤íŒ¨: {e}")
                continue
        
        if saved_count > 0:
            logger.info(f"âœ… ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì™„ë£Œ: {symbol}-{interval}, {saved_count}ê°œ ì—í”¼ì†Œë“œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë ˆì§ ë¼ìš°íŒ… ê²°ê³¼ rl_episodes ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.debug(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
        return False

def save_integrated_analysis_results(coin: str, interval: str, regime: str, analysis_result: Any,
                                     market_type: str = "COIN", market: str = "BITHUMB") -> bool:
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ learning_strategies.dbì— ì €ì¥ (integrated_analysis_results í…Œì´ë¸”)

    ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ: id, market_type, market, symbol, interval, regime, fractal_score, multi_timeframe_score,
                 indicator_cross_score, ensemble_score, ensemble_confidence,
                 final_signal_score, signal_confidence, signal_action, created_at
    """
    import time
    import random

    # coin -> symbol ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±)
    symbol = coin
    
    max_retries = 5
    
    for attempt in range(max_retries):
        try:
            with get_learning_db_connection(LEARNING_RESULTS_DB_PATH) as conn:
                cursor = conn.cursor()

                # ì•ˆì „í•˜ê²Œ ì†ì„± ì ‘ê·¼
                try:
                    # symbolì€ íŒŒë¼ë¯¸í„° ìš°ì„  ì‚¬ìš©
                    result_symbol = getattr(analysis_result, 'symbol', getattr(analysis_result, 'coin', symbol))
                    # intervalì€ íŒŒë¼ë¯¸í„° ìš°ì„  ì‚¬ìš©
                    result_interval = interval if interval else getattr(analysis_result, 'interval', 'all_intervals')
                    result_regime = getattr(analysis_result, 'regime', regime if regime else 'neutral')

                    # ë¶„ì„ ì ìˆ˜ë“¤
                    fractal_score = getattr(analysis_result, 'fractal_score', 0.0)
                    multi_timeframe_score = getattr(analysis_result, 'multi_timeframe_score', 0.0)
                    indicator_cross_score = getattr(analysis_result, 'indicator_cross_score', 0.0)

                    # ì•™ìƒë¸” ì ìˆ˜
                    ensemble_score = getattr(analysis_result, 'ensemble_score', 0.0)
                    ensemble_confidence = getattr(analysis_result, 'ensemble_confidence', 0.0)

                    # ìµœì¢… ì‹œê·¸ë„
                    final_signal_score = getattr(analysis_result, 'final_signal_score', 0.5)
                    signal_confidence = getattr(analysis_result, 'signal_confidence', 0.5)
                    signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
                    created_at = getattr(analysis_result, 'created_at', datetime.now().isoformat())
                except Exception as e:
                    logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ì†ì„± ì ‘ê·¼ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
                    result_symbol = symbol
                    result_interval = interval
                    result_regime = regime if regime else 'neutral'
                    fractal_score = 0.0
                    multi_timeframe_score = 0.0
                    indicator_cross_score = 0.0
                    ensemble_score = 0.0
                    ensemble_confidence = 0.0
                    final_signal_score = 0.5
                    signal_confidence = 0.5
                    signal_action = 'HOLD'
                    created_at = datetime.now().isoformat()

                # ì™„ì „í•œ ìŠ¤í‚¤ë§ˆì— ë§ì¶˜ INSERT (symbol ì»¬ëŸ¼ ì‚¬ìš©)
                cursor.execute("""
                    INSERT INTO integrated_analysis_results
                    (market_type, market, symbol, interval, regime, fractal_score, multi_timeframe_score,
                     indicator_cross_score, ensemble_score, ensemble_confidence,
                     final_signal_score, signal_confidence, signal_action, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    market_type,
                    market,
                    result_symbol,
                    result_interval,
                    result_regime,
                    fractal_score,
                    multi_timeframe_score,
                    indicator_cross_score,
                    ensemble_score,
                    ensemble_confidence,
                    final_signal_score,
                    signal_confidence,
                    signal_action,
                    created_at
                ))

                conn.commit()
                logger.info(f"âœ… í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {symbol}-{interval}")
                return True

        except Exception as e:
            is_locked = "database is locked" in str(e) or "disk I/O error" in str(e) or "malformed" in str(e)
            if is_locked and attempt < max_retries - 1:
                wait_time = (2 ** attempt) + random.uniform(0.1, 1.0)
                logger.warning(f"âš ï¸ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¼ì‹œì  ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time.sleep(wait_time)
            else:
                if attempt == max_retries - 1:
                     logger.error(f"âŒ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ (ìµœì¢…): {e}")
                # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œ ì‹¤íŒ¨í•˜ë©´ False ë°˜í™˜
                
    return False

def load_integrated_analysis_results(coin: str, interval: str, db_path: str = None, limit: int = 1) -> Optional[Dict[str, Any]]:
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ learning_strategies.dbì—ì„œ ë¡œë“œ (ê°œë³„ ì½”ì¸ ì „ëµ ë¶„ì„)

    ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ: id, market_type, market, symbol, interval, regime, fractal_score, multi_timeframe_score,
                 indicator_cross_score, ensemble_score, ensemble_confidence,
                 final_signal_score, signal_confidence, signal_action, created_at
    """
    try:
        # DB ê²½ë¡œ ì„¤ì • (ë””ë ‰í† ë¦¬ ëª¨ë“œ ì§€ì›)
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        elif os.path.isdir(db_path):
            db_path = os.path.join(db_path, 'common_strategies.db')
            
        symbol = coin

        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()

            # ìµœì‹  í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë°˜ì˜, symbol ì‚¬ìš©)
            cursor.execute("""
                SELECT
                    symbol, interval, regime, fractal_score, multi_timeframe_score,
                    indicator_cross_score, ensemble_score, ensemble_confidence,
                    final_signal_score, signal_confidence, signal_action, created_at,
                    market_type, market
                FROM integrated_analysis_results
                WHERE symbol = ? AND interval = ?
                ORDER BY created_at DESC
                LIMIT ?
            """, (symbol, interval, limit))

            rows = cursor.fetchall()
            if not rows:
                return None

            # ê°€ì¥ ìµœì‹  ê²°ê³¼ ë°˜í™˜
            row = rows[0]
            result = {
                'coin': row[0],  # í˜¸í™˜ì„±ì„ ìœ„í•´ coin í‚¤ ìœ ì§€ (ê°’ì€ symbol)
                'symbol': row[0],
                'interval': row[1],
                'regime': row[2],
                'fractal_score': row[3],
                'multi_timeframe_score': row[4],
                'indicator_cross_score': row[5],
                'ensemble_score': row[6],
                'ensemble_confidence': row[7],
                'final_signal_score': row[8],
                'signal_confidence': row[9],
                'signal_action': row[10],
                'created_at': row[11],
                'market_type': row[12],
                'market': row[13]
            }

            return result

    except Exception as e:
        logger.error(f"âŒ í†µí•© ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def save_strategy_summary_for_signals(coin: str, interval: str, db_path: str = None) -> bool:
    """learning_strategies.dbì˜ strategiesë¥¼ ìš”ì•½í•˜ì—¬ learning_strategies.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # learning_strategies.dbì—ì„œ ì „ëµ ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # í•´ë‹¹ ì½”ì¸/ì¸í„°ë²Œì˜ ì „ëµë“¤ ì¡°íšŒ
            cursor.execute("""
                SELECT id, rsi_min, rsi_max, volume_ratio_min, volume_ratio_max,
                       macd_buy_threshold, macd_sell_threshold, profit, win_rate,
                       sharpe_ratio, calmar_ratio, profit_factor, quality_grade
                FROM strategies
                WHERE symbol = ? AND interval = ?
                ORDER BY profit DESC, win_rate DESC
                LIMIT 100
            """, (coin, interval))
            
            strategies = cursor.fetchall()
            
            if not strategies:
                logger.warning(f"âš ï¸ {coin}-{interval} ì „ëµ ë°ì´í„° ì—†ìŒ")
                return False
            
            # ìš”ì•½ ì •ë³´ ê³„ì‚°
            top_strategy = strategies[0]
            top_strategy_id = top_strategy[0]
            top_strategy_params = json.dumps({
                'rsi_min': top_strategy[1],
                'rsi_max': top_strategy[2],
                'volume_ratio_min': top_strategy[3],
                'volume_ratio_max': top_strategy[4],
                'macd_buy_threshold': top_strategy[5],
                'macd_sell_threshold': top_strategy[6]
            })
            top_profit = top_strategy[7] or 0.0
            top_win_rate = top_strategy[8] or 0.0
            top_quality_grade = top_strategy[12] or 'F'
            
            # í‰ê·  ê³„ì‚°
            profits = [s[7] or 0.0 for s in strategies]
            win_rates = [s[8] or 0.0 for s in strategies]
            sharpe_ratios = [s[9] or 0.0 for s in strategies]
            calmar_ratios = [s[10] or 0.0 for s in strategies]
            profit_factors = [s[11] or 1.0 for s in strategies]
            
            avg_profit = sum(profits) / len(profits) if profits else 0.0
            avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0.0
            avg_sharpe_ratio = sum(sharpe_ratios) / len(sharpe_ratios) if sharpe_ratios else 0.0
            avg_calmar_ratio = sum(calmar_ratios) / len(calmar_ratios) if calmar_ratios else 0.0
            avg_profit_factor = sum(profit_factors) / len(profit_factors) if profit_factors else 1.0
            
            # ë“±ê¸‰ë³„ ì¹´ìš´íŠ¸
            s_grade_count = sum(1 for s in strategies if s[12] == 'S')
            a_grade_count = sum(1 for s in strategies if s[12] == 'A')
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO strategy_summary_for_signals
                    (market_type, market, symbol, interval, top_strategy_id, top_strategy_params, top_profit, top_win_rate,
                     top_quality_grade, avg_profit, avg_win_rate, avg_sharpe_ratio, avg_calmar_ratio,
                     avg_profit_factor, total_strategies, s_grade_count, a_grade_count, updated_at)
                    VALUES ('COIN', 'BITHUMB', ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, top_strategy_id, top_strategy_params, top_profit, top_win_rate,
                    top_quality_grade, avg_profit, avg_win_rate, avg_sharpe_ratio, avg_calmar_ratio,
                    avg_profit_factor, len(strategies), s_grade_count, a_grade_count
                ))
                
                conn.commit()
                logger.info(f"âœ… ì „ëµ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin}-{interval} ({len(strategies)}ê°œ ì „ëµ)")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ì „ëµ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def _calculate_global_confidence(strategies: List[tuple]) -> float:
    """ê¸€ë¡œë²Œ ì „ëµ ì‹ ë¢°ë„ ê³„ì‚°"""
    if not strategies:
        return 0.0
    
    try:
        # ë“±ê¸‰ë³„ ê°€ì¤‘ì¹˜
        grade_weights = {
            'S': 1.0, 'A': 0.7, 'B': 0.4, 'C': 0.2, 'D': 0.1, 'F': 0.0,
            'UNKNOWN': 0.0
        }
        
        # ì „ëµ ë°ì´í„° êµ¬ì¡°: (strategy_id, score, ...)
        # strategiesëŠ” íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì •
        grade_scores = []
        strategy_count = len(strategies)
        
        # ê° ì „ëµì˜ ë“±ê¸‰ ì •ë³´ ì¶”ì¶œ (ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
        for strategy in strategies:
            # strategyê°€ íŠœí”Œì¸ ê²½ìš°, ë“±ê¸‰ ì •ë³´ë¥¼ ì¶”ì¶œ
            # ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”
            if isinstance(strategy, tuple) and len(strategy) > 0:
                # ë“±ê¸‰ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: strategy[3]ì— ë“±ê¸‰ì´ ìˆë‹¤ê³  ê°€ì •)
                if len(strategy) > 3:
                    grade = strategy[3] if isinstance(strategy[3], str) else 'UNKNOWN'
                else:
                    grade = 'UNKNOWN'
            else:
                grade = 'UNKNOWN'
            
            grade_scores.append(grade_weights.get(grade, 0.0))
        
        avg_grade_score = sum(grade_scores) / len(grade_scores) if grade_scores else 0.0
        count_score = min(1.0, strategy_count / 100.0)
        
        # ë“±ê¸‰ ì ìˆ˜ 70%, ì „ëµ ìˆ˜ 30% ê°€ì¤‘ì¹˜
        confidence = avg_grade_score * 0.7 + count_score * 0.3
        return round(confidence, 3)
        
    except Exception as e:
        logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        return 0.7

def _extract_rsi_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ RSI íŒ¨í„´ ì¶”ì¶œ"""
    try:
        rsi_mean = dna_data.get('rsi_min', {}).get('mean', 50.0)
        
        if rsi_mean < 30:
            return "oversold_dominant"
        elif rsi_mean > 70:
            return "overbought_dominant"
        elif 40 <= rsi_mean <= 60:
            return "neutral_balanced"
        else:
            return "medium"
    except Exception as e:
        logger.debug(f"âš ï¸ RSI íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "medium"

def _extract_macd_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ MACD íŒ¨í„´ ì¶”ì¶œ"""
    try:
        macd_buy = dna_data.get('macd_buy_threshold', {}).get('mean', 0.0)
        macd_sell = dna_data.get('macd_sell_threshold', {}).get('mean', 0.0)
        
        if macd_buy > 0.01 and macd_sell < -0.01:
            return "strong_trend_following"
        elif abs(macd_buy) < 0.005 and abs(macd_sell) < 0.005:
            return "neutral"
        else:
            return "moderate_trend"
    except Exception as e:
        logger.debug(f"âš ï¸ MACD íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "neutral"

def _extract_volume_pattern(dna_data: Dict) -> str:
    """ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ Volume íŒ¨í„´ ì¶”ì¶œ"""
    try:
        vol_min = dna_data.get('volume_ratio_min', {}).get('mean', 1.0)
        vol_max = dna_data.get('volume_ratio_max', {}).get('mean', 2.0)
        
        if vol_min > 1.5:
            return "high_volume_focus"
        elif vol_max < 1.2:
            return "low_volume_focus"
        else:
            return "normal"
    except Exception as e:
        logger.debug(f"âš ï¸ Volume íŒ¨í„´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "normal"

def save_dna_summary_for_signals(coin: str, interval: str = None, db_path: str = None) -> bool:
    """learning_strategies.dbì˜ strategy_dnaë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # learning_strategies.dbì—ì„œ DNA ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # DNA ë°ì´í„° ì¡°íšŒ
            if coin:
                cursor.execute("""
                    SELECT dna_data FROM strategy_dna
                    WHERE symbol = ? AND (interval = ? OR interval IS NULL)
                    ORDER BY created_at DESC LIMIT 1
                """, (coin, interval))
            else:
                cursor.execute("""
                    SELECT dna_data FROM strategy_dna
                    ORDER BY created_at DESC LIMIT 1
                """)
            
            row = cursor.fetchone()
            if not row:
                logger.warning(f"âš ï¸ DNA ë°ì´í„° ì—†ìŒ: {coin}")
                return False
            
            dna_data = json.loads(row[0])
            
            # ìš”ì•½ ì •ë³´ ê³„ì‚°
            profitability_score = dna_data.get('win_rate', {}).get('mean', 0.0)
            stability_score = min(1.0, dna_data.get('trades_count', {}).get('mean', 0) / 100.0)
            scalability_score = dna_data.get('complexity_score', {}).get('mean', 0.5)
            dna_quality = min(1.0, dna_data.get('analysis_info', {}).get('total_strategies', 0) / 1000.0)
            
            # ğŸ”¥ ì‹¤ì œ DNA ë°ì´í„°ì—ì„œ íŒ¨í„´ ì¶”ì¶œ
            rsi_pattern = _extract_rsi_pattern(dna_data)
            macd_pattern = _extract_macd_pattern(dna_data)
            volume_pattern = _extract_volume_pattern(dna_data)
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO dna_summary_for_signals
                    (market_type, market, symbol, interval, profitability_score, stability_score, scalability_score,
                     dna_quality, rsi_pattern, macd_pattern, volume_pattern, updated_at)
                    VALUES ('COIN', 'BITHUMB', ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, profitability_score, stability_score, scalability_score,
                    dna_quality, rsi_pattern, macd_pattern, volume_pattern
                ))
                
                conn.commit()
                logger.info(f"âœ… DNA ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin or 'ì „ì²´'}")
                return True
                
    except Exception as e:
        logger.error(f"âŒ DNA ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_global_strategy_summary_for_signals(interval: str, db_path: str = None) -> bool:
    """learning_strategies.dbì˜ global_strategiesë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # learning_strategies.dbì—ì„œ ê¸€ë¡œë²Œ ì „ëµ ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # ê¸€ë¡œë²Œ ì „ëµ ì¡°íšŒ
            cursor.execute("""
                SELECT strategy_id, performance_score, global_dna_pattern, 
                       global_fractal_score, global_synergy_score
                FROM global_strategies
                ORDER BY performance_score DESC
                LIMIT 50
            """)
            
            strategies = cursor.fetchall()
            
            if not strategies:
                logger.warning(f"âš ï¸ {interval} ê¸€ë¡œë²Œ ì „ëµ ë°ì´í„° ì—†ìŒ")
                return False
            
            top_strategy = strategies[0]
            top_strategy_id = top_strategy[0]
            top_strategy_params = json.dumps({
                'dna_pattern': top_strategy[2],
                'fractal_score': top_strategy[3],
                'synergy_score': top_strategy[4]
            })
            top_global_score = top_strategy[1] or 0.0
            
            # í‰ê·  ê³„ì‚°
            scores = [s[1] or 0.0 for s in strategies]
            avg_global_score = sum(scores) / len(scores) if scores else 0.0
            # ğŸ”¥ ì‹¤ì œ ì „ëµ ë“±ê¸‰ ê¸°ë°˜ìœ¼ë¡œ ê¸€ë¡œë²Œ ì‹ ë¢°ë„ ê³„ì‚°
            avg_global_confidence = _calculate_global_confidence(strategies)
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO global_strategy_summary_for_signals
                    (interval, top_global_strategy_id, top_global_strategy_params, top_global_score,
                     avg_global_score, avg_global_confidence, total_global_strategies, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    interval, top_strategy_id, top_strategy_params, top_global_score,
                    avg_global_score, avg_global_confidence, len(strategies)
                ))
                
                conn.commit()
                logger.info(f"âœ… ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {interval} ({len(strategies)}ê°œ)")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_analysis_summary_for_signals(coin: str, interval: str, db_path: str = None) -> bool:
    """learning_strategies.dbì˜ fractal_analysis/synergy_analysisë¥¼ ìš”ì•½í•˜ì—¬ learning_results.dbì— ì €ì¥"""
    try:
        import json
        from rl_pipeline.db.connection_pool import get_optimized_db_connection
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        # learning_strategies.dbì—ì„œ ë¶„ì„ ë°ì´í„° ì½ê¸°
        with get_optimized_db_connection("strategies") as conn:
            cursor = conn.cursor()
            
            # í”„ë™íƒˆ ë¶„ì„
            cursor.execute("""
                SELECT fractal_score, pattern_distribution, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio
                FROM fractal_analysis
                WHERE symbol = ? AND interval = ?
                ORDER BY created_at DESC LIMIT 1
            """, (coin, interval))
            
            fractal_row = cursor.fetchone()
            fractal_score = 0.0
            fractal_pattern = "{}"
            optimal_rsi_min = 30.0
            optimal_rsi_max = 70.0
            optimal_volume_ratio = 1.0
            
            if fractal_row:
                fractal_score = fractal_row[0] or 0.0
                fractal_pattern = fractal_row[1] or "{}"
                optimal_rsi_min = fractal_row[2] or 30.0
                optimal_rsi_max = fractal_row[3] or 70.0
                optimal_volume_ratio = fractal_row[4] or 1.0
            
            # ì‹œë„ˆì§€ ë¶„ì„
            cursor.execute("""
                SELECT synergy_score, synergy_patterns
                FROM synergy_analysis
                WHERE symbol = ? AND interval = ?
                ORDER BY created_at DESC LIMIT 1
            """, (coin, interval))
            
            synergy_row = cursor.fetchone()
            synergy_score = 0.0
            synergy_patterns = "{}"
            
            if synergy_row:
                synergy_score = synergy_row[0] or 0.0
                synergy_patterns = synergy_row[1] or "{}"
            
            # learning_results.dbì— ì €ì¥
            with get_learning_db_connection(db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    INSERT OR REPLACE INTO analysis_summary_for_signals
                    (market_type, market, symbol, interval, fractal_score, fractal_pattern, synergy_score,
                     synergy_patterns, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio, updated_at)
                    VALUES ('COIN', 'BITHUMB', ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                """, (
                    coin, interval, fractal_score, fractal_pattern, synergy_score,
                    synergy_patterns, optimal_rsi_min, optimal_rsi_max, optimal_volume_ratio
                ))
                
                conn.commit()
                logger.info(f"âœ… ë¶„ì„ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {coin}-{interval}")
                return True
                
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_global_strategy_results(
    overall_score: float,
    overall_confidence: float = 0.5,
    top_performers: List[Dict[str, Any]] = None,
    db_path: str = None
) -> bool:
    """ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ë¥¼ learning_results.dbì— ì €ì¥
    
    Args:
        overall_score: ì „ì²´ ì„±ê³¼ ì ìˆ˜
        overall_confidence: ì „ì²´ ì‹ ë¢°ë„
        top_performers: ìƒìœ„ ì„±ê³¼ì ë¦¬ìŠ¤íŠ¸
        db_path: DB ê²½ë¡œ (ê¸°ë³¸ê°’: LEARNING_RESULTS_DB_PATH)
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        import json
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        if top_performers is None:
            top_performers = []
        
        # ìƒìœ„ ì„±ê³¼ìì—ì„œ ì½”ì¸/ì¸í„°ë²Œ ì¶”ì¶œ
        # ğŸ”¥ íƒ€ì… í™•ì¸: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
        top_coins = []
        top_intervals = []
        for p in top_performers[:10]:
            if isinstance(p, dict):
                coin = p.get('coin', '')
                interval = p.get('interval', '')
                if coin:
                    top_coins.append(coin)
                if interval:
                    top_intervals.append(interval)
        
        top_coins = list(set(top_coins))
        top_intervals = list(set(top_intervals))
        
        # ì´ì „ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ policy_improvement ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
        policy_improvement = 0.0  # ì¶”í›„ ì´ì „ ë°ì´í„°ì™€ ë¹„êµ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO global_strategy_results (
                    overall_score, overall_confidence, policy_improvement, convergence_rate,
                    top_performers, top_symbols, top_intervals
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                overall_score,
                overall_confidence,
                policy_improvement,
                0.0,  # convergence_rate (ê³„ì‚° í•„ìš” ì‹œ ì¶”ê°€)
                json.dumps(top_performers),
                json.dumps(top_coins),
                json.dumps(top_intervals)
            ))
            
            conn.commit()
            logger.info(f"âœ… ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ì ìˆ˜ {overall_score:.3f}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        return False

def load_global_strategies_from_db(interval: str = None, db_path: str = None) -> List[Dict[str, Any]]:
    """ê¸€ë¡œë²Œ ì „ëµì„ learning_strategies.dbì—ì„œ ë¡œë“œ"""
    try:
        import json
        from rl_pipeline.core.env import config
        
        db_path = db_path or config.STRATEGIES_DB
        
        # ğŸ”§ ë””ë ‰í† ë¦¬ ëª¨ë“œ ì§€ì›: í´ë”ë©´ common_strategies.db ì‚¬ìš©
        if os.path.isdir(db_path) or not db_path.endswith('.db'):
            db_path = os.path.join(db_path, 'common_strategies.db')
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not os.path.exists(db_path):
            logger.info(f"â„¹ï¸ ê¸€ë¡œë²Œ ì „ëµ DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {db_path} (ì •ìƒ - ì•„ì§ í•™ìŠµ ë°ì´í„° ì—†ìŒ)")
            return []
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # global_strategies í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='global_strategies'
            """)
            
            if not cursor.fetchone():
                logger.warning("âš ï¸ global_strategies í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê¸€ë¡œë²Œ ì „ëµ ì¡°íšŒ
            if interval:
                cursor.execute("""
                    SELECT id, symbol, interval, strategy_type, params, name, description,
                           profit, profit_factor, win_rate, trades_count, quality_grade,
                           market_condition, regime, created_at, updated_at, meta
                    FROM global_strategies
                    WHERE interval = ?
                    ORDER BY created_at DESC
                """, (interval,))
            else:
                cursor.execute("""
                    SELECT id, symbol, interval, strategy_type, params, name, description,
                           profit, profit_factor, win_rate, trades_count, quality_grade,
                           market_condition, regime, created_at, updated_at, meta
                    FROM global_strategies
                    ORDER BY created_at DESC
                """)
            
            strategies = []
            for row in cursor.fetchall():
                try:
                    strategy = {
                        'id': row[0],
                        'coin': row[1],
                        'interval': row[2],
                        'strategy_type': row[3],
                        'params': json.loads(row[4]) if row[4] else {},
                        'name': row[5],
                        'description': row[6],
                        'profit': row[7] or 0.0,
                        'profit_factor': row[8] or 0.0,
                        'win_rate': row[9] or 0.5,
                        'trades_count': row[10] or 0,
                        'quality_grade': row[11] or 'A',
                        'market_condition': row[12] or 'neutral',
                        'regime': row[13] or 'neutral',
                        'created_at': row[14],
                        'updated_at': row[15],
                        'meta': json.loads(row[16]) if row[16] else {}
                    }
                    strategies.append(strategy)
                except Exception as e:
                    logger.warning(f"âš ï¸ ê¸€ë¡œë²Œ ì „ëµ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            return strategies
            
    except Exception as e:
        logger.error(f"âŒ ê¸€ë¡œë²Œ ì „ëµ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def get_pipeline_performance_summary(days: int = 7, db_path: str = None) -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ìš”ì•½"""
    try:
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            # ìµœê·¼ Nì¼ê°„ì˜ ì‹¤í–‰ ë¡œê·¸ ì¡°íšŒ
            cursor.execute("""
                SELECT * FROM pipeline_execution_logs 
                WHERE created_at >= datetime('now', '-{} days')
                ORDER BY created_at DESC
            """.format(days))
            
            rows = cursor.fetchall()
            
            if not rows:
                return {'error': 'No data found'}
            
            # í†µê³„ ê³„ì‚°
            total_runs = len(rows)
            successful_runs = len([r for r in rows if r['status'] == 'success'])
            failed_runs = total_runs - successful_runs
            
            avg_execution_time = sum(r['execution_time'] for r in rows) / total_runs
            avg_signal_score = sum(r['signal_score'] for r in rows if r['signal_score'] > 0) / successful_runs if successful_runs > 0 else 0
            
            # ì•¡ì…˜ë³„ ë¶„í¬
            action_distribution = {}
            for row in rows:
                action = row['signal_action']
                action_distribution[action] = action_distribution.get(action, 0) + 1
            
            # ë ˆì§ë³„ ë¶„í¬
            regime_distribution = {}
            for row in rows:
                regime = row['regime_detected']
                regime_distribution[regime] = regime_distribution.get(regime, 0) + 1
            
            summary = {
                'period_days': days,
                'total_runs': total_runs,
                'successful_runs': successful_runs,
                'failed_runs': failed_runs,
                'success_rate': successful_runs / total_runs if total_runs > 0 else 0,
                'avg_execution_time': avg_execution_time,
                'avg_signal_score': avg_signal_score,
                'action_distribution': action_distribution,
                'regime_distribution': regime_distribution,
                'created_at': datetime.now().isoformat()
            }
            
            return summary
            
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

def save_realtime_feedback(
    coin: str,
    interval: str,
    signal_id: str,
    signal_score: float,
    signal_action: str,
    signal_timestamp: datetime,
    actual_profit: float = 0.0,
    actual_success: bool = False,
    market_condition: str = 'unknown',
    learning_adjustment: float = 0.0,
    strategy_update: Dict[str, Any] = None,
    db_path: str = None
) -> bool:
    """ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°± ì €ì¥ - ì‹¤ì œ ë§¤ë§¤ ê²°ê³¼ë¥¼ í•™ìŠµ ë£¨í”„ë¡œ í”¼ë“œë°±
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ
        signal_id: ì‹œê·¸ë„ ê³ ìœ  ID
        signal_score: ì‹œê·¸ë„ ì ìˆ˜
        signal_action: ì‹œê·¸ë„ ì•¡ì…˜ (buy/sell/hold)
        signal_timestamp: ì‹œê·¸ë„ ë°œìƒ ì‹œê°
        actual_profit: ì‹¤ì œ ìˆ˜ìµë¥ 
        actual_success: ì„±ê³µ ì—¬ë¶€
        market_condition: ì‹œì¥ ìƒíƒœ
        learning_adjustment: í•™ìŠµ ì¡°ì •ê°’
        strategy_update: ì „ëµ ì—…ë°ì´íŠ¸ ì •ë³´ (JSON)
        db_path: DB ê²½ë¡œ
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        import json
        
        if db_path is None:
            db_path = LEARNING_RESULTS_DB_PATH
        
        if strategy_update is None:
            strategy_update = {}
        
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO realtime_learning_feedback
                (market_type, market, symbol, interval, signal_id, signal_score, signal_action, signal_timestamp,
                 actual_profit, actual_success, market_condition, learning_adjustment,
                 strategy_update, created_at)
                VALUES ('COIN', 'BITHUMB', ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                coin,
                interval,
                signal_id,
                signal_score,
                signal_action,
                signal_timestamp.isoformat() if isinstance(signal_timestamp, datetime) else signal_timestamp,
                actual_profit,
                1 if actual_success else 0,  # SQLiteëŠ” BOOLEANì„ INTEGERë¡œ ì €ì¥
                market_condition,
                learning_adjustment,
                json.dumps(strategy_update),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            logger.info(f"âœ… ì‹¤ì‹œê°„ í”¼ë“œë°± ì €ì¥ ì™„ë£Œ: {coin}-{interval} (signal_id={signal_id}, profit={actual_profit:.2f}%)")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        return False

def get_realtime_feedback_summary(
    coin: str = None,
    interval: str = None,
    days: int = 7,
    db_path: str = None
) -> Dict[str, Any]:
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ìš”ì•½ í†µê³„ ì¡°íšŒ
    
    Args:
        coin: ì½”ì¸ ì‹¬ë³¼ (Noneì´ë©´ ì „ì²´)
        interval: ì¸í„°ë²Œ (Noneì´ë©´ ì „ì²´)
        days: ì¡°íšŒ ê¸°ê°„ (ì¼)
        db_path: DB ê²½ë¡œ
    
    Returns:
        í”¼ë“œë°± ìš”ì•½ í†µê³„
    """
    try:
        with get_learning_db_connection(db_path) as conn:
            cursor = conn.cursor()
            
            # WHERE ì¡°ê±´ ë™ì  êµ¬ì„±
            conditions = ["signal_timestamp >= datetime('now', '-{} days')".format(days)]
            params = []
            
            if coin:
                conditions.append("symbol = ?")
                params.append(coin)
            
            if interval:
                conditions.append("interval = ?")
                params.append(interval)
            
            where_clause = " AND ".join(conditions)
            
            # í†µê³„ ê³„ì‚°
            cursor.execute(f"""
                SELECT 
                    COUNT(*) as total_feedbacks,
                    SUM(CASE WHEN actual_success = 1 THEN 1 ELSE 0 END) as successful_signals,
                    AVG(actual_profit) as avg_profit,
                    AVG(signal_score) as avg_signal_score,
                    COUNT(DISTINCT symbol) as distinct_coins,
                    COUNT(DISTINCT interval) as distinct_intervals
                FROM realtime_learning_feedback
                WHERE {where_clause}
            """, params)
            
            row = cursor.fetchone()
            
            if not row or row[0] == 0:
                return {
                    'total_feedbacks': 0,
                    'success_rate': 0.0,
                    'avg_profit': 0.0,
                    'avg_signal_score': 0.0
                }
            
            total = row[0]
            successful = row[1] or 0
            avg_profit = row[2] or 0.0
            avg_signal_score = row[3] or 0.0
            
            return {
                'total_feedbacks': total,
                'successful_signals': successful,
                'success_rate': successful / total if total > 0 else 0.0,
                'avg_profit': avg_profit,
                'avg_signal_score': avg_signal_score,
                'distinct_coins': row[4] or 0,
                'distinct_intervals': row[5] or 0,
                'period_days': days
            }
            
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}

# í¸ì˜ í•¨ìˆ˜ë“¤
