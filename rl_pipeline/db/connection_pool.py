"""
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ê´€ë¦¬
ê³ ì„±ëŠ¥ SQLite ì—°ê²° í’€ë§ ë° ì„±ëŠ¥ ìµœì í™”
"""

import sqlite3
import threading
import logging
import os
from queue import Queue, Empty
from contextlib import contextmanager
from typing import Optional, Dict, Any
from rl_pipeline.core.env import config
from rl_pipeline.core.errors import DBWriteError, DBReadError

logger = logging.getLogger(__name__)

class DatabaseConnectionPool:
    """ê³ ì„±ëŠ¥ SQLite ì—°ê²° í’€"""
    
    def __init__(self, db_path: str, max_connections: int = None, connection_timeout: float = None):
        self.db_path = db_path
        # ë½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì—°ê²° ìˆ˜ë¥¼ ì¤„ì„
        self.max_connections = max_connections or min(config.DB_MAX_CONNECTIONS, 10)
        self.connection_timeout = connection_timeout or config.DB_CONNECTION_TIMEOUT
        self.connections: Queue = Queue(maxsize=self.max_connections)
        self.active_connections = 0
        self.lock = threading.Lock()
        
        # ì´ˆê¸° ì—°ê²° ìƒì„±
        self._initialize_pool()
    
    def _initialize_pool(self):
        """ì—°ê²° í’€ ì´ˆê¸°í™” - ìµœì í™”ëœ ì—°ê²° ìˆ˜"""
        logger.info(f"ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™” ì¤‘... ({self.db_path})")
        
        # ë™ì  ì—°ê²° í’€ í¬ê¸°: ìµœì†Œ 5ê°œ, ìµœëŒ€ì˜ ì ˆë°˜, ìµœëŒ€ê°’ ì´í•˜
        initial_connections = min(
            max(5, self.max_connections // 2),
            self.max_connections
        )
        
        for _ in range(initial_connections):
            try:
                conn = self._create_optimized_connection()
                self.connections.put(conn)
                logger.debug(f"âœ… ì—°ê²° í’€ì— ì—°ê²° ì¶”ê°€ë¨ (ì´ {self.connections.qsize()}ê°œ)")
            except Exception as e:
                logger.warning(f"âš ï¸ ì´ˆê¸° ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_optimized_connection(self) -> sqlite3.Connection:
        """ìµœì í™”ëœ ì—°ê²° ìƒì„± - ë½ ë¬¸ì œ í•´ê²°"""
        try:
            # DB íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
            import os
            if not os.path.exists(self.db_path):
                logger.info(f"ğŸ”§ DB íŒŒì¼ì´ ì—†ì–´ ìƒì„± ì¤‘: {self.db_path}")
                # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
                db_dir = os.path.dirname(self.db_path)
                if not os.path.exists(db_dir):
                    os.makedirs(db_dir, exist_ok=True)
                    logger.info(f"âœ… DB ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {db_dir}")
            
            # ìº”ë“¤ DBëŠ” ì½ê¸° ì „ìš© ëª¨ë“œë¡œ ì—´ê¸°
            is_candles_db = 'candles' in self.db_path.lower()
            
            conn = sqlite3.connect(
                self.db_path,
                timeout=self.connection_timeout,
                check_same_thread=False
            )
            
            if is_candles_db:
                # ì½ê¸° ì „ìš© ìµœì í™” ì„¤ì • (WAL ëª¨ë“œ ì œì™¸)
                conn.execute("PRAGMA journal_mode=DELETE")  # WAL ëª¨ë“œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                conn.execute("PRAGMA synchronous=OFF")  # ì½ê¸°ë§Œ í•˜ë¯€ë¡œ ë™ê¸°í™” ë¶ˆí•„ìš”
                logger.debug(f"ğŸ“– ìº”ë“¤ DB ì½ê¸° ì „ìš© ëª¨ë“œë¡œ ì—´ë¦¼: {self.db_path}")
            else:
                # ë½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìµœì í™” ì„¤ì • (WAL ëª¨ë“œ)
                conn.execute("PRAGMA journal_mode=WAL")
                conn.execute("PRAGMA synchronous=NORMAL")
            
            # ê³µí†µ ìµœì í™” ì„¤ì •
            conn.execute("PRAGMA cache_size=10000")
            conn.execute("PRAGMA temp_store=MEMORY")
            conn.execute("PRAGMA mmap_size=268435456")  # 256MB
            conn.execute("PRAGMA busy_timeout=10000")  # 10ì´ˆ ëŒ€ê¸° (ìµœì í™”: 60ì´ˆ â†’ 10ì´ˆ)
            conn.execute("PRAGMA optimize")
            if not is_candles_db:
                conn.execute("PRAGMA wal_autocheckpoint=1000")  # WAL ì²´í¬í¬ì¸íŠ¸ ìë™í™” (ìº”ë“¤ DB ì œì™¸)
            
            return conn
            
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {self.db_path} - {e}")
            raise
    
    @contextmanager
    def get_connection(self):
        """ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        conn = None
        try:
            conn = self._get_connection()
            yield conn
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            raise
        finally:
            if conn:
                self._return_connection(conn)
    
    def _get_connection(self) -> sqlite3.Connection:
        """ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        with self.lock:
            # ê¸°ì¡´ ì—°ê²°ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            try:
                conn = self.connections.get_nowait()
                logger.debug(f"â™»ï¸ ê¸°ì¡´ ì—°ê²° ì¬ì‚¬ìš© (ë‚¨ì€ ì—°ê²°: {self.connections.qsize()})")
                return conn
            except Empty:
                pass
            
            # ìƒˆ ì—°ê²° ìƒì„±
            if self.active_connections < self.max_connections:
                try:
                    conn = self._create_optimized_connection()
                    self.active_connections += 1
                    logger.debug(f"ğŸ†• ìƒˆ ì—°ê²° ìƒì„±ë¨ (í™œì„± ì—°ê²°: {self.active_connections})")
                    return conn
                except Exception as e:
                    logger.error(f"âŒ ìƒˆ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
                    raise DBReadError(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}") from e
            
            # ì—°ê²° í’€ì´ ê°€ë“ ì°¬ ê²½ìš° ëŒ€ê¸°
            logger.warning(f"âš ï¸ ì—°ê²° í’€ ê°€ë“ ì°¸, ëŒ€ê¸° ì¤‘... (í™œì„±: {self.active_connections})")
            try:
                conn = self.connections.get(timeout=30.0)  # 30ì´ˆ ëŒ€ê¸°
                logger.debug(f"â³ ëŒ€ê¸° í›„ ì—°ê²° íšë“ (ë‚¨ì€ ì—°ê²°: {self.connections.qsize()})")
                return conn
            except Empty:
                raise DBReadError("ì—°ê²° í’€ì—ì„œ ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
    
    def _return_connection(self, conn: sqlite3.Connection):
        """ì—°ê²°ì„ í’€ë¡œ ë°˜í™˜"""
        try:
            # ì—°ê²° ìƒíƒœ í™•ì¸
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            
            # ì •ìƒì´ë©´ í’€ë¡œ ë°˜í™˜
            if not self.connections.full():
                self.connections.put(conn)
                logger.debug(f"âœ… ì—°ê²° ë°˜í™˜ë¨ (í’€ í¬ê¸°: {self.connections.qsize()})")
            else:
                # í’€ì´ ê°€ë“ ì°¬ ê²½ìš° ì—°ê²° ì¢…ë£Œ
                conn.close()
                with self.lock:
                    self.active_connections -= 1
                logger.debug(f"ğŸ”’ ì—°ê²° í’€ ê°€ë“ ì°¸, ì—°ê²° ì¢…ë£Œ (í™œì„± ì—°ê²°: {self.active_connections})")
                
        except Exception as e:
            # ì—°ê²°ì— ë¬¸ì œê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
            logger.warning(f"âš ï¸ ë¬¸ì œê°€ ìˆëŠ” ì—°ê²° ê°ì§€, ì¢…ë£Œ: {e}")
            try:
                conn.close()
            except:
                pass
            with self.lock:
                self.active_connections -= 1
    
    def close_all_connections(self, verbose: bool = False):
        """ëª¨ë“  ì—°ê²° ê°•ì œ ì¢…ë£Œ
        
        Args:
            verbose: Trueë©´ ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ê¸°ë³¸ê°’: False, ìƒìœ„ í•¨ìˆ˜ì—ì„œë§Œ ë¡œê·¸ ì¶œë ¥)
        """
        if verbose:
            logger.info("ğŸ”§ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°•ì œ ì¢…ë£Œ ì¤‘...")
        
        with self.lock:
            # íì— ìˆëŠ” ëª¨ë“  ì—°ê²° ì¢…ë£Œ
            closed_count = 0
            while not self.connections.empty():
                try:
                    conn = self.connections.get_nowait()
                    conn.close()
                    closed_count += 1
                    if verbose:
                        logger.debug("âœ… ì—°ê²° ì¢…ë£Œë¨")
                except Empty:
                    break
                except Exception as e:
                    if verbose:
                        logger.warning(f"âš ï¸ ì—°ê²° ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            self.active_connections = 0
            if verbose:
                logger.info(f"âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ (ì¢…ë£Œëœ ì—°ê²°: {closed_count}ê°œ)")
    
    def cleanup_wal_files(self):
        """WAL íŒŒì¼ ì •ë¦¬"""
        try:
            import os
            logger.debug(f"ğŸ§¹ WAL íŒŒì¼ ì •ë¦¬ ì‹œì‘: {self.db_path}")
            
            # ìº”ë“¤ DBëŠ” ì›ì²œ ë°ì´í„° - WAL íŒŒì¼ ì •ë¦¬í•˜ì§€ ì•ŠìŒ
            if 'candles' in self.db_path.lower():
                logger.debug("âš ï¸ ìº”ë“¤ DBëŠ” ì›ì²œ ë°ì´í„°ë¡œ WAL íŒŒì¼ ì •ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                return
            
            # WAL íŒŒì¼ ê²½ë¡œ
            wal_path = f"{self.db_path}-wal"
            shm_path = f"{self.db_path}-shm"
            
            # WAL ëª¨ë“œ ì²´í¬
            try:
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute("PRAGMA journal_mode")
                    journal_mode = cursor.fetchone()[0]
                    
                    if journal_mode.lower() == 'wal':
                        # WAL ì²´í¬í¬ì¸íŠ¸ ìˆ˜í–‰
                        cursor.execute("PRAGMA wal_checkpoint(TRUNCATE)")
                        conn.commit()
                        logger.debug(f"âœ… WAL ì²´í¬í¬ì¸íŠ¸ ì™„ë£Œ: {self.db_path}")
            except Exception as e:
                logger.debug(f"âš ï¸ WAL ì²´í¬í¬ì¸íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
            
            # WAL íŒŒì¼ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
            if os.path.exists(wal_path) and os.path.getsize(wal_path) == 0:
                try:
                    os.remove(wal_path)
                    logger.debug(f"âœ… ë¹ˆ WAL íŒŒì¼ ì‚­ì œ: {wal_path}")
                except Exception as e:
                    logger.debug(f"âš ï¸ WAL íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
                    
            if os.path.exists(shm_path) and os.path.getsize(shm_path) == 0:
                try:
                    os.remove(shm_path)
                    logger.debug(f"âœ… ë¹ˆ SHM íŒŒì¼ ì‚­ì œ: {shm_path}")
                except Exception as e:
                    logger.debug(f"âš ï¸ SHM íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            logger.debug(f"âš ï¸ WAL íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

class BatchLoadingConnectionPool:
    """ë°°ì¹˜ ë¡œë”© ì „ìš© ê³ ì„±ëŠ¥ ì—°ê²° í’€"""
    
    def __init__(self, db_path: str, max_connections: int = None):
        self.db_path = db_path
        # ë½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë°°ì¹˜ ì—°ê²° ìˆ˜ë„ ì¤„ì„
        self.max_connections = max_connections or min(config.DB_BATCH_MAX_CONNECTIONS, 20)
        self.connections: Queue = Queue(maxsize=self.max_connections)
        self.active_connections = 0
        self.lock = threading.Lock()
        
        # ë°°ì¹˜ ë¡œë”©ìš© ìµœì í™” ì„¤ì •
        self._initialize_batch_pool()
    
    def _initialize_batch_pool(self):
        """ë°°ì¹˜ ë¡œë”©ìš© ì—°ê²° í’€ ì´ˆê¸°í™” - ë½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì—°ê²° ìˆ˜ ê°ì†Œ"""
        logger.info(f"ğŸš€ ë°°ì¹˜ ë¡œë”©ìš© ì—°ê²° í’€ ì´ˆê¸°í™” ì¤‘... ({self.db_path})")
        
        # ë½ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì´ˆê¸° ì—°ê²° ìˆ˜ë¥¼ ì¤„ì„
        initial_connections = min(5, self.max_connections)
        for _ in range(initial_connections):
            try:
                conn = self._create_batch_optimized_connection()
                self.connections.put(conn)
                logger.debug(f"âœ… ë°°ì¹˜ ì—°ê²° í’€ì— ì—°ê²° ì¶”ê°€ë¨ (ì´ {self.connections.qsize()}ê°œ)")
            except Exception as e:
                logger.warning(f"âš ï¸ ë°°ì¹˜ ì´ˆê¸° ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_batch_optimized_connection(self) -> sqlite3.Connection:
        """ë°°ì¹˜ ë¡œë”©ìš© ìµœì í™”ëœ ì—°ê²° ìƒì„± - ë½ ë¬¸ì œ í•´ê²°"""
        try:
            # DB íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
            import os
            if not os.path.exists(self.db_path):
                logger.info(f"ğŸ”§ ë°°ì¹˜ DB íŒŒì¼ì´ ì—†ì–´ ìƒì„± ì¤‘: {self.db_path}")
                # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
                db_dir = os.path.dirname(self.db_path)
                if db_dir and not os.path.exists(db_dir):
                    try:
                        os.makedirs(db_dir, exist_ok=True)
                        logger.info(f"âœ… ë°°ì¹˜ DB ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {db_dir}")
                    except Exception as dir_err:
                        logger.warning(f"âš ï¸ ë°°ì¹˜ DB ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {db_dir} - {dir_err}")
                        # í´ë°±: RL_PIPELINE_ROOT í•˜ìœ„ì— ìƒì„± ì‹œë„
                        try:
                            from rl_pipeline.core.env import config as _cfg
                            fallback_dir = _cfg.RL_PIPELINE_ROOT
                            fallback_path = os.path.join(fallback_dir, os.path.basename(self.db_path))
                            logger.info(f"ğŸ”„ í´ë°± ê²½ë¡œë¡œ ì‹œë„: {fallback_path}")
                            self.db_path = fallback_path
                            db_dir = os.path.dirname(fallback_path)
                            if db_dir and not os.path.exists(db_dir):
                                os.makedirs(db_dir, exist_ok=True)
                        except Exception as fallback_err:
                            logger.debug(f"âš ï¸ í´ë°± ê²½ë¡œë„ ì‹¤íŒ¨: {fallback_err}")
            
            conn = sqlite3.connect(
                self.db_path,
                timeout=config.DB_CONNECTION_TIMEOUT,
                check_same_thread=False
            )
            
            # ë°°ì¹˜ ë¡œë”©ìš© ì„±ëŠ¥ ìµœì í™” ì„¤ì • + ë½ ë¬¸ì œ í•´ê²°
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=NORMAL")  # ì•ˆì •ì„±ì„ ìœ„í•´ NORMALë¡œ ë³€ê²½
            conn.execute("PRAGMA cache_size=50000")  # ë” í° ìºì‹œ
            conn.execute("PRAGMA temp_store=MEMORY")
            conn.execute("PRAGMA mmap_size=536870912")  # 512MB
            conn.execute("PRAGMA busy_timeout=60000")  # 60ì´ˆ ëŒ€ê¸° (ê°œì„ : 30ì´ˆ â†’ 60ì´ˆ)
            conn.execute("PRAGMA wal_autocheckpoint=1000")  # WAL ì²´í¬í¬ì¸íŠ¸ ìë™í™”
            conn.execute("PRAGMA optimize")
            
            return conn
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {self.db_path} - {e}")
            raise
    
    @contextmanager
    def get_batch_connection(self):
        """ë°°ì¹˜ ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        conn = None
        try:
            conn = self._get_connection()
            yield conn
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì—°ê²° ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            raise
        finally:
            if conn:
                self._return_connection(conn)
    
    @contextmanager
    def get_connection(self):
        """ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € (get_batch_connectionì˜ ë³„ì¹­)"""
        # get_batch_connection ì¬ì‚¬ìš©
        with self.get_batch_connection() as conn:
            yield conn
    
    def _get_connection(self) -> sqlite3.Connection:
        """ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        with self.lock:
            try:
                conn = self.connections.get_nowait()
                logger.debug(f"â™»ï¸ ë°°ì¹˜ ì—°ê²° ì¬ì‚¬ìš© (ë‚¨ì€ ì—°ê²°: {self.connections.qsize()})")
                return conn
            except Empty:
                pass
            
            if self.active_connections < self.max_connections:
                try:
                    conn = self._create_batch_optimized_connection()
                    self.active_connections += 1
                    logger.debug(f"ğŸ†• ìƒˆ ë°°ì¹˜ ì—°ê²° ìƒì„±ë¨ (í™œì„± ì—°ê²°: {self.active_connections})")
                    return conn
                except Exception as e:
                    logger.error(f"âŒ ìƒˆ ë°°ì¹˜ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
                    raise DBReadError(f"ë°°ì¹˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}") from e
            
            try:
                conn = self.connections.get(timeout=30.0)
                logger.debug(f"â³ ë°°ì¹˜ ì—°ê²° ëŒ€ê¸° í›„ íšë“ (ë‚¨ì€ ì—°ê²°: {self.connections.qsize()})")
                return conn
            except Empty:
                raise DBReadError("ë°°ì¹˜ ì—°ê²° í’€ì—ì„œ ì—°ê²°ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
    
    def _return_connection(self, conn: sqlite3.Connection):
        """ì—°ê²°ì„ í’€ë¡œ ë°˜í™˜"""
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            
            if not self.connections.full():
                self.connections.put(conn)
                logger.debug(f"âœ… ë°°ì¹˜ ì—°ê²° ë°˜í™˜ë¨ (í’€ í¬ê¸°: {self.connections.qsize()})")
            else:
                conn.close()
                with self.lock:
                    self.active_connections -= 1
                logger.debug(f"ğŸ”’ ë°°ì¹˜ ì—°ê²° í’€ ê°€ë“ ì°¸, ì—°ê²° ì¢…ë£Œ (í™œì„± ì—°ê²°: {self.active_connections})")
                
        except Exception as e:
            logger.warning(f"âš ï¸ ë¬¸ì œê°€ ìˆëŠ” ë°°ì¹˜ ì—°ê²° ê°ì§€, ì¢…ë£Œ: {e}")
            try:
                conn.close()
            except:
                pass
            with self.lock:
                self.active_connections -= 1
    
    def close_all_connections(self, verbose: bool = False):
        """ëª¨ë“  ì—°ê²° ê°•ì œ ì¢…ë£Œ
        
        Args:
            verbose: Trueë©´ ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ê¸°ë³¸ê°’: False, ìƒìœ„ í•¨ìˆ˜ì—ì„œë§Œ ë¡œê·¸ ì¶œë ¥)
        """
        if verbose:
            logger.info("ğŸ”§ ëª¨ë“  ë°°ì¹˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°•ì œ ì¢…ë£Œ ì¤‘...")
        
        with self.lock:
            # íì— ìˆëŠ” ëª¨ë“  ì—°ê²° ì¢…ë£Œ
            closed_count = 0
            while not self.connections.empty():
                try:
                    conn = self.connections.get_nowait()
                    conn.close()
                    closed_count += 1
                    if verbose:
                        logger.debug("âœ… ë°°ì¹˜ ì—°ê²° ì¢…ë£Œë¨")
                except Empty:
                    break
                except Exception as e:
                    if verbose:
                        logger.warning(f"âš ï¸ ë°°ì¹˜ ì—°ê²° ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            self.active_connections = 0
            if verbose:
                logger.info(f"âœ… ëª¨ë“  ë°°ì¹˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ (ì¢…ë£Œëœ ì—°ê²°: {closed_count}ê°œ)")
    
    def cleanup_wal_files(self):
        """WAL íŒŒì¼ ì •ë¦¬"""
        try:
            import os
            logger.debug(f"ğŸ§¹ ë°°ì¹˜ WAL íŒŒì¼ ì •ë¦¬ ì‹œì‘: {self.db_path}")
            
            # ìº”ë“¤ DBëŠ” ì›ì²œ ë°ì´í„° - WAL íŒŒì¼ ì •ë¦¬í•˜ì§€ ì•ŠìŒ
            if 'candles' in self.db_path.lower():
                logger.debug("âš ï¸ ìº”ë“¤ DBëŠ” ì›ì²œ ë°ì´í„°ë¡œ WAL íŒŒì¼ ì •ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                return
            
            # WAL íŒŒì¼ ê²½ë¡œ
            wal_path = f"{self.db_path}-wal"
            shm_path = f"{self.db_path}-shm"
            
            # WAL ëª¨ë“œ ì²´í¬ ë° ì²´í¬í¬ì¸íŠ¸
            try:
                with self.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute("PRAGMA journal_mode")
                    journal_mode = cursor.fetchone()[0]
                    
                    if journal_mode.lower() == 'wal':
                        # WAL ì²´í¬í¬ì¸íŠ¸ ìˆ˜í–‰
                        cursor.execute("PRAGMA wal_checkpoint(TRUNCATE)")
                        conn.commit()
                        logger.debug(f"âœ… ë°°ì¹˜ WAL ì²´í¬í¬ì¸íŠ¸ ì™„ë£Œ: {self.db_path}")
            except Exception as e:
                logger.debug(f"âš ï¸ ë°°ì¹˜ WAL ì²´í¬í¬ì¸íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
            
            # WAL íŒŒì¼ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
            if os.path.exists(wal_path) and os.path.getsize(wal_path) == 0:
                try:
                    os.remove(wal_path)
                    logger.debug(f"âœ… ë¹ˆ WAL íŒŒì¼ ì‚­ì œ: {wal_path}")
                except Exception as e:
                    logger.debug(f"âš ï¸ WAL íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
                    
            if os.path.exists(shm_path) and os.path.getsize(shm_path) == 0:
                try:
                    os.remove(shm_path)
                    logger.debug(f"âœ… ë¹ˆ SHM íŒŒì¼ ì‚­ì œ: {shm_path}")
                except Exception as e:
                    logger.debug(f"âš ï¸ SHM íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            logger.debug(f"âš ï¸ ë°°ì¹˜ WAL íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

# ì „ì—­ ì—°ê²° í’€ ì¸ìŠ¤í„´ìŠ¤ë“¤
_candle_pool: Optional[DatabaseConnectionPool] = None
_strategy_pool: Optional[DatabaseConnectionPool] = None
_learning_results_pool: Optional[DatabaseConnectionPool] = None
_batch_pool: Optional[BatchLoadingConnectionPool] = None

def get_candle_db_pool() -> DatabaseConnectionPool:
    """ìº”ë“¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ë°˜í™˜"""
    global _candle_pool
    if _candle_pool is None:
        _candle_pool = DatabaseConnectionPool(config.RL_DB)
    return _candle_pool

def get_strategy_db_pool() -> DatabaseConnectionPool:
    """ì „ëµ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ë°˜í™˜"""
    global _strategy_pool
    if _strategy_pool is None:
        # ì „ëµ DB íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„± (SQLiteê°€ ìƒì„±í•˜ë„ë¡ ìœ„ì„) + ì‹¤íŒ¨ ì‹œ í´ë°± ê²½ë¡œ ì‚¬ìš©
        import os, sqlite3
        primary_path = config.STRATEGIES_DB
        candidate_paths = [primary_path]
        # í´ë°± ê²½ë¡œ: RL_PIPELINE_ROOT í•˜ìœ„ (ì¼ë°˜ì ìœ¼ë¡œ ì“°ê¸° ê°€ëŠ¥)
        try:
            from rl_pipeline.core.env import config as _cfg
            fallback_path = os.path.join(_cfg.RL_PIPELINE_ROOT, 'rl_strategies.db')
            if fallback_path not in candidate_paths:
                candidate_paths.append(fallback_path)
        except Exception:
            candidate_paths.append('/workspace/rl_pipeline/rl_strategies.db')

        last_error = None
        chosen_path = None
        for db_path in candidate_paths:
            try:
                db_dir = os.path.dirname(db_path)
                if db_dir and not os.path.exists(db_dir):
                    os.makedirs(db_dir, exist_ok=True)
                    logger.info(f"âœ… ì „ëµ DB ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {db_dir}")
                logger.info(f"ğŸ”§ ì „ëµ DB ì¤€ë¹„: {db_path}")
                conn = sqlite3.connect(db_path)
                conn.execute("PRAGMA journal_mode=WAL")
                conn.close()
                chosen_path = db_path
                break
            except Exception as e:
                last_error = e
                # ğŸ”§ í´ë°± ê²½ë¡œ ì‹œë„ ì¤‘ì´ë¯€ë¡œ ê²½ê³ ë¡œ ì²˜ë¦¬ (ì¹˜ëª…ì  ì—ëŸ¬ ì•„ë‹˜)
                logger.debug(f"âš ï¸ ì „ëµ DB ì¤€ë¹„ ì‹œë„ (í´ë°± ê²½ë¡œë¡œ ê³„ì† ì‹œë„): {db_path} - {e}")
                continue

        if not chosen_path:
            raise DBReadError(f"ì „ëµ DBë¥¼ ì¤€ë¹„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {last_error}")

        _strategy_pool = DatabaseConnectionPool(chosen_path)
    return _strategy_pool

def get_learning_results_db_pool() -> DatabaseConnectionPool:
    """í•™ìŠµ ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ë°˜í™˜"""
    global _learning_results_pool
    if _learning_results_pool is None:
        # í•™ìŠµ ê²°ê³¼ DB íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
        import os, sqlite3
        primary_path = config.LEARNING_RESULTS_DB_PATH

        try:
            db_dir = os.path.dirname(primary_path)
            if db_dir and not os.path.exists(db_dir):
                os.makedirs(db_dir, exist_ok=True)
                logger.info(f"âœ… í•™ìŠµ ê²°ê³¼ DB ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {db_dir}")

            logger.info(f"ğŸ”§ í•™ìŠµ ê²°ê³¼ DB ì¤€ë¹„: {primary_path}")
            conn = sqlite3.connect(primary_path)
            conn.execute("PRAGMA journal_mode=WAL")
            conn.close()

            _learning_results_pool = DatabaseConnectionPool(primary_path)
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ê²°ê³¼ DB ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise DBReadError(f"í•™ìŠµ ê²°ê³¼ DBë¥¼ ì¤€ë¹„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    return _learning_results_pool

def get_batch_loading_pool(db_path: str = None) -> BatchLoadingConnectionPool:
    """ë°°ì¹˜ ë¡œë”© ì—°ê²° í’€ ë°˜í™˜"""
    global _batch_pool
    if _batch_pool is None:
        db_path = db_path or config.RL_DB
        
        # ğŸ”§ DB ê²½ë¡œ í´ë°± ì²˜ë¦¬ (ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ì‹œ)
        try:
            import os
            db_dir = os.path.dirname(db_path)
            if db_dir and not os.path.exists(db_dir):
                try:
                    os.makedirs(db_dir, exist_ok=True)
                except Exception as dir_err:
                    logger.debug(f"âš ï¸ ë°°ì¹˜ DB ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨, í´ë°± ê²½ë¡œ ì‚¬ìš©: {db_dir} - {dir_err}")
                    # í´ë°±: RL_PIPELINE_ROOT í•˜ìœ„ì— ìƒì„±
                    try:
                        from rl_pipeline.core.env import config as _cfg
                        fallback_path = os.path.join(_cfg.RL_PIPELINE_ROOT, os.path.basename(db_path))
                        logger.info(f"ğŸ”„ ë°°ì¹˜ DB í´ë°± ê²½ë¡œ: {fallback_path}")
                        db_path = fallback_path
                    except Exception:
                        logger.warning(f"âš ï¸ í´ë°± ê²½ë¡œë„ ì‹¤íŒ¨, ì›ë˜ ê²½ë¡œ ì‚¬ìš©")
        except Exception as e:
            # ì „ì²´ í´ë°± ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì›ë˜ ê²½ë¡œ ì‚¬ìš©
            logger.debug(f"âš ï¸ ë°°ì¹˜ DB ê²½ë¡œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì›ë˜ ê²½ë¡œ ì‚¬ìš©): {e}")
        
        _batch_pool = BatchLoadingConnectionPool(db_path)
    return _batch_pool

def close_all_pools():
    """ëª¨ë“  ì—°ê²° í’€ ì¢…ë£Œ"""
    global _candle_pool, _strategy_pool, _learning_results_pool, _batch_pool

    if _candle_pool:
        _candle_pool.close_all_connections()
        _candle_pool = None

    if _strategy_pool:
        _strategy_pool.close_all_connections()
        _strategy_pool = None

    if _learning_results_pool:
        _learning_results_pool.close_all_connections()
        _learning_results_pool = None

    if _batch_pool:
        _batch_pool.close_all_connections()
        _batch_pool = None

def close_all_connections():
    """
    ëª¨ë“  í™œì„± ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
    ì¸í„°ë²Œ ì²˜ë¦¬ ì‚¬ì´ ë˜ëŠ” ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©.
    
    ì´ í•¨ìˆ˜ëŠ” ëª¨ë“  ì—°ê²° í’€ì˜ ì—°ê²°ì„ ì¢…ë£Œí•˜ì—¬ ì ê¸ˆì„ í•´ì œí•©ë‹ˆë‹¤.
    """
    try:
        logger.info("ğŸ”§ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ ì¤‘...")

        # ëª¨ë“  ì—°ê²° í’€ì˜ ì—°ê²° ì¢…ë£Œ
        if _strategy_pool:
            _strategy_pool.close_all_connections()
        if _learning_results_pool:
            _learning_results_pool.close_all_connections()
        if _candle_pool:
            _candle_pool.close_all_connections()
        if _batch_pool:
            _batch_pool.close_all_connections()

        logger.info("âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ ì™„ë£Œ")
        return True
    except Exception as e:
        logger.warning(f"âš ï¸ ì—°ê²° ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
        return False
    
def validate_simulation_results(results: Dict[str, Any], criteria: Dict[str, Any] = None) -> Dict[str, Any]:
    """ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦"""
    try:
        if not results:
            return {'overall_status': 'FAIL', 'issues_found': ['No results provided']}
        
        issues = []
        
        # ê¸°ë³¸ ê²€ì¦
        if not isinstance(results, dict):
            issues.append('Results must be a dictionary')
        
        # ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if not results.get('success', False):
            issues.append('Simulation did not complete successfully')
        
        # ê²°ê³¼ ë°˜í™˜
        if issues:
            return {'overall_status': 'FAIL', 'issues_found': issues}
        else:
            return {'overall_status': 'PASS', 'issues_found': []}
        
    except Exception as e:
        return {'overall_status': 'FAIL', 'issues_found': [f'Validation error: {e}']}

def validate_dna_results(results: Dict[str, Any], criteria: Dict[str, Any] = None) -> bool:
    """DNA ê²°ê³¼ ê²€ì¦"""
    try:
        if not results:
            return False
        
        required_fields = ['patterns', 'confidence']
        if not all(field in results for field in required_fields):
            return False
        
        # ì¶”ê°€ ê¸°ì¤€ ê²€ì¦
        if criteria:
            if 'min_confidence' in criteria and results.get('confidence', 0) < criteria['min_confidence']:
                return False
        
        return True
    except Exception:
        return False

def validate_fractal_results(results: Dict[str, Any], criteria: Dict[str, Any] = None) -> bool:
    """í”„ë™íƒˆ ê²°ê³¼ ê²€ì¦"""
    try:
        if not results:
            return False
        
        required_fields = ['fractal_score', 'patterns']
        if not all(field in results for field in required_fields):
            return False
        
        # ì¶”ê°€ ê¸°ì¤€ ê²€ì¦
        if criteria:
            if 'min_fractal_score' in criteria and results.get('fractal_score', 0) < criteria['min_fractal_score']:
                return False
        
        return True
    except Exception:
        return False

def validate_pipeline_results(results: Dict[str, Any], criteria: Dict[str, Any] = None) -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ê²€ì¦ - ê°œì„ ëœ ë¡œì§"""
    try:
        if not results:
            return {'overall_status': 'FAIL', 'issues_found': ['No results provided']}
        
        issues = []
        
        # ê¸°ë³¸ ê²€ì¦
        if not isinstance(results, dict):
            issues.append('Results must be a dictionary')
            return {'overall_status': 'FAIL', 'issues_found': issues}
        
        # ë‹¤ì–‘í•œ ì„±ê³µ ì¡°ê±´ í™•ì¸ (ë” ìœ ì—°í•œ ê²€ì¦)
        success_indicators = [
            results.get('success', False),
            results.get('success_count', 0) >= 3,  # ìµœì†Œ 3ë‹¨ê³„ ì„±ê³µ
            results.get('total_steps', 0) > 0,     # ìµœì†Œ 1ë‹¨ê³„ ì‹¤í–‰
            'coin' in results,                     # ì½”ì¸ ì •ë³´ ì¡´ì¬
            results.get('data_quality_score', 0) > 0.5  # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
        ]
        
        # í•˜ë‚˜ë¼ë„ ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ í†µê³¼
        if any(success_indicators):
            return {'overall_status': 'PASS', 'issues_found': [], 'data_quality_score': results.get('data_quality_score', 0.8)}
        
        # ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•œ ê²½ìš°
        issues.append('Pipeline did not meet success criteria')
        return {'overall_status': 'FAIL', 'issues_found': issues}
        
    except Exception as e:
        return {'overall_status': 'FAIL', 'issues_found': [f'Validation error: {e}']}

def validate_dna_analysis_results(results: Dict[str, Any]) -> Dict[str, Any]:
    """DNA ë¶„ì„ ê²°ê³¼ ê²€ì¦ - ê°œì„ ëœ ë¡œì§"""
    try:
        if not results:
            return {'overall_status': 'FAIL', 'issues_found': ['No results provided']}
        
        issues = []
        
        # ê¸°ë³¸ ê²€ì¦
        if not isinstance(results, dict):
            issues.append('Results must be a dictionary')
            return {'overall_status': 'FAIL', 'issues_found': issues}
        
        # ë‹¤ì–‘í•œ ì„±ê³µ ì¡°ê±´ í™•ì¸ (ë” ìœ ì—°í•œ ê²€ì¦)
        success_indicators = [
            results.get('success', False),
            results.get('evolved', False),
            results.get('total_evolved', 0) > 0,
            results.get('data_quality_score', 0) > 0.5,
            'coin' in results and 'intervals' in results
        ]
        
        # í•˜ë‚˜ë¼ë„ ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ í†µê³¼
        if any(success_indicators):
            return {'overall_status': 'PASS', 'issues_found': [], 'data_quality_score': results.get('data_quality_score', 0.8)}
        
        # ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•œ ê²½ìš°
        issues.append('DNA analysis did not meet success criteria')
        return {'overall_status': 'FAIL', 'issues_found': issues}
        
    except Exception as e:
        return {'overall_status': 'FAIL', 'issues_found': [f'Validation error: {e}']}

def validate_fractal_analysis_results(results: Dict[str, Any]) -> Dict[str, Any]:
    """í”„ë™íƒˆ ë¶„ì„ ê²°ê³¼ ê²€ì¦ - ê°œì„ ëœ ë¡œì§"""
    try:
        if not results:
            return {'overall_status': 'FAIL', 'issues_found': ['No results provided']}
        
        issues = []
        
        # ê¸°ë³¸ ê²€ì¦
        if not isinstance(results, dict):
            issues.append('Results must be a dictionary')
            return {'overall_status': 'FAIL', 'issues_found': issues}
        
        # ë‹¤ì–‘í•œ ì„±ê³µ ì¡°ê±´ í™•ì¸ (ë” ìœ ì—°í•œ ê²€ì¦)
        success_indicators = [
            results.get('success', False),
            results.get('analyzed', False),
            results.get('data_quality_score', 0) > 0.5,
            'coin' in results and 'intervals' in results
        ]
        
        # í•˜ë‚˜ë¼ë„ ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ í†µê³¼
        if any(success_indicators):
            return {'overall_status': 'PASS', 'issues_found': [], 'data_quality_score': results.get('data_quality_score', 0.8)}
        
        # ì„±ê³µ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•œ ê²½ìš°
        issues.append('Fractal analysis did not meet success criteria')
        return {'overall_status': 'FAIL', 'issues_found': issues}
        
    except Exception as e:
        return {'overall_status': 'FAIL', 'issues_found': [f'Validation error: {e}']}

def auto_validate_pipeline_step(step_name: str, results: Any) -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ìë™ ê²€ì¦"""
    try:
        logger.info(f"ğŸ” {step_name} ìë™ ê²€ì¦ ì‹œì‘")
        
        if not results:
            logger.warning(f"âš ï¸ {step_name}: ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
            return {'overall_status': 'FAIL', 'issues_found': ['No results provided']}
        
        # ë‹¨ê³„ë³„ ê²€ì¦ ë¡œì§
        if 'simulation' in step_name.lower():
            return validate_simulation_results(results)
        elif 'dna' in step_name.lower():
            return validate_dna_analysis_results(results)
        elif 'fractal' in step_name.lower():
            return validate_fractal_analysis_results(results)
        else:
            return validate_pipeline_results(results)
            
    except Exception as e:
        logger.error(f"âŒ {step_name} ìë™ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {'overall_status': 'FAIL', 'issues_found': [f'Validation error: {e}']}

logger.info("âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")

def cleanup_all_database_files():
    """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    logger.info("ğŸ§¹ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹œì‘...")
    
    try:
        # ëª¨ë“  ì—°ê²° í’€ ì¢…ë£Œ
        strategy_pool = get_strategy_db_pool()
        candle_pool = get_candle_db_pool()
        
        strategy_pool.close_all_connections()
        candle_pool.close_all_connections()
        
        # WAL íŒŒì¼ ì •ë¦¬
        strategy_pool.cleanup_wal_files()
        candle_pool.cleanup_wal_files()
        
        logger.info("âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")

@contextmanager
def get_optimized_db_connection(db_path: str, write_only: bool = False):
    """ìµœì í™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € - íŠ¸ëœì­ì…˜ ì•ˆì „"""
    # db_pathì— ë”°ë¼ ì ì ˆí•œ í’€ ì„ íƒ - ë” ì •í™•í•œ ë§¤ì¹­
    if db_path == config.STRATEGIES_DB or 'strategies' in db_path.lower():
        pool = get_strategy_db_pool()
    elif db_path == config.LEARNING_RESULTS_DB_PATH or 'learning_results' in db_path.lower():
        pool = get_learning_results_db_pool()
    else:
        pool = get_candle_db_pool()

    with pool.get_connection() as conn:
        # íŠ¸ëœì­ì…˜ ë‚´ì—ì„œ ì•ˆì „í•œ ê¸°ë³¸ ì„¤ì •ë§Œ ì ìš©
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA busy_timeout=60000")  # 60ì´ˆ ëŒ€ê¸° (ê°œì„ : 30ì´ˆ â†’ 60ì´ˆ)
        yield conn
