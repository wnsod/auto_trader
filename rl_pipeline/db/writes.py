"""
ë°ì´í„°ë² ì´ìŠ¤ ì“°ê¸° ì „ìš© ì»¤ë„¥ì…˜ ë° ë°°ì¹˜ ì²˜ë¦¬
ë‹¨ì¼ writer íë¡œ ë°°ì¹˜ insert/update, íŠ¸ëœì­ì…˜ ê´€ë¦¬
"""

import sqlite3
import logging
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from contextlib import contextmanager
from datetime import datetime
from rl_pipeline.db.connection_pool import get_strategy_db_pool, get_batch_loading_pool
from rl_pipeline.core.errors import DBWriteError
from rl_pipeline.core.utils import safe_json_dumps, _format_decimal_precision

logger = logging.getLogger(__name__)

def execute_query(query: str, params: tuple = (), db_path: str = "strategies") -> bool:
    """ì¿¼ë¦¬ ì‹¤í–‰"""
    try:
        pool = get_strategy_db_pool() if db_path == "strategies" else get_batch_loading_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            conn.commit()
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

def write_batch(rows: List[Dict[str, Any]], table: str, db_path: str = None, checkpoint: bool = False, verify: bool = False) -> int:
    """ë°°ì¹˜ ì“°ê¸°
    Args:
        rows: ì‚½ì…/ì—…ë°ì´íŠ¸í•  í–‰ ëª©ë¡
        table: ëŒ€ìƒ í…Œì´ë¸”ëª…
        db_path: ì„ íƒì  DB ê²½ë¡œ (ì—†ìœ¼ë©´ ì „ëµ DB ì‚¬ìš©)
        checkpoint: ì“°ê¸° ì´í›„ WAL ì²´í¬í¬ì¸íŠ¸ë¥¼ ê°•ì œ ìˆ˜í–‰í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ False)
        verify: ì“°ê¸° ì§í›„ COUNT ê²€ì¦ì„ ìˆ˜í–‰í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ False)
    """
    if not rows:
        return 0
    
    try:
        if db_path:
            pool = get_batch_loading_pool(db_path)
        else:
            pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # ì²« ë²ˆì§¸ í–‰ìœ¼ë¡œ ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
            columns = list(rows[0].keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO {table} ({', '.join(columns)}) VALUES ({placeholders})"
            
            # ë°°ì¹˜ ì‹¤í–‰
            batch_data = []
            for row in rows:
                values = []
                for col in columns:
                    value = row.get(col)
                    # íŠ¹ì • í•„ë“œëŠ” í¬ë§·íŒ… ì ìš©
                    if col in ['profit', 'win_rate', 'max_drawdown', 'sharpe_ratio', 'profit_factor']:
                        value = _format_decimal_precision(value, col)
                    elif isinstance(value, dict):
                        value = safe_json_dumps(value)
                    values.append(value)
                batch_data.append(tuple(values))
            
            cursor.executemany(query, batch_data)
            logger.info(f"ğŸ” executemany ì‹¤í–‰ ì™„ë£Œ: {len(batch_data)}ê°œ í–‰")

            conn.commit()
            logger.info(f"ğŸ” ì»¤ë°‹ ì™„ë£Œ")

            # ê³ ë¹„ìš© ë™ì‘ì€ ì„ íƒì ìœ¼ë¡œ ìˆ˜í–‰
            if checkpoint:
                conn.execute("PRAGMA wal_checkpoint(PASSIVE)")
                logger.info(f"ğŸ” WAL ì²´í¬í¬ì¸íŠ¸ ì™„ë£Œ (PASSIVE)")

            if verify:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                logger.info(f"ğŸ” ì¦‰ì‹œ í™•ì¸: {table} í…Œì´ë¸”ì— {count}ê°œ ë ˆì½”ë“œ ì¡´ì¬")
            
            logger.info(f"âœ… ë°°ì¹˜ ì“°ê¸° ì™„ë£Œ: {len(rows)}í–‰ -> {table}")
            return len(rows)
            
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ì“°ê¸° ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ë°°ì¹˜ ì“°ê¸° ì‹¤íŒ¨ ({table}): {e}") from e

def upsert(data: Dict[str, Any], table: str, key_columns: List[str], db_path: str = None) -> bool:
    """Upsert (INSERT OR REPLACE)"""
    try:
        if db_path:
            pool = get_strategy_db_pool()
        else:
            pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            columns = list(data.keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO {table} ({', '.join(columns)}) VALUES ({placeholders})"
            
            values = []
            for col in columns:
                value = data.get(col)
                if col in ['profit', 'win_rate', 'max_drawdown', 'sharpe_ratio', 'profit_factor']:
                    value = _format_decimal_precision(value, col)
                elif isinstance(value, dict):
                    value = safe_json_dumps(value)
                values.append(value)
            
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.debug(f"âœ… Upsert ì™„ë£Œ: {table}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ Upsert ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"Upsert ì‹¤íŒ¨ ({table}): {e}") from e

def update_strategy_performance(strategy_id: str, performance_data: Dict[str, Any]) -> bool:
    """ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # ì„±ê³¼ ë°ì´í„° í¬ë§·íŒ…
            formatted_data = {}
            for key, value in performance_data.items():
                if key in ['profit', 'win_rate', 'max_drawdown', 'sharpe_ratio', 'profit_factor']:
                    formatted_data[key] = _format_decimal_precision(value, key)
                else:
                    formatted_data[key] = value
            
            # ì—…ë°ì´íŠ¸ ì¿¼ë¦¬ ìƒì„±
            set_clauses = []
            values = []
            for key, value in formatted_data.items():
                set_clauses.append(f"{key} = ?")
                values.append(value)
            
            values.append(strategy_id)
            query = f"UPDATE coin_strategies SET {', '.join(set_clauses)} WHERE id = ?"
            
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.debug(f"âœ… ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {strategy_id}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}") from e

def save_strategy_dna(coin: str, dna_data: Dict[str, Any]) -> bool:
    """ì „ëµ DNA ì €ì¥"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # DNA ë°ì´í„° ì¤€ë¹„ (interval ì¶”ì¶œ)
            interval = dna_data.get('interval')
            
            dna_record = {
                'coin': coin,
                'interval': interval,
                'dna_patterns': safe_json_dumps(dna_data.get('dna_patterns', {})),
                'dna_data': safe_json_dumps(dna_data),
                'created_at': pd.Timestamp.now().isoformat(),
                'quality_score': dna_data.get('quality_score', 0.0)
            }
            
            # Upsert ì‹¤í–‰
            columns = list(dna_record.keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO strategy_dna ({', '.join(columns)}) VALUES ({placeholders})"
            
            values = [dna_record[col] for col in columns]
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.info(f"âœ… ì „ëµ DNA ì €ì¥ ì™„ë£Œ: {coin} {interval}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì „ëµ DNA ì €ì¥ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì „ëµ DNA ì €ì¥ ì‹¤íŒ¨: {e}") from e

def save_fractal_analysis(coin: str, interval: str, fractal_data: Dict[str, Any]) -> bool:
    """í”„ë™íƒˆ ë¶„ì„ ê²°ê³¼ ì €ì¥ - ê°œì„ ëœ ë²„ì „ (ëª¨ë“  ì»¬ëŸ¼ í¬í•¨)"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # í”„ë™íƒˆ ë°ì´í„° ì¤€ë¹„ (ëª¨ë“  ì»¬ëŸ¼ í¬í•¨)
            fractal_record = {
                'coin': coin,
                'interval': interval,
                'analysis_type': fractal_data.get('analysis_type', 'fractal_pattern'),
                'fractal_score': _format_decimal_precision(fractal_data.get('fractal_score', 0.0), 'fractal_score'),
                'pattern_distribution': safe_json_dumps(fractal_data.get('pattern_distribution', {})),
                'pruned_strategies_count': fractal_data.get('pruned_strategies_count', 0),
                'total_strategies': fractal_data.get('total_strategies', 0),
                'avg_profit': fractal_data.get('avg_profit', 0.0),
                'avg_win_rate': fractal_data.get('avg_win_rate', 0.0),
                'optimal_rsi_min': fractal_data.get('optimal_rsi_min', 30.0),
                'optimal_rsi_max': fractal_data.get('optimal_rsi_max', 70.0),
                'optimal_volume_ratio': fractal_data.get('optimal_volume_ratio', 1.0),
                'created_at': pd.Timestamp.now().isoformat()
            }
            
            # Upsert ì‹¤í–‰
            columns = list(fractal_record.keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO fractal_analysis ({', '.join(columns)}) VALUES ({placeholders})"
            
            values = [fractal_record[col] for col in columns]
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.info(f"âœ… í”„ë™íƒˆ ë¶„ì„ ì €ì¥ ì™„ë£Œ: {coin} {interval} (ì „ì²´ ì»¬ëŸ¼ í¬í•¨)")
            return True
            
    except Exception as e:
        logger.error(f"âŒ í”„ë™íƒˆ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"í”„ë™íƒˆ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}") from e

def save_synergy_analysis(coin: str, interval: str, synergy_data: Dict[str, Any]) -> bool:
    """ì‹œë„ˆì§€ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # ì‹œë„ˆì§€ ë°ì´í„° ì¤€ë¹„
            synergy_record = {
                'coin': coin,
                'interval': interval,
                'synergy_score': _format_decimal_precision(synergy_data.get('synergy_score', 0.0), 'synergy_score'),
                'synergy_patterns': safe_json_dumps(synergy_data.get('synergy_patterns', {})),
                'created_at': pd.Timestamp.now().isoformat()
            }
            
            # Upsert ì‹¤í–‰
            columns = list(synergy_record.keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO synergy_analysis ({', '.join(columns)}) VALUES ({placeholders})"
            
            values = [synergy_record[col] for col in columns]
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.info(f"âœ… ì‹œë„ˆì§€ ë¶„ì„ ì €ì¥ ì™„ë£Œ: {coin} {interval}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì‹œë„ˆì§€ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì‹œë„ˆì§€ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}") from e

def save_run_metadata(run_metadata: Dict[str, Any]) -> bool:
    """ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì €ì¥"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            run_record = {
                'run_id': run_metadata.get('run_id'),
                'coin': run_metadata.get('coin'),
                'interval': run_metadata.get('interval'),
                'start_time': run_metadata.get('start_time'),
                'end_time': run_metadata.get('end_time'),
                'status': run_metadata.get('status', 'running'),
                'strategies_count': run_metadata.get('strategies_count', 0),
                'successful_strategies': run_metadata.get('successful_strategies', 0),
                'error_count': run_metadata.get('error_count', 0)
            }
            
            # Upsert ì‹¤í–‰
            columns = list(run_record.keys())
            placeholders = ', '.join(['?' for _ in columns])
            query = f"INSERT OR REPLACE INTO runs ({', '.join(columns)}) VALUES ({placeholders})"
            
            values = [run_record[col] for col in columns]
            cursor.execute(query, tuple(values))
            conn.commit()
            
            logger.info(f"âœ… ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {run_record['run_id']}")
            return True
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}") from e

def delete_strategies(strategy_ids: List[str]) -> int:
    """ì „ëµ ì‚­ì œ"""
    if not strategy_ids:
        return 0
    
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            placeholders = ', '.join(['?' for _ in strategy_ids])
            query = f"DELETE FROM coin_strategies WHERE id IN ({placeholders})"
            
            cursor.execute(query, tuple(strategy_ids))
            conn.commit()
            
            deleted_count = cursor.rowcount
            logger.info(f"âœ… ì „ëµ ì‚­ì œ ì™„ë£Œ: {deleted_count}ê°œ")
            return deleted_count
            
    except Exception as e:
        logger.error(f"âŒ ì „ëµ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì „ëµ ì‚­ì œ ì‹¤íŒ¨: {e}") from e

def cleanup_old_data(table: str, days_to_keep: int = 30, db_path: str = None) -> int:
    """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
    try:
        if db_path:
            pool = get_strategy_db_pool()
        else:
            pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            query = f"DELETE FROM {table} WHERE created_at < datetime('now', '-{days_to_keep} days')"
            cursor.execute(query)
            conn.commit()
            
            deleted_count = cursor.rowcount
            logger.info(f"âœ… ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {table}ì—ì„œ {deleted_count}í–‰ ì‚­ì œ")
            return deleted_count
            
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
        raise DBWriteError(f"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}") from e

# âš ï¸ DEPRECATED: ë¯¸ì‚¬ìš© í…Œì´ë¸” ê´€ë ¨ í•¨ìˆ˜ë“¤ (í…Œì´ë¸” ì œê±°ë¨)
# - market_condition_analysis: ë ˆê±°ì‹œ, ë¯¸ì‚¬ìš©
# - dna_market_analysis (strategy_dnaë¡œ ëŒ€ì²´)

# def save_market_condition_analysis(coin: str, interval: str, market_condition: str,
#                                   confidence: float, analysis_data: Dict[str, Any]) -> bool:
#     """ğŸ”´ DEPRECATED: ì‹œì¥ ìƒí™© ë¶„ì„ ê²°ê³¼ ì €ì¥ - market_condition_analysis í…Œì´ë¸” ì œê±°ë¨"""
#     logger.warning("âš ï¸ save_market_condition_analysisëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (í…Œì´ë¸” ì œê±°ë¨)")
#     return False
# - fractal_market_analysis (fractal_analysisë¡œ ëŒ€ì²´)
# - routing_market_analysis (regime_routing_resultsë¡œ ëŒ€ì²´)

def save_dna_by_market_condition(coin: str, interval: str, market_condition: str, 
                               dna_patterns: Dict[str, Any]) -> bool:
    """âš ï¸ DEPRECATED: ë¯¸ì‚¬ìš© í…Œì´ë¸” (dna_market_analysis) - í•¨ìˆ˜ëŠ” ìœ ì§€í•˜ë˜ ë™ì‘ ì•ˆí•¨"""
    logger.debug(f"âš ï¸ save_dna_by_market_condition í˜¸ì¶œë¨ (deprecated): {coin}-{interval}")
    return True  # í…Œì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ ì„±ê³µìœ¼ë¡œ ë°˜í™˜

def save_fractal_by_market_condition(coin: str, interval: str, market_condition: str, 
                                   fractal_features: Dict[str, Any]) -> bool:
    """âš ï¸ DEPRECATED: ë¯¸ì‚¬ìš© í…Œì´ë¸” (fractal_market_analysis) - í•¨ìˆ˜ëŠ” ìœ ì§€í•˜ë˜ ë™ì‘ ì•ˆí•¨"""
    logger.debug(f"âš ï¸ save_fractal_by_market_condition í˜¸ì¶œë¨ (deprecated): {coin}-{interval}")
    return True  # í…Œì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ ì„±ê³µìœ¼ë¡œ ë°˜í™˜

def save_routing_by_market_condition(coin: str, routing_results: Dict[str, Any], 
                                   integrated_routing: Dict[str, Any]) -> bool:
    """âš ï¸ DEPRECATED: ë¯¸ì‚¬ìš© í…Œì´ë¸” (routing_market_analysis) - í•¨ìˆ˜ëŠ” ìœ ì§€í•˜ë˜ ë™ì‘ ì•ˆí•¨"""
    logger.debug(f"âš ï¸ save_routing_by_market_condition í˜¸ì¶œë¨ (deprecated): {coin}")
    return True  # í…Œì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ ì„±ê³µìœ¼ë¡œ ë°˜í™˜

@contextmanager
def transaction(db_path: str = None):
    """íŠ¸ëœì­ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    from rl_pipeline.db.connection_pool import get_candle_db_pool
    
    # db_pathì— ë”°ë¼ ì ì ˆí•œ í’€ ì„ íƒ
    if db_path and 'candles' in db_path.lower():
        pool = get_candle_db_pool()
    else:
        pool = get_strategy_db_pool()
    
    with pool.get_connection() as conn:
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise DBWriteError(f"íŠ¸ëœì­ì…˜ ì‹¤íŒ¨: {e}") from e

def save_coin_analysis_ratios(coin: str, interval: str, analysis_type: str, 
                             ratios_data: Dict[str, Any]) -> bool:
    """ğŸš€ ì½”ì¸ë³„ ë¶„ì„ ë¹„ìœ¨ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        pool = get_strategy_db_pool()
        
        with pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            check_query = """
            SELECT id FROM coin_analysis_ratios 
            WHERE coin = ? AND interval = ? AND analysis_type = ?
            """
            cursor.execute(check_query, (coin, interval, analysis_type))
            existing = cursor.fetchone()
            
            if existing:
                # ì—…ë°ì´íŠ¸
                update_query = """
                UPDATE coin_analysis_ratios SET
                    fractal_ratios = ?,
                    multi_timeframe_ratios = ?,
                    indicator_cross_ratios = ?,
                    coin_specific_ratios = ?,
                    volatility_ratios = ?,
                    volume_ratios = ?,
                    optimal_modules = ?,
                    interval_weights = ?,
                    performance_score = ?,
                    accuracy_score = ?,
                    updated_at = CURRENT_TIMESTAMP
                WHERE coin = ? AND interval = ? AND analysis_type = ?
                """

                cursor.execute(update_query, (
                    safe_json_dumps(ratios_data.get('fractal_ratios', {})),
                    safe_json_dumps(ratios_data.get('multi_timeframe_ratios', {})),
                    safe_json_dumps(ratios_data.get('indicator_cross_ratios', {})),
                    safe_json_dumps(ratios_data.get('coin_specific_ratios', {})),
                    safe_json_dumps(ratios_data.get('volatility_ratios', {})),
                    safe_json_dumps(ratios_data.get('volume_ratios', {})),
                    safe_json_dumps(ratios_data.get('optimal_modules', {})),
                    safe_json_dumps(ratios_data.get('interval_weights', {})),
                    ratios_data.get('performance_score', 0.0),
                    ratios_data.get('accuracy_score', 0.0),
                    coin, interval, analysis_type
                ))
            else:
                # ìƒˆë¡œ ì‚½ì…
                insert_query = """
                INSERT INTO coin_analysis_ratios (
                    coin, interval, analysis_type,
                    fractal_ratios, multi_timeframe_ratios, indicator_cross_ratios,
                    coin_specific_ratios, volatility_ratios, volume_ratios,
                    optimal_modules, interval_weights, performance_score, accuracy_score
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """

                cursor.execute(insert_query, (
                    coin, interval, analysis_type,
                    safe_json_dumps(ratios_data.get('fractal_ratios', {})),
                    safe_json_dumps(ratios_data.get('multi_timeframe_ratios', {})),
                    safe_json_dumps(ratios_data.get('indicator_cross_ratios', {})),
                    safe_json_dumps(ratios_data.get('coin_specific_ratios', {})),
                    safe_json_dumps(ratios_data.get('volatility_ratios', {})),
                    safe_json_dumps(ratios_data.get('volume_ratios', {})),
                    safe_json_dumps(ratios_data.get('optimal_modules', {})),
                    safe_json_dumps(ratios_data.get('interval_weights', {})),
                    ratios_data.get('performance_score', 0.0),
                    ratios_data.get('accuracy_score', 0.0)
                ))
            
            conn.commit()
            logger.info(f"âœ… {coin} {interval} ë¶„ì„ ë¹„ìœ¨ ì €ì¥ ì™„ë£Œ")
            return True
            
    except Exception as e:
        logger.error(f"âŒ {coin} {interval} ë¶„ì„ ë¹„ìœ¨ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_coin_global_weights(coin: str, weights_data: Dict[str, Any]) -> bool:
    """ğŸ”¥ ì½”ì¸ vs ê¸€ë¡œë²Œ ì „ëµ ê°€ì¤‘ì¹˜ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

    Args:
        coin: ì½”ì¸ ì´ë¦„ (ì˜ˆ: 'BTC')
        weights_data: ê°€ì¤‘ì¹˜ ë°ì´í„°
            - coin_weight: ê°œë³„ ì½”ì¸ ì „ëµ ê°€ì¤‘ì¹˜ (0~1)
            - global_weight: ê¸€ë¡œë²Œ ì „ëµ ê°€ì¤‘ì¹˜ (0~1)
            - coin_score: ì½”ì¸ ì „ëµ ì„±ëŠ¥ ì ìˆ˜
            - global_score: ê¸€ë¡œë²Œ ì „ëµ ì„±ëŠ¥ ì ìˆ˜
            - data_quality_score: ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
            - coin_strategy_count: ì½”ì¸ ì „ëµ ê°œìˆ˜
            - global_strategy_count: ê¸€ë¡œë²Œ ì „ëµ ê°œìˆ˜
            - coin_avg_profit: ì½”ì¸ ì „ëµ í‰ê·  ìˆ˜ìµ
            - global_avg_profit: ê¸€ë¡œë²Œ ì „ëµ í‰ê·  ìˆ˜ìµ
            - coin_win_rate: ì½”ì¸ ì „ëµ ìŠ¹ë¥ 
            - global_win_rate: ê¸€ë¡œë²Œ ì „ëµ ìŠ¹ë¥ 

    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        pool = get_strategy_db_pool()

        with pool.get_connection() as conn:
            cursor = conn.cursor()

            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            check_query = "SELECT coin FROM coin_global_weights WHERE coin = ?"
            cursor.execute(check_query, (coin,))
            existing = cursor.fetchone()

            if existing:
                # ì—…ë°ì´íŠ¸
                update_query = """
                UPDATE coin_global_weights SET
                    coin_weight = ?,
                    global_weight = ?,
                    coin_score = ?,
                    global_score = ?,
                    data_quality_score = ?,
                    coin_strategy_count = ?,
                    global_strategy_count = ?,
                    coin_avg_profit = ?,
                    global_avg_profit = ?,
                    coin_win_rate = ?,
                    global_win_rate = ?,
                    updated_at = CURRENT_TIMESTAMP
                WHERE coin = ?
                """

                cursor.execute(update_query, (
                    weights_data.get('coin_weight', 0.7),
                    weights_data.get('global_weight', 0.3),
                    weights_data.get('coin_score', 0.0),
                    weights_data.get('global_score', 0.0),
                    weights_data.get('data_quality_score', 0.0),
                    weights_data.get('coin_strategy_count', 0),
                    weights_data.get('global_strategy_count', 0),
                    weights_data.get('coin_avg_profit', 0.0),
                    weights_data.get('global_avg_profit', 0.0),
                    weights_data.get('coin_win_rate', 0.0),
                    weights_data.get('global_win_rate', 0.0),
                    coin
                ))
            else:
                # ìƒˆë¡œ ì‚½ì…
                insert_query = """
                INSERT INTO coin_global_weights (
                    coin, coin_weight, global_weight,
                    coin_score, global_score, data_quality_score,
                    coin_strategy_count, global_strategy_count,
                    coin_avg_profit, global_avg_profit,
                    coin_win_rate, global_win_rate
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """

                cursor.execute(insert_query, (
                    coin,
                    weights_data.get('coin_weight', 0.7),
                    weights_data.get('global_weight', 0.3),
                    weights_data.get('coin_score', 0.0),
                    weights_data.get('global_score', 0.0),
                    weights_data.get('data_quality_score', 0.0),
                    weights_data.get('coin_strategy_count', 0),
                    weights_data.get('global_strategy_count', 0),
                    weights_data.get('coin_avg_profit', 0.0),
                    weights_data.get('global_avg_profit', 0.0),
                    weights_data.get('coin_win_rate', 0.0),
                    weights_data.get('global_win_rate', 0.0)
                ))

            conn.commit()
            logger.info(f"âœ… {coin} ì½”ì¸ vs ê¸€ë¡œë²Œ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ (coin: {weights_data.get('coin_weight', 0.7):.2f}, global: {weights_data.get('global_weight', 0.3):.2f})")
            return True

    except Exception as e:
        logger.error(f"âŒ {coin} ì½”ì¸ vs ê¸€ë¡œë²Œ ê°€ì¤‘ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False