"""
ì‹¤ì „ìš© ë©€í‹° ì½”ì¸/ì¸í„°ë²Œ DQN í•™ìŠµ ì‹œìŠ¤í…œ
ëª¨ë“  ì½”ì¸-ì¸í„°ë²Œ ì¡°í•©ì— ëŒ€í•´ DQN ì—ì´ì „íŠ¸ í•™ìŠµ
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

import logging
import sqlite3
from datetime import datetime
from typing import Dict, List, Tuple
import json

from rl_pipeline.training.train_rl_agent import train_dqn_agent, load_candle_data_from_db
from rl_pipeline.core.env import config

logger = logging.getLogger(__name__)


def get_available_coin_intervals() -> List[Tuple[str, str, int]]:
    """
    DBì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ì½”ì¸-ì¸í„°ë²Œ ì¡°í•© ì¡°íšŒ

    Returns:
        [(coin, interval, candle_count), ...]
    """
    with sqlite3.connect(config.RL_DB) as conn:
        result = conn.execute("""
            SELECT coin, interval, COUNT(*) as cnt
            FROM candles
            GROUP BY coin, interval
            HAVING cnt >= 500  -- ìµœì†Œ 500ê°œ ìº”ë“¤ í•„ìš”
            ORDER BY coin, interval
        """).fetchall()

    return result


def save_training_results(
    coin: str,
    interval: str,
    results: Dict,
    model_path: str,
    training_time: float
):
    """
    í•™ìŠµ ê²°ê³¼ë¥¼ DBì— ì €ì¥

    Args:
        coin: ì½”ì¸
        interval: ì¸í„°ë²Œ
        results: train_dqn_agent ê²°ê³¼
        model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        training_time: í•™ìŠµ ì‹œê°„ (ì´ˆ)
    """
    with sqlite3.connect(config.RL_DB) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS dqn_training_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                coin TEXT NOT NULL,
                interval TEXT NOT NULL,
                trained_at TEXT NOT NULL,
                num_episodes INTEGER,
                avg_reward REAL,
                avg_return REAL,
                avg_win_rate REAL,
                final_epsilon REAL,
                total_train_steps INTEGER,
                model_path TEXT,
                training_time REAL,
                UNIQUE(coin, interval, trained_at)
            )
        """)

        conn.execute("""
            INSERT OR REPLACE INTO dqn_training_results
            (coin, interval, trained_at, num_episodes, avg_reward, avg_return,
             avg_win_rate, final_epsilon, total_train_steps, model_path, training_time)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            coin,
            interval,
            datetime.now().isoformat(),
            len(results['episode_rewards']),
            float(sum(results['episode_rewards']) / len(results['episode_rewards'])),
            float(sum(results['episode_returns']) / len(results['episode_returns'])),
            float(sum(results['episode_win_rates']) / len(results['episode_win_rates'])),
            float(results['final_epsilon']),
            int(results['total_train_steps']),
            model_path,
            training_time
        ))

        conn.commit()

    logger.info(f"âœ… í•™ìŠµ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ: {coin}-{interval}")


def train_single_agent(
    coin: str,
    interval: str,
    num_episodes: int = 100,
    candle_limit: int = None
) -> Dict:
    """
    ë‹¨ì¼ ì½”ì¸-ì¸í„°ë²Œ ì¡°í•©ì— ëŒ€í•´ DQN í•™ìŠµ

    Args:
        coin: ì½”ì¸ (ì˜ˆ: "BTC")
        interval: ì¸í„°ë²Œ (ì˜ˆ: "15m")
        num_episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
        candle_limit: ì‚¬ìš©í•  ìº”ë“¤ ìµœëŒ€ ê°œìˆ˜ (None=ì „ì²´)

    Returns:
        í•™ìŠµ ê²°ê³¼
    """
    import time
    start_time = time.time()

    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸš€ DQN í•™ìŠµ ì‹œì‘: {coin}-{interval}")
    logger.info(f"{'='*60}")

    # 1. ë°ì´í„° ë¡œë“œ
    candle_data = load_candle_data_from_db(coin, interval, limit=candle_limit)
    logger.info(f"   ìº”ë“¤ ë°ì´í„°: {len(candle_data)}ê°œ")

    # 2. í•™ìŠµ ì‹¤í–‰
    model_path = f"models/dqn_{coin.lower()}_{interval}.pkl"

    results = train_dqn_agent(
        candle_data=candle_data,
        num_episodes=num_episodes,
        save_path=model_path,
        log_interval=max(10, num_episodes // 10)
    )

    training_time = time.time() - start_time

    # 3. ê²°ê³¼ ì €ì¥
    save_training_results(coin, interval, results, model_path, training_time)

    # 4. ê²°ê³¼ ìš”ì•½
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… {coin}-{interval} í•™ìŠµ ì™„ë£Œ!")
    logger.info(f"{'='*60}")
    logger.info(f"   í‰ê·  ë³´ìƒ: {sum(results['episode_rewards'])/len(results['episode_rewards']):.2f}")
    logger.info(f"   í‰ê·  ìˆ˜ìµë¥ : {sum(results['episode_returns'])/len(results['episode_returns']):.2%}")
    logger.info(f"   í‰ê·  ìŠ¹ë¥ : {sum(results['episode_win_rates'])/len(results['episode_win_rates']):.2%}")
    logger.info(f"   ìµœì¢… Epsilon: {results['final_epsilon']:.4f}")
    logger.info(f"   í•™ìŠµ ìŠ¤í…: {results['total_train_steps']}")
    logger.info(f"   í•™ìŠµ ì‹œê°„: {training_time:.1f}ì´ˆ")
    logger.info(f"   ëª¨ë¸ ê²½ë¡œ: {model_path}")

    return results


def train_all_agents(
    coins: List[str] = None,
    intervals: List[str] = None,
    num_episodes: int = 100,
    candle_limit: int = None
):
    """
    ëª¨ë“  ì½”ì¸-ì¸í„°ë²Œ ì¡°í•©ì— ëŒ€í•´ DQN í•™ìŠµ

    Args:
        coins: í•™ìŠµí•  ì½”ì¸ ëª©ë¡ (None=ì „ì²´)
        intervals: í•™ìŠµí•  ì¸í„°ë²Œ ëª©ë¡ (None=ì „ì²´)
        num_episodes: ì—í”¼ì†Œë“œ ìˆ˜
        candle_limit: ìº”ë“¤ ì œí•œ
    """
    import time
    total_start = time.time()

    # ì‚¬ìš© ê°€ëŠ¥í•œ ì¡°í•© ì¡°íšŒ
    available = get_available_coin_intervals()

    # í•„í„°ë§
    if coins:
        available = [(c, i, cnt) for c, i, cnt in available if c in coins]
    if intervals:
        available = [(c, i, cnt) for c, i, cnt in available if i in intervals]

    logger.info(f"\n{'#'*60}")
    logger.info(f"# ì‹¤ì „ìš© DQN ë©€í‹° ì—ì´ì „íŠ¸ í•™ìŠµ ì‹œì‘")
    logger.info(f"{'#'*60}")
    logger.info(f"í•™ìŠµ ëŒ€ìƒ: {len(available)}ê°œ ì¡°í•©")
    logger.info(f"ì—í”¼ì†Œë“œ: {num_episodes}")
    logger.info(f"ìº”ë“¤ ì œí•œ: {candle_limit if candle_limit else 'ì „ì²´'}\n")

    results_summary = []

    for idx, (coin, interval, cnt) in enumerate(available, 1):
        logger.info(f"\n[{idx}/{len(available)}] {coin}-{interval} (ìº”ë“¤: {cnt:,}ê°œ)")

        try:
            results = train_single_agent(
                coin=coin,
                interval=interval,
                num_episodes=num_episodes,
                candle_limit=candle_limit
            )

            results_summary.append({
                'coin': coin,
                'interval': interval,
                'success': True,
                'avg_return': sum(results['episode_returns'])/len(results['episode_returns']),
                'avg_win_rate': sum(results['episode_win_rates'])/len(results['episode_win_rates'])
            })

        except Exception as e:
            logger.error(f"âŒ {coin}-{interval} í•™ìŠµ ì‹¤íŒ¨: {e}")
            results_summary.append({
                'coin': coin,
                'interval': interval,
                'success': False,
                'error': str(e)
            })

    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    total_time = time.time() - total_start

    logger.info(f"\n{'#'*60}")
    logger.info(f"# ì „ì²´ í•™ìŠµ ì™„ë£Œ!")
    logger.info(f"{'#'*60}")
    logger.info(f"ì´ í•™ìŠµ ì‹œê°„: {total_time/60:.1f}ë¶„")
    logger.info(f"ì„±ê³µ: {sum(1 for r in results_summary if r['success'])}/{len(results_summary)}")

    # ì„±ëŠ¥ ìˆœìœ„
    logger.info(f"\n=== ì„±ëŠ¥ ìˆœìœ„ (í‰ê·  ìˆ˜ìµë¥ ) ===")
    successful = [r for r in results_summary if r['success']]
    successful.sort(key=lambda x: x['avg_return'], reverse=True)

    for idx, r in enumerate(successful[:10], 1):
        logger.info(f"{idx:2d}. {r['coin']:5s}-{r['interval']:4s}: "
                   f"ìˆ˜ìµë¥  {r['avg_return']:+.2%}, ìŠ¹ë¥  {r['avg_win_rate']:.2%}")

    # ê²°ê³¼ JSON ì €ì¥
    with open('models/dqn_training_summary.json', 'w') as f:
        json.dump(results_summary, f, indent=2)

    logger.info(f"\nâœ… ìš”ì•½ ì €ì¥: models/dqn_training_summary.json")


if __name__ == "__main__":
    import argparse

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(message)s'
    )

    parser = argparse.ArgumentParser(description='DQN ë©€í‹° ì—ì´ì „íŠ¸ í•™ìŠµ (DB ê¸°ë°˜)')
    parser.add_argument('--coins', nargs='+', help='í•™ìŠµí•  ì½”ì¸ í•„í„° (ì„ íƒì‚¬í•­, ë¯¸ì§€ì •ì‹œ DBì˜ ëª¨ë“  ì½”ì¸)')
    parser.add_argument('--intervals', nargs='+', help='í•™ìŠµí•  ì¸í„°ë²Œ í•„í„° (ì„ íƒì‚¬í•­, ë¯¸ì§€ì •ì‹œ ëª¨ë“  ì¸í„°ë²Œ)')
    parser.add_argument('--episodes', type=int, default=100, help='ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--candle-limit', type=int, help='ìº”ë“¤ ìµœëŒ€ ê°œìˆ˜ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ì‹œ ì‚¬ìš©, ì˜ˆ: 500)')

    args = parser.parse_args()

    # DBì— ìˆëŠ” ì½”ì¸-ì¸í„°ë²Œ ì¡°í•©ìœ¼ë¡œ ìë™ í•™ìŠµ
    train_all_agents(
        coins=args.coins,
        intervals=args.intervals,
        num_episodes=args.episodes,
        candle_limit=args.candle_limit
    )
