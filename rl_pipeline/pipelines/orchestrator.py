"""
í†µí•© íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
"""

import sys
import os
import logging
import random
import pandas as pd
import numpy as np
from datetime import datetime
from contextlib import contextmanager
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict

# ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡° import
try:
    import rl_pipeline.core.env as core_env
    import rl_pipeline.core.errors as core_errors
    import rl_pipeline.strategy.manager as strategy_manager
    import rl_pipeline.simulation.selfplay as selfplay
    import rl_pipeline.routing.regime_router as regime_router
    import rl_pipeline.analysis.integrated_analyzer as integrated_analyzer
    import rl_pipeline.analysis.integrated_analysis_v1 as integrated_analysis_v1
    import rl_pipeline.db.schema as db_schema
    import rl_pipeline.db.connection_pool as db_pool
    import rl_pipeline.db.reads as db_reads
    import rl_pipeline.db.learning_results as learning_results

    config = core_env.config
    AZError = core_errors.AZError
    create_run_record = strategy_manager.create_run_record
    update_run_record = strategy_manager.update_run_record
    create_coin_strategies = strategy_manager.create_coin_strategies
    create_global_strategies = strategy_manager.create_global_strategies
    run_self_play_test = selfplay.run_self_play_test
    RegimeRouter = regime_router.RegimeRouter
    create_regime_routing_strategies = regime_router.create_regime_routing_strategies
    IntegratedAnalyzer = integrated_analyzer.IntegratedAnalyzer
    IntegratedAnalyzerV1 = integrated_analysis_v1.IntegratedAnalyzerV1
    analyze_coin_strategies = integrated_analyzer.analyze_coin_strategies
    analyze_global_strategies = integrated_analyzer.analyze_global_strategies
    ensure_indexes = db_schema.ensure_indexes
    setup_database_tables = db_schema.setup_database_tables
    create_coin_strategies_table = db_schema.create_coin_strategies_table
    get_optimized_db_connection = db_pool.get_optimized_db_connection
    save_selfplay_results = learning_results.save_selfplay_results
    save_regime_routing_results = learning_results.save_regime_routing_results
    save_integrated_analysis_results = learning_results.save_integrated_analysis_results

    NEW_PIPELINE_AVAILABLE = True
    # ğŸ”¥ ì¤‘ë³µ ë©”ì‹œì§€ ì œê±° (absolute_zero_system.pyì—ì„œ ì´ë¯¸ ì¶œë ¥)

except ImportError as e:
    print(f"ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    config = None
    AZError = Exception
    NEW_PIPELINE_AVAILABLE = False

logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜
AZ_STRATEGY_POOL_SIZE = int(os.getenv('AZ_STRATEGY_POOL_SIZE', '15000'))
AZ_SELFPLAY_EPISODES = int(os.getenv('AZ_SELFPLAY_EPISODES', '200'))
AZ_SELFPLAY_AGENTS_PER_EPISODE = int(os.getenv('AZ_SELFPLAY_AGENTS_PER_EPISODE', '4'))  # ì—í”¼ì†Œë“œë‹¹ ì—ì´ì „íŠ¸ ìˆ˜
PREDICTIVE_SELFPLAY_RATIO = float(os.getenv('PREDICTIVE_SELFPLAY_RATIO', '0.2'))
PREDICTIVE_SELFPLAY_EPISODES = int(os.getenv('PREDICTIVE_SELFPLAY_EPISODES', '50'))  # ğŸ”¥ ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜ (50ê°œ ì „ëµ Ã— 50ë²ˆ ë°˜ë³µ, ìµœëŒ€ê°’)
PREDICTIVE_SELFPLAY_LEARNING_RATE = float(os.getenv('PREDICTIVE_SELFPLAY_LEARNING_RATE', '0.1'))  # ğŸ”¥ ì˜ˆì¸¡ ì •ì±… ì—…ë°ì´íŠ¸ í•™ìŠµë¥ 
PREDICTIVE_SELFPLAY_EARLY_STOP = os.getenv('PREDICTIVE_SELFPLAY_EARLY_STOP', 'true').lower() == 'true'  # ğŸ”¥ ì¡°ê¸° ì¢…ë£Œ í™œì„±í™”
PREDICTIVE_SELFPLAY_EARLY_STOP_PATIENCE = int(os.getenv('PREDICTIVE_SELFPLAY_EARLY_STOP_PATIENCE', '15'))  # ğŸ”¥ ê°œì„ : ì¡°ê¸° ì¢…ë£Œ ì¸ë‚´ì‹¬ (5 â†’ 15)
PREDICTIVE_SELFPLAY_EARLY_STOP_ACCURACY = float(os.getenv('PREDICTIVE_SELFPLAY_EARLY_STOP_ACCURACY', '0.85'))  # ğŸ”¥ ì¡°ê¸° ì¢…ë£Œ ì •í™•ë„ ì„ê³„ê°’
PREDICTIVE_SELFPLAY_MIN_IMPROVEMENT = float(os.getenv('PREDICTIVE_SELFPLAY_MIN_IMPROVEMENT', '0.01'))  # ğŸ”¥ ìµœì†Œ ê°œì„  ì„ê³„ê°’
PREDICTIVE_SELFPLAY_MIN_EPISODES = int(os.getenv('PREDICTIVE_SELFPLAY_MIN_EPISODES', '20'))  # ğŸ”¥ ê°œì„ : ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ (10 â†’ 20)


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    coin: str
    interval: str
    strategies_created: int = 0
    selfplay_episodes: int = 0
    regime_detected: str = "neutral"
    routing_results: int = 0
    signal_score: float = 0.0
    signal_action: str = "HOLD"
    execution_time: float = 0.0
    status: str = "pending"
    created_at: str = ""
    selfplay_result: Optional[Dict[str, Any]] = None  # ğŸ”¥ self-play ê²°ê³¼ ì €ì¥

def validate_selfplay_result(result: Dict, coin: str, interval: str) -> Dict[str, Any]:
    """ì˜ˆì¸¡ Self-play ê²°ê³¼ ê²€ì¦

    Args:
        result: Self-play ê²°ê³¼ dict
        coin: ì½”ì¸ ì‹¬ë³¼
        interval: ì¸í„°ë²Œ

    Returns:
        Dict: ê²€ì¦ ê²°ê³¼ {'valid': bool, 'issues': List[str], 'warnings': List[str]}
    """
    issues = []
    warnings = []

    try:
        # 1. í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['cycle_results', 'episodes', 'avg_accuracy', 'best_accuracy', 'strategy_count']
        for field in required_fields:
            if field not in result:
                issues.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")

        # 2. ë°ì´í„° íƒ€ì… í™•ì¸
        if 'episodes' in result and not isinstance(result['episodes'], int):
            issues.append(f"episodes íƒ€ì… ì˜¤ë¥˜: {type(result['episodes'])}")

        if 'avg_accuracy' in result and not isinstance(result['avg_accuracy'], (int, float)):
            issues.append(f"avg_accuracy íƒ€ì… ì˜¤ë¥˜: {type(result['avg_accuracy'])}")

        if 'cycle_results' in result and not isinstance(result['cycle_results'], list):
            issues.append(f"cycle_results íƒ€ì… ì˜¤ë¥˜: {type(result['cycle_results'])}")

        # 3. ë…¼ë¦¬ì  ì¼ê´€ì„± í™•ì¸
        if 'episodes' in result and 'cycle_results' in result:
            if result['episodes'] != len(result['cycle_results']):
                warnings.append(f"ì—í”¼ì†Œë“œ ìˆ˜ ë¶ˆì¼ì¹˜: episodes={result['episodes']}, cycle_results ê¸¸ì´={len(result['cycle_results'])}")

        # 4. ì •í™•ë„ ë²”ìœ„ í™•ì¸
        if 'avg_accuracy' in result:
            accuracy = result['avg_accuracy']
            if not (0 <= accuracy <= 1):
                issues.append(f"avg_accuracy ë²”ìœ„ ì˜¤ë¥˜: {accuracy} (0~1 ë²”ìœ„ ë²—ì–´ë‚¨)")

            # ì¸í„°ë²Œë³„ ì˜ˆìƒ ì •í™•ë„ ë²”ìœ„
            expected_ranges = {
                '15m': (0.70, 1.00),
                '30m': (0.65, 1.00),
                '240m': (0.50, 0.85),
                '1d': (0.45, 0.80)
            }

            if interval in expected_ranges:
                min_acc, max_acc = expected_ranges[interval]
                if accuracy < min_acc * 0.8:  # 20% ë§ˆì§„
                    warnings.append(f"{interval} ì •í™•ë„ê°€ ì˜ˆìƒë³´ë‹¤ ë‚®ìŒ: {accuracy:.3f} (ì˜ˆìƒ ë²”ìœ„: {min_acc:.2f}~{max_acc:.2f})")
                elif accuracy > max_acc * 1.1:
                    warnings.append(f"{interval} ì •í™•ë„ê°€ ì˜ˆìƒë³´ë‹¤ ë†’ìŒ: {accuracy:.3f} (ê³¼ì í•© ê°€ëŠ¥ì„±)")

        # 5. ì „ëµ ìˆ˜ í™•ì¸
        if 'strategy_count' in result:
            if result['strategy_count'] < 10:
                warnings.append(f"ì „ëµ ìˆ˜ê°€ ë„ˆë¬´ ì ìŒ: {result['strategy_count']}")
            elif result['strategy_count'] > 200:
                warnings.append(f"ì „ëµ ìˆ˜ê°€ ë„ˆë¬´ ë§ìŒ: {result['strategy_count']}")

        # 6. ì¡°ê¸° ì¢…ë£Œ í™•ì¸
        if 'episodes' in result:
            from rl_pipeline.pipelines.orchestrator import PREDICTIVE_SELFPLAY_EPISODES
            if result['episodes'] < 5:
                issues.append(f"ì—í”¼ì†Œë“œ ìˆ˜ê°€ ë„ˆë¬´ ì ìŒ: {result['episodes']} (ìµœì†Œ 5ê°œ í•„ìš”)")
            elif result['episodes'] < PREDICTIVE_SELFPLAY_EPISODES * 0.2:
                warnings.append(f"ë§¤ìš° ì´ë¥¸ ì¡°ê¸° ì¢…ë£Œ: {result['episodes']}/{PREDICTIVE_SELFPLAY_EPISODES} ì—í”¼ì†Œë“œ")

        # 7. cycle_results ìƒì„¸ ê²€ì¦
        if 'cycle_results' in result and isinstance(result['cycle_results'], list):
            for idx, cycle in enumerate(result['cycle_results']):
                if not isinstance(cycle, dict):
                    issues.append(f"cycle_results[{idx}] íƒ€ì… ì˜¤ë¥˜: {type(cycle)}")
                    continue

                # ê° cycleì˜ í•„ìˆ˜ í•„ë“œ
                cycle_fields = ['episode', 'accuracy']
                for field in cycle_fields:
                    if field not in cycle:
                        issues.append(f"cycle_results[{idx}]ì— í•„ë“œ ëˆ„ë½: {field}")

    except Exception as e:
        issues.append(f"ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")

    return {
        'valid': len(issues) == 0,
        'issues': issues,
        'warnings': warnings,
        'coin': coin,
        'interval': interval
    }


def validate_integrated_learning_data(
    coin: str,
    all_interval_selfplay: Dict[str, Dict],
    pipeline_results: List,
    min_intervals: int = 2,
    min_total_episodes: int = 10
) -> Dict[str, Any]:
    """
    í†µí•© í•™ìŠµ ë°ì´í„° ê²€ì¦

    Args:
        coin: ì½”ì¸ ì‹¬ë³¼
        all_interval_selfplay: ì¸í„°ë²Œë³„ Self-play ê²°ê³¼ {interval: result_dict}
        pipeline_results: íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        min_intervals: ìµœì†Œ í•„ìš” ì¸í„°ë²Œ ìˆ˜
        min_total_episodes: ìµœì†Œ ì´ ì—í”¼ì†Œë“œ ìˆ˜

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    issues = []
    warnings = []
    stats = {}

    # 1. ì¸í„°ë²Œ ìˆ˜ ê²€ì¦
    num_intervals = len(all_interval_selfplay)
    stats['num_intervals'] = num_intervals

    if num_intervals == 0:
        issues.append("Self-play ê²°ê³¼ê°€ ì „í˜€ ì—†ìŒ")
        return {
            'valid': False,
            'issues': issues,
            'warnings': warnings,
            'stats': stats
        }

    if num_intervals < min_intervals:
        warnings.append(f"ì¸í„°ë²Œ ìˆ˜ ë¶€ì¡± ({num_intervals} < {min_intervals})")

    # 2. ê° ì¸í„°ë²Œë³„ ë°ì´í„° ê²€ì¦
    interval_stats = {}
    total_episodes = 0
    total_accuracy_sum = 0
    accuracy_count = 0

    for interval, sp_result in all_interval_selfplay.items():
        interval_stat = {
            'interval': interval,
            'valid': True,
            'episodes': 0,
            'avg_accuracy': 0.0,
            'best_accuracy': 0.0,
            'issues': []
        }

        # 2.1 ê²°ê³¼ íƒ€ì… ê²€ì¦
        if not isinstance(sp_result, dict):
            interval_stat['valid'] = False
            interval_stat['issues'].append(f"ê²°ê³¼ê°€ dict íƒ€ì…ì´ ì•„ë‹˜: {type(sp_result)}")
            interval_stats[interval] = interval_stat
            continue

        # 2.2 í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['cycle_results', 'episodes', 'avg_accuracy']
        missing_fields = [f for f in required_fields if f not in sp_result]
        if missing_fields:
            interval_stat['valid'] = False
            interval_stat['issues'].append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing_fields}")

        # 2.3 ì—í”¼ì†Œë“œ ìˆ˜ ê²€ì¦
        cycle_results = sp_result.get('cycle_results', [])
        episodes = sp_result.get('episodes', 0)

        if not isinstance(cycle_results, list):
            interval_stat['valid'] = False
            interval_stat['issues'].append("cycle_resultsê°€ list íƒ€ì…ì´ ì•„ë‹˜")
        else:
            interval_stat['episodes'] = len(cycle_results)
            total_episodes += len(cycle_results)

            if len(cycle_results) != episodes:
                warnings.append(f"{interval}: cycle_results ê¸¸ì´({len(cycle_results)})ì™€ episodes({episodes}) ë¶ˆì¼ì¹˜")

            # ì¸í„°ë²Œë³„ ìµœì†Œ ì—í”¼ì†Œë“œ ê²€ì¦
            interval_min_episodes = {
                '15m': 5,
                '30m': 5,
                '240m': 8,
                '1d': 10
            }
            min_eps = interval_min_episodes.get(interval, 5)
            if len(cycle_results) < min_eps:
                warnings.append(f"{interval}: ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({len(cycle_results)} < {min_eps})")

        # 2.4 ì •í™•ë„ ê²€ì¦
        avg_accuracy = sp_result.get('avg_accuracy', 0.0)
        best_accuracy = sp_result.get('best_accuracy', 0.0)

        interval_stat['avg_accuracy'] = avg_accuracy
        interval_stat['best_accuracy'] = best_accuracy

        if avg_accuracy > 0:
            total_accuracy_sum += avg_accuracy
            accuracy_count += 1

        # ì •í™•ë„ ë²”ìœ„ ê²€ì¦ (ì¸í„°ë²Œë³„ ê¸°ëŒ€ ë²”ìœ„)
        expected_ranges = {
            '15m': (0.60, 1.00),
            '30m': (0.55, 1.00),
            '240m': (0.40, 0.90),
            '1d': (0.35, 0.85)
        }

        if interval in expected_ranges:
            min_acc, max_acc = expected_ranges[interval]
            if avg_accuracy < min_acc:
                warnings.append(f"{interval}: í‰ê·  ì •í™•ë„ê°€ ê¸°ëŒ€ ë²”ìœ„ë³´ë‹¤ ë‚®ìŒ ({avg_accuracy:.2%} < {min_acc:.2%})")
            elif avg_accuracy > max_acc:
                warnings.append(f"{interval}: í‰ê·  ì •í™•ë„ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŒ ({avg_accuracy:.2%} > {max_acc:.2%})")

        if best_accuracy < avg_accuracy:
            warnings.append(f"{interval}: best_accuracy({best_accuracy:.2%}) < avg_accuracy({avg_accuracy:.2%})")

        # 2.5 cycle_results ë‚´ë¶€ ë°ì´í„° ê²€ì¦
        if isinstance(cycle_results, list) and len(cycle_results) > 0:
            for idx, cycle in enumerate(cycle_results):
                if not isinstance(cycle, dict):
                    warnings.append(f"{interval}: cycle_results[{idx}]ê°€ dictê°€ ì•„ë‹˜")
                    continue

                if 'accuracy' not in cycle:
                    warnings.append(f"{interval}: cycle_results[{idx}]ì— accuracy ì—†ìŒ")

                # ì •í™•ë„ ì¶”ì„¸ ê²€ì¦ (ë§ˆì§€ë§‰ 5ê°œ ì—í”¼ì†Œë“œ)
                if idx >= len(cycle_results) - 5:
                    cycle_acc = cycle.get('accuracy', 0)
                    if cycle_acc < 0.3:  # ë„ˆë¬´ ë‚®ì€ ì •í™•ë„
                        warnings.append(f"{interval}: ì—í”¼ì†Œë“œ {idx+1} ì •í™•ë„ ë§¤ìš° ë‚®ìŒ ({cycle_acc:.2%})")

        interval_stats[interval] = interval_stat

    # 3. ì´ ì—í”¼ì†Œë“œ ìˆ˜ ê²€ì¦
    stats['total_episodes'] = total_episodes
    if total_episodes < min_total_episodes:
        issues.append(f"ì´ ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({total_episodes} < {min_total_episodes})")

    # 4. í‰ê·  ì •í™•ë„ ê²€ì¦
    if accuracy_count > 0:
        overall_avg_accuracy = total_accuracy_sum / accuracy_count
        stats['overall_avg_accuracy'] = overall_avg_accuracy

        if overall_avg_accuracy < 0.50:
            warnings.append(f"ì „ì²´ í‰ê·  ì •í™•ë„ê°€ ë‚®ìŒ ({overall_avg_accuracy:.2%})")
    else:
        stats['overall_avg_accuracy'] = 0.0
        warnings.append("ì •í™•ë„ ë°ì´í„° ì—†ìŒ")

    # 5. ì¸í„°ë²Œ ë¶„í¬ ê²€ì¦
    stats['interval_distribution'] = interval_stats

    # ê¸´ ì¸í„°ë²Œ(240m, 1d) ë°ì´í„° ê²€ì¦
    long_intervals = ['240m', '1d']
    has_long_interval = any(i in all_interval_selfplay for i in long_intervals)
    if not has_long_interval:
        warnings.append("ì¥ê¸° ì¸í„°ë²Œ(240m, 1d) ë°ì´í„° ì—†ìŒ - í•™ìŠµ í’ˆì§ˆ ì €í•˜ ê°€ëŠ¥")

    # 6. íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì™€ ì¼ê´€ì„± ê²€ì¦
    pipeline_intervals = {r.interval for r in pipeline_results if r.interval}
    selfplay_intervals = set(all_interval_selfplay.keys())

    missing_in_selfplay = pipeline_intervals - selfplay_intervals
    if missing_in_selfplay:
        warnings.append(f"íŒŒì´í”„ë¼ì¸ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ Self-play ê²°ê³¼ ì—†ëŠ” ì¸í„°ë²Œ: {missing_in_selfplay}")

    # 7. ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = 0.0

    # ì¸í„°ë²Œ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 30ì )
    quality_score += min(num_intervals / 4.0 * 30, 30)

    # ì—í”¼ì†Œë“œ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 30ì )
    quality_score += min(total_episodes / 50.0 * 30, 30)

    # ì •í™•ë„ ì ìˆ˜ (ìµœëŒ€ 40ì )
    if accuracy_count > 0:
        # 50% ì •í™•ë„ë¥¼ 0ì , 80% ì´ìƒì„ ë§Œì ìœ¼ë¡œ
        acc_score = max(0, (overall_avg_accuracy - 0.50) / 0.30 * 40)
        quality_score += min(acc_score, 40)

    stats['quality_score'] = round(quality_score, 2)

    # 8. ìµœì¢… ê²€ì¦ ê²°ê³¼
    valid = len(issues) == 0

    return {
        'valid': valid,
        'issues': issues,
        'warnings': warnings,
        'stats': stats,
        'quality_score': stats['quality_score']
    }


def validate_global_strategy_pool(
    pool: Dict[str, List[Dict]],
    coins: List[str],
    intervals: List[str],
    min_strategies_per_interval: int = 10
) -> Dict[str, Any]:
    """
    ê¸€ë¡œë²Œ ì „ëµ í’€ ê²€ì¦ (1ë‹¨ê³„: ê°œë³„ ì „ëµ ìˆ˜ì§‘)

    Args:
        pool: ì¸í„°ë²Œë³„ ì „ëµ í’€ {interval: [strategies]}
        coins: ìˆ˜ì§‘ ëŒ€ìƒ ì½”ì¸ ëª©ë¡
        intervals: ìˆ˜ì§‘ ëŒ€ìƒ ì¸í„°ë²Œ ëª©ë¡
        min_strategies_per_interval: ì¸í„°ë²Œë‹¹ ìµœì†Œ ì „ëµ ìˆ˜

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    issues = []
    warnings = []
    stats = {}

    # 1. ê¸°ë³¸ ê²€ì¦
    if not pool:
        issues.append("ìˆ˜ì§‘ëœ ì „ëµ í’€ì´ ë¹„ì–´ìˆìŒ")
        return {
            'valid': False,
            'issues': issues,
            'warnings': warnings,
            'stats': {}
        }

    # 2. ì¸í„°ë²Œë³„ ì „ëµ ìˆ˜ ê²€ì¦
    interval_stats = {}
    total_strategies = 0

    for interval in intervals:
        strategies = pool.get(interval, [])
        strategy_count = len(strategies)
        total_strategies += strategy_count

        interval_stat = {
            'interval': interval,
            'strategy_count': strategy_count,
            'valid': True,
            'issues': []
        }

        if strategy_count == 0:
            warnings.append(f"{interval}: ì „ëµ ì—†ìŒ")
            interval_stat['valid'] = False
            interval_stat['issues'].append("ì „ëµ ì—†ìŒ")
        elif strategy_count < min_strategies_per_interval:
            warnings.append(f"{interval}: ì „ëµ ìˆ˜ ë¶€ì¡± ({strategy_count} < {min_strategies_per_interval})")

        # ì „ëµ í’ˆì§ˆ ê²€ì¦ (ìƒ˜í”Œë§)
        if strategies:
            # ì²« 10ê°œ ì „ëµ ìƒ˜í”Œë§
            sample_size = min(10, len(strategies))
            for i, strategy in enumerate(strategies[:sample_size]):
                if not isinstance(strategy, dict):
                    interval_stat['issues'].append(f"ì „ëµ [{i}]ê°€ dict íƒ€ì…ì´ ì•„ë‹˜: {type(strategy)}")
                    continue

                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ['strategy_id', 'coin', 'interval']
                missing = [f for f in required_fields if f not in strategy]
                if missing:
                    interval_stat['issues'].append(f"ì „ëµ [{i}] í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing}")

        interval_stats[interval] = interval_stat

    stats['interval_distribution'] = interval_stats
    stats['total_strategies'] = total_strategies
    stats['intervals_covered'] = len([i for i in intervals if pool.get(i)])
    stats['intervals_expected'] = len(intervals)

    # 3. ì „ì²´ ê²€ì¦
    if stats['intervals_covered'] < len(intervals) / 2:
        warnings.append(f"ì¸í„°ë²Œ ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ ({stats['intervals_covered']}/{len(intervals)})")

    if total_strategies == 0:
        issues.append("ì „ì²´ ì „ëµ ìˆ˜ 0ê°œ")

    # 4. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = 0.0

    # ì¸í„°ë²Œ ì»¤ë²„ë¦¬ì§€ ì ìˆ˜ (40ì )
    coverage_ratio = stats['intervals_covered'] / max(1, len(intervals))
    quality_score += coverage_ratio * 40

    # ì „ëµ ìˆ˜ ì ìˆ˜ (60ì ) - ì¸í„°ë²Œë‹¹ í‰ê·  50ê°œ ê¸°ì¤€
    avg_strategies_per_interval = total_strategies / max(1, len(intervals))
    strategy_score = min(avg_strategies_per_interval / 50.0 * 60, 60)
    quality_score += strategy_score

    stats['quality_score'] = round(quality_score, 2)

    # 5. ìµœì¢… ê²€ì¦
    valid = len(issues) == 0

    return {
        'valid': valid,
        'issues': issues,
        'warnings': warnings,
        'stats': stats,
        'quality_score': stats['quality_score']
    }


def validate_global_strategy_patterns(
    patterns: Dict[str, Any],
    min_patterns_per_interval: int = 3
) -> Dict[str, Any]:
    """
    ê¸€ë¡œë²Œ ì „ëµ íŒ¨í„´ ê²€ì¦ (3ë‹¨ê³„: ê³µí†µ íŒ¨í„´ ì¶”ì¶œ)

    Args:
        patterns: ì¶”ì¶œëœ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
        min_patterns_per_interval: ì¸í„°ë²Œë‹¹ ìµœì†Œ íŒ¨í„´ ìˆ˜

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    issues = []
    warnings = []
    stats = {}

    # 1. ê¸°ë³¸ ê²€ì¦
    if not patterns:
        issues.append("ì¶”ì¶œëœ íŒ¨í„´ ì—†ìŒ")
        return {
            'valid': False,
            'issues': issues,
            'warnings': warnings,
            'stats': {}
        }

    # 2. íŒ¨í„´ êµ¬ì¡° ê²€ì¦
    total_patterns = 0
    interval_pattern_stats = {}

    for interval, interval_patterns in patterns.items():
        if not isinstance(interval_patterns, (list, dict)):
            warnings.append(f"{interval}: íŒ¨í„´ íƒ€ì… ì˜¤ë¥˜ ({type(interval_patterns)})")
            continue

        pattern_count = len(interval_patterns) if isinstance(interval_patterns, (list, dict)) else 0
        total_patterns += pattern_count

        interval_pattern_stats[interval] = {
            'interval': interval,
            'pattern_count': pattern_count
        }

        if pattern_count < min_patterns_per_interval:
            warnings.append(f"{interval}: íŒ¨í„´ ìˆ˜ ë¶€ì¡± ({pattern_count} < {min_patterns_per_interval})")

    stats['interval_patterns'] = interval_pattern_stats
    stats['total_patterns'] = total_patterns
    stats['intervals_covered'] = len(patterns)

    # 3. í’ˆì§ˆ ì ìˆ˜
    quality_score = 0.0

    # íŒ¨í„´ ìˆ˜ ì ìˆ˜ (100ì )
    if total_patterns > 0:
        quality_score = min(total_patterns / 20.0 * 100, 100)

    stats['quality_score'] = round(quality_score, 2)

    # 4. ìµœì¢… ê²€ì¦
    valid = len(issues) == 0 and total_patterns > 0

    return {
        'valid': valid,
        'issues': issues,
        'warnings': warnings,
        'stats': stats,
        'quality_score': stats['quality_score']
    }


def validate_global_strategy_quality(
    final_strategies: Dict[str, List[Dict]],
    intervals: List[str],
    min_strategies_per_interval: int = 5
) -> Dict[str, Any]:
    """
    ìµœì¢… ê¸€ë¡œë²Œ ì „ëµ í’ˆì§ˆ ê²€ì¦ (7ë‹¨ê³„: ì €ì¥ ì „)

    Args:
        final_strategies: ìµœì¢… ê¸€ë¡œë²Œ ì „ëµ {interval: [strategies]}
        intervals: ê¸°ëŒ€ë˜ëŠ” ì¸í„°ë²Œ ëª©ë¡
        min_strategies_per_interval: ì¸í„°ë²Œë‹¹ ìµœì†Œ ì „ëµ ìˆ˜

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    issues = []
    warnings = []
    stats = {}

    # 1. ê¸°ë³¸ ê²€ì¦
    if not final_strategies:
        issues.append("ìµœì¢… ì „ëµ ì—†ìŒ")
        return {
            'valid': False,
            'issues': issues,
            'warnings': warnings,
            'stats': {}
        }

    # 2. ì¸í„°ë²Œë³„ ì „ëµ ê²€ì¦
    interval_stats = {}
    total_strategies = 0

    for interval in intervals:
        strategies = final_strategies.get(interval, [])
        strategy_count = len(strategies)
        total_strategies += strategy_count

        interval_stat = {
            'interval': interval,
            'strategy_count': strategy_count,
            'valid': strategy_count >= min_strategies_per_interval
        }

        if strategy_count == 0:
            issues.append(f"{interval}: ìµœì¢… ì „ëµ ì—†ìŒ")
            interval_stat['valid'] = False
        elif strategy_count < min_strategies_per_interval:
            warnings.append(f"{interval}: ìµœì¢… ì „ëµ ìˆ˜ ë¶€ì¡± ({strategy_count} < {min_strategies_per_interval})")

        # ì „ëµ êµ¬ì¡° ê²€ì¦ (ìƒ˜í”Œë§)
        if strategies:
            sample = strategies[0] if len(strategies) > 0 else None
            if sample and not isinstance(sample, dict):
                warnings.append(f"{interval}: ì „ëµì´ dict íƒ€ì…ì´ ì•„ë‹˜")

        interval_stats[interval] = interval_stat

    stats['interval_distribution'] = interval_stats
    stats['total_strategies'] = total_strategies
    stats['intervals_covered'] = len([i for i in intervals if final_strategies.get(i)])
    stats['intervals_expected'] = len(intervals)

    # 3. ì»¤ë²„ë¦¬ì§€ ê²€ì¦
    coverage_ratio = stats['intervals_covered'] / max(1, len(intervals))
    if coverage_ratio < 0.5:
        warnings.append(f"ì¸í„°ë²Œ ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ ({stats['intervals_covered']}/{len(intervals)})")

    # 4. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = 0.0

    # ì»¤ë²„ë¦¬ì§€ ì ìˆ˜ (50ì )
    quality_score += coverage_ratio * 50

    # ì „ëµ ìˆ˜ ì ìˆ˜ (50ì ) - ì¸í„°ë²Œë‹¹ í‰ê·  20ê°œ ê¸°ì¤€
    avg_strategies = total_strategies / max(1, len(intervals))
    strategy_score = min(avg_strategies / 20.0 * 50, 50)
    quality_score += strategy_score

    stats['quality_score'] = round(quality_score, 2)
    stats['avg_strategies_per_interval'] = round(avg_strategies, 2)

    # 5. ìµœì¢… ê²€ì¦
    valid = len(issues) == 0 and total_strategies > 0

    return {
        'valid': valid,
        'issues': issues,
        'warnings': warnings,
        'stats': stats,
        'quality_score': stats['quality_score']
    }


class IntegratedPipelineOrchestrator:
    """í†µí•©ëœ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    # ğŸ”§ í´ë˜ìŠ¤ ë³€ìˆ˜: ëª¨ë¸ ìºì‹œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± - ë™ì¼ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ)
    _neural_policy_cache: Dict[str, Dict[str, Any]] = {}
    _cache_key: Optional[str] = None
    
    def __init__(self, session_id: Optional[str] = None):
        self.session_id = session_id  # ë””ë²„ê·¸ ì„¸ì…˜ ID ì €ì¥
        if NEW_PIPELINE_AVAILABLE:
            self.strategy_manager = None
            self.regime_router = RegimeRouter(session_id=session_id)
            self.integrated_analyzer = IntegratedAnalyzer(session_id=session_id)
        else:
            self.strategy_manager = None
            self.regime_router = None
            self.integrated_analyzer = None

        # ğŸ”¥ self-play ê²°ê³¼ ì €ì¥ì†Œ (ì¸í„°ë²Œë³„ - í†µí•© í•™ìŠµì— ì‚¬ìš©)
        self._current_selfplay_result: Dict[str, Dict[str, Any]] = {}

        logger.info("ğŸš€ í†µí•©ëœ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_complete_pipeline(self, coin: str, interval: str, candle_data: pd.DataFrame) -> PipelineResult:
        """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            start_time = datetime.now()
            logger.info(f"ğŸš€ {coin}-{interval} í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # 1ë‹¨ê³„: ì „ëµ ìƒì„±
            logger.info("1ï¸âƒ£ ì „ëµ ìƒì„± ë‹¨ê³„ ì‹œì‘")
            strategies = self._create_strategies(coin, interval, candle_data)
            logger.info(f"âœ… {len(strategies)}ê°œ ì „ëµ ìƒì„± ì™„ë£Œ")

            # ğŸ§¬ 1-1ë‹¨ê³„: ê¸°ì¡´ ì „ëµ ì§„í™” (ìœ ì „ ì•Œê³ ë¦¬ì¦˜)
            evolved_genetic_strategies = self._evolve_existing_strategies(coin, interval, strategies)
            if evolved_genetic_strategies:
                strategies.extend(evolved_genetic_strategies)
                logger.info(f"ğŸ§¬ {len(evolved_genetic_strategies)}ê°œ ì§„í™” ì „ëµ ì¶”ê°€ (ì´ {len(strategies)}ê°œ)")

            # 2ë‹¨ê³„: Self-play ì§„í™” + ì‹¤ì œ ìº”ë“¤ ë°ì´í„° ì „ë‹¬ ğŸ”¥
            logger.info("2ï¸âƒ£ Self-play ì§„í™” ë‹¨ê³„ ì‹œì‘")
            evolved_strategies = self._evolve_strategies_with_selfplay(coin, strategies, interval, candle_data)
            logger.info(f"âœ… Self-play ì§„í™” ì™„ë£Œ: {len(evolved_strategies)}ê°œ ì „ëµ")
            
            # 3ë‹¨ê³„: í†µí•©ë¶„ì„ (ë ˆì§ ë¼ìš°íŒ… ì œê±°, ì „ëµì„ ì§ì ‘ ì „ë‹¬)
            logger.info("3ï¸âƒ£ í†µí•©ë¶„ì„ ë‹¨ê³„ ì‹œì‘")
            analysis_result = self._perform_integrated_analysis(coin, interval, evolved_strategies, candle_data)
            
            # ğŸ”¥ analysis_resultëŠ” dictë¡œ ë°˜í™˜ë˜ë¯€ë¡œ dict ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼
            if isinstance(analysis_result, dict):
                signal_action = analysis_result.get('signal_action', 'HOLD')
                signal_score = analysis_result.get('signal_score', analysis_result.get('final_signal_score', 0.0))
                logger.info(f"âœ… í†µí•©ë¶„ì„ ì™„ë£Œ: {signal_action} (ì ìˆ˜: {signal_score:.3f})")
            else:
                # ê°ì²´ì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
                signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
                signal_score = getattr(analysis_result, 'final_signal_score', getattr(analysis_result, 'signal_score', 0.0))
                logger.info(f"âœ… í†µí•©ë¶„ì„ ì™„ë£Œ: {signal_action} (ì ìˆ˜: {signal_score:.3f})")
            
            # ğŸ”¥ 3-1ë‹¨ê³„: ì „ëµ ë“±ê¸‰ ë™ì  ì—…ë°ì´íŠ¸ (ë ˆì§ ë¼ìš°íŒ… ì œê±°)
            try:
                from rl_pipeline.analysis.strategy_grade_updater import StrategyGradeUpdater
                grade_updater = StrategyGradeUpdater()
                
                # í†µí•© ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ë“±ê¸‰ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
                analysis_grade_updates = grade_updater.update_grades_from_analysis_results(
                    coin, interval, analysis_result, evolved_strategies
                )
                
                # í†µí•© ì—…ë°ì´íŠ¸ ì ìš©
                if analysis_grade_updates:
                    updated_count = grade_updater.apply_grade_updates(coin, interval, analysis_grade_updates, update_db=True)
                    logger.info(f"ğŸ”¥ [{coin}-{interval}] ì „ëµ ë“±ê¸‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ ì „ëµ")
                else:
                    logger.debug(f"ğŸ“Š [{coin}-{interval}] ë“±ê¸‰ ì—…ë°ì´íŠ¸ ëŒ€ìƒ ì—†ìŒ")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ì „ëµ ë“±ê¸‰ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            # ğŸ”¥ ê²°ê³¼ ì €ì¥: í†µí•© ë¶„ì„ë§Œ ì €ì¥
            try:
                if analysis_result:
                    # regime ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    try:
                        regime = getattr(analysis_result, 'regime', 'neutral')
                    except:
                        regime = 'neutral'
                    learning_results.save_integrated_analysis_results(coin, interval, regime, analysis_result)
                else:
                    logger.warning(f"âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ì–´ ì €ì¥ ê±´ë„ˆëœ€: {coin}-{interval}")
            except Exception as e:
                logger.warning(f"âš ï¸ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ğŸ†• ì‹œê·¸ë„ ê³„ì‚°ìš© ìš”ì•½ ë°ì´í„° ì €ì¥ (rl_strategies.db)
            try:
                from rl_pipeline.db.learning_results import (
                    save_strategy_summary_for_signals,
                    save_dna_summary_for_signals,
                    save_global_strategy_summary_for_signals,
                    save_analysis_summary_for_signals
                )
                
                logger.info(f"ğŸ“Š {coin}-{interval} ì‹œê·¸ë„ ê³„ì‚°ìš© ìš”ì•½ ë°ì´í„° ì €ì¥ ì‹œì‘...")
                
                # ì „ëµ ìš”ì•½ ì €ì¥
                save_strategy_summary_for_signals(coin, interval)
                
                # DNA ìš”ì•½ ì €ì¥
                save_dna_summary_for_signals(coin, interval)
                
                # ë¶„ì„ ìš”ì•½ ì €ì¥
                save_analysis_summary_for_signals(coin, interval)
                
                # ê¸€ë¡œë²Œ ì „ëµ ìš”ì•½ ì €ì¥ (ì¸í„°ë²Œë³„)
                save_global_strategy_summary_for_signals(interval)
                
                logger.info(f"âœ… {coin}-{interval} ì‹œê·¸ë„ ê³„ì‚°ìš© ìš”ì•½ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì‹œê·¸ë„ ê³„ì‚°ìš© ìš”ì•½ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ğŸ”¥ 5ë‹¨ê³„: ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ (ê±°ë˜ ì‹œìŠ¤í…œ ì—°ë™) - ì„ íƒì 
            # âš ï¸ absolute_zero_systemì€ trading_system.dbì™€ ë¬´ê´€í•´ì•¼ í•˜ë¯€ë¡œ ë¹„í™œì„±í™”
            # í™œì„±í™”í•˜ë ¤ë©´ ENABLE_TRADING_SYSTEM_INTEGRATION=true í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            enable_trading_integration = os.getenv('ENABLE_TRADING_SYSTEM_INTEGRATION', 'false').lower() == 'true'
            if enable_trading_integration:
                try:
                    from rl_pipeline.db.realtime_signal_storage import save_realtime_signal_from_analysis
                    
                    logger.info("5ï¸âƒ£ ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ë‹¨ê³„ ì‹œì‘")
                    signal_saved = save_realtime_signal_from_analysis(
                        coin, interval, analysis_result, candle_data
                    )
                    
                    if signal_saved:
                        logger.info(f"âœ… [{coin}-{interval}] ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ì™„ë£Œ (ê±°ë˜ ì‹œìŠ¤í…œ ì—°ë™)")
                    else:
                        logger.warning(f"âš ï¸ [{coin}-{interval}] ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ì‹¤íŒ¨")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                logger.debug(f"ğŸ“Š {coin}-{interval}: ê±°ë˜ ì‹œìŠ¤í…œ ì—°ë™ ë¹„í™œì„±í™” (ENABLE_TRADING_SYSTEM_INTEGRATION=false)")
            
            # ê²°ê³¼ ìƒì„±
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # ğŸ”¥ analysis_resultê°€ dictì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
            if analysis_result:
                if isinstance(analysis_result, dict):
                    regime_detected = analysis_result.get('regime', 'neutral')
                    signal_score = analysis_result.get('signal_score', analysis_result.get('final_signal_score', 0.0))
                    signal_action = analysis_result.get('signal_action', 'HOLD')
                else:
                    regime_detected = getattr(analysis_result, 'regime', 'neutral')
                    signal_score = getattr(analysis_result, 'final_signal_score', getattr(analysis_result, 'signal_score', 0.0))
                    signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
            else:
                regime_detected = 'neutral'
                signal_score = 0.0
                signal_action = 'HOLD'
            
            result = PipelineResult(
                coin=coin,
                interval=interval,
                strategies_created=len(strategies),
                selfplay_episodes=len(evolved_strategies),
                regime_detected=regime_detected,
                routing_results=0,  # ë ˆì§ ë¼ìš°íŒ… ì œê±°ë¨
                signal_score=signal_score,
                signal_action=signal_action,
                execution_time=execution_time,
                status="success",
                created_at=datetime.now().isoformat()
            )
            
            logger.info(f"ğŸ‰ {coin}-{interval} íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {execution_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"âŒ {coin}-{interval} íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            logger.debug(f"íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´:\n{error_details}")
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # ì‹¤íŒ¨í•œ ë‹¨ê³„ ì •ë³´ ê¸°ë¡
            failed_step = getattr(e, 'failed_step', 'unknown')
            logger.warning(f"âš ï¸ {coin}-{interval} íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ë‹¨ê³„: {failed_step}, ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
            
            return PipelineResult(
                coin=coin,
                interval=interval,
                strategies_created=0,
                selfplay_episodes=0,
                regime_detected="unknown",
                routing_results=0,
                signal_score=0.0,
                signal_action="HOLD",
                execution_time=execution_time,
                status="failed",
                created_at=datetime.now().isoformat()
            )
    
    def _create_strategies(self, coin: str, interval: str, candle_data: pd.DataFrame) -> List[Dict[str, Any]]:
        """1ë‹¨ê³„: ì „ëµ ìƒì„± (ì½”ì¸ë³„ ì „ëµë§Œ)"""
        try:
            if not NEW_PIPELINE_AVAILABLE:
                logger.warning("âš ï¸ ìƒˆë¡œìš´ ëª¨ë“ˆë“¤ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ì—¬ ê¸°ë³¸ ì „ëµ ìƒì„±")
                return self._create_default_strategies(coin, interval)
            
            # ì½”ì¸ë³„ ì „ëµ ìƒì„±ë§Œ ìˆ˜í–‰ (ê¸€ë¡œë²Œ ì „ëµì€ ëª¨ë“  ì‹œê°„ëŒ€ ì™„ë£Œ í›„ì— ìƒì„±)
            # create_coin_strategies ë‚´ë¶€ì—ì„œ ì´ë¯¸ ë°ì´í„° ë¶€ì¡± ì‹œ create_basic_strategy()ë¡œ í´ë°± ì²˜ë¦¬ë¨
            strategies_count = create_coin_strategies(coin, [interval], {(coin, interval): candle_data})
            
            logger.info(f"ğŸ“Š ì½”ì¸ë³„ ì „ëµ ìƒì„± ì™„ë£Œ: {strategies_count}ê°œ")
            
            # ğŸ”¥ DB ì»¤ë°‹ í›„ ì²´í¬í¬ì¸íŠ¸ ìˆ˜í–‰ (ë‹¤ë¥¸ ì»¤ë„¥ì…˜ì´ ì¦‰ì‹œ ì½ì„ ìˆ˜ ìˆë„ë¡)
            try:
                from rl_pipeline.db.connection_pool import get_optimized_db_connection
                with get_optimized_db_connection("strategies") as conn:
                    conn.execute("PRAGMA wal_checkpoint(PASSIVE)")
                    conn.commit()
                    logger.info("ğŸ” WAL ì²´í¬í¬ì¸íŠ¸ ì™„ë£Œ (ë‹¤ë¥¸ ì»¤ë„¥ì…˜ì—ì„œ ì¦‰ì‹œ ì¡°íšŒ ê°€ëŠ¥)")
            except Exception as e:
                logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì‹¤íŒ¨: {e}")
            
            # DBì—ì„œ ìƒì„±ëœ ì „ëµ ì¡°íšŒ (ë°©ê¸ˆ ìƒì„±í•œ ì „ëµ í¬í•¨) - ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©
            try:
                from rl_pipeline.db.reads import load_strategies_pool
                from datetime import datetime

                # ğŸ†• ì¦ë¶„ í•™ìŠµ: í•™ìŠµ ì™„ë£Œë˜ì§€ ì•Šì€ ì „ëµë§Œ ë¡œë“œ
                # training_historyì— ì—†ëŠ” ì „ëµ = í•™ìŠµ í•„ìš”í•œ ì „ëµ
                logger.info(f"ğŸ“Š {coin}-{interval}: ë¯¸í•™ìŠµ ì „ëµ ë¡œë“œ ì‹œì‘ (ì¦ë¶„ í•™ìŠµ ëª¨ë“œ)")

                # ë¯¸í•™ìŠµ ì „ëµ ë¡œë“œ (LEFT JOINìœ¼ë¡œ training_history ì—†ëŠ” ê²ƒë§Œ)
                from rl_pipeline.db.connection_pool import get_optimized_db_connection

                db_strategies = []
                try:
                    with get_optimized_db_connection("strategies") as conn:
                        cursor = conn.cursor()

                        # training_historyì— ì—†ëŠ” ì „ëµë§Œ ì¡°íšŒ
                        query = """
                            SELECT cs.*
                            FROM coin_strategies cs
                            LEFT JOIN strategy_training_history sth ON cs.id = sth.strategy_id
                            WHERE cs.coin = ? AND cs.interval = ?
                              AND sth.strategy_id IS NULL
                            ORDER BY cs.created_at DESC
                            LIMIT 100
                        """

                        cursor.execute(query, (coin, interval))
                        rows = cursor.fetchall()

                        # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
                        columns = [desc[0] for desc in cursor.description]

                        # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        for row in rows:
                            strategy_dict = dict(zip(columns, row))
                            db_strategies.append(strategy_dict)

                except Exception as e:
                    logger.error(f"âŒ ë¯¸í•™ìŠµ ì „ëµ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    # Fallback: ê¸°ì¡´ ë°©ì‹
                    db_strategies = load_strategies_pool(
                        coin=coin,
                        interval=interval,
                        limit=100,
                        order_by="created_at DESC, id DESC",
                        include_unknown=True
                    )

                logger.info(f"âœ… {coin}-{interval}: {len(db_strategies)}ê°œ ë¯¸í•™ìŠµ ì „ëµ ë¡œë“œ ì™„ë£Œ")
                
                # ğŸ” ë””ë²„ê¹…: ì‹¤ì œ ì¡°íšŒëœ í–‰ ìˆ˜ í™•ì¸
                logger.info(f"ğŸ” DB ì¿¼ë¦¬ ê²°ê³¼: {len(db_strategies)}ê°œ í–‰ ì¡°íšŒë¨")
                
                # ì „ì²´ ì „ëµ ìˆ˜ í™•ì¸
                try:
                    from rl_pipeline.db.connection_pool import get_optimized_db_connection
                    with get_optimized_db_connection("strategies") as conn:
                        cursor = conn.cursor()
                        count_query = "SELECT COUNT(*) FROM coin_strategies WHERE coin = ? AND interval = ?"
                        cursor.execute(count_query, (coin, interval))
                        total_count = cursor.fetchone()[0]
                        logger.info(f"ğŸ” DB ì „ì²´ ì „ëµ ìˆ˜: {total_count}ê°œ")
                except Exception:
                    pass
                
                # ğŸ” ë””ë²„ê¹…: ì²« 5ê°œ ì „ëµì˜ ID ì¶œë ¥
                if db_strategies:
                    logger.info(f"ğŸ” ë¡œë“œëœ ì „ëµ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ):")
                    for i, s in enumerate(db_strategies[:5]):
                        logger.info(f"  [{i+1}] ID: {s.get('id', 'N/A')}, created_at: {s.get('created_at', 'N/A')}")
                
                if db_strategies:
                    logger.info(f"âœ… DBì—ì„œ {len(db_strategies)}ê°œ ì „ëµ ë¡œë“œ ì™„ë£Œ (ë°©ê¸ˆ ìƒì„±í•œ ì „ëµ í¬í•¨)")
                    
                    # ğŸ†• ë°©í–¥ì„± í•„í„°ë§ (ì„ íƒì  ì‚¬ìš© - í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
                    # ì „ëµ ë‹¤ì–‘ì„±ì„ ìœ„í•´ í•„í„°ë§ì„ ì„ íƒì ìœ¼ë¡œë§Œ ì‚¬ìš©
                    enable_filtering = os.getenv('ENABLE_STRATEGY_DIRECTION_FILTERING', 'false').lower() == 'true'
                    
                    if enable_filtering:
                        filtered_strategies = self._filter_strategies_by_direction(
                            db_strategies, coin, interval, candle_data
                        )
                        
                        if filtered_strategies and len(filtered_strategies) >= len(db_strategies) * 0.5:
                            # í•„í„°ë§ í›„ 50% ì´ìƒ ë‚¨ìœ¼ë©´ ì‚¬ìš©
                            logger.info(f"âœ… ë°©í–¥ì„± í•„í„°ë§ ì™„ë£Œ: {len(db_strategies)}ê°œ â†’ {len(filtered_strategies)}ê°œ (ë°©í–¥ì„± ìˆëŠ” ì „ëµë§Œ)")
                            return filtered_strategies
                        else:
                            # í•„í„°ë§ í›„ ì „ëµì´ ë¶€ì¡±í•˜ë©´ ì›ë³¸ ì‚¬ìš© (ëª¨ë“  ì „ëµ í…ŒìŠ¤íŠ¸)
                            logger.info(f"ğŸ“Š ë°©í–¥ì„± í•„í„°ë§ ê²°ê³¼ ë¶€ì¡± ({len(filtered_strategies) if filtered_strategies else 0}ê°œ), ëª¨ë“  ì „ëµ ì‚¬ìš© (ë‹¤ì–‘ì„± í™•ë³´)")
                            return db_strategies
                    else:
                        # í•„í„°ë§ ë¹„í™œì„±í™”: ëª¨ë“  ì „ëµ ì‚¬ìš© (ë‹¤ì–‘ì„± í™•ë³´)
                        logger.info(f"ğŸ“Š ë°©í–¥ì„± í•„í„°ë§ ë¹„í™œì„±í™”, ëª¨ë“  {len(db_strategies)}ê°œ ì „ëµ ì‚¬ìš© (ë‹¤ì–‘ì„± í™•ë³´)")
                        return db_strategies
                else:
                    logger.warning(f"âš ï¸ DB ì¡°íšŒ ê²°ê³¼ 0ê°œ, ê¸°ë³¸ ì „ëµ ì‚¬ìš©")
                    return self._create_default_strategies(coin, interval)
            except Exception as e:
                logger.warning(f"âš ï¸ DB ì „ëµ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return self._create_default_strategies(coin, interval)
            
        except Exception as e:
            logger.error(f"âŒ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_default_strategies(coin, interval)
    
    def _run_predictive_selfplay(self, coin: str, interval: str, strategies: List[Dict[str, Any]], candle_data: pd.DataFrame):
        """ğŸ”¥ ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ë£¨í”„ ì‹¤í–‰ (ì „ëµ ìƒì„± ì§í›„)

        ê°•í™”í•™ìŠµ ë£¨í”„ë¥¼ í†µí•´ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤:
        1. ì˜ˆì¸¡ ìƒì„± (ë°©í–¥, í™•ì‹ ë„, horizon_k)
        2. ì‹¤ì œ ê²°ê³¼ í™•ì¸ (TP/SL ë„ë‹¬ ì‹œì , ìˆ˜ìµë¥ )
        3. ë³´ìƒ ê³„ì‚° (ë°©í–¥ ì •í™•ë„, horizon_k ì •í™•ë„, ìˆ˜ìµë¥ )
        4. ì •ì±… ì—…ë°ì´íŠ¸ (ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ì€ ì „ëµì˜ í™•ì‹ ë„ ì¦ê°€, horizon_k ìµœì í™”)
        5. ë°˜ë³µ (ì—¬ëŸ¬ ì—í”¼ì†Œë“œ)

        í•™ìŠµ ëª©í‘œ:
        - ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ (predicted_dir)
        - ìµœì  ìº”ë“¤ ì‹œì  ì°¾ê¸° (horizon_k) - ëª‡ ë²ˆì§¸ ìº”ë“¤ì—ì„œ ê°€ì¥ ë†’ì€ ìˆ˜ìµë¥ ì¸ì§€
        - ì‹ ë¢°ë„ í–¥ìƒ (predicted_conf)

        Returns:
            Dict: Self-play ê²°ê³¼ (cycle_results, episodes, avg_accuracy í¬í•¨)
        """
        try:
            if not strategies or len(strategies) == 0:
                logger.warning("âš ï¸ ì˜ˆì¸¡ Self-play: ì „ëµì´ ì—†ì–´ ê±´ë„ˆëœ€")
                return None

            if candle_data is None or len(candle_data) < 20:
                logger.warning("âš ï¸ ì˜ˆì¸¡ Self-play: ìº”ë“¤ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê±´ë„ˆëœ€")
                return None

            logger.info(f"ğŸ”¥ ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ì‹œì‘: {coin}-{interval} ({len(strategies)}ê°œ ì „ëµ, {PREDICTIVE_SELFPLAY_EPISODES}ê°œ ì—í”¼ì†Œë“œ)")

            # ì˜ˆì¸¡ Self-play ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©
            try:
                from rl_pipeline.simulation import PREDICTIVE_SELFPLAY_AVAILABLE, run_predictive_self_play_test

                if PREDICTIVE_SELFPLAY_AVAILABLE and run_predictive_self_play_test:
                    # ì˜ˆì¸¡ Self-play ì‹¤í–‰
                    logger.info("ğŸ“Š ì˜ˆì¸¡ Self-play ëª¨ë“ˆ ì‚¬ìš©")
                    # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    from rl_pipeline.db.reads import extract_strategy_params
                    strategy_params_list = [extract_strategy_params(strategy) for strategy in strategies[:100]]  # ìµœëŒ€ 100ê°œ

                    predictive_result = run_predictive_self_play_test(
                        strategies=strategy_params_list,
                        candle_data=candle_data,
                        coin=coin,
                        interval=interval
                    )

                    if predictive_result:
                        logger.info(f"âœ… ì˜ˆì¸¡ Self-play ì™„ë£Œ: {predictive_result.get('episodes', 0)}ê°œ ì—í”¼ì†Œë“œ")
                        return predictive_result
                    else:
                        logger.warning("âš ï¸ ì˜ˆì¸¡ Self-play ê²°ê³¼ ì—†ìŒ")
                        return None
                else:
                    # ğŸ”¥ ê°•í™”í•™ìŠµ ë£¨í”„ ì‹¤í–‰ (ì˜ˆì¸¡ Self-play ëª¨ë“ˆì´ ì—†ì„ ë•Œ)
                    logger.info("ğŸ“Š ì˜ˆì¸¡ Self-play ëª¨ë“ˆ ì—†ìŒ, ê°•í™”í•™ìŠµ ë£¨í”„ ëª¨ë“œ ì‚¬ìš©")
                    result = self._run_predictive_rl_loop(coin, interval, strategies, candle_data)
                    return result

            except ImportError:
                # ğŸ”¥ ê°•í™”í•™ìŠµ ë£¨í”„ ì‹¤í–‰ (ì˜ˆì¸¡ Self-play ëª¨ë“ˆì´ ì—†ì„ ë•Œ)
                logger.info("ğŸ“Š ì˜ˆì¸¡ Self-play ëª¨ë“ˆ ì—†ìŒ, ê°•í™”í•™ìŠµ ë£¨í”„ ëª¨ë“œ ì‚¬ìš©")
                result = self._run_predictive_rl_loop(coin, interval, strategies, candle_data)
                return result

        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ Self-play ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            logger.exception(e)
            return None
    
    def _run_predictive_rl_loop(self, coin: str, interval: str, strategies: List[Dict[str, Any]], candle_data: pd.DataFrame):
        """ğŸ”¥ ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ë£¨í”„ ì‹¤í–‰

        ë°˜ë³µ í•™ìŠµì„ í†µí•´ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤:
        1. ì˜ˆì¸¡ ìƒì„± (í•™ìŠµëœ ì •ì±… ì‚¬ìš©) - ëª¨ë“  ì „ëµì— ëŒ€í•´
        2. ì‹¤ì œ ê²°ê³¼ í™•ì¸ (TP/SL ë„ë‹¬ ì‹œì , ìˆ˜ìµë¥ )
        3. ë³´ìƒ ê³„ì‚°
        4. ì •ì±… ì—…ë°ì´íŠ¸
        5. ë°˜ë³µ (ìµœëŒ€ PREDICTIVE_SELFPLAY_EPISODESë²ˆ)

        êµ¬ì¡°: 50ê°œ ì „ëµ Ã— 50ê°œ ì—í”¼ì†Œë“œ = ì´ 2500ë²ˆì˜ ì˜ˆì¸¡ ìƒì„±/í•™ìŠµ
        ê° ì—í”¼ì†Œë“œë§ˆë‹¤ ëª¨ë“  ì „ëµì— ëŒ€í•´ ì˜ˆì¸¡ ìƒì„± â†’ ê²°ê³¼ í™•ì¸ â†’ ì •ì±… ì—…ë°ì´íŠ¸

        Returns:
            Dict: Self-play ê²°ê³¼ (cycle_results, episodes, avg_accuracy í¬í•¨)
        """
        try:
            # ì „ëµë³„ ì˜ˆì¸¡ ì •ì±… ì´ˆê¸°í™” (í™•ì‹ ë„, horizon_k)
            strategy_policies = {}
            for strategy in strategies[:100]:  # ìµœëŒ€ 100ê°œ ì „ëµ
                strategy_id = strategy.get('id', 'unknown')
                strategy_policies[strategy_id] = {
                    'predicted_conf': 0.5,  # ì´ˆê¸° í™•ì‹ ë„
                    'horizon_k': 10,  # ì´ˆê¸° horizon_k
                    'direction': None,  # ì „ëµ ë°©í–¥ (buy/sell/neutral)
                    'accuracy_history': [],  # ì •í™•ë„ ì´ë ¥
                    'reward_history': [],  # ë³´ìƒ ì´ë ¥
                    'opposite_direction_count': 0,  # ğŸ”¥ ë°˜ëŒ€ ë°©í–¥ ë°œìƒ íšŸìˆ˜
                    'total_predictions': 0,  # ğŸ”¥ ì´ ì˜ˆì¸¡ íšŸìˆ˜
                    'direction_reassessed': False  # ğŸ”¥ ë°©í–¥ ì¬í‰ê°€ ì—¬ë¶€
                }

            # ğŸ”¥ ì¸í„°ë²Œë³„ë¡œ ë‹¤ë¥¸ ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì ìš©
            interval_config = {
                '15m': {'min_episodes': 20, 'patience': 15, 'accuracy_threshold': 0.75},  # ğŸ”¥ ê°œì„ : min_episodes 10â†’20, patience 5â†’15, threshold 0.85â†’0.75
                '30m': {'min_episodes': 25, 'patience': 18, 'accuracy_threshold': 0.70},  # ğŸ”¥ ê°œì„ : min_episodes 15â†’25, patience 6â†’18, threshold 0.80â†’0.70
                '240m': {'min_episodes': 30, 'patience': 20, 'accuracy_threshold': 0.65},  # ğŸ”¥ ê°œì„ : min_episodes 20â†’30, patience 8â†’20, threshold 0.70â†’0.65
                '1d': {'min_episodes': 35, 'patience': 25, 'accuracy_threshold': 0.60}  # ğŸ”¥ ê°œì„ : min_episodes 25â†’35, patience 10â†’25, threshold 0.65â†’0.60
            }
            config = interval_config.get(interval, {'min_episodes': PREDICTIVE_SELFPLAY_MIN_EPISODES, 'patience': PREDICTIVE_SELFPLAY_EARLY_STOP_PATIENCE, 'accuracy_threshold': PREDICTIVE_SELFPLAY_EARLY_STOP_ACCURACY})

            min_episodes = config['min_episodes']
            patience = config['patience']
            accuracy_threshold = config['accuracy_threshold']

            logger.info(f"ğŸ“Š ì˜ˆì¸¡ Self-play êµ¬ì¡°: {len(strategies)}ê°œ ì „ëµ Ã— {PREDICTIVE_SELFPLAY_EPISODES}ê°œ ì—í”¼ì†Œë“œ = ìµœëŒ€ {len(strategies) * PREDICTIVE_SELFPLAY_EPISODES}ë²ˆ í•™ìŠµ")
            logger.info(f"ğŸ“Š {interval} ì¡°ê¸° ì¢…ë£Œ ì„¤ì •: ìµœì†Œ ì—í”¼ì†Œë“œ {min_episodes}ê°œ, patience {patience}íšŒ, ì •í™•ë„ ì„ê³„ê°’ {accuracy_threshold:.2%}")

            # ğŸ”¥ ì¡°ê¸° ì¢…ë£Œ ì„¤ì • ë¡œê¹… (ë””ë²„ê·¸ìš©)
            try:
                from rl_pipeline.monitoring.simulation_debugger import SimulationDebugger
                early_stop_debugger = SimulationDebugger(session_id=None)  # ì „ì—­ ë¡œê±°
                early_stop_debugger.log({
                    'event': 'early_stop_config',
                    'coin': coin,
                    'interval': interval,
                    'min_episodes': min_episodes,
                    'patience': patience,
                    'accuracy_threshold': accuracy_threshold,
                    'max_episodes': PREDICTIVE_SELFPLAY_EPISODES,
                    'min_improvement': PREDICTIVE_SELFPLAY_MIN_IMPROVEMENT
                })
            except Exception as debug_err:
                logger.debug(f"âš ï¸ ì¡°ê¸° ì¢…ë£Œ ì„¤ì • ë¡œê¹… ì‹¤íŒ¨: {debug_err}")

            # ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ ë³€ìˆ˜
            best_accuracy = 0.0
            no_improvement_count = 0
            accuracy_history = []  # ì „ì²´ í‰ê·  ì •í™•ë„ ì´ë ¥
            cycle_results = []  # ğŸ”¥ ì—í”¼ì†Œë“œë³„ ê²°ê³¼ ì €ì¥

            # ê°•í™”í•™ìŠµ ë£¨í”„
            for episode in range(PREDICTIVE_SELFPLAY_EPISODES):
                logger.debug(f"ğŸ“Š ì˜ˆì¸¡ Self-play ì—í”¼ì†Œë“œ {episode + 1}/{PREDICTIVE_SELFPLAY_EPISODES} ({len(strategies)}ê°œ ì „ëµ)")

                # 1. ì˜ˆì¸¡ ìƒì„± (í•™ìŠµëœ ì •ì±… ì‚¬ìš©) - ëª¨ë“  ì „ëµì— ëŒ€í•´
                predictions = self._create_predictions_with_policy(
                    coin, interval, strategies, candle_data, strategy_policies, episode
                )

                if not predictions:
                    logger.warning(f"âš ï¸ ì—í”¼ì†Œë“œ {episode + 1}: ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨")
                    continue

                # 2. ì‹¤ì œ ê²°ê³¼ í™•ì¸ (TP/SL ë„ë‹¬ ì‹œì , ìˆ˜ìµë¥ )
                results = self._check_prediction_results(
                    coin, interval, predictions, candle_data
                )

                if not results:
                    logger.warning(f"âš ï¸ ì—í”¼ì†Œë“œ {episode + 1}: ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨")
                    continue

                # 3. ë³´ìƒ ê³„ì‚° ë° ì •ì±… ì—…ë°ì´íŠ¸
                self._update_prediction_policy(
                    coin, interval, results, strategy_policies
                )

                # í˜„ì¬ ì—í”¼ì†Œë“œì˜ í‰ê·  ì •í™•ë„ ê³„ì‚°
                # ğŸ”¥ ìµœê·¼ 5ê°œ ì—í”¼ì†Œë“œì˜ í‰ê·  ì •í™•ë„ ì‚¬ìš© (ë” ì•ˆì •ì ì¸ ì¸¡ì •)
                current_accuracy = np.mean([
                    np.mean(p['accuracy_history'][-5:]) if len(p['accuracy_history']) >= 5 else (np.mean(p['accuracy_history']) if p['accuracy_history'] else 0.0)
                    for p in strategy_policies.values()
                ])
                accuracy_history.append(current_accuracy)

                # ğŸ”¥ ì—í”¼ì†Œë“œ ê²°ê³¼ ì €ì¥ (í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ results í‚¤ ì¶”ê°€)
                # ì˜ˆì¸¡ self-playëŠ” ì „ëµë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ resultsì— í¬í•¨

                # ğŸ†• resultsë¥¼ episode_idë¡œ ë§¤í•‘í•˜ì—¬ ë¹ ë¥´ê²Œ ì¡°íšŒ (actual ê°’ í¬í•¨)
                results_by_episode_id = {r['episode_id']: r for r in results}

                episode_results = {}
                for strategy_id, policy in strategy_policies.items():
                    if strategy_id in [p.get('strategy_id') for p in predictions]:
                        # ì „ëµë³„ ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
                        strategy_predictions = [p for p in predictions if p.get('strategy_id') == strategy_id]
                        if strategy_predictions:
                            # ğŸ”¥ ì˜ˆì¸¡ ë°©í–¥ì„ trades í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•™ìŠµ ì‹œìŠ¤í…œì´ ì•¡ì…˜ì„ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡)
                            trades = []
                            for pred in strategy_predictions:
                                predicted_dir = pred.get('predicted_dir', 0)
                                # predicted_dir: 1=BUY, -1=SELL, 0=HOLD
                                if predicted_dir == 1:
                                    direction = 'BUY'
                                elif predicted_dir == -1:
                                    direction = 'SELL'
                                else:
                                    direction = 'HOLD'

                                # ğŸ†• episode_idë¡œ actual ê°’ ì¡°íšŒ
                                episode_id = pred.get('episode_id')
                                actual_result = results_by_episode_id.get(episode_id, {})

                                trades.append({
                                    'direction': direction,
                                    'entry_price': round(pred.get('entry_price', 0.0), 8),  # ê°€ê²© ì†Œìˆ«ì  8ìë¦¬
                                    'predicted_conf': round(pred.get('predicted_conf', 0.5), 2),  # ì†Œìˆ«ì  2ìë¦¬
                                    'horizon_k': int(pred.get('horizon_k', 10)),  # ì •ìˆ˜
                                    'target_move_pct': round(pred.get('target_move_pct', 0.02), 4),  # ì†Œìˆ«ì  4ìë¦¬
                                    # ğŸ†• ì‹¤ì œ ê²°ê³¼ ì¶”ê°€ (í•™ìŠµìš© ë ˆì´ë¸”)
                                    'actual_move_pct': round(actual_result.get('actual_move_pct', 0.0), 4),  # ì†Œìˆ«ì  4ìë¦¬
                                    'actual_horizon': int(actual_result.get('actual_horizon', pred.get('horizon_k', 10))),  # ì •ìˆ˜
                                    'actual_dir': actual_result.get('actual_dir', 0),
                                    'reward': round(actual_result.get('reward', 0.0), 4)  # ì†Œìˆ«ì  4ìë¦¬
                                })
                            
                            # ğŸ”¥ ì „ëµ ë°©í–¥ ì •ë³´ ì¶”ê°€ (ë§¤ìˆ˜/ë§¤ë„ ì „ëµ êµ¬ë¶„ì„ ìœ„í•´)
                            strategy_direction = policy.get('direction', 'neutral')  # 'buy', 'sell', 'neutral'
                            
                            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„±ê³¼ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            episode_results[strategy_id] = {
                                'total_pnl': 0.0,  # ì˜ˆì¸¡ self-playì—ì„œëŠ” ì§ì ‘ ê³„ì‚° ë¶ˆê°€
                                'win_rate': policy.get('accuracy_history', [0.0])[-1] if policy.get('accuracy_history') else 0.0,
                                'total_trades': len(strategy_predictions),
                                'trades': trades,  # ğŸ”¥ ì˜ˆì¸¡ ë°©í–¥ì„ trades í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                'accuracy': policy.get('accuracy_history', [0.0])[-1] if policy.get('accuracy_history') else 0.0,
                                'predicted_conf': policy.get('predicted_conf', 0.5),
                                'horizon_k': policy.get('horizon_k', 10),
                                'strategy_direction': strategy_direction  # ğŸ”¥ ì „ëµ ë°©í–¥ ì¶”ê°€ (ë§¤ìˆ˜/ë§¤ë„ êµ¬ë¶„)
                            }

                cycle_results.append({
                    'episode': episode + 1,
                    'accuracy': current_accuracy,
                    'best_accuracy': best_accuracy,
                    'predictions': len(predictions),
                    'results': episode_results  # ğŸ”¥ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ ì¶”ê°€
                })

                # ğŸ”¥ ì¡°ê¸° ì¢…ë£Œ ì²´í¬ (ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ í™•ì¸)
                if PREDICTIVE_SELFPLAY_EARLY_STOP and (episode + 1) >= min_episodes:
                    # ì •í™•ë„ ì„ê³„ê°’ ë‹¬ì„± ì²´í¬ (ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ ì´í›„ì—ë§Œ)
                    if current_accuracy >= accuracy_threshold:
                        logger.info(f"ğŸ¯ ì¡°ê¸° ì¢…ë£Œ: ì •í™•ë„ ì„ê³„ê°’ ë‹¬ì„± ({current_accuracy:.3f} >= {accuracy_threshold:.3f})")
                        logger.info(f"âœ… ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ì™„ë£Œ (ì—í”¼ì†Œë“œ {episode + 1}/{PREDICTIVE_SELFPLAY_EPISODES}): í‰ê·  ì •í™•ë„ {current_accuracy:.3f}")
                        return {
                            'cycle_results': cycle_results,
                            'episodes': episode + 1,
                            'avg_accuracy': current_accuracy,
                            'best_accuracy': best_accuracy,
                            'strategy_count': len(strategies)
                        }

                    # ê°œì„ ë„ ì²´í¬ (ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ ì´í›„ì—ë§Œ)
                    improvement = current_accuracy - best_accuracy if best_accuracy > 0 else current_accuracy

                    if improvement >= PREDICTIVE_SELFPLAY_MIN_IMPROVEMENT:
                        # ê°œì„ ë¨
                        best_accuracy = current_accuracy
                        no_improvement_count = 0
                    else:
                        # ê°œì„  ì—†ìŒ
                        no_improvement_count += 1
                        if no_improvement_count >= patience:
                            logger.info(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ: {patience}íšŒ ì—°ì† ê°œì„  ì—†ìŒ (ìµœê³  ì •í™•ë„: {best_accuracy:.3f}, í˜„ì¬: {current_accuracy:.3f})")
                            logger.info(f"âœ… ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ì™„ë£Œ (ì—í”¼ì†Œë“œ {episode + 1}/{PREDICTIVE_SELFPLAY_EPISODES}): í‰ê·  ì •í™•ë„ {current_accuracy:.3f}")
                            return {
                                'cycle_results': cycle_results,
                                'episodes': episode + 1,
                                'avg_accuracy': current_accuracy,
                                'best_accuracy': best_accuracy,
                                'strategy_count': len(strategies)
                            }
                elif PREDICTIVE_SELFPLAY_EARLY_STOP and (episode + 1) < min_episodes:
                    # ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜ ë¯¸ë§Œ: ê°œì„  ì¶”ì ë§Œ ìˆ˜í–‰ (ì¡°ê¸° ì¢…ë£Œ ì•ˆ í•¨)
                    improvement = current_accuracy - best_accuracy if best_accuracy > 0 else current_accuracy
                    if improvement >= PREDICTIVE_SELFPLAY_MIN_IMPROVEMENT:
                        best_accuracy = current_accuracy
                        no_improvement_count = 0
                    else:
                        no_improvement_count += 1

                # ì¤‘ê°„ ë¡œê¹… (10 ì—í”¼ì†Œë“œë§ˆë‹¤)
                if (episode + 1) % 10 == 0:
                    logger.info(f"ğŸ“ˆ ì—í”¼ì†Œë“œ {episode + 1}/{PREDICTIVE_SELFPLAY_EPISODES}: í‰ê·  ì •í™•ë„ {current_accuracy:.3f} (ìµœê³ : {best_accuracy:.3f}, ê°œì„  ì—†ìŒ: {no_improvement_count}íšŒ)")

            # ìµœì¢… ë¡œê¹… (ëª¨ë“  ì—í”¼ì†Œë“œ ì™„ë£Œ)
            final_avg_accuracy = np.mean([
                np.mean(p['accuracy_history']) if p['accuracy_history'] else 0.0
                for p in strategy_policies.values()
            ])
            logger.info(f"âœ… ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ì™„ë£Œ (ëª¨ë“  ì—í”¼ì†Œë“œ ì™„ë£Œ): í‰ê·  ì •í™•ë„ {final_avg_accuracy:.3f} (ìµœê³ : {best_accuracy:.3f})")

            # ğŸ”¥ ê²°ê³¼ ë°˜í™˜
            return {
                'cycle_results': cycle_results,
                'episodes': len(cycle_results),
                'avg_accuracy': final_avg_accuracy,
                'best_accuracy': best_accuracy,
                'strategy_count': len(strategies)
            }

        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ Self-play ê°•í™”í•™ìŠµ ë£¨í”„ ì‹¤íŒ¨: {e}")
            logger.exception(e)
            return None
    
    def _create_predictions_with_policy(
        self, 
        coin: str, 
        interval: str, 
        strategies: List[Dict[str, Any]], 
        candle_data: pd.DataFrame,
        strategy_policies: Dict[str, Dict[str, Any]],
        episode: int
    ) -> List[Dict[str, Any]]:
        """ğŸ”¥ í•™ìŠµëœ ì •ì±…ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìƒì„±"""
        try:
            from rl_pipeline.db.rl_writes import save_episode_prediction
            from rl_pipeline.analysis.integrated_analyzer import IntegratedAnalyzer
            from datetime import datetime
            import uuid

            # ğŸ”¥ ìº”ë“¤ ë°ì´í„° ì •ë ¬ (timestamp ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ)
            candle_data_sorted = candle_data.copy()
            if 'timestamp' in candle_data_sorted.columns:
                candle_data_sorted = candle_data_sorted.sort_values('timestamp', ascending=True).reset_index(drop=True)

            # ğŸ”¥ ì˜ˆì¸¡ self-play: ê³¼ê±° ì§„ì…ì  ì‚¬ìš© (ë¯¸ë˜ ìº”ë“¤ í™•ë³´)
            # ì „ì²´ ë°ì´í„°ì˜ 70% ì§€ì ì„ ì§„ì…ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬, 30%ì˜ ë¯¸ë˜ ë°ì´í„°ë¡œ TP/SL ì‹œë®¬ë ˆì´ì…˜
            total_candles = len(candle_data_sorted)
            entry_position = int(total_candles * 0.7)  # 70% ì§€ì 

            # ì§„ì…ì  ê¸°ì¤€ ì´ì „ 100ê°œ ìº”ë“¤ ì‚¬ìš© (ì§€í‘œ ê³„ì‚°ìš©)
            start_idx = max(0, entry_position - 100)
            recent_candles = candle_data_sorted.iloc[start_idx:entry_position].copy()

            if len(recent_candles) < 10:
                logger.warning("âš ï¸ ì˜ˆì¸¡ ìƒì„±: ìº”ë“¤ ë°ì´í„° ë¶€ì¡±")
                return []

            # ë¯¸ë˜ ìº”ë“¤ í™•ì¸ (ì‹œë®¬ë ˆì´ì…˜ìš©)
            future_candles_available = total_candles - entry_position
            if future_candles_available < 10:
                logger.warning(f"âš ï¸ ì˜ˆì¸¡ ìƒì„±: ë¯¸ë˜ ìº”ë“¤ ë¶€ì¡± ({future_candles_available}ê°œ)")
                return []

            logger.info(f"ğŸ“Š ì˜ˆì¸¡ ìƒì„± ì¤€ë¹„: ì „ì²´ {total_candles}ê°œ ìº”ë“¤, ì§„ì…ì  {entry_position}, ë¯¸ë˜ {future_candles_available}ê°œ")

            # ì „ëµ ë°©í–¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¶„ì„ê¸° ìƒì„± (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ)
            analyzer = IntegratedAnalyzer()
            
            predictions = []

            # ğŸ”¥ ì „ëµë§ˆë‹¤ ë‹¤ë¥¸ ìº”ë“¤ ìœ„ì¹˜ ì‚¬ìš© (ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™© í•™ìŠµ)
            num_strategies_to_process = min(100, len(strategies))

            for strategy_idx, strategy in enumerate(strategies[:100]):  # ìµœëŒ€ 100ê°œ ì „ëµ ì²˜ë¦¬
                try:
                    strategy_id = strategy.get('id', f"strategy_{uuid.uuid4().hex[:8]}")

                    # ğŸ”¥ ê° ì „ëµë§ˆë‹¤ ë‹¤ë¥¸ ìº”ë“¤ ìœ„ì¹˜ ì„ íƒ
                    # recent_candles êµ¬ê°„ ë‚´ì—ì„œ ê· ë“± ë¶„ì‚° (ìµœëŒ€ 50ê°œ ìº”ë“¤ ë²”ìœ„)
                    max_lookback = min(50, len(recent_candles) - 20)  # ìµœì†Œ 20ê°œëŠ” ë‚¨ê²¨ë‘ 
                    candle_offset = strategy_idx % max_lookback
                    candle_idx = -1 - candle_offset  # -1, -2, -3, ..., -50

                    # ì •ì±… ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ì´ˆê¸°í™”)
                    policy = strategy_policies.get(strategy_id, {
                        'predicted_conf': 0.5,
                        'horizon_k': 10,
                        'direction': None
                    })
                    
                    # ğŸ”¥ í•´ë‹¹ ì „ëµì˜ ìº”ë“¤ ìœ„ì¹˜ì—ì„œ ê°€ê²© ë° ì§€í‘œ ì¶”ì¶œ
                    current_price = float(recent_candles['close'].iloc[candle_idx])
                    current_rsi = float(recent_candles['rsi'].iloc[candle_idx]) if 'rsi' in recent_candles.columns else 50.0
                    current_macd = float(recent_candles['macd'].iloc[candle_idx]) if 'macd' in recent_candles.columns else 0.0
                    current_macd_signal = float(recent_candles['macd_signal'].iloc[candle_idx]) if 'macd_signal' in recent_candles.columns else 0.0
                    current_volume_ratio = float(recent_candles['volume_ratio'].iloc[candle_idx]) if 'volume_ratio' in recent_candles.columns else 1.0

                    # ì „ëµ ë°©í–¥ì„± ë¶„ë¥˜ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
                    if policy['direction'] is None:
                        strategy_direction = analyzer._classify_strategy_direction(strategy)
                        policy['direction'] = strategy_direction

                    # ğŸ”¥ ì „ëµ ë°©í–¥ì— ë”°ë¼ ì˜ˆì¸¡ ë°©í–¥ ê²°ì • (ì¼ê´€ì„± ìœ ì§€)
                    # ë¹„ìŠ·í•œ ì „ëµì€ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë˜, ì‹œì¥ ìƒí™©ì— ë”°ë¼ í™•ì‹ ë„ë§Œ ì¡°ì •
                    # í†µí•© ë¶„ì„ì—ì„œ í™•ì‹ ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì‹œê·¸ë„ ê²°ì •
                    if policy['direction'] == 'buy':
                        predicted_dir = 1  # ë§¤ìˆ˜ ì „ëµì€ í•­ìƒ BUY ì˜ˆì¸¡ (ì¼ê´€ì„±)
                    elif policy['direction'] == 'sell':
                        predicted_dir = -1  # ë§¤ë„ ì „ëµì€ í•­ìƒ SELL ì˜ˆì¸¡ (ì¼ê´€ì„±)
                    else:
                        predicted_dir = 0  # ì¤‘ë¦½ ì „ëµì€ HOLD
                    
                    # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    rsi_min = strategy.get('rsi_min', 30.0)
                    rsi_max = strategy.get('rsi_max', 70.0)
                    macd_buy_threshold = strategy.get('macd_buy_threshold', 0.0)
                    macd_sell_threshold = strategy.get('macd_sell_threshold', 0.0)
                    volume_ratio_min = strategy.get('volume_ratio_min', 1.0)
                    
                    # ğŸ”¥ ì‹œì¥ ìƒí™©ê³¼ ì „ëµ ì¡°ê±´ ë¹„êµí•˜ì—¬ í™•ì‹ ë„ë§Œ ì¡°ì •
                    # ì˜ˆì¸¡ ë°©í–¥ì€ ì „ëµ ë°©í–¥ì— ë”°ë¼ ê³ ì •, í™•ì‹ ë„ë§Œ ì‹œì¥ ìƒí™©ì— ë”°ë¼ ì¡°ì •
                    market_alignment_score = 0.0  # ì‹œì¥ ìƒí™©ê³¼ ì „ëµì˜ ì¼ì¹˜ë„ (0.0 ~ 1.0)
                    
                    if policy['direction'] == 'buy':
                        # ë§¤ìˆ˜ ì „ëµ: ì‹œì¥ ìƒí™©ì´ ë§¤ìˆ˜ ì¡°ê±´ì— ë§ëŠ”ì§€ í™•ì¸
                        rsi_ok = current_rsi <= rsi_max  # RSIê°€ ì „ëµì˜ ìµœëŒ€ê°’ ì´í•˜
                        macd_ok = current_macd > macd_buy_threshold  # MACDê°€ ë§¤ìˆ˜ ì„ê³„ê°’ ì´ìƒ
                        volume_ok = current_volume_ratio >= volume_ratio_min  # ê±°ë˜ëŸ‰ ì¶©ë¶„
                        
                        # ì‹œì¥ ìƒí™© ì ìˆ˜ ê³„ì‚°
                        if rsi_ok:
                            market_alignment_score += 0.4
                        if macd_ok:
                            market_alignment_score += 0.4
                        if volume_ok:
                            market_alignment_score += 0.2
                        
                        # ê³¼ë§¤ìˆ˜ êµ¬ê°„ì´ë©´ í™•ì‹ ë„ í¬ê²Œ ê°ì†Œ
                        if current_rsi > 70:
                            market_alignment_score *= 0.3  # ê³¼ë§¤ìˆ˜ êµ¬ê°„ì€ ì¼ì¹˜ë„ í¬ê²Œ ê°ì†Œ
                            
                    elif policy['direction'] == 'sell':
                        # ë§¤ë„ ì „ëµ: ì‹œì¥ ìƒí™©ì´ ë§¤ë„ ì¡°ê±´ì— ë§ëŠ”ì§€ í™•ì¸
                        rsi_ok = current_rsi >= rsi_min  # RSIê°€ ì „ëµì˜ ìµœì†Œê°’ ì´ìƒ
                        macd_ok = current_macd < macd_sell_threshold  # MACDê°€ ë§¤ë„ ì„ê³„ê°’ ì´í•˜
                        volume_ok = current_volume_ratio >= volume_ratio_min  # ê±°ë˜ëŸ‰ ì¶©ë¶„
                        
                        # ì‹œì¥ ìƒí™© ì ìˆ˜ ê³„ì‚°
                        if rsi_ok:
                            market_alignment_score += 0.4
                        if macd_ok:
                            market_alignment_score += 0.4
                        if volume_ok:
                            market_alignment_score += 0.2
                        
                        # ê³¼ë§¤ë„ êµ¬ê°„ì´ë©´ í™•ì‹ ë„ í¬ê²Œ ê°ì†Œ
                        if current_rsi < 30:
                            market_alignment_score *= 0.3  # ê³¼ë§¤ë„ êµ¬ê°„ì€ ì¼ì¹˜ë„ í¬ê²Œ ê°ì†Œ
                    
                    elif policy['direction'] == 'neutral':
                        # ì¤‘ë¦½ ì „ëµ: RSIê°€ ì¤‘ë¦½ êµ¬ê°„(30~70)ì¼ ë•Œ ë†’ì€ ì¼ì¹˜ë„
                        if 30 <= current_rsi <= 70:
                            market_alignment_score = 0.7
                        else:
                            market_alignment_score = 0.3
                    
                    # ğŸ”¥ í•™ìŠµëœ í™•ì‹ ë„ì— ì‹œì¥ ìƒí™© ì¼ì¹˜ë„ë¥¼ ë°˜ì˜
                    # ì‹œì¥ ìƒí™©ì´ ì „ëµ ì¡°ê±´ê³¼ ì¼ì¹˜í• ìˆ˜ë¡ í™•ì‹ ë„ ì¦ê°€, ë¶ˆì¼ì¹˜í•˜ë©´ ê°ì†Œ
                    # í†µí•© ë¶„ì„ì—ì„œ í™•ì‹ ë„ê°€ ë†’ì€ ì „ëµì˜ ì˜ˆì¸¡ì´ ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë°›ìŒ
                    base_conf = max(0.1, min(1.0, policy['predicted_conf']))
                    predicted_conf = base_conf * (0.3 + 0.7 * market_alignment_score)  # ìµœì†Œ 30% í™•ì‹ ë„ ìœ ì§€
                    predicted_conf = round(max(0.1, min(1.0, predicted_conf)), 2)  # ì†Œìˆ«ì  2ìë¦¬
                    
                    # ğŸ”¥ í•™ìŠµëœ horizon_k ì‚¬ìš© (ì •ì±…ì—ì„œ ê°€ì ¸ì˜´)
                    horizon_k = max(1, int(policy['horizon_k']))

                    # ëª©í‘œ ë³€ë™ë¥  ì„¤ì •
                    target_move_pct = round(0.02, 4)  # ëª©í‘œ ë³€ë™ë¥  2% (ì†Œìˆ«ì  4ìë¦¬)

                    # ğŸ”¥ ì§„ì… ì‹œì : í•´ë‹¹ ì „ëµì˜ ìº”ë“¤ ìœ„ì¹˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
                    # ê° ì „ëµë§ˆë‹¤ ë‹¤ë¥¸ ì‹œì ì—ì„œ ì˜ˆì¸¡ â†’ ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™© í•™ìŠµ
                    if 'timestamp' in recent_candles.columns:
                        ts_value = recent_candles['timestamp'].iloc[candle_idx]
                        if isinstance(ts_value, pd.Timestamp):
                            ts_entry = int(ts_value.timestamp())  # pandas.Timestamp â†’ Unix íƒ€ì„ìŠ¤íƒ¬í”„
                        else:
                            ts_entry = int(ts_value)
                    else:
                        ts_entry = int(datetime.now().timestamp())

                    # ì˜ˆì¸¡ ì €ì¥
                    episode_id = f"pred_{coin}_{interval}_{strategy_id}_{episode}_{ts_entry}"
                    
                    save_episode_prediction(
                        episode_id=episode_id,
                        coin=coin,
                        interval=interval,
                        strategy_id=strategy_id,
                        state_key=f"{coin}_{interval}_{ts_entry}",
                        predicted_dir=predicted_dir,
                        predicted_conf=predicted_conf,
                        entry_price=current_price,
                        target_move_pct=target_move_pct,
                        horizon_k=horizon_k,
                        ts_entry=ts_entry
                    )
                    
                    predictions.append({
                        'episode_id': episode_id,
                        'strategy_id': strategy_id,
                        'predicted_dir': predicted_dir,
                        'predicted_conf': round(predicted_conf, 2),  # ì†Œìˆ«ì  2ìë¦¬
                        'horizon_k': int(horizon_k),  # ì •ìˆ˜
                        'entry_price': round(current_price, 8),  # ê°€ê²© ì†Œìˆ«ì  8ìë¦¬
                        'target_move_pct': round(target_move_pct, 4),  # ì†Œìˆ«ì  4ìë¦¬
                        'ts_entry': ts_entry
                    })
                    
                except Exception as e:
                    logger.debug(f"âš ï¸ ì „ëµ {strategy.get('id', 'unknown')} ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
                    continue
            
            return predictions
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _check_prediction_results(
        self,
        coin: str,
        interval: str,
        predictions: List[Dict[str, Any]],
        candle_data: pd.DataFrame
    ) -> List[Dict[str, Any]]:
        """ğŸ”¥ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ (ì‹¤ì œ TP/SL ë„ë‹¬ ì‹œì , ìˆ˜ìµë¥  ê³„ì‚°)
        
        ì‹¤ì œ ìº”ë“¤ ë°ì´í„°ì—ì„œ TP/SL ë„ë‹¬ ì‹œì ì„ ì°¾ê³  ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        try:
            from rl_pipeline.engine.reward_engine import RewardEngine
            from rl_pipeline.db.rl_writes import save_episode_summary
            
            reward_engine = RewardEngine()
            results = []
            
            # ì¸í„°ë²Œì— ë”°ë¥¸ ìº”ë“¤ ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
            interval_seconds = {
                '15m': 15 * 60,
                '30m': 30 * 60,
                '240m': 240 * 60,
                '1d': 24 * 60 * 60
            }
            candle_seconds = interval_seconds.get(interval, 15 * 60)
            
            for pred in predictions:
                try:
                    episode_id = pred['episode_id']
                    strategy_id = pred['strategy_id']
                    predicted_dir = pred['predicted_dir']
                    predicted_conf = pred['predicted_conf']
                    horizon_k = pred['horizon_k']
                    entry_price = pred['entry_price']
                    target_move_pct = pred['target_move_pct']
                    ts_entry = pred['ts_entry']
                    
                    # ì§„ì… ì‹œì ì˜ ìº”ë“¤ ì¸ë±ìŠ¤ ì°¾ê¸°
                    # ğŸ”¥ candle_dataë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ì¸ë±ìŠ¤ ë¦¬ì…‹
                    candle_data_sorted = candle_data.copy()
                    if 'timestamp' in candle_data_sorted.columns:
                        # timestampëŠ” ì´ë¯¸ datetime64[ns]ë¡œ ë³€í™˜ë˜ì–´ ìˆìŒ (candle_loader.pyì—ì„œ unit='s' ì‚¬ìš©)
                        candle_data_sorted = candle_data_sorted.sort_values('timestamp').reset_index(drop=True)
                    
                    entry_idx = None
                    # ê°€ì¥ ê°€ê¹Œìš´ íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸°
                    if 'timestamp' in candle_data_sorted.columns:
                        for idx in range(len(candle_data_sorted)):
                            row = candle_data_sorted.iloc[idx]
                            try:
                                candle_ts = int(pd.Timestamp(row['timestamp']).timestamp())
                                if abs(candle_ts - ts_entry) < candle_seconds * 2:  # 2ë°° ì—¬ìœ  (ì¸ë±ìŠ¤ ì˜¤ì°¨ ê³ ë ¤)
                                    entry_idx = idx
                                    break
                            except Exception:
                                continue
                    
                    if entry_idx is None:
                        # ì§„ì… ì‹œì ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ë°ì´í„° ë¶ˆì¼ì¹˜)
                        logger.warning(f"âš ï¸ ì§„ì… ì‹œì ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {episode_id} (ts_entry={ts_entry})")
                        continue
                    
                    # TP/SL ê³„ì‚° (ì „ëµì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
                    tp_pct = target_move_pct  # TP = ëª©í‘œ ë³€ë™ë¥ 
                    sl_pct = -target_move_pct * 0.5  # SL = TPì˜ 50% (ê¸°ë³¸ê°’)
                    
                    # ì‹¤ì œ ê²°ê³¼ í™•ì¸ (horizon_k ë²”ìœ„ ë‚´ì—ì„œ)
                    actual_horizon = None
                    actual_move_pct = 0.0
                    first_event = 'expiry'
                    max_profit_pct = 0.0
                    max_profit_horizon = 0
                    
                    # horizon_k ë²”ìœ„ ë‚´ì—ì„œ ìµœëŒ€ ìˆ˜ìµë¥ ê³¼ ê·¸ ì‹œì  ì°¾ê¸°
                    # ğŸ”¥ candle_data_sorted ì‚¬ìš© (ì •ë ¬ëœ ë°ì´í„°)
                    for k in range(1, min(horizon_k + 10, len(candle_data_sorted) - entry_idx)):
                        if entry_idx + k >= len(candle_data_sorted):
                            break
                        
                        current_candle = candle_data_sorted.iloc[entry_idx + k]
                        current_price = float(current_candle['close'])
                        
                        # ìˆ˜ìµë¥  ê³„ì‚°
                        if predicted_dir == 1:  # ìƒìŠ¹ ì˜ˆì¸¡
                            move_pct = (current_price - entry_price) / entry_price
                        elif predicted_dir == -1:  # í•˜ë½ ì˜ˆì¸¡
                            move_pct = (entry_price - current_price) / entry_price
                        else:  # ì¤‘ë¦½
                            move_pct = abs(current_price - entry_price) / entry_price
                        
                        # ìµœëŒ€ ìˆ˜ìµë¥  ì¶”ì 
                        if move_pct > max_profit_pct:
                            max_profit_pct = move_pct
                            max_profit_horizon = k
                        
                        # TP/SL ë„ë‹¬ í™•ì¸
                        if predicted_dir == 1:  # ìƒìŠ¹ ì˜ˆì¸¡
                            if move_pct >= tp_pct:
                                first_event = 'TP'
                                actual_horizon = k
                                actual_move_pct = move_pct
                                break
                            elif move_pct <= sl_pct:
                                first_event = 'SL'
                                actual_horizon = k
                                actual_move_pct = move_pct
                                break
                        elif predicted_dir == -1:  # í•˜ë½ ì˜ˆì¸¡
                            if move_pct >= tp_pct:
                                first_event = 'TP'
                                actual_horizon = k
                                actual_move_pct = move_pct
                                break
                            elif move_pct <= sl_pct:
                                first_event = 'SL'
                                actual_horizon = k
                                actual_move_pct = move_pct
                                break
                    
                    # ë§Œë£Œ ì‹œ ìµœëŒ€ ìˆ˜ìµë¥  ì‚¬ìš©
                    if first_event == 'expiry':
                        actual_horizon = horizon_k
                        actual_move_pct = max_profit_pct
                    
                    # ì‹¤ì œ ë°©í–¥ ê³„ì‚°
                    actual_dir = 1 if actual_move_pct > 0.001 else (-1 if actual_move_pct < -0.001 else 0)
                    
                    # ë³´ìƒ ê³„ì‚°
                    reward_components = reward_engine.compute_reward(
                        predicted_dir=predicted_dir,
                        predicted_target=target_move_pct,
                        predicted_horizon=horizon_k,
                        actual_dir=actual_dir,
                        actual_move_pct=actual_move_pct,
                        actual_horizon=actual_horizon or horizon_k,
                        first_event=first_event,
                        interval=interval
                    )
                    
                    # ì˜ˆì¸¡ ì •í™•ë„ í”Œë˜ê·¸
                    acc_flag = reward_engine.compute_predictive_accuracy_flag(
                        first_event=first_event,
                        predicted_dir=predicted_dir,
                        actual_move_pct=actual_move_pct
                    )
                    
                    # ê²°ê³¼ ì €ì¥
                    ts_exit = ts_entry + (actual_horizon or horizon_k) * candle_seconds
                    
                    save_episode_summary(
                        episode_id=episode_id,
                        ts_exit=ts_exit,
                        first_event=first_event,
                        t_hit=actual_horizon or horizon_k,
                        realized_ret_signed=actual_move_pct,
                        total_reward=reward_components.reward_total,
                        acc_flag=acc_flag,
                        coin=coin,
                        interval=interval,
                        strategy_id=strategy_id,
                        source_type='predictive'
                    )
                    
                    results.append({
                        'episode_id': episode_id,
                        'strategy_id': strategy_id,
                        'predicted_dir': predicted_dir,
                        'predicted_conf': round(predicted_conf, 2),  # ì†Œìˆ«ì  2ìë¦¬
                        'horizon_k': int(horizon_k),  # ì •ìˆ˜
                        'actual_dir': actual_dir,
                        'actual_move_pct': round(actual_move_pct, 4),  # ì†Œìˆ«ì  4ìë¦¬
                        'actual_horizon': int(actual_horizon or horizon_k),  # ì •ìˆ˜
                        'max_profit_pct': round(max_profit_pct, 4),  # ì†Œìˆ«ì  4ìë¦¬
                        'max_profit_horizon': int(max_profit_horizon),  # ì •ìˆ˜
                        'first_event': first_event,
                        'reward': round(reward_components.reward_total, 4),  # ì†Œìˆ«ì  4ìë¦¬
                        'acc_flag': acc_flag
                    })
                    
                except Exception as e:
                    logger.debug(f"âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
                    continue
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def _update_prediction_policy(
        self,
        coin: str,
        interval: str,
        results: List[Dict[str, Any]],
        strategy_policies: Dict[str, Dict[str, Any]]
    ):
        """ğŸ”¥ ì˜ˆì¸¡ ì •ì±… ì—…ë°ì´íŠ¸ (ê°•í™”í•™ìŠµ)
        
        ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ì€ ì „ëµì˜ í™•ì‹ ë„ ì¦ê°€, horizon_k ìµœì í™”
        """
        try:
            learning_rate = PREDICTIVE_SELFPLAY_LEARNING_RATE
            
            for result in results:
                strategy_id = result['strategy_id']
                
                if strategy_id not in strategy_policies:
                    continue
                
                policy = strategy_policies[strategy_id]
                
                # ì •í™•ë„ ë° ë³´ìƒ ì¶”ì¶œ
                acc_flag = result['acc_flag']
                reward = result['reward']
                max_profit_pct = result['max_profit_pct']
                max_profit_horizon = result['max_profit_horizon']
                predicted_horizon = result['horizon_k']
                actual_horizon = result['actual_horizon']
                predicted_dir = result['predicted_dir']
                actual_dir = result['actual_dir']
                
                # ğŸ”¥ ë°˜ëŒ€ ë°©í–¥ ë°œìƒ ì¶”ì 
                policy['total_predictions'] += 1
                is_opposite_direction = False
                if predicted_dir == 1 and actual_dir == -1:  # ìƒìŠ¹ ì˜ˆì¸¡í–ˆëŠ”ë° í•˜ë½
                    is_opposite_direction = True
                    policy['opposite_direction_count'] += 1
                elif predicted_dir == -1 and actual_dir == 1:  # í•˜ë½ ì˜ˆì¸¡í–ˆëŠ”ë° ìƒìŠ¹
                    is_opposite_direction = True
                    policy['opposite_direction_count'] += 1
                
                # ì •í™•ë„ ì´ë ¥ ì—…ë°ì´íŠ¸
                policy['accuracy_history'].append(acc_flag)
                policy['reward_history'].append(reward)
                
                # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
                if len(policy['accuracy_history']) > 10:
                    policy['accuracy_history'] = policy['accuracy_history'][-10:]
                if len(policy['reward_history']) > 10:
                    policy['reward_history'] = policy['reward_history'][-10:]
                
                # ğŸ”¥ ë°˜ëŒ€ ë°©í–¥ ë°œìƒ ë¹ˆë„ ê³„ì‚° ë° ì „ëµ ë°©í–¥ ì¬í‰ê°€
                if policy['total_predictions'] >= 5:  # ìµœì†Œ 5íšŒ ì˜ˆì¸¡ í›„ ì¬í‰ê°€ ê°€ëŠ¥
                    opposite_rate = policy['opposite_direction_count'] / policy['total_predictions']
                    
                    # ë°˜ëŒ€ ë°©í–¥ ë°œìƒ ë¹ˆë„ê°€ 60% ì´ìƒì´ë©´ ì „ëµ ë°©í–¥ ì¬í‰ê°€
                    if opposite_rate >= 0.6 and not policy['direction_reassessed']:
                        # ğŸ”¥ ì „ëµ ë°©í–¥ ì¬í‰ê°€: ì‹¤ì œ ì„±ê³¼ ê¸°ë°˜ìœ¼ë¡œ ì¬ë¶„ë¥˜
                        original_direction = policy['direction']
                        new_direction = self._reassess_strategy_direction(
                            coin, interval, strategy_id, predicted_dir, actual_dir, 
                            policy['accuracy_history'], policy['reward_history']
                        )
                        
                        if new_direction != original_direction:
                            logger.warning(f"ğŸ”„ {coin}-{interval} ì „ëµ {strategy_id} ë°©í–¥ ì¬í‰ê°€: "
                                         f"{original_direction} â†’ {new_direction} "
                                         f"(ë°˜ëŒ€ ë°©í–¥ ë°œìƒë¥ : {opposite_rate:.1%})")
                            policy['direction'] = new_direction
                            policy['direction_reassessed'] = True
                            # ë°©í–¥ ì¬í‰ê°€ í›„ ì¹´ìš´í„° ë¦¬ì…‹
                            policy['opposite_direction_count'] = 0
                            policy['total_predictions'] = 0
                
                # ğŸ”¥ í™•ì‹ ë„ ì—…ë°ì´íŠ¸ (ì •í™•ë„ê°€ ë†’ì„ìˆ˜ë¡ ì¦ê°€)
                if acc_flag == 1:
                    # ì˜ˆì¸¡ ì •í™•: í™•ì‹ ë„ ì¦ê°€
                    policy['predicted_conf'] = round(min(1.0, policy['predicted_conf'] + learning_rate * 0.1), 2)  # ì†Œìˆ«ì  2ìë¦¬
                else:
                    # ì˜ˆì¸¡ ë¶€ì •í™•: í™•ì‹ ë„ ê°ì†Œ
                    # ğŸ”¥ ë°˜ëŒ€ ë°©í–¥ì´ë©´ ë” í° í˜ë„í‹°
                    penalty = learning_rate * (0.1 if is_opposite_direction else 0.05)
                    policy['predicted_conf'] = round(max(0.1, policy['predicted_conf'] - penalty), 2)  # ì†Œìˆ«ì  2ìë¦¬
                
                # ğŸ”¥ horizon_k ìµœì í™” (ìµœëŒ€ ìˆ˜ìµë¥ ì´ ë°œìƒí•œ ì‹œì ìœ¼ë¡œ ì—…ë°ì´íŠ¸)
                if max_profit_horizon > 0 and max_profit_pct > 0.01:  # ìµœì†Œ 1% ìˆ˜ìµë¥ 
                    # ìµœëŒ€ ìˆ˜ìµë¥  ì‹œì ìœ¼ë¡œ horizon_k ì—…ë°ì´íŠ¸ (ì§€ìˆ˜ ì´ë™ í‰ê· )
                    policy['horizon_k'] = int(
                        policy['horizon_k'] * (1 - learning_rate) + 
                        max_profit_horizon * learning_rate
                    )
                    policy['horizon_k'] = max(1, min(50, policy['horizon_k']))  # 1~50 ë²”ìœ„ ì œí•œ
                
                # ë³´ìƒ ê¸°ë°˜ ì¶”ê°€ ì—…ë°ì´íŠ¸
                if reward > 0.5:
                    # ë†’ì€ ë³´ìƒ: í™•ì‹ ë„ ì¶”ê°€ ì¦ê°€
                    policy['predicted_conf'] = round(min(1.0, policy['predicted_conf'] + learning_rate * 0.05), 2)  # ì†Œìˆ«ì  2ìë¦¬
                elif reward < -0.5:
                    # ë‚®ì€ ë³´ìƒ: í™•ì‹ ë„ ì¶”ê°€ ê°ì†Œ
                    policy['predicted_conf'] = round(max(0.1, policy['predicted_conf'] - learning_rate * 0.1), 2)  # ì†Œìˆ«ì  2ìë¦¬
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ì •ì±… ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _get_opposite_direction(self, direction: int, fallback_direction: int = 1) -> str:
        """ë°©í–¥ì˜ ë°˜ëŒ€ ë°©í–¥ ë°˜í™˜ (neutral ê¸ˆì§€)

        Args:
            direction: ì›ë˜ ë°©í–¥ (1=buy, -1=sell, 0=neutral)
            fallback_direction: directionì´ 0ì¼ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ë°©í–¥

        Returns:
            'buy' ë˜ëŠ” 'sell' (neutral ë°˜í™˜ ì•ˆ í•¨)
        """
        if direction == 1:
            return 'sell'
        elif direction == -1:
            return 'buy'
        else:
            # neutralì´ì—ˆë‹¤ë©´ fallback ë°©í–¥ì˜ ë°˜ëŒ€
            return 'sell' if fallback_direction == 1 else 'buy'

    def _reassess_strategy_direction(
        self,
        coin: str,
        interval: str,
        strategy_id: str,
        predicted_dir: int,
        actual_dir: int,
        accuracy_history: List[int],
        reward_history: List[float]
    ) -> str:
        """ğŸ”¥ ì „ëµ ë°©í–¥ ì¬í‰ê°€ (ì‹¤ì œ ì„±ê³¼ ê¸°ë°˜)

        ë°˜ëŒ€ ë°©í–¥ì´ ìì£¼ ë°œìƒí•˜ë©´ ì‹¤ì œ ì„±ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°©í–¥ì„ ì¬í‰ê°€í•©ë‹ˆë‹¤.

        âš ï¸ í•µì‹¬ ì² í•™: ì¬í‰ê°€ í›„ì—ë„ ë°˜ë“œì‹œ ì˜ˆì¸¡ì„ ê³„ì†í•´ì•¼ í•©ë‹ˆë‹¤ (neutral ê¸ˆì§€).
        - ì˜ˆì¸¡ì´ í‹€ë¦¬ë“  ë§ë“  â†’ ê³„ì† ì˜ˆì¸¡
        - ì‹¤ì œë¡œ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ì›€ì§ì˜€ëŠ”ì§€ ëª¨ë‘ ì €ì¥
        - ê·¸ íŒ¨í„´ì„ í•™ìŠµ
        - í•™ìŠµëœ ê²°ê³¼ë¥¼ ì‚¬ìš©

        Args:
            coin: ì½”ì¸ ì‹¬ë³¼
            interval: ì¸í„°ë²Œ
            strategy_id: ì „ëµ ID
            predicted_dir: ì˜ˆì¸¡ ë°©í–¥ (1/-1/0)
            actual_dir: ì‹¤ì œ ë°©í–¥ (1/-1/0)
            accuracy_history: ì •í™•ë„ ì´ë ¥
            reward_history: ë³´ìƒ ì´ë ¥

        Returns:
            ì¬í‰ê°€ëœ ì „ëµ ë°©í–¥ ('buy' ë˜ëŠ” 'sell', neutral ì ˆëŒ€ ë°˜í™˜ ì•ˆ í•¨)
        """
        try:
            # ì‹¤ì œ ì„±ê³¼ ê¸°ë°˜ ë°©í–¥ ê²°ì •
            avg_accuracy = np.mean(accuracy_history) if accuracy_history else 0.0
            avg_reward = np.mean(reward_history) if reward_history else 0.0

            # ğŸ”¥ ì „ëµ: ë°˜ëŒ€ ë°©í–¥ì´ ìì£¼ ë°œìƒ â†’ ì‹¤ì œ ë°©í–¥ìœ¼ë¡œ ë³€ê²½
            # ì˜ˆ: BUY ì˜ˆì¸¡ì´ ìì£¼ ì‹¤íŒ¨ â†’ ì‹¤ì œë¡œëŠ” SELL ì „ëµì¼ ìˆ˜ ìˆìŒ

            # ì •í™•ë„ë‚˜ ë³´ìƒì´ ë‚®ìœ¼ë©´ â†’ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì „í™˜ (ê³„ì† ì˜ˆì¸¡)
            should_flip = (
                avg_accuracy < 0.4 or  # ì •í™•ë„ 40% ë¯¸ë§Œ
                avg_reward < -0.1       # ë³´ìƒ ìŒìˆ˜
            )

            if should_flip:
                # ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ê³„ì† ì˜ˆì¸¡
                return self._get_opposite_direction(predicted_dir, actual_dir)

            # ì„±ê³¼ê°€ ì• ë§¤í•˜ë©´ â†’ ì¼ë‹¨ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì‹œë„
            # (ì–´ì°¨í”¼ í•™ìŠµì„ ìœ„í•´ ê³„ì† ì˜ˆì¸¡í•´ì•¼ í•¨)
            return self._get_opposite_direction(predicted_dir, actual_dir)

        except Exception as e:
            logger.debug(f"âš ï¸ ì „ëµ ë°©í–¥ ì¬í‰ê°€ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œì—ë„ neutral ê¸ˆì§€ â†’ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ
            return self._get_opposite_direction(predicted_dir, actual_dir)
    
    def _create_predictions_for_strategies(self, coin: str, interval: str, strategies: List[Dict[str, Any]], candle_data: pd.DataFrame):
        """ğŸ”¥ ì „ëµì— ëŒ€í•œ ì˜ˆì¸¡ ìƒì„± ë° ì €ì¥ (ë§¤ìˆ˜/ë§¤ë„ ì „ëµ êµ¬ë¶„)
        
        ë§¤ìˆ˜ ì „ëµ: predicted_dir = +1 (ìƒìŠ¹ ì˜ˆì¸¡)
        ë§¤ë„ ì „ëµ: predicted_dir = -1 (í•˜ë½ ì˜ˆì¸¡)
        ì¤‘ë¦½ ì „ëµ: predicted_dir = 0 (ì¤‘ë¦½ ì˜ˆì¸¡)
        
        âš ï¸ ì´ ë©”ì„œë“œëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ, ê°•í™”í•™ìŠµ ë£¨í”„ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        try:
            from rl_pipeline.db.rl_writes import save_episode_prediction
            from rl_pipeline.analysis.integrated_analyzer import IntegratedAnalyzer
            from datetime import datetime
            import uuid
            
            # ìµœê·¼ ìº”ë“¤ ë°ì´í„° ì‚¬ìš© (ì˜ˆì¸¡ ìƒì„±ìš©)
            recent_candles = candle_data.tail(min(100, len(candle_data)))
            if len(recent_candles) < 10:
                logger.warning("âš ï¸ ì˜ˆì¸¡ ìƒì„±: ìº”ë“¤ ë°ì´í„° ë¶€ì¡±")
                return
            
            # í˜„ì¬ ê°€ê²© ë° ì§€í‘œ ê³„ì‚°
            current_price = float(recent_candles['close'].iloc[-1])
            
            # ì „ëµ ë°©í–¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¶„ì„ê¸° ìƒì„±
            analyzer = IntegratedAnalyzer()
            
            # ì „ëµë³„ ì˜ˆì¸¡ ìƒì„±
            buy_predictions = 0
            sell_predictions = 0
            neutral_predictions = 0
            
            for strategy in strategies[:100]:  # ìµœëŒ€ 100ê°œ ì „ëµ ì²˜ë¦¬
                try:
                    strategy_id = strategy.get('id', f"strategy_{uuid.uuid4().hex[:8]}")
                    
                    # ğŸ”¥ ì „ëµ ë°©í–¥ì„± ë¶„ë¥˜ (ë§¤ìˆ˜/ë§¤ë„/ì¤‘ë¦½)
                    strategy_direction = analyzer._classify_strategy_direction(strategy)
                    
                    # ğŸ”¥ ì „ëµ ë°©í–¥ì— ë”°ë¼ ì˜ˆì¸¡ ë°©í–¥ ê²°ì •
                    if strategy_direction == 'buy':
                        # ë§¤ìˆ˜ ì „ëµ â†’ ìƒìŠ¹ ì˜ˆì¸¡ (+1)
                        predicted_dir = 1
                        buy_predictions += 1
                    elif strategy_direction == 'sell':
                        # ë§¤ë„ ì „ëµ â†’ í•˜ë½ ì˜ˆì¸¡ (-1)
                        predicted_dir = -1
                        sell_predictions += 1
                    else:
                        # ì¤‘ë¦½ ì „ëµ â†’ ì¤‘ë¦½ ì˜ˆì¸¡ (0)
                        predicted_dir = 0
                        neutral_predictions += 1
                    
                    # í™•ì‹ ë„ ê³„ì‚° (ì „ëµ íŒŒë¼ë¯¸í„° ê¸°ë°˜)
                    # RSI, MACD ë“± ì§€í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™•ì‹ ë„ ê³„ì‚° ê°€ëŠ¥
                    predicted_conf = 0.5  # ê¸°ë³¸ í™•ì‹ ë„ (í–¥í›„ ê°œì„  ê°€ëŠ¥)
                    
                    # ëª©í‘œ ë³€ë™ë¥  ë° ëª©í‘œ ìº”ë“¤ ìˆ˜ ì„¤ì •
                    target_move_pct = 0.02  # ëª©í‘œ ë³€ë™ë¥  2%
                    horizon_k = 10  # ëª©í‘œ ìº”ë“¤ ìˆ˜ (ì¸í„°ë²Œì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
                    
                    # ì˜ˆì¸¡ ì €ì¥
                    episode_id = f"pred_{coin}_{interval}_{strategy_id}_{int(datetime.now().timestamp())}"
                    ts_entry = int(datetime.now().timestamp())
                    
                    save_episode_prediction(
                        episode_id=episode_id,
                        coin=coin,
                        interval=interval,
                        strategy_id=strategy_id,
                        state_key=f"{coin}_{interval}_{ts_entry}",
                        predicted_dir=predicted_dir,
                        predicted_conf=predicted_conf,
                        entry_price=current_price,
                        target_move_pct=target_move_pct,
                        horizon_k=horizon_k,
                        ts_entry=ts_entry
                    )
                    
                except Exception as e:
                    logger.debug(f"âš ï¸ ì „ëµ {strategy.get('id', 'unknown')} ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ: ì´ {buy_predictions + sell_predictions + neutral_predictions}ê°œ (ë§¤ìˆ˜: {buy_predictions}, ë§¤ë„: {sell_predictions}, ì¤‘ë¦½: {neutral_predictions})")
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _evolve_strategies_with_selfplay(self, coin: str, strategies: List[Dict[str, Any]], interval: str = None, candle_data: pd.DataFrame = None) -> List[Dict[str, Any]]:
        """2ë‹¨ê³„: Self-play ì§„í™” + ì‹¤ì œ ìº”ë“¤ ë°ì´í„° ì‚¬ìš© ğŸ”¥"""
        try:
            if not strategies:
                logger.warning("âš ï¸ ì§„í™”í•  ì „ëµì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ëª¨ë“  ì „ëµì„ Self-playì— ì‚¬ìš© (100% í™œìš©ë¥ )
            top_strategies = strategies  # ëª¨ë“  ì „ëµ ì‚¬ìš©
            
            # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ - ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©
            from rl_pipeline.db.reads import extract_strategy_params
            strategy_params_list = [extract_strategy_params(strategy) for strategy in top_strategies]
            
            # Self-play ì‹¤í–‰ - ì „ì²´ ì „ëµ í’€ì—ì„œ ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ìƒ˜í”Œë§
            from rl_pipeline.simulation.selfplay import run_self_play_test
            
            # DBì—ì„œ ëª¨ë“  ì „ëµ ë¡œë“œ (ë” í° í’€ ì‚¬ìš©) - ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©
            all_strategies_pool = []
            try:
                from rl_pipeline.db.reads import load_strategies_pool, extract_strategy_params
                
                # interval í•„í„° ì¶”ê°€í•˜ì—¬ ê°™ì€ interval ì „ëµë§Œ ë¡œë“œ
                # ğŸ”¥ UNKNOWN ë“±ê¸‰ ì „ëµë„ í¬í•¨ (include_unknown=True)
                db_strategies = load_strategies_pool(
                    coin=coin,
                    interval=interval,
                    limit=AZ_STRATEGY_POOL_SIZE,  # 0ì´ë©´ ì œí•œ ì—†ìŒ
                    order_by="id DESC",
                    include_unknown=True  # ğŸ”¥ UNKNOWN ë“±ê¸‰ í¬í•¨
                )
                
                if interval:
                    logger.info(f"ğŸ“Š DBì—ì„œ {coin}-{interval} ì „ëµ ë¡œë“œ ì¤‘... (UNKNOWN ë“±ê¸‰ í¬í•¨, ìµœëŒ€ {AZ_STRATEGY_POOL_SIZE}ê°œ)")
                else:
                    logger.info(f"ğŸ“Š DBì—ì„œ {coin} (ëª¨ë“  interval) ì „ëµ ë¡œë“œ ì¤‘... (UNKNOWN ë“±ê¸‰ í¬í•¨)")
                
                # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                all_strategies_pool = [extract_strategy_params(s) for s in db_strategies]
                
                # ğŸ” ì²« 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                for i, params in enumerate(all_strategies_pool[:3]):
                    logger.info(f"  ì „ëµ {i+1}: RSI={params['rsi_min']:.1f}-{params['rsi_max']:.1f}, "
                               f"StopLoss={params['stop_loss_pct']:.3f}, TakeProfit={params['take_profit_pct']:.3f}")
                
                if interval:
                    logger.info(f"âœ… DBì—ì„œ {len(all_strategies_pool)}ê°œ {coin}-{interval} ì „ëµ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.info(f"âœ… DBì—ì„œ {len(all_strategies_pool)}ê°œ {coin} ì „ëµ ë¡œë“œ ì™„ë£Œ (ëª¨ë“  interval)")
            except Exception as e:
                logger.warning(f"âš ï¸ ì „ì²´ ì „ëµ í’€ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì „ëµë§Œ ì‚¬ìš©")
                all_strategies_pool = strategy_params_list
            
            # ğŸ”¥ ë™ì  ì—í”¼ì†Œë“œ ìˆ˜ ê³„ì‚°: ëª¨ë“  ì „ëµì´ self-playë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡
            agents_per_episode = AZ_SELFPLAY_AGENTS_PER_EPISODE
            total_strategies = len(all_strategies_pool) if all_strategies_pool else len(strategy_params_list)
            
            # ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜: ëª¨ë“  ì „ëµì´ ìµœì†Œ 1ë²ˆì”© ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡
            # ì¤‘ë³µ í—ˆìš©ì„ ê³ ë ¤í•˜ì—¬ ì—¬ìœ ìˆê²Œ ì„¤ì •
            min_episodes_for_all = max(1, int(total_strategies / agents_per_episode * 1.2))  # 20% ì—¬ìœ 
            # ê¸°ë³¸ ì—í”¼ì†Œë“œ ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ë” í° ê°’ ì‚¬ìš©
            dynamic_episodes = max(AZ_SELFPLAY_EPISODES, min_episodes_for_all)
            
            if dynamic_episodes > AZ_SELFPLAY_EPISODES:
                logger.info(f"ğŸ“ˆ ì—í”¼ì†Œë“œ ìˆ˜ ë™ì  ì¡°ì •: {AZ_SELFPLAY_EPISODES} â†’ {dynamic_episodes}ê°œ "
                           f"(ì „ëµ ìˆ˜: {total_strategies}ê°œ, ì—í”¼ì†Œë“œë‹¹ {agents_per_episode}ê°œ)")
            else:
                logger.info(f"ğŸ“Š ì—í”¼ì†Œë“œ ìˆ˜: {dynamic_episodes}ê°œ (ê¸°ë³¸ê°’ ì‚¬ìš©, ì „ëµ ìˆ˜: {total_strategies}ê°œ)")
            
            # ğŸ†• í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ì²´í¬
            use_hybrid = os.getenv('USE_HYBRID', 'false').lower() == 'true'
            hybrid_config = None
            neural_policy = None
            
            if use_hybrid:
                try:
                    # í•˜ì´ë¸Œë¦¬ë“œ ì„¤ì • ë¡œë“œ
                    config_path = os.getenv('HYBRID_CONFIG_PATH', '/workspace/rl_pipeline/hybrid/config_hybrid.json')
                    if os.path.exists(config_path):
                        import json
                        with open(config_path, 'r') as f:
                            hybrid_config = json.load(f)
                        
                        # ëª¨ë¸ ë¡œë“œ (ê°€ì¥ ìµœì‹  ëª¨ë¸ ë˜ëŠ” ì§€ì •ëœ ëª¨ë¸)
                        model_id = os.getenv('HYBRID_MODEL_ID', 'latest')
                        cache_key = None
                        ckpt_path = None
                        
                        if model_id == 'latest':
                            # ìµœì‹  ëª¨ë¸ ì°¾ê¸°
                            from rl_pipeline.db.connection_pool import get_strategy_db_pool
                            with get_strategy_db_pool().get_connection() as conn:
                                cursor = conn.cursor()
                                cursor.execute("""
                                    SELECT model_id, ckpt_path FROM policy_models 
                                    ORDER BY created_at DESC LIMIT 1
                                """)
                                result = cursor.fetchone()
                                if result:
                                    model_id = result[0]
                                    ckpt_path = result[1]
                                    cache_key = f"{model_id}_{ckpt_path}"
                                else:
                                    # ğŸ”§ ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ì—†ëŠ” ê²ƒì€ ì •ìƒ (ìë™ í•™ìŠµ í›„ ìƒì„±ë¨)
                                    logger.info("â„¹ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤ (ì²˜ìŒ ì‹¤í–‰ ë˜ëŠ” ìë™ í•™ìŠµ ëŒ€ê¸° ì¤‘)")
                                    logger.info("ğŸ’¡ ìë™ í•™ìŠµì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ Self-play í›„ ëª¨ë¸ì´ ìƒì„±ë˜ê³ , ë‹¤ìŒ ì‹¤í–‰ë¶€í„° í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œê°€ ìë™ í™œì„±í™”ë©ë‹ˆë‹¤.")
                                    logger.info("ğŸ“Š í˜„ì¬ëŠ” ê·œì¹™ ê¸°ë°˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤ (ì •ìƒ ë™ì‘)")
                                    use_hybrid = False
                                    model_id = None
                        else:
                            # ì§€ì •ëœ ëª¨ë¸ ë¡œë“œ
                            checkpoint_dir = hybrid_config.get('paths', {}).get('checkpoints', '/workspace/rl_pipeline/artifacts/checkpoints')
                            ckpt_path = os.path.join(checkpoint_dir, f"{model_id}.ckpt")
                            cache_key = f"{model_id}_{ckpt_path}"
                            if not os.path.exists(ckpt_path):
                                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
                                use_hybrid = False
                                model_id = None
                        
                        # ğŸ”§ ëª¨ë¸ ìºì‹±: ê°™ì€ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ
                        if model_id and cache_key:
                            if cache_key == IntegratedPipelineOrchestrator._cache_key:
                                # ìºì‹œëœ ëª¨ë¸ ì¬ì‚¬ìš©
                                neural_policy = IntegratedPipelineOrchestrator._neural_policy_cache.get(cache_key)
                                if neural_policy:
                                    logger.debug(f"â™»ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìºì‹œ ì¬ì‚¬ìš©: {model_id}")
                                else:
                                    # ìºì‹œê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¡œë“œ
                                    from rl_pipeline.hybrid.neural_policy_jax import load_ckpt
                                    neural_policy = load_ckpt(ckpt_path)
                                    IntegratedPipelineOrchestrator._neural_policy_cache[cache_key] = neural_policy
                                    IntegratedPipelineOrchestrator._cache_key = cache_key
                                    logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ë¡œë“œ ë° ìºì‹œ: {model_id}")
                            else:
                                # ìƒˆë¡œìš´ ëª¨ë¸ ë¡œë“œ
                                from rl_pipeline.hybrid.neural_policy_jax import load_ckpt
                                # ğŸ”§ ê¸°ì¡´ ìºì‹œ í´ë¦¬ì–´ (ë©”ëª¨ë¦¬ ì ˆì•½)
                                if IntegratedPipelineOrchestrator._neural_policy_cache:
                                    logger.debug("ğŸ—‘ï¸ ê¸°ì¡´ ëª¨ë¸ ìºì‹œ í´ë¦¬ì–´ (ë©”ëª¨ë¦¬ ì ˆì•½)")
                                    IntegratedPipelineOrchestrator._neural_policy_cache.clear()
                                neural_policy = load_ckpt(ckpt_path)
                                IntegratedPipelineOrchestrator._neural_policy_cache[cache_key] = neural_policy
                                IntegratedPipelineOrchestrator._cache_key = cache_key
                                logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ë¡œë“œ ë° ìºì‹œ: {model_id}")
                        else:
                            neural_policy = None
                        
                        if neural_policy:
                            hybrid_config['enable_neural'] = True
                        else:
                            hybrid_config['enable_neural'] = False
                            use_hybrid = False
                            
                except FileNotFoundError as e:
                    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° (ìƒˆ ëª¨ë¸ í•„ìš”)
                    logger.debug(f"â„¹ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ, ìƒˆ ëª¨ë¸ ì‚¬ìš©: {e}")
                    use_hybrid = False
                except Exception as e:
                    # ğŸ”§ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë” ëª…í™•í•œ ë©”ì‹œì§€
                    error_msg = str(e)
                    if "unpack" in error_msg.lower() or "extra data" in error_msg.lower():
                        logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ ê°ì§€ (ê·œì¹™ ê¸°ë°˜ ëª¨ë“œë¡œ í´ë°±): {error_msg}")
                        logger.info(f"   ğŸ’¡ ì†ìƒëœ ì²´í¬í¬ì¸íŠ¸ëŠ” ë¬´ì‹œí•˜ê³  ìƒˆ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤")
                    else:
                        logger.warning(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ì„¤ì • ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {error_msg}")
                    use_hybrid = False
            
            # Self-play ì‹¤í–‰ - ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ë‹¤ë¥¸ ì „ëµ ìƒ˜í”Œë§ + ì‹¤ì œ ìº”ë“¤ ë°ì´í„° ğŸ”¥
            # ì „ëµ í’€ í¬ê¸°ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ ìˆ˜ ì¡°ì •
            # **ì¤‘ìš”**: ì „ëµ í’€ í¬ê¸°ë³´ë‹¤ ì‘ê²Œ ì„¤ì •í•´ì•¼ ë‹¤ì–‘ì„± í™•ë³´ ê°€ëŠ¥
            total_pool_size = len(all_strategies_pool) if all_strategies_pool else 0
            if total_pool_size > 8:
                agents_per_episode = 4  # ì „ëµ í’€ì´ ì¶©ë¶„í•˜ë©´ 4ê°œ
            elif total_pool_size > 4:
                agents_per_episode = 3  # ì „ëµ í’€ì´ ë³´í†µì´ë©´ 3ê°œ
            elif total_pool_size > 0:
                agents_per_episode = min(2, total_pool_size)  # ì „ëµ í’€ì´ ì‘ìœ¼ë©´ 1-2ê°œ
            else:
                agents_per_episode = 3  # ì „ëµ í’€ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            
            logger.info(f"ğŸ¯ ì—ì´ì „íŠ¸ ì„¤ì •: ì „ëµ í’€ {total_pool_size}ê°œ ì¤‘ ë§¤ ì—í”¼ì†Œë“œ {agents_per_episode}ê°œ ì‚¬ìš© (ë‹¤ì–‘ì„± í™•ë³´)")
            
            # ğŸ†• ì ì‘í˜• ì˜ˆì¸¡ Self-play ë¹„ìœ¨ ê³„ì‚°
            try:
                from rl_pipeline.pipelines.selfplay_adaptive import get_adaptive_predictive_ratio
                adaptive_ratio = get_adaptive_predictive_ratio(
                    coin=coin,
                    interval=interval,
                    base_ratio=PREDICTIVE_SELFPLAY_RATIO,
                    enable_auto=True
                )
            except Exception as e:
                logger.warning(f"âš ï¸ ì ì‘í˜• ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
                adaptive_ratio = PREDICTIVE_SELFPLAY_RATIO
            
            
            # Self-play ì§„í™” ì‹¤í–‰ (ê¸°ë³¸ ëª¨ë“œ)
            logger.info("ğŸš€ Self-play ì§„í™” ì‹¤í–‰")
            selfplay_result = run_self_play_test(
                strategy_params_list,
                episodes=dynamic_episodes,
                all_strategy_pool=all_strategies_pool if all_strategies_pool else strategy_params_list,
                agents_per_episode=agents_per_episode,
                candle_data=candle_data,
                coin=coin,
                interval=interval,
                session_id=self.session_id  # ì„¸ì…˜ ID ì „ë‹¬
            )
            
            
            
            # ì „ëµ ì§„í™” ì ìš©
            evolved_strategies = self._apply_selfplay_evolution(
                strategies,
                selfplay_result,
                used_predictive=False,
                dual_mode=False
            )
            
            # ğŸ”¥ selfplay ê²°ê³¼ ì €ì¥ (ë‚˜ì¤‘ì— ë ˆì§ ë¼ìš°íŒ…ì—ì„œ ì‚¬ìš©)
            self._current_selfplay_result[interval] = selfplay_result
            
            return evolved_strategies
        except Exception as e:
            logger.error(f"âŒ Self-play ì§„í™” ì‹¤íŒ¨: {e}")
            logger.exception(e)
            return strategies  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì „ëµ ë°˜í™˜

    
    def _analyze_strategy_synergy(self, coin: str, interval: str, strategies: List[Dict[str, Any]], candle_data: pd.DataFrame) -> Dict[str, Any]:
        """ì „ëµ ê°„ ì‹œë„ˆì§€ ë¶„ì„"""
        try:
            if not strategies:
                return {'synergy_score': 0.5, 'synergy_patterns': {}}
            
            # ì „ëµ íŒŒë¼ë¯¸í„° ìœ ì‚¬ë„ ë¶„ì„
            param_similarities = []
            for i, s1 in enumerate(strategies[:10]):
                for s2 in strategies[i+1:i+3]:
                    try:
                        # RSI ìœ ì‚¬ë„
                        rsi_sim = 1.0 - abs(s1.get('rsi_min', 30) - s2.get('rsi_min', 30)) / 40.0
                        # Volume ìœ ì‚¬ë„
                        vol_sim = 1.0 - abs(s1.get('volume_ratio_min', 1.0) - s2.get('volume_ratio_min', 1.0))
                        param_similarities.append((rsi_sim + vol_sim) / 2)
                    except:
                        pass
            
            synergy_score = sum(param_similarities) / len(param_similarities) if param_similarities else 0.5
            
            return {
                'synergy_score': float(synergy_score),
                'synergy_patterns': {
                    'strategy_count': len(strategies),
                    'avg_similarity': float(np.mean(param_similarities)) if param_similarities else 0.5
                }
            }
        except Exception as e:
            logger.error(f"Synergy ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'synergy_score': 0.5}
    
    def _analyze_dual_selfplay_synergy(
        self, 
        coin: str, 
        interval: str, 
        evolved_strategies: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ì´ì¤‘ Self-play ì‹œë„ˆì§€ ë¶„ì„
        
        ì˜ˆì¸¡ ì‹¤í˜„ + ê¸°ì¡´ Self-play ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìƒí˜¸ ë³´ì™„ ê´€ê³„ ê²€ì¦
        
        Args:
            coin: ì½”ì¸ ì‹¬ë³¼
            interval: ì¸í„°ë²Œ
            evolved_strategies: ì§„í™”ëœ ì „ëµ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì‹œë„ˆì§€ ë¶„ì„ ê²°ê³¼
        """
        try:
            from rl_pipeline.db.connection_pool import get_optimized_db_connection
            
            with get_optimized_db_connection("strategies") as conn:
                cursor = conn.cursor()
                
                # ìµœê·¼ ì˜ˆì¸¡ ì‹¤í˜„ ê²°ê³¼ ì¡°íšŒ
                cursor.execute("""
                    SELECT 
                        AVG(CASE WHEN acc_flag = 1 THEN 1.0 ELSE 0.0 END) as avg_pred_accuracy,
                        AVG(realized_ret_signed) as avg_pred_return,
                        COUNT(*) as pred_count
                    FROM rl_episode_summary
                    WHERE coin = ? AND interval = ?
                      AND ts_exit >= datetime('now', '-7 days')
                """, (coin, interval))
                
                pred_result = cursor.fetchone()
                avg_pred_accuracy = pred_result[0] if pred_result[0] else 0.0
                avg_pred_return = pred_result[1] if pred_result[1] else 0.0
                pred_count = pred_result[2] if pred_result[2] else 0
                
                # ìµœê·¼ ê¸°ì¡´ Self-play ê²°ê³¼ ì¡°íšŒ
                cursor.execute("""
                    SELECT 
                        AVG(win_rate) as avg_win_rate,
                        AVG(total_return) as avg_return,
                        COUNT(*) as trad_count
                    FROM simulation_results
                    WHERE coin = ? AND interval = ?
                      AND created_at >= datetime('now', '-7 days')
                """, (coin, interval))
                
                trad_result = cursor.fetchone()
                avg_win_rate = trad_result[0] if trad_result[0] else 0.0
                avg_return = trad_result[1] if trad_result[1] else 0.0
                trad_count = trad_result[2] if trad_result[2] else 0
                
                # ì‹œë„ˆì§€ ì ìˆ˜ ê³„ì‚°
                # ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ê³  ê±°ë˜ ì„±ê³¼ë„ ì¢‹ìœ¼ë©´ ë†’ì€ ì‹œë„ˆì§€
                if pred_count > 0 and trad_count > 0:
                    synergy_score = (
                        (avg_pred_accuracy * 0.6) +  # ì˜ˆì¸¡ ì •í™•ë„ 60%
                        (min(avg_win_rate, 1.0) * 0.4)  # ìŠ¹ë¥  40%
                    )
                    
                    logger.info(f"ğŸ’¡ ì´ì¤‘ Self-play ì‹œë„ˆì§€ ë¶„ì„ ({coin}-{interval}):")
                    logger.info(f"   ğŸ¯ ì˜ˆì¸¡ ì‹¤í˜„: ì •í™•ë„ {avg_pred_accuracy:.1%}, ìˆ˜ìµ {avg_pred_return:+.2%} ({pred_count}ê±´)")
                    logger.info(f"   ğŸ“Š ê¸°ì¡´ Self-play: ìŠ¹ë¥  {avg_win_rate:.1%}, ìˆ˜ìµ {avg_return:+.2%} ({trad_count}ê±´)")
                    logger.info(f"   âš¡ ì‹œë„ˆì§€ ì ìˆ˜: {synergy_score:.2f} "
                              f"{'ğŸ”¥ ìš°ìˆ˜' if synergy_score > 0.7 else 'âœ… ì–‘í˜¸' if synergy_score > 0.5 else 'âš ï¸ ê°œì„  í•„ìš”'}")
                    
                    return {
                        'synergy_score': synergy_score,
                        'pred_accuracy': avg_pred_accuracy,
                        'pred_return': avg_pred_return,
                        'pred_count': pred_count,
                        'trad_win_rate': avg_win_rate,
                        'trad_return': avg_return,
                        'trad_count': trad_count
                    }
                
                return {'synergy_score': 0.5, 'insufficient_data': True}
                
        except Exception as e:
            logger.debug(f"âš ï¸ ì´ì¤‘ Self-play ì‹œë„ˆì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'synergy_score': 0.5, 'error': str(e)}
    
    def _apply_selfplay_evolution(
        self, 
        strategies: List[Dict[str, Any]], 
        selfplay_result: Dict[str, Any],
        used_predictive: bool = False,
        dual_mode: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Self-play ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ëµ ì§„í™” ì ìš©
        
        ğŸ”¥ ìƒí˜¸ ë³´ì™„ ì§„í™”:
        - ì˜ˆì¸¡ ì‹¤í˜„ Self-play: ì˜ˆì¸¡ ì •í™•ë„ ê¸°ë°˜ ì§„í™” (ë°©í–¥/ê°€ê²©/ì‹œê°„ ì •í™•ë„)
        - ê¸°ì¡´ Self-play: ê±°ë˜ ì„±ê³¼ ê¸°ë°˜ ì§„í™” (ìŠ¹ë¥ /ìˆ˜ìµë¥ /ìƒ¤í”„)
        - ë™ì‹œ ì‹¤í–‰ ëª¨ë“œ: ë‘ ê²°ê³¼ í†µí•©í•˜ì—¬ ë“±ê¸‰ ì •í™•ë„ í–¥ìƒ ğŸ”¥
        
        Args:
            strategies: ì›ë³¸ ì „ëµ ë¦¬ìŠ¤íŠ¸
            selfplay_result: Self-play ê²°ê³¼
            used_predictive: ì˜ˆì¸¡ ì‹¤í˜„ Self-play ì‚¬ìš© ì—¬ë¶€
            dual_mode: ë™ì‹œ ì‹¤í–‰ ëª¨ë“œ ì—¬ë¶€
        """
        try:
            evolved_strategies = []
            
            # Self-play ê²°ê³¼ì—ì„œ í•™ìŠµëœ íŒ¨í„´ ì¶”ì¶œ
            summary = selfplay_result.get("summary", {})
            cycle_results = selfplay_result.get("cycle_results", [])
            
            # ğŸ”¥ ë™ì‹œ ì‹¤í–‰ ëª¨ë“œ: ë‘ ê²°ê³¼ í†µí•© ì²˜ë¦¬ (ë“±ê¸‰ ì •í™•ë„ í–¥ìƒ)
            if dual_mode and selfplay_result.get('dual_mode'):
                traditional_result = selfplay_result.get('traditional_result')
                predictive_result = selfplay_result.get('predictive_result')
                
                # ë‘ ê²°ê³¼ ëª¨ë‘ í™œìš©í•˜ì—¬ ì¢…í•© í‰ê°€
                logger.info(f"ğŸ”¥ ë™ì‹œ ì‹¤í–‰ ëª¨ë“œ: ë‘ ë°©ì‹ ê²°ê³¼ í†µí•© í‰ê°€ ì¤‘ (ë“±ê¸‰ ì •í™•ë„ í–¥ìƒ ëª©í‘œ)")
                
                # ì˜ˆì¸¡ ì •í™•ë„ ë°ì´í„° ì¶”ì¶œ
                pred_accuracy = 0.0
                pred_reward = 0.0
                pred_count = 0
                if predictive_result and predictive_result.get("status") in ["success", "failed"]:
                    episode_results = predictive_result.get("episode_results", [])
                    # ğŸ”¥ ì„±ê³µí•œ ì—í”¼ì†Œë“œë§Œ ê³„ì‚° (ìŠ¤í‚µ ì œì™¸)
                    successful_episodes = [r for r in episode_results if r.get("status") == "success"]
                    if successful_episodes:
                        pred_count = len(successful_episodes)
                        # ğŸ”¥ result êµ¬ì¡° í™•ì¸: result ì•ˆì— ìˆê±°ë‚˜ ì§ì ‘ ìˆì„ ìˆ˜ ìˆìŒ
                        acc_flags = []
                        rewards = []
                        for e in successful_episodes:
                            # result ì•ˆì—ì„œ ë¨¼ì € ì°¾ê³ , ì—†ìœ¼ë©´ ì§ì ‘ ì°¾ê¸°
                            result = e.get("result", {})
                            if result:
                                acc_flag = result.get("acc_flag")
                                total_reward = result.get("total_reward")
                            else:
                                acc_flag = e.get("acc_flag")
                                total_reward = e.get("total_reward")
                            
                            if acc_flag is not None:
                                acc_flags.append(acc_flag)
                            if total_reward is not None:
                                rewards.append(total_reward)
                        
                        if acc_flags:
                            pred_accuracy = sum(acc_flags) / len(acc_flags)
                        if rewards:
                            pred_reward = sum(rewards) / len(rewards)
                    else:
                        # ìŠ¤í‚µëœ ì—í”¼ì†Œë“œ ì •ë³´ ë¡œê¹…
                        skipped_count = len([r for r in episode_results if r.get("status") == "skipped"])
                        logger.debug(f"ğŸ“Š ì˜ˆì¸¡ ì‹¤í˜„ ì—í”¼ì†Œë“œ: ì„±ê³µ 0ê°œ, ìŠ¤í‚µ {skipped_count}ê°œ")
                
                # ê±°ë˜ ì„±ê³¼ ë°ì´í„° ì¶”ì¶œ
                trad_win_rate = 0.0
                trad_profit = 0.0
                trad_count = 0
                if traditional_result and traditional_result.get("status") == "success":
                    summary = traditional_result.get("summary", {}) or {}
                    
                    # ğŸ”¥ summaryì—ì„œ ì§ì ‘ ì¶”ì¶œ (None ì²´í¬ ê°•í™”)
                    trad_win_rate = summary.get("average_win_rate") if summary.get("average_win_rate") is not None else 0
                    trad_profit = summary.get("average_profit") if summary.get("average_profit") is not None else 0
                    trad_count = summary.get("total_trades") if summary.get("total_trades") is not None else 0
                    
                    # ğŸ”¥ summaryì—ì„œ ê°’ì´ ì—†ê±°ë‚˜ 0ì´ë©´ cycle_resultsì—ì„œ ê³„ì‚° (ê°œì„ )
                    if (trad_win_rate == 0 and trad_profit == 0) or (not summary):
                        cycle_results = traditional_result.get("cycle_results", [])
                        if cycle_results:
                            all_trades = []
                            all_profits = []
                            total_trades_from_cycles = 0
                            for cycle in cycle_results:
                                results = cycle.get("results", {})
                                for agent_id, agent_result in results.items():
                                    if agent_result:
                                        trades = agent_result.get("trades", [])
                                        trades_count = agent_result.get("total_trades", len(trades) if trades else 0)
                                        total_trades_from_cycles += trades_count
                                        if trades:
                                            all_trades.extend(trades)
                                        profit = agent_result.get("profit", 0)
                                        if profit != 0:
                                            all_profits.append(profit)
                            
                            if all_trades or total_trades_from_cycles > 0:
                                wins = sum(1 for t in all_trades if t.get("profit", 0) > 0) if all_trades else 0
                                trad_win_rate = wins / len(all_trades) if all_trades else 0
                                trad_profit = sum(all_profits) / len(all_profits) if all_profits else 0
                                trad_count = total_trades_from_cycles if total_trades_from_cycles > 0 else len(all_trades)
                                logger.debug(f"ğŸ“Š cycle_resultsì—ì„œ ê³„ì‚°: ìŠ¹ë¥  {trad_win_rate:.1%}, ìˆ˜ìµ {trad_profit:.2f}, ê±°ë˜ {trad_count}íšŒ")
                            elif total_trades_from_cycles == 0:
                                logger.warning(f"âš ï¸ cycle_resultsì—ì„œ ê±°ë˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ (total_trades=0)")
                
                logger.info(f"ğŸ“Š í†µí•© í‰ê°€:")
                logger.info(f"   ğŸ¯ ì˜ˆì¸¡ ì‹¤í˜„: ì •í™•ë„ {pred_accuracy:.1%}, ë³´ìƒ {pred_reward:.3f} ({pred_count}ê±´ ì„±ê³µ)")
                logger.info(f"   ğŸ“Š ê¸°ì¡´ Self-play: ìŠ¹ë¥  {trad_win_rate:.1%}, ìˆ˜ìµ {trad_profit:+.2f} ({trad_count}ê±´ ê±°ë˜)")
                
                # ë“±ê¸‰ ì •í™•ë„ë¥¼ ìœ„í•´ ë‘ ë°ì´í„° ëª¨ë‘ ë°˜ì˜ (ë™ì‹œ ì‹¤í–‰ ëª¨ë“œì˜ í•µì‹¬!)
                if pred_accuracy > 0.6 and trad_win_rate > 0.5:
                    logger.info(f"âœ… ìš°ìˆ˜í•œ í†µí•© ì„±ê³¼ â†’ ë“±ê¸‰ ì •í™•ë„ í–¥ìƒ ê¸°ëŒ€")
                    # ë™ì‹œ ì‹¤í–‰ ëª¨ë“œì—ì„œëŠ” ì˜ˆì¸¡ ì •í™•ë„ì™€ ê±°ë˜ ì„±ê³¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ë“±ê¸‰ ë¶€ì—¬
                    # ì´ ì •ë³´ëŠ” ì´í›„ ë¡¤ì—… ë‹¨ê³„ì—ì„œ í™œìš©ë¨
            
            # ğŸ”¥ ì˜ˆì¸¡ ì‹¤í˜„ Self-play ê²°ê³¼ ì²˜ë¦¬ (ë‹¨ë… ì‹¤í–‰ ì‹œ)
            elif used_predictive:
                episode_results = selfplay_result.get("episode_results", [])
                successful_episodes = [r for r in episode_results if r.get("status") == "success"]
                
                if successful_episodes:
                    # ì˜ˆì¸¡ ì •í™•ë„ ê¸°ë°˜ ì§„í™”
                    avg_accuracy = sum(e.get("acc_flag", 0) for e in successful_episodes) / len(successful_episodes)
                    avg_reward = sum(e.get("total_reward", 0) for e in successful_episodes) / len(successful_episodes)
                    
                    logger.info(f"ğŸ“Š ì˜ˆì¸¡ ì‹¤í˜„ ê²°ê³¼: í‰ê·  ì •í™•ë„ {avg_accuracy:.1%}, í‰ê·  ë³´ìƒ {avg_reward:.3f}")
                    
                    # ì˜ˆì¸¡ ì„±ê³¼ê°€ ì¢‹ì€ ì „ëµì€ ì˜ˆì¸¡ ê´€ë ¨ íŒŒë¼ë¯¸í„° ê°•í™”
                    if avg_accuracy > 0.7 and avg_reward > 0.5:
                        logger.info(f"âœ… ì˜ˆì¸¡ ëŠ¥ë ¥ ìš°ìˆ˜ â†’ ì˜ˆì¸¡ ê´€ë ¨ íŒŒë¼ë¯¸í„° ê°•í™”")
            
            # ğŸ”¥ ëª¨ë“  ì—í”¼ì†Œë“œì—ì„œ ì‚¬ìš©ëœ ì „ëµ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
            all_evolved_params = []
            for cycle in cycle_results:
                results = cycle.get("results", {})
                for agent_id, performance in results.items():
                    # ì „ëµ íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘
                    if 'strategy_params' in performance:
                        all_evolved_params.append(performance['strategy_params'])
            
            # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì˜ ì„±ê³¼ë¥¼ ì „ëµ ì„±ëŠ¥ ì§€í‘œë¡œ ì‚¬ìš©
            for i, strategy in enumerate(strategies):
                # ì›ë³¸ ì „ëµ ë³µì‚¬
                evolved_strategy = strategy.copy()
                
                # ğŸ”¥ ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°ë¡œ ì—…ë°ì´íŠ¸
                if cycle_results and len(cycle_results) > 0:
                    last_episode = cycle_results[-1]
                    last_results = last_episode.get("results", {})
                    if last_results and i < len(last_results):
                        # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì˜ ê° ì—ì´ì „íŠ¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©
                        agent_performances = list(last_results.values())
                        if i < len(agent_performances) and 'strategy_params' in agent_performances[i]:
                            evolved_params = agent_performances[i]['strategy_params']
                            # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
                            evolved_strategy['rsi_min'] = evolved_params.get('rsi_min', evolved_strategy.get('rsi_min', 30.0))
                            evolved_strategy['rsi_max'] = evolved_params.get('rsi_max', evolved_strategy.get('rsi_max', 70.0))
                            evolved_strategy['volume_ratio_min'] = evolved_params.get('volume_ratio_min', evolved_strategy.get('volume_ratio_min', 1.0))
                            evolved_strategy['volume_ratio_max'] = evolved_params.get('volume_ratio_max', evolved_strategy.get('volume_ratio_max', 2.0))
                            evolved_strategy['stop_loss_pct'] = evolved_params.get('stop_loss_pct', evolved_strategy.get('stop_loss_pct', 0.02))
                            evolved_strategy['take_profit_pct'] = evolved_params.get('take_profit_pct', evolved_strategy.get('take_profit_pct', 0.04))
                            evolved_strategy['macd_buy_threshold'] = evolved_params.get('macd_buy_threshold', evolved_strategy.get('macd_buy_threshold', 0.01))
                            evolved_strategy['macd_sell_threshold'] = evolved_params.get('macd_sell_threshold', evolved_strategy.get('macd_sell_threshold', -0.01))
                
                # Self-play ê²°ê³¼ì—ì„œ ì‹¤ì œ ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ
                # ğŸ”¥ ì˜¨ë¼ì¸ Self-playì˜ ê²½ìš° summaryì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (ì „ëµë³„ ëˆ„ì  ì„±ê³¼)
                if selfplay_result and selfplay_result.get("source") == "online_selfplay":
                    # ì˜¨ë¼ì¸ Self-playëŠ” summaryì— ì „ëµë³„ ìƒì„¸ ì„±ê³¼ê°€ ìˆìŒ
                    summary = selfplay_result.get("summary", {})
                    strategy_details = summary.get("strategy_details", {})
                    
                    # í˜„ì¬ ì „ëµ IDë¡œ ì„±ê³¼ ì°¾ê¸°
                    strategy_id = evolved_strategy.get('id')
                    if strategy_id and strategy_id in strategy_details:
                        strategy_perf = strategy_details[strategy_id]
                        evolved_strategy['profit'] = strategy_perf.get('avg_profit', 0.0) * strategy_perf.get('segment_count', 1)  # ì´ ìˆ˜ìµ
                        evolved_strategy['win_rate'] = 0.5 if strategy_perf.get('avg_pf', 0.0) > 1.0 else (0.3 if strategy_perf.get('avg_pf', 0.0) > 0.5 else 0.2)  # PF ê¸°ë°˜ ì¶”ì •
                        evolved_strategy['trades_count'] = strategy_perf.get('total_trades', 0)
                        evolved_strategy['max_drawdown'] = strategy_perf.get('max_mdd', 0.0)
                        evolved_strategy['sharpe_ratio'] = strategy_perf.get('avg_sharpe', 0.0)
                        evolved_strategy['profit_factor'] = strategy_perf.get('avg_pf', 0.0)
                        logger.debug(f"ğŸ“Š ì˜¨ë¼ì¸ Self-play ì„±ê³¼ ë°˜ì˜: {strategy_id}, ìˆ˜ìµ={evolved_strategy['profit']:.2f}, ê±°ë˜={evolved_strategy['trades_count']}")
                    elif cycle_results:
                        # strategy_detailsì— ì—†ìœ¼ë©´ cycle_resultsì—ì„œ ê³„ì‚°
                        all_profits = []
                        all_win_rates = []
                        all_trades = []
                        all_drawdowns = []
                        all_sharpes = []
                        all_pfs = []
                        
                        # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì˜ ëˆ„ì  ì„±ê³¼ ì‚¬ìš©
                        for cycle in cycle_results:
                            results = cycle.get("results", {})
                            for agent_id, agent_result in results.items():
                                if agent_id == strategy_id or not strategy_id:  # ì „ëµ ID ë§¤ì¹­ ë˜ëŠ” ëª¨ë“  ì „ëµ
                                    if agent_result:
                                        all_profits.append(agent_result.get('total_pnl', 0.0))
                                        all_win_rates.append(agent_result.get('win_rate', 0.0))
                                        all_trades.append(agent_result.get('total_trades', 0))
                                        all_drawdowns.append(agent_result.get('max_drawdown', 0.0))
                                        all_sharpes.append(agent_result.get('sharpe_ratio', 0.0))
                                        all_pfs.append(agent_result.get('profit_factor', 0.0))
                        
                        if all_profits:
                            evolved_strategy['profit'] = sum(all_profits)  # ëˆ„ì  ìˆ˜ìµ
                            evolved_strategy['win_rate'] = sum(all_win_rates) / len(all_win_rates) if all_win_rates else 0.0
                            evolved_strategy['trades_count'] = sum(all_trades)
                            evolved_strategy['max_drawdown'] = max(all_drawdowns) if all_drawdowns else 0.0
                            evolved_strategy['sharpe_ratio'] = sum(all_sharpes) / len(all_sharpes) if all_sharpes else 0.0
                            evolved_strategy['profit_factor'] = sum(all_pfs) / len(all_pfs) if all_pfs else 0.0
                elif cycle_results:
                    # ì „í†µ Self-play ë˜ëŠ” ê¸°íƒ€: ëª¨ë“  ì—í”¼ì†Œë“œì˜ ëˆ„ì  ì„±ê³¼ ì‚¬ìš©
                    all_profits = []
                    all_win_rates = []
                    all_trades = []
                    all_drawdowns = []
                    all_sharpes = []
                    all_pfs = []
                    
                    for cycle in cycle_results:
                        results = cycle.get("results", {})
                        strategy_id_check = evolved_strategy.get('id')
                        for agent_id, agent_result in results.items():
                            if not strategy_id_check or agent_id == strategy_id_check:
                                if agent_result:
                                    all_profits.append(agent_result.get('total_pnl', 0.0))
                                    all_win_rates.append(agent_result.get('win_rate', 0.0))
                                    all_trades.append(agent_result.get('total_trades', 0))
                                    all_drawdowns.append(agent_result.get('max_drawdown', 0.0))
                                    all_sharpes.append(agent_result.get('sharpe_ratio', 0.0))
                                    all_pfs.append(agent_result.get('profit_factor', 0.0))
                    
                    if all_profits:
                        evolved_strategy['profit'] = sum(all_profits)  # ëˆ„ì  ìˆ˜ìµ
                        evolved_strategy['win_rate'] = sum(all_win_rates) / len(all_win_rates) if all_win_rates else 0.0
                        evolved_strategy['trades_count'] = sum(all_trades)
                        evolved_strategy['max_drawdown'] = max(all_drawdowns) if all_drawdowns else 0.0
                        evolved_strategy['sharpe_ratio'] = sum(all_sharpes) / len(all_sharpes) if all_sharpes else 0.0
                        evolved_strategy['profit_factor'] = sum(all_pfs) / len(all_pfs) if all_pfs else 0.0
                        
                        # ì¶”ê°€ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                        # Calmar Ratio
                        if evolved_strategy['max_drawdown'] > 0:
                            evolved_strategy['calmar_ratio'] = (evolved_strategy['profit'] / 10000.0) / evolved_strategy['max_drawdown']
                        else:
                            evolved_strategy['calmar_ratio'] = 0.0
                        
                        # Profit Factor (ì´ë¯¸ ìœ„ì—ì„œ ì„¤ì •ëœ ê²½ìš° ìœ ì§€, ì—†ìœ¼ë©´ ê³„ì‚°)
                        if 'profit_factor' not in evolved_strategy or evolved_strategy.get('profit_factor', 0.0) == 0.0:
                            evolved_strategy['profit_factor'] = evolved_strategy['win_rate'] / (1 - evolved_strategy['win_rate']) if evolved_strategy['win_rate'] < 1 else 10.0
                        
                        # Avg Profit Per Trade
                        if evolved_strategy['trades_count'] > 0:
                            evolved_strategy['avg_profit_per_trade'] = evolved_strategy['profit'] / evolved_strategy['trades_count']
                        else:
                            evolved_strategy['avg_profit_per_trade'] = 0.0
                        
                        # Complexity Score
                        param_count = sum([
                            1 if evolved_strategy.get('rsi_min') else 0,
                            1 if evolved_strategy.get('rsi_max') else 0,
                            1 if evolved_strategy.get('volume_ratio_min') else 0,
                            1 if evolved_strategy.get('volume_ratio_max') else 0,
                            1 if evolved_strategy.get('macd_buy_threshold') else 0,
                            1 if evolved_strategy.get('macd_sell_threshold') else 0,
                        ])
                        evolved_strategy['complexity_score'] = min(1.0, param_count / 6.0)
                        
                        # Score (ì¢…í•© ì ìˆ˜) - ì ˆëŒ€ ê¸°ì¤€
                        profit = evolved_strategy.get('profit', 0)
                        win_rate = evolved_strategy.get('win_rate', 0)
                        sharpe = evolved_strategy.get('sharpe_ratio', 0)
                        max_dd = evolved_strategy.get('max_drawdown', 0)
                        profit_factor = evolved_strategy.get('profit_factor', 0)
                        trades_count = evolved_strategy.get('trades_count', 0)
                        
                        # ì ˆëŒ€ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
                        # profitì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜ (10000ë‹¬ëŸ¬ ê¸°ì¤€)
                        profit_percent = (profit / 10000.0) * 100 if isinstance(profit, (int, float)) else 0.0
                        
                        # 1. ìˆ˜ìµì„± (35%): ì‹¤ì œ ìˆ˜ìµë¥  ê¸°ì¤€ (í¼ì„¼íŠ¸)
                        if profit_percent > 10.0:  # 10% ì´ìƒ
                            profit_score = 1.0
                        elif profit_percent > 5.0:  # 5% ì´ìƒ
                            profit_score = 0.8
                        elif profit_percent > 2.0:  # 2% ì´ìƒ
                            profit_score = 0.6
                        elif profit_percent > 0:  # 0% ì´ìƒ
                            profit_score = 0.4
                        elif profit_percent > -2.0:  # -2% ì´ìƒ
                            profit_score = 0.2
                        else:  # ì†ì‹¤
                            profit_score = 0.0
                        
                        # 2. ìŠ¹ë¥  (25%): ì ˆëŒ€ ê¸°ì¤€
                        if win_rate > 0.65:
                            win_rate_score = 1.0
                        elif win_rate > 0.55:
                            win_rate_score = 0.8
                        elif win_rate > 0.50:
                            win_rate_score = 0.6
                        elif win_rate > 0.45:
                            win_rate_score = 0.4
                        elif win_rate > 0.40:
                            win_rate_score = 0.2
                        else:
                            win_rate_score = 0.0
                        
                        # 3. ìƒ¤í”„ ë¹„ìœ¨ (20%)
                        if sharpe > 2.0:
                            sharpe_score = 1.0
                        elif sharpe > 1.5:
                            sharpe_score = 0.8
                        elif sharpe > 1.0:
                            sharpe_score = 0.6
                        elif sharpe > 0.5:
                            sharpe_score = 0.4
                        elif sharpe > 0:
                            sharpe_score = 0.2
                        else:
                            sharpe_score = 0.0
                        
                        # 4. ìµœëŒ€ ë‚™í­ (10%)
                        max_dd_score = max(0, 1.0 - (max_dd / 0.2))  # 20% ì´ìƒ ë‚™í­ì´ë©´ 0ì 
                        
                        # 5. ìˆ˜ìµë¹„ (10%) ğŸ†•
                        if profit_factor > 3.0:  # ì´ìµ/ì†ì‹¤ 3ë°° ì´ìƒ
                            profit_factor_score = 1.0
                        elif profit_factor > 2.0:  # ì´ìµ/ì†ì‹¤ 2ë°° ì´ìƒ
                            profit_factor_score = 0.8
                        elif profit_factor > 1.5:  # ì´ìµ/ì†ì‹¤ 1.5ë°° ì´ìƒ
                            profit_factor_score = 0.6
                        elif profit_factor > 1.0:  # ì´ìµ/ì†ì‹¤ 1ë°° ì´ìƒ
                            profit_factor_score = 0.4
                        elif profit_factor > 0.7:  # ì´ìµ/ì†ì‹¤ 0.7ë°° ì´ìƒ
                            profit_factor_score = 0.2
                        else:  # ì†ì‹¤ì´ ë” í¼
                            profit_factor_score = 0.0
                        
                        evolved_strategy['score'] = (
                            profit_score * 0.30 +      # 30% (ì•ˆì •ì„± ê°•í™”)
                            win_rate_score * 0.20 +   # 20% (PFê°€ ë” ì¤‘ìš”)
                            sharpe_score * 0.25 +     # 25% (ë¦¬ìŠ¤í¬ ëŒ€ë¹„ íš¨ìœ¨ ê°•í™”)
                            max_dd_score * 0.15 +     # 15% (ì¥ê¸° ìƒì¡´ í•µì‹¬)
                            profit_factor_score * 0.10  # 10% (ê¸°ì´ˆ í’ˆì§ˆ)
                        )
                        
                        # ğŸ”¥ Quality Grade - ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë“±ê¸‰ ë¶€ì—¬ ì œê±°
                        # ì‹œë®¬ë ˆì´ì…˜ì€ íŒŒë¼ë¯¸í„° íŠœë‹(ì§„í™”)ì—ë§Œ ì‚¬ìš©í•˜ê³ ,
                        # ë“±ê¸‰ì€ ë ˆì§ ë¼ìš°íŒ…(ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸) + í†µí•© ë¶„ì„ ê²°ê³¼ë¡œë§Œ ê²°ì •
                        # ì´ìœ : ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì˜ ì™œê³¡(íŠ¹íˆ 240m 100% ìŠ¹ë¥  ë“±) ë°©ì§€
                        evolved_strategy['quality_grade'] = 'UNKNOWN'  # ì´ˆê¸°ê°’, ë¼ìš°íŒ…/ë¶„ì„ í›„ ì—…ë°ì´íŠ¸ë¨

                        # ì°¸ê³ : ê¸°ì¡´ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë“±ê¸‰ ê³„ì‚° (í˜„ì¬ ë¹„í™œì„±í™”)
                        # from rl_pipeline.core.strategy_grading import StrategyGrading
                        # evolved_strategy['quality_grade'] = StrategyGrading.calculate_grade(
                        #     profit_percent=profit_percent,
                        #     win_rate=win_rate,
                        #     sharpe=sharpe,
                        #     max_dd=max_dd,
                        #     profit_factor=profit_factor,
                        #     is_initial_learning=False
                        # )
                
                # Self-play ê²°ê³¼ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì¡°ì •
                if i < len(summary.get("top_performers", [])):
                    performer_data = summary["top_performers"][i]
                    
                    # ì„±ê³¼ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •
                    if performer_data.get("win_rate", 0) > 0.6:
                        # ë†’ì€ ìŠ¹ë¥ : ë” ê³µê²©ì ìœ¼ë¡œ
                        evolved_strategy['rsi_min'] = max(20, evolved_strategy.get('rsi_min', 30) - 5)
                        evolved_strategy['rsi_max'] = min(80, evolved_strategy.get('rsi_max', 70) + 5)
                    elif performer_data.get("win_rate", 0) < 0.4:
                        # ë‚®ì€ ìŠ¹ë¥ : ë” ë³´ìˆ˜ì ìœ¼ë¡œ
                        evolved_strategy['rsi_min'] = min(40, evolved_strategy.get('rsi_min', 30) + 5)
                        evolved_strategy['rsi_max'] = max(60, evolved_strategy.get('rsi_max', 70) - 5)
                
                # ğŸ”¥ ìƒí˜¸ ë³´ì™„ ì§„í™” ë©”íƒ€ë°ì´í„° ì¶”ê°€
                evolved_strategy['evolved'] = True
                evolved_strategy['evolution_source'] = 'predictive' if used_predictive else 'traditional'
                evolved_strategy['evolution_timestamp'] = datetime.now().isoformat()
                
                evolved_strategies.append(evolved_strategy)
            
            return evolved_strategies
            
        except Exception as e:
            logger.error(f"âŒ Self-play ì§„í™” ì ìš© ì‹¤íŒ¨: {e}")
            return strategies

    def _evolve_existing_strategies(self, coin: str, interval: str, new_strategies: List[Dict]) -> List[Dict]:
        """
        ê¸°ì¡´ ì „ëµì„ ì§„í™”ì‹œì¼œ ìƒˆë¡œìš´ ì „ëµ ìƒì„± (ìœ ì „ ì•Œê³ ë¦¬ì¦˜)

        Args:
            coin: ì½”ì¸
            interval: ì¸í„°ë²Œ
            new_strategies: ìƒˆë¡œ ìƒì„±ëœ ì „ëµ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì§„í™”ëœ ì „ëµ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í™˜ê²½ë³€ìˆ˜ë¡œ ì§„í™” í™œì„±í™” ì—¬ë¶€ í™•ì¸
            enable_evolution = os.getenv('ENABLE_STRATEGY_EVOLUTION', 'true').lower() == 'true'

            if not enable_evolution:
                logger.debug(f"â­ï¸ {coin}-{interval}: ì „ëµ ì§„í™” ë¹„í™œì„±í™”")
                return []

            logger.info(f"ğŸ§¬ {coin}-{interval}: ì „ëµ ì§„í™” ì‹œì‘")

            # StrategyEvolver import
            from rl_pipeline.strategy.strategy_evolver import StrategyEvolver
            from rl_pipeline.db.connection_pool import get_strategy_db_pool

            # ê¸°ì¡´ ì „ëµ ì¡°íšŒ (DBì—ì„œ)
            pool = get_strategy_db_pool()
            with pool.get_connection() as conn:
                cursor = conn.cursor()

                # ìƒìœ„ ë“±ê¸‰ ì „ëµë§Œ ì¡°íšŒ (S, A, B)
                cursor.execute("""
                    SELECT
                        cs.id as strategy_id,
                        cs.coin,
                        cs.interval,
                        cs.params,
                        cs.regime,
                        sg.grade as quality_grade,
                        sr.avg_ret,
                        sr.win_rate,
                        sr.predictive_accuracy
                    FROM coin_strategies cs
                    LEFT JOIN strategy_grades sg ON cs.id = sg.strategy_id
                    LEFT JOIN rl_strategy_rollup sr ON cs.id = sr.strategy_id
                    WHERE cs.coin = ?
                      AND cs.interval = ?
                      AND sg.grade IN ('S', 'A', 'B')
                    ORDER BY sg.grade_score DESC
                    LIMIT 100
                """, (coin, interval))

                rows = cursor.fetchall()

                if not rows:
                    logger.debug(f"â­ï¸ {coin}-{interval}: ì§„í™” ê°€ëŠ¥í•œ ìƒìœ„ ì „ëµ ì—†ìŒ")
                    return []

                # Dictë¡œ ë³€í™˜
                import json
                existing_strategies = []
                for row in rows:
                    strategy_dict = {
                        'strategy_id': row[0],
                        'coin': row[1],
                        'interval': row[2],
                        'params': json.loads(row[3]) if row[3] else {},
                        'regime': row[4],
                        'quality_grade': row[5] or 'UNKNOWN',
                        'avg_ret': row[6] or 0.0,
                        'win_rate': row[7] or 0.0,
                        'predictive_accuracy': row[8] or 0.0
                    }
                    existing_strategies.append(strategy_dict)

                logger.info(f"ğŸ“Š {coin}-{interval}: ì§„í™” ëŒ€ìƒ ì „ëµ {len(existing_strategies)}ê°œ ë°œê²¬")

            # StrategyEvolver ì´ˆê¸°í™”
            evolver = StrategyEvolver()

            # ìƒìœ„ ì „ëµ ì„ ë³„
            top_strategies = evolver.select_top_strategies(
                existing_strategies,
                top_percent=0.3,  # ìƒìœ„ 30%
                min_grade='B'     # B ë“±ê¸‰ ì´ìƒ
            )

            if not top_strategies:
                logger.debug(f"â­ï¸ {coin}-{interval}: ì„ ë³„ëœ ìƒìœ„ ì „ëµ ì—†ìŒ")
                return []

            logger.info(f"âœ… {coin}-{interval}: ìƒìœ„ ì „ëµ {len(top_strategies)}ê°œ ì„ ë³„")

            # ì§„í™” ì‹¤í–‰ (êµë°° + ë³€ì´)
            # ìµœëŒ€ 5ê°œì˜ ì§„í™”ëœ ì „ëµ ìƒì„±
            max_evolved = min(5, len(top_strategies) // 2)
            evolved_strategies = []

            for i in range(max_evolved):
                try:
                    # ëœë¤ìœ¼ë¡œ ë‘ ë¶€ëª¨ ì„ íƒ
                    import random
                    parent1 = random.choice(top_strategies)
                    parent2 = random.choice(top_strategies)

                    # êµë°°
                    child_params = evolver.crossover(parent1, parent2)

                    # ë³€ì´ (tuple ë°˜í™˜: (dict, str))
                    mutated_params, mutation_desc = evolver.mutate(child_params)

                    # ì§„í™”ëœ ì „ëµ ìƒì„± (Strategy ê°ì²´ë¡œ ë³€í™˜)
                    from rl_pipeline.core.types import Strategy
                    evolved_strategy = Strategy(
                        id=f"evolved_{coin}_{interval}_{i}_{datetime.now().timestamp()}",
                        coin=coin,
                        interval=interval,
                        **mutated_params
                    )

                    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    evolved_strategy.parent_strategy_id = parent1.get('strategy_id')
                    evolved_strategy.similarity_classification = 'evolved'
                    evolved_strategy.similarity_score = 0.7

                    evolved_strategies.append(evolved_strategy)
                    logger.debug(f"ğŸ§¬ ì§„í™” ì „ëµ #{i+1} ìƒì„± (ë¶€ëª¨: {parent1.get('strategy_id')[:8]}...)")

                except Exception as e:
                    logger.warning(f"âš ï¸ ì§„í™” ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
                    continue

            if evolved_strategies:
                logger.info(f"âœ… {coin}-{interval}: {len(evolved_strategies)}ê°œ ì§„í™” ì „ëµ ìƒì„± ì™„ë£Œ")

            return evolved_strategies

        except Exception as e:
            logger.error(f"âŒ {coin}-{interval}: ì „ëµ ì§„í™” ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []

    def run_partial_pipeline(self, coin: str, interval: str, candle_data: pd.DataFrame) -> PipelineResult:
        """1-2ë‹¨ê³„ë§Œ ì‹¤í–‰: ì „ëµìƒì„± â†’ Self-play(ì˜µì…˜) â†’ í†µí•©ë¶„ì„"""
        try:
            start_time = datetime.now()
            
            # 1ë‹¨ê³„: ì „ëµ ìƒì„±
            logger.info("1ï¸âƒ£ ì „ëµ ìƒì„± ë‹¨ê³„ ì‹œì‘")
            strategies = self._create_strategies(coin, interval, candle_data)
            logger.info(f"âœ… {len(strategies)}ê°œ ì „ëµ ìƒì„± ì™„ë£Œ")

            # ğŸ§¬ 1-1ë‹¨ê³„: ê¸°ì¡´ ì „ëµ ì§„í™” (ìœ ì „ ì•Œê³ ë¦¬ì¦˜)
            evolved_genetic_strategies = self._evolve_existing_strategies(coin, interval, strategies)
            if evolved_genetic_strategies:
                strategies.extend(evolved_genetic_strategies)
                logger.info(f"ğŸ§¬ {len(evolved_genetic_strategies)}ê°œ ì§„í™” ì „ëµ ì¶”ê°€ (ì´ {len(strategies)}ê°œ)")

            # ğŸ”¥ ì˜ˆì¸¡ Self-play ì‹¤í–‰ (ì „ëµ ìƒì„± ì§í›„)
            predictive_selfplay_result = None
            enable_predictive_selfplay = os.getenv('ENABLE_PREDICTIVE_SELFPLAY', 'true').lower() == 'true'
            if enable_predictive_selfplay:
                logger.info("ğŸ”¥ ì˜ˆì¸¡ Self-play ì‹¤í–‰ (ì „ëµ ìƒì„± ì§í›„)")

                # ğŸ”¥ ë””ë²„ê±° ì´ˆê¸°í™”
                simulation_debugger = None
                try:
                    from rl_pipeline.monitoring.simulation_debugger import SimulationDebugger
                    simulation_debugger = SimulationDebugger(session_id=self.session_id)
                except Exception as debug_err:
                    logger.debug(f"âš ï¸ SimulationDebugger ì´ˆê¸°í™” ì‹¤íŒ¨: {debug_err}")

                try:
                    # Self-play ì‹œì‘ ë¡œê¹…
                    if simulation_debugger:
                        candle_count = len(candle_data) if candle_data is not None and not candle_data.empty else 0
                        simulation_debugger.log_selfplay_start(
                            coin=coin,
                            interval=interval,
                            num_episodes=PREDICTIVE_SELFPLAY_EPISODES,
                            num_agents=len(strategies[:100]),
                            candle_count=candle_count
                        )

                    predictive_selfplay_result = self._run_predictive_selfplay(coin, interval, strategies, candle_data)

                    if predictive_selfplay_result:
                        episodes = predictive_selfplay_result.get('episodes', 0)
                        avg_accuracy = predictive_selfplay_result.get('avg_accuracy', 0)
                        best_accuracy = predictive_selfplay_result.get('best_accuracy', 0)

                        logger.info(f"âœ… ì˜ˆì¸¡ Self-play ì™„ë£Œ: {episodes}ê°œ ì—í”¼ì†Œë“œ, í‰ê·  ì •í™•ë„ {avg_accuracy:.3f}, ìµœê³  ì •í™•ë„ {best_accuracy:.3f}")

                        # ğŸ”¥ Self-play ê²°ê³¼ ê²€ì¦
                        validation = validate_selfplay_result(predictive_selfplay_result, coin, interval)
                        if not validation['valid']:
                            logger.error(f"âŒ Self-play ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {validation['issues']}")
                            if simulation_debugger:
                                simulation_debugger.log_error(
                                    error_msg="Self-play ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨",
                                    context={
                                        'coin': coin,
                                        'interval': interval,
                                        'issues': validation['issues'],
                                        'warnings': validation['warnings']
                                    }
                                )
                        else:
                            if validation['warnings']:
                                logger.warning(f"âš ï¸ Self-play ê²°ê³¼ ê²½ê³ : {validation['warnings']}")
                            logger.info(f"âœ… Self-play ê²°ê³¼ ê²€ì¦ í†µê³¼")

                            # ê²€ì¦ ê²°ê³¼ ì €ì¥
                            if simulation_debugger:
                                simulation_debugger.log({
                                    'event': 'selfplay_validation',
                                    'coin': coin,
                                    'interval': interval,
                                    'valid': True,
                                    'warnings': validation['warnings']
                                })

                        # ğŸ”¥ Self-play ì¢…ë£Œ ë¡œê¹…
                        if simulation_debugger:
                            simulation_debugger.log_selfplay_end(
                                coin=coin,
                                interval=interval,
                                total_episodes=episodes,
                                summary={
                                    'avg_accuracy': avg_accuracy,
                                    'best_accuracy': best_accuracy,
                                    'strategy_count': predictive_selfplay_result.get('strategy_count', 0),
                                    'type': 'predictive',
                                    'early_stopped': episodes < PREDICTIVE_SELFPLAY_EPISODES
                                }
                            )

                            # ğŸ”¥ ì—í”¼ì†Œë“œë³„ ì •í™•ë„ ì €ì¥
                            for cycle_result in predictive_selfplay_result.get('cycle_results', []):
                                simulation_debugger.log({
                                    'event': 'predictive_selfplay_episode',
                                    'coin': coin,
                                    'interval': interval,
                                    'episode': cycle_result.get('episode'),
                                    'accuracy': cycle_result.get('accuracy'),
                                    'best_accuracy': cycle_result.get('best_accuracy'),
                                    'predictions': cycle_result.get('predictions')
                                })
                    else:
                        logger.warning("âš ï¸ ì˜ˆì¸¡ Self-play ê²°ê³¼ ì—†ìŒ")

                        # ğŸ”¥ ì‹¤íŒ¨ ë¡œê¹…
                        if simulation_debugger:
                            simulation_debugger.log_error(
                                error_msg="ì˜ˆì¸¡ Self-play ê²°ê³¼ ì—†ìŒ",
                                context={'coin': coin, 'interval': interval}
                            )
                except Exception as e:
                    logger.warning(f"âš ï¸ ì˜ˆì¸¡ Self-play ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")

                    # ğŸ”¥ ì—ëŸ¬ ë¡œê¹…
                    if simulation_debugger:
                        simulation_debugger.log_error(
                            error_msg="ì˜ˆì¸¡ Self-play ì‹¤í–‰ ì‹¤íŒ¨",
                            context={'coin': coin, 'interval': interval},
                            exception=e
                        )

            # ğŸ”¥ ì‹œë®¬ë ˆì´ì…˜ Self-playëŠ” Paper Tradingìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ ì œê±°ë¨
            # Paper Tradingì´ ì‹¤ì œ ì‹œì¥ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì„±ê³¼ ê²€ì¦ ê°€ëŠ¥
            evolved_strategies = strategies
            selfplay_result = predictive_selfplay_result

            logger.info("â­ï¸ ì‹œë®¬ë ˆì´ì…˜ Self-play ê±´ë„ˆë›°ê¸° (Paper Tradingìœ¼ë¡œ ëŒ€ì²´)")
            logger.info("   ğŸ’¡ ì˜ˆì¸¡ ì •í™•ë„ëŠ” ì˜ˆì¸¡ Self-playì—ì„œ ìˆ˜ì§‘ë©ë‹ˆë‹¤")
            
            # ğŸ”¥ í†µí•©ë¶„ì„ì€ ëª¨ë“  ì¸í„°ë²Œì˜ ì „ëµ ìƒì„±ì´ ì™„ë£Œëœ í›„ì—ë§Œ ì‹¤í–‰ë¨
            # (run_integrated_analysis_all_intervalsì—ì„œ ì‹¤í–‰)
            logger.debug(f"ğŸ“Š {coin}-{interval}: ì „ëµ ìƒì„± ì™„ë£Œ, í†µí•©ë¶„ì„ì€ ëª¨ë“  ì¸í„°ë²Œ ì™„ë£Œ í›„ ì‹¤í–‰")

            # ğŸ”¥ Self-play ì™„ë£Œ í›„ ë¡¤ì—… ë° ë“±ê¸‰ í‰ê°€ ì¶”ê°€ (ìë™í™”)
            try:
                logger.info(f"ğŸ”„ {coin}-{interval} ë¡¤ì—… ë° ë“±ê¸‰ í‰ê°€ ì‹œì‘...")
                from rl_pipeline.engine.rollup_batch import run_full_rollup_and_grades
                
                rollup_result = run_full_rollup_and_grades(coin=coin, interval=interval)
                
                if rollup_result.get("success"):
                    graded_count = rollup_result.get('grades_updated', 0)
                    logger.info(f"âœ… {coin}-{interval} ë¡¤ì—… ë° ë“±ê¸‰ í‰ê°€ ì™„ë£Œ: {graded_count}ê°œ ì „ëµ")
                    
                    # ğŸ”¥ coin_strategies í…Œì´ë¸”ì˜ quality_gradeë„ ë™ê¸°í™”
                    try:
                        self._sync_strategy_grades_to_coin_strategies(coin, interval)
                    except Exception as sync_error:
                        logger.debug(f"âš ï¸ ë“±ê¸‰ ë™ê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {sync_error}")
                else:
                    logger.warning(f"âš ï¸ ë¡¤ì—… ì‹¤í–‰ ì‹¤íŒ¨: {rollup_result.get('error', 'unknown')}")
            except Exception as e:
                logger.warning(f"âš ï¸ ë¡¤ì—… ë° ë“±ê¸‰ í‰ê°€ ì‹¤íŒ¨: {e}")
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # ğŸ”¥ í†µí•©ë¶„ì„ì€ ëª¨ë“  ì¸í„°ë²Œ ì™„ë£Œ í›„ì—ë§Œ ì‹¤í–‰ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
            regime_detected = 'neutral'
            signal_score = 0.0
            signal_action = 'HOLD'
            
            return PipelineResult(
                coin=coin,
                interval=interval,
                strategies_created=len(evolved_strategies),
                selfplay_episodes=len(selfplay_result.get('cycle_results', [])) if selfplay_result and isinstance(selfplay_result, dict) else 0,
                regime_detected=regime_detected,
                routing_results=0,  # ë ˆì§ ë¼ìš°íŒ… ì œê±°ë¨
                signal_score=signal_score,
                signal_action=signal_action,
                execution_time=execution_time,
                status="partial_complete",
                created_at=datetime.now().isoformat(),
                selfplay_result=selfplay_result  # ğŸ”¥ self-play ê²°ê³¼ ì €ì¥ (Noneì¼ ìˆ˜ ìˆìŒ)
            )
            
        except Exception as e:
            logger.error(f"âŒ ë¶€ë¶„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return PipelineResult(
                coin=coin,
                interval=interval,
                strategies_created=0,
                selfplay_episodes=0,
                regime_detected="unknown",
                routing_results=0,
                signal_score=0.0,
                signal_action="ERROR",
                execution_time=0.0,
                status="failed",
                created_at=datetime.now().isoformat()
            )
    
    def run_integrated_analysis_all_intervals(self, coin: str, pipeline_results: List[PipelineResult], all_candle_data: Dict[Tuple[str, str], pd.DataFrame] = None) -> PipelineResult:
        """ì „ì²´ ì¸í„°ë²Œ í†µí•©ë¶„ì„ ì‹¤í–‰"""
        try:
            start_time = datetime.now()
            
            # ğŸ”¥ ëª…í™•í•œ ë¡œê·¸: ëª¨ë“  ì¸í„°ë²Œ ì™„ë£Œ í›„ í†µí•© ë¶„ì„ ì‹œì‘
            intervals_completed = [r.interval for r in pipeline_results if r.interval]
            logger.info(f"ğŸ“Š {coin}: ëª¨ë“  ì¸í„°ë²Œ ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ ({len(intervals_completed)}ê°œ: {', '.join(intervals_completed)})")
            logger.info(f"ğŸš€ {coin}: ì „ì²´ í†µí•© ë¶„ì„ ì‹œì‘ (ëª¨ë“  ì¸í„°ë²Œ ë°ì´í„° ì¢…í•©)")
            
            # ğŸ”¥ í†µí•©ë¶„ì„ê¸° v1 ì´ˆê¸°í™” (ê³„ì¸µì  ë¶„ì„)
            logger.info(f"ğŸš€ {coin}: í†µí•© ë¶„ì„ v1 ì‹¤í–‰ (ê³„ì¸µì  êµ¬ì¡°: ì¥ê¸°=ë°©í–¥, ë‹¨ê¸°=íƒ€ì´ë°)")
            analyzer_v1 = IntegratedAnalyzerV1()

            # í†µí•©ë¶„ì„ ì‹¤í–‰ (v1: ë‹¨ìˆœíˆ coinë§Œ ì „ë‹¬, DBì—ì„œ ìë™ ë¡œë“œ)
            try:
                # v1 ë¶„ì„ ì‹¤í–‰
                v1_result = analyzer_v1.analyze(coin)

                logger.info(f"âœ… {coin}: v1 í†µí•© ë¶„ì„ ì™„ë£Œ")
                logger.info(f"   ë°©í–¥: {v1_result['direction']}, íƒ€ì´ë°: {v1_result['timing']}, "
                          f"í¬ê¸°: {v1_result['size']:.3f}, í™•ì‹ ë„: {v1_result['confidence']:.3f}, "
                          f"ê¸°ê°„: {v1_result['horizon']}")

                # v1 ê²°ê³¼ë¥¼ v0 í˜•ì‹ìœ¼ë¡œ ë§¤í•‘
                direction = v1_result['direction']
                timing = v1_result['timing']

                # signal_action ë§¤í•‘
                if direction == 'NEUTRAL' or timing == 'WAIT':
                    signal_action = 'HOLD'
                elif direction == 'LONG' and timing == 'NOW':
                    signal_action = 'BUY'
                elif direction == 'SHORT' and timing == 'NOW':
                    signal_action = 'SELL'
                elif timing == 'EXIT':
                    # ì²­ì‚° ì‹ í˜¸
                    if direction == 'LONG':
                        signal_action = 'SELL'  # ë¡± ì²­ì‚°
                    elif direction == 'SHORT':
                        signal_action = 'BUY'   # ìˆ ì²­ì‚°
                    else:
                        signal_action = 'HOLD'
                else:
                    signal_action = 'HOLD'

                # analysis_result ê°ì²´ ìƒì„± (v0 í˜¸í™˜)
                analysis_result = type('obj', (object,), {
                    'signal_action': signal_action,
                    'final_signal_score': v1_result['size'],
                    'signal_confidence': v1_result['confidence'],
                    'direction': direction,
                    'timing': timing,
                    'horizon': v1_result['horizon'],
                    'v1_reason': v1_result['reason']
                })

            except Exception as analysis_error:
                logger.error(f"âŒ í†µí•©ë¶„ì„ v1 ì‹¤í–‰ ì‹¤íŒ¨: {analysis_error}")
                import traceback
                traceback.print_exc()
                analysis_result = type('obj', (object,), {
                    'signal_action': 'HOLD',
                    'final_signal_score': 0.5,
                    'signal_confidence': 0.0
                })
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # ë¶„ì„ ê²°ê³¼ì—ì„œ ê°’ ì¶”ì¶œ
            signal_score = getattr(analysis_result, 'final_signal_score', 0.5)
            signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
            
            # ğŸ”¥ ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ (ì „ì²´ ì¸í„°ë²Œ í†µí•© ê²°ê³¼) - ì„ íƒì 
            # âš ï¸ absolute_zero_systemì€ trading_system.dbì™€ ë¬´ê´€í•´ì•¼ í•˜ë¯€ë¡œ ë¹„í™œì„±í™”
            # í™œì„±í™”í•˜ë ¤ë©´ ENABLE_TRADING_SYSTEM_INTEGRATION=true í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            enable_trading_integration = os.getenv('ENABLE_TRADING_SYSTEM_INTEGRATION', 'false').lower() == 'true'
            if enable_trading_integration:
                try:
                    from rl_pipeline.db.realtime_signal_storage import save_realtime_signal_from_analysis
                    
                    # ê°€ì¥ ìµœì‹  ìº”ë“¤ ë°ì´í„° ì„ íƒ
                    latest_candle_data = None
                    if all_candle_data:
                        latest_key = max(all_candle_data.keys(), 
                            key=lambda k: all_candle_data[k].index[-1] if hasattr(all_candle_data[k], 'index') and len(all_candle_data[k]) > 0 else 0,
                            default=None)
                        if latest_key:
                            latest_candle_data = all_candle_data[latest_key]
                    
                    save_realtime_signal_from_analysis(
                        coin, 'combined', analysis_result, latest_candle_data
                    )
                    logger.info(f"âœ… [{coin}] ì „ì²´ ì¸í„°ë²Œ í†µí•© ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ [{coin}] ì‹¤ì‹œê°„ ì‹œê·¸ë„ ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                logger.debug(f"ğŸ“Š {coin}: ê±°ë˜ ì‹œìŠ¤í…œ ì—°ë™ ë¹„í™œì„±í™” (ENABLE_TRADING_SYSTEM_INTEGRATION=false)")
            
            # ğŸ”¥ í†µí•© í•™ìŠµ ì‹¤í–‰ (ëª¨ë“  ì¸í„°ë²Œ self-play + ë¶„ì„ ê²°ê³¼ í™œìš©)
            trained_model_id = None
            try:
                from rl_pipeline.hybrid.auto_trainer import (
                    auto_train_from_integrated_analysis,
                    should_auto_train
                )
                
                # ğŸ”¥ ëª…í™•í•œ ë¡œê·¸: í†µí•© ë¶„ì„ ì™„ë£Œ í›„ í•™ìŠµ ì‹œì‘
                logger.info(f"ğŸš€ {coin}: í†µí•© ë¶„ì„ ì™„ë£Œ â†’ í†µí•© í•™ìŠµ ì‹œì‘ (ëª¨ë“  ì¸í„°ë²Œ self-play ë°ì´í„° í™œìš©)")
                
                # ëª¨ë“  ì¸í„°ë²Œì˜ self-play ê²°ê³¼ ìˆ˜ì§‘ (PipelineResultì—ì„œ)
                all_interval_selfplay = {}
                for result in pipeline_results:
                    if result.interval and result.selfplay_result:
                        all_interval_selfplay[result.interval] = result.selfplay_result
                    else:
                        # ğŸ”¥ ë””ë²„ê¹…: selfplay_resultê°€ ì—†ëŠ” ê²½ìš° ë¡œê·¸
                        if result.interval:
                            logger.info(f"ğŸ“Š {coin}-{result.interval}: selfplay_result ì—†ìŒ (í†µí•© í•™ìŠµì—ì„œ ì œì™¸)")

                logger.info(f"ğŸ“Š {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ - ì¸í„°ë²Œ: {list(all_interval_selfplay.keys())} ({len(all_interval_selfplay)}ê°œ)")

                # ğŸ”¥ í†µí•© í•™ìŠµ ë°ì´í„° ê²€ì¦
                validation_result = validate_integrated_learning_data(
                    coin=coin,
                    all_interval_selfplay=all_interval_selfplay,
                    pipeline_results=pipeline_results,
                    min_intervals=2,
                    min_total_episodes=10
                )

                # ğŸ”¥ ê²€ì¦ ê²°ê³¼ ë¡œê¹…
                logger.info(f"ğŸ“Š {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
                logger.info(f"   â””â”€ ê²€ì¦ í†µê³¼: {validation_result['valid']}")
                logger.info(f"   â””â”€ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {validation_result.get('quality_score', 0)}/100")
                logger.info(f"   â””â”€ ì¸í„°ë²Œ ìˆ˜: {validation_result['stats'].get('num_intervals', 0)}ê°œ")
                logger.info(f"   â””â”€ ì´ ì—í”¼ì†Œë“œ: {validation_result['stats'].get('total_episodes', 0)}ê°œ")
                logger.info(f"   â””â”€ í‰ê·  ì •í™•ë„: {validation_result['stats'].get('overall_avg_accuracy', 0):.2%}")

                if validation_result['issues']:
                    logger.error(f"âŒ {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨:")
                    for issue in validation_result['issues']:
                        logger.error(f"   â””â”€ {issue}")

                if validation_result['warnings']:
                    logger.warning(f"âš ï¸ {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ê²½ê³ :")
                    for warning in validation_result['warnings']:
                        logger.warning(f"   â””â”€ {warning}")

                # ğŸ”¥ ì¸í„°ë²Œë³„ ìƒì„¸ í†µê³„ ë¡œê¹…
                interval_dist = validation_result['stats'].get('interval_distribution', {})
                if interval_dist:
                    logger.info(f"ğŸ“Š {coin}: ì¸í„°ë²Œë³„ Self-play í†µê³„:")
                    for interval, stat in interval_dist.items():
                        logger.info(f"   â””â”€ {interval}: {stat['episodes']}ê°œ ì—í”¼ì†Œë“œ, í‰ê·  ì •í™•ë„ {stat['avg_accuracy']:.2%}")
                        if stat.get('issues'):
                            for issue in stat['issues']:
                                logger.error(f"      â””â”€ âŒ {issue}")

                # ğŸ”¥ ë””ë²„ê·¸ ì‹œìŠ¤í…œì— ê²€ì¦ ê²°ê³¼ ì €ì¥
                try:
                    from rl_pipeline.monitoring.simulation_debugger import SimulationDebugger
                    debugger = SimulationDebugger(session_id=self.session_id)
                    debugger.log({
                        'event': 'integrated_learning_validation',
                        'coin': coin,
                        'validation_result': {
                            'valid': validation_result['valid'],
                            'quality_score': validation_result.get('quality_score', 0),
                            'num_intervals': validation_result['stats'].get('num_intervals', 0),
                            'total_episodes': validation_result['stats'].get('total_episodes', 0),
                            'overall_avg_accuracy': validation_result['stats'].get('overall_avg_accuracy', 0),
                            'num_issues': len(validation_result['issues']),
                            'num_warnings': len(validation_result['warnings'])
                        },
                        'issues': validation_result['issues'],
                        'warnings': validation_result['warnings']
                    })
                except Exception as debug_error:
                    logger.debug(f"âš ï¸ ê²€ì¦ ê²°ê³¼ ë””ë²„ê·¸ ë¡œê¹… ì‹¤íŒ¨: {debug_error}")

                # í•™ìŠµ ì¡°ê±´ ì²´í¬ (ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜)
                total_episodes = sum(
                    len(sp_result.get('cycle_results', []))
                    for sp_result in all_interval_selfplay.values()
                    if isinstance(sp_result, dict)
                )

                logger.info(f"ğŸ“Š {coin}: ì´ {total_episodes}ê°œ ì—í”¼ì†Œë“œ ìˆ˜ì§‘ë¨ (ìµœì†Œ í•„ìš”: 10ê°œ)")

                # ğŸ”¥ ê²€ì¦ ì‹¤íŒ¨ ì‹œ í•™ìŠµ ê±´ë„ˆë›°ê¸°
                if not validation_result['valid']:
                    logger.error(f"âŒ {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ë¡œ í•™ìŠµ ê±´ë„ˆëœ€")
                    logger.error(f"   â””â”€ ê²€ì¦ ì´ìŠˆ: {validation_result['issues']}")
                elif validation_result.get('quality_score', 0) < 30:
                    logger.warning(f"âš ï¸ {coin}: ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ë‚®ìŒ ({validation_result.get('quality_score', 0)}/100), í•™ìŠµ ê±´ë„ˆëœ€")
                elif all_interval_selfplay and total_episodes >= 10:
                    # ENABLE_AUTO_TRAINING ì²´í¬
                    auto_train_enabled = os.getenv('ENABLE_AUTO_TRAINING', 'false').lower() == 'true'
                    use_hybrid = os.getenv('USE_HYBRID', 'false').lower() == 'true'
                    
                    logger.info(f"ğŸ“Š {coin}: í•™ìŠµ ì¡°ê±´ ì²´í¬ - ENABLE_AUTO_TRAINING={auto_train_enabled}, USE_HYBRID={use_hybrid}")
                    
                    if auto_train_enabled and use_hybrid:
                        config_path = os.getenv('HYBRID_CONFIG_PATH', '/workspace/rl_pipeline/hybrid/config_hybrid.json')
                        
                        logger.info(f"ğŸš€ {coin}: í†µí•© í•™ìŠµ ì‹œì‘ (ì¸í„°ë²Œ: {list(all_interval_selfplay.keys())}, ì´ {total_episodes}ê°œ ì—í”¼ì†Œë“œ)")
                        
                        trained_model_id = auto_train_from_integrated_analysis(
                            coin=coin,
                            all_interval_selfplay=all_interval_selfplay,
                            analysis_result=analysis_result,  # ğŸ”¥ ë¶„ì„ ê²°ê³¼ ì „ë‹¬
                            config_path=config_path,
                            min_episodes=10
                        )
                        
                        if trained_model_id:
                            logger.info(f"âœ… {coin}: í†µí•© í•™ìŠµ ì™„ë£Œ, ëª¨ë¸ ID: {trained_model_id}")
                        else:
                            logger.info(f"ğŸ“Š {coin}: í†µí•© í•™ìŠµ ë°ì´í„° ë¶€ì¡± ë˜ëŠ” í•™ìŠµ ì‹¤íŒ¨")
                    else:
                        if not auto_train_enabled:
                            logger.info(f"ğŸ“Š {coin}: ìë™ í•™ìŠµ ë¹„í™œì„±í™” (ENABLE_AUTO_TRAINING=false)")
                        elif not use_hybrid:
                            logger.info(f"ğŸ“Š {coin}: ìë™ í•™ìŠµ ë¹„í™œì„±í™” (USE_HYBRID=false)")
                else:
                    if not all_interval_selfplay:
                        logger.info(f"ğŸ“Š {coin}: self-play ê²°ê³¼ ì—†ìŒ, í†µí•© í•™ìŠµ ê±´ë„ˆëœ€")
                    elif total_episodes < 10:
                        logger.info(f"ğŸ“Š {coin}: ì—í”¼ì†Œë“œ ìˆ˜ ë¶€ì¡± ({total_episodes} < 10), í†µí•© í•™ìŠµ ê±´ë„ˆëœ€")
                        
            except ImportError as import_err:
                logger.warning(f"âš ï¸ í†µí•© í•™ìŠµ ëª¨ë“ˆ ì—†ìŒ (í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ë¯¸ì„¤ì¹˜): {import_err}")
                import traceback
                logger.debug(f"ì„í¬íŠ¸ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            except Exception as e:
                logger.error(f"âŒ í†µí•© í•™ìŠµ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
                import traceback
                logger.debug(f"í†µí•© í•™ìŠµ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")

            # ğŸ”¥ í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (í•™ìŠµ ì™„ë£Œ í›„ ì €ì¥)
            try:
                # regime ì¶”ì¶œ (v1ì—ì„œëŠ” regime ì •ë³´ ì‚¬ìš© ì•ˆ í•¨)
                regime = 'neutral'

                # ğŸ”¥ ëª…í™•í•œ ë¡œê·¸: í•™ìŠµ ì™„ë£Œ í›„ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥
                logger.info(f"ğŸ’¾ {coin}: í†µí•© í•™ìŠµ ì™„ë£Œ â†’ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹œì‘")

                # centralized save í•¨ìˆ˜ ì‚¬ìš© (rl_strategies.dbì— ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆë¡œ ì €ì¥)
                learning_results.save_integrated_analysis_results(coin, "all_intervals", regime, analysis_result)
                logger.info(f"âœ… {coin}-all_intervals í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {signal_action} (ì ìˆ˜: {signal_score:.3f})")

                # ğŸ”¥ DB ì»¤ë°‹ ì™„ë£Œ ëŒ€ê¸° (Paper Tradingì´ ì¦‰ì‹œ ì¡°íšŒí•  ìˆ˜ ìˆë„ë¡)
                import time
                time.sleep(0.05)  # 50ms ëŒ€ê¸°

                # ğŸ”¥ ê°œë³„ ì¸í„°ë²Œë³„ë¡œë„ ê²°ê³¼ ì €ì¥ (Paper Tradingì´ ê°œë³„ ì¸í„°ë²Œë³„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡)
                saved_intervals = []
                for result in pipeline_results:
                    if result.interval and result.interval != "all_intervals":
                        try:
                            learning_results.save_integrated_analysis_results(
                                coin, result.interval, regime, analysis_result
                            )
                            saved_intervals.append(result.interval)
                            logger.debug(f"âœ… {coin}-{result.interval} í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ (ê°œë³„ ì¸í„°ë²Œ ë³µì œ)")
                        except Exception as e:
                            logger.debug(f"âš ï¸ {coin}-{result.interval} í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

                if saved_intervals:
                    logger.info(f"âœ… {coin} ê°œë³„ ì¸í„°ë²Œ ì €ì¥ ì™„ë£Œ: {', '.join(saved_intervals)}")

                # ğŸ”¥ ëª¨ë“  ì €ì¥ ì™„ë£Œ í›„ ì¶”ê°€ ëŒ€ê¸°
                time.sleep(0.05)  # 50ms ëŒ€ê¸°

            except Exception as save_err:
                logger.warning(f"âš ï¸ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_err}")
                import traceback
                logger.debug(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")

            return PipelineResult(
                coin=coin,
                interval="all_intervals",
                strategies_created=sum(r.strategies_created for r in pipeline_results),
                selfplay_episodes=sum(r.selfplay_episodes for r in pipeline_results),
                regime_detected="multi_interval",
                routing_results=sum(r.routing_results for r in pipeline_results),
                signal_score=signal_score,
                signal_action=signal_action,
                execution_time=execution_time,
                status="success",
                created_at=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ í†µí•©ë¶„ì„ ì‹¤íŒ¨: {e}")
            return PipelineResult(
                coin=coin,
                interval="all_intervals",
                strategies_created=0,
                selfplay_episodes=0,
                regime_detected="unknown",
                routing_results=0,
                signal_score=0.5,
                signal_action="HOLD",
                execution_time=0.0,
                status="failed",
                created_at=datetime.now().isoformat()
            )

    def _perform_integrated_analysis(self, coin: str, interval: str, strategies: List[Dict[str, Any]], 
                                   candle_data: pd.DataFrame) -> Any:
        """3ë‹¨ê³„: í†µí•©ë¶„ì„ (ğŸ”¥ ë‹¤ì¤‘ ì¸í„°ë²Œ ë¶„ì„ ê°œì„ , ë ˆì§ ë¼ìš°íŒ… ì œê±°)"""
        try:
            if not strategies:
                logger.warning("âš ï¸ ë¶„ì„í•  ì „ëµì´ ì—†ìŠµë‹ˆë‹¤")
                return self._create_default_analysis_result(coin, interval)
            
            # í˜„ì¬ ë ˆì§ ê°ì§€ (regime_transition_prob í¬í•¨)
            current_regime, regime_confidence, regime_transition_prob = self.regime_router.detect_current_regime(coin, interval, candle_data)
            logger.info(f"ğŸ“Š í˜„ì¬ ë ˆì§: {current_regime} (ì‹ ë¢°ë„: {regime_confidence:.2f}, ì „í™˜ í™•ë¥ : {regime_transition_prob:.2%})")
            
            logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ì „ëµ: {len(strategies)}ê°œ")
            
            # ğŸ”¥ ë‹¨ì¼ ì¸í„°ë²Œ ë¶„ì„ë§Œ ìˆ˜í–‰ (ê°œë³„ ì¸í„°ë²Œ ì²˜ë¦¬ ì‹œ)
            # ë‹¤ì¤‘ ì¸í„°ë²Œ ë¶„ì„ì€ run_integrated_analysis_all_intervalsì—ì„œë§Œ ìˆ˜í–‰
            try:
                logger.info(f"ğŸ“Š ë‹¨ì¼ ì¸í„°ë²Œ ë¶„ì„ ì‹¤í–‰: {coin}-{interval}")
                analysis_result = analyze_coin_strategies(coin, interval, current_regime, strategies, candle_data)
            except Exception as e:
                logger.warning(f"âš ï¸ ë‹¨ì¼ ì¸í„°ë²Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
                # í´ë°±: ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
                analysis_result = self._create_default_analysis_result(coin, interval)

            # ğŸ”¥ analysis_resultëŠ” dictë¡œ ë°˜í™˜ë˜ë¯€ë¡œ dict ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼
            if isinstance(analysis_result, dict):
                signal_action = analysis_result.get('signal_action', 'HOLD')
                signal_score = analysis_result.get('signal_score', analysis_result.get('final_signal_score', 0.0))
                logger.info(f"ğŸ” í†µí•©ë¶„ì„ ì™„ë£Œ: {signal_action} (ì ìˆ˜: {signal_score:.3f})")
            else:
                # ê°ì²´ì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
                signal_action = getattr(analysis_result, 'signal_action', 'HOLD')
                signal_score = getattr(analysis_result, 'final_signal_score', getattr(analysis_result, 'signal_score', 0.0))
                logger.info(f"ğŸ” í†µí•©ë¶„ì„ ì™„ë£Œ: {signal_action} (ì ìˆ˜: {signal_score:.3f})")

            # Dictë¡œ ë³€í™˜ (validator í˜¸í™˜ì„±)
            # ğŸ”¥ analysis_resultê°€ ì´ë¯¸ dictì¸ì§€ í™•ì¸
            if isinstance(analysis_result, dict):
                result_dict = analysis_result.copy()
                # signal_scoreê°€ ì—†ìœ¼ë©´ final_signal_scoreì—ì„œ ê°€ì ¸ì˜¤ê¸°
                if 'signal_score' not in result_dict and 'final_signal_score' in result_dict:
                    result_dict['signal_score'] = result_dict.pop('final_signal_score')
                return result_dict
            else:
                # ê°ì²´ì¸ ê²½ìš° asdict ì‚¬ìš©
                result_dict = asdict(analysis_result)
                result_dict['signal_score'] = result_dict.pop('final_signal_score')
                return result_dict
            
        except Exception as e:
            logger.error(f"âŒ í†µí•©ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_analysis_result(coin, interval)
    
    def _create_default_strategies(self, coin: str, interval: str) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ì „ëµ ìƒì„± - 24ê°œ ë‹¤ì–‘ì„± ì „ëµ + ì‹œì¥ ë ˆì§ë³„ ì „ë¬¸ ì „ëµ + ê¸°ì¡´ ê³ ë“±ê¸‰ ì „ëµ ì°¸ê³ """
        try:
            import random
            
            # ğŸ” ê¸°ì¡´ ê³ ë“±ê¸‰ ì „ëµ ë¡œë“œí•˜ì—¬ ì°¸ê³ 
            high_grade_base_strategies = []
            try:
                from rl_pipeline.db.reads import load_strategies_by_grade
                existing_strategies = load_strategies_by_grade(coin, interval, 'A', limit=10)  # Aë“±ê¸‰ ìƒìœ„ 10ê°œ
                
                if existing_strategies and len(existing_strategies) >= 3:
                    logger.info(f"âœ… ê¸°ì¡´ ê³ ë“±ê¸‰ ì „ëµ {len(existing_strategies)}ê°œ ë¡œë“œí•˜ì—¬ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©")
                    
                    # ê³ ë“±ê¸‰ ì „ëµì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©
                    for strategy in existing_strategies[:5]:  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
                        if 'params' in strategy and isinstance(strategy['params'], dict):
                            base_params = {
                                'rsi_min': strategy['params'].get('rsi_min', 30),
                                'rsi_max': strategy['params'].get('rsi_max', 70),
                                'volume_ratio_min': strategy['params'].get('volume_ratio_min', 1.0),
                                'volume_ratio_max': strategy['params'].get('volume_ratio_max', 2.0),
                                'macd_buy_threshold': strategy['params'].get('macd_buy_threshold', 0.01),
                                'macd_sell_threshold': strategy['params'].get('macd_sell_threshold', -0.01),
                                'stop_loss_pct': strategy['params'].get('stop_loss_pct', 0.02),
                                'take_profit_pct': strategy['params'].get('take_profit_pct', 0.05),
                                'type': f'evolved_{strategy.get("quality_grade", "A")}'
                            }
                            high_grade_base_strategies.append(base_params)
                        elif 'rsi_min' in strategy:  # paramsê°€ dictê°€ ì•„ë‹Œ ê²½ìš°
                            base_params = {
                                'rsi_min': strategy.get('rsi_min', 30),
                                'rsi_max': strategy.get('rsi_max', 70),
                                'volume_ratio_min': strategy.get('volume_ratio_min', 1.0),
                                'volume_ratio_max': strategy.get('volume_ratio_max', 2.0),
                                'macd_buy_threshold': strategy.get('macd_buy_threshold', 0.01),
                                'macd_sell_threshold': strategy.get('macd_sell_threshold', -0.01),
                                'stop_loss_pct': strategy.get('stop_loss_pct', 0.02),
                                'take_profit_pct': strategy.get('take_profit_pct', 0.05),
                                'type': f'evolved_{strategy.get("quality_grade", "A")}'
                            }
                            high_grade_base_strategies.append(base_params)
                    
                    logger.info(f"  âœ… ê³ ë“±ê¸‰ ì „ëµ ë² ì´ìŠ¤ë¡œ {len(high_grade_base_strategies)}ê°œ ì¤€ë¹„")
                else:
                    logger.info(f"  â„¹ï¸ ê¸°ì¡´ ê³ ë“±ê¸‰ ì „ëµ ë¶€ì¡±({len(existing_strategies) if existing_strategies else 0}ê°œ), ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
            except Exception as e:
                logger.debug(f"âš ï¸ ê¸°ì¡´ ì „ëµ ë¡œë“œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
            # ğŸ¯ ì‹œì¥ ë ˆì§ë³„ ì „ëµ í…œí”Œë¦¿ (ì „ë¬¸ì„±)
            regime_strategies = {
                'trend': [
                    # ìƒìŠ¹ ì¶”ì„¸ ì¶”ì¢… ì „ëµ
                    {'rsi_min': 40, 'rsi_max': 75, 'volume_ratio_min': 1.2, 'volume_ratio_max': 2.5,
                     'macd_buy_threshold': 0.015, 'macd_sell_threshold': -0.008, 'stop_loss_pct': 0.02, 'take_profit_pct': 0.06},
                    # í•˜ë½ ì¶”ì„¸ ì¶”ì¢… ì „ëµ
                    {'rsi_min': 25, 'rsi_max': 60, 'volume_ratio_min': 1.0, 'volume_ratio_max': 2.2,
                     'macd_buy_threshold': -0.01, 'macd_sell_threshold': 0.02, 'stop_loss_pct': 0.025, 'take_profit_pct': 0.05},
                ],
                'range': [
                    # ë°•ìŠ¤ê¶Œ ëŒíŒŒ ì „ëµ
                    {'rsi_min': 20, 'rsi_max': 80, 'volume_ratio_min': 1.3, 'volume_ratio_max': 3.0,
                     'macd_buy_threshold': 0.02, 'macd_sell_threshold': -0.02, 'stop_loss_pct': 0.015, 'take_profit_pct': 0.04},
                    # ë°•ìŠ¤ê¶Œ ë‚´ ê±°ë˜ ì „ëµ
                    {'rsi_min': 30, 'rsi_max': 70, 'volume_ratio_min': 0.8, 'volume_ratio_max': 1.5,
                     'macd_buy_threshold': 0.008, 'macd_sell_threshold': -0.008, 'stop_loss_pct': 0.03, 'take_profit_pct': 0.07},
                ],
                'volatile': [
                    # ê³ ë³€ë™ì„± ëŒ€ì‘ ì „ëµ
                    {'rsi_min': 35, 'rsi_max': 65, 'volume_ratio_min': 1.5, 'volume_ratio_max': 4.0,
                     'macd_buy_threshold': 0.025, 'macd_sell_threshold': -0.025, 'stop_loss_pct': 0.04, 'take_profit_pct': 0.1},
                    # ì•ˆì •ì  ë³€ë™ì„± ëŒ€ì‘
                    {'rsi_min': 38, 'rsi_max': 62, 'volume_ratio_min': 1.1, 'volume_ratio_max': 2.0,
                     'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01, 'stop_loss_pct': 0.025, 'take_profit_pct': 0.055},
                ],
                'neutral': [
                    # ë³´ìˆ˜ì  ê· í˜• ì „ëµ
                    {'rsi_min': 32, 'rsi_max': 68, 'volume_ratio_min': 1.0, 'volume_ratio_max': 2.0,
                     'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01, 'stop_loss_pct': 0.02, 'take_profit_pct': 0.05},
                    # ê³µê²©ì  ê· í˜• ì „ëµ
                    {'rsi_min': 28, 'rsi_max': 72, 'volume_ratio_min': 1.2, 'volume_ratio_max': 2.3,
                     'macd_buy_threshold': 0.012, 'macd_sell_threshold': -0.012, 'stop_loss_pct': 0.025, 'take_profit_pct': 0.06},
                ]
            }
            
            # ê¸°ë³¸ ì „ëµ íƒ€ì… (18ê°œ)
            basic_strategies = [
                # ë³´ìˆ˜ì  ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 32, 'rsi_max': 68, 'volume_ratio_min': 1.0, 'volume_ratio_max': 2.0, 'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01, 'stop_loss_pct': 0.02, 'take_profit_pct': 0.05, 'type': 'conservative'},
                {'rsi_min': 35, 'rsi_max': 65, 'volume_ratio_min': 0.9, 'volume_ratio_max': 1.9, 'macd_buy_threshold': 0.008, 'macd_sell_threshold': -0.008, 'stop_loss_pct': 0.015, 'take_profit_pct': 0.045, 'type': 'conservative'},
                {'rsi_min': 30, 'rsi_max': 70, 'volume_ratio_min': 1.1, 'volume_ratio_max': 2.1, 'macd_buy_threshold': 0.012, 'macd_sell_threshold': -0.012, 'stop_loss_pct': 0.025, 'take_profit_pct': 0.055, 'type': 'conservative'},
                
                # ê³µê²©ì  ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 25, 'rsi_max': 75, 'volume_ratio_min': 1.2, 'volume_ratio_max': 2.5, 'macd_buy_threshold': 0.015, 'macd_sell_threshold': -0.015, 'stop_loss_pct': 0.03, 'take_profit_pct': 0.07, 'type': 'aggressive'},
                {'rsi_min': 20, 'rsi_max': 80, 'volume_ratio_min': 1.3, 'volume_ratio_max': 2.8, 'macd_buy_threshold': 0.02, 'macd_sell_threshold': -0.02, 'stop_loss_pct': 0.035, 'take_profit_pct': 0.08, 'type': 'aggressive'},
                {'rsi_min': 28, 'rsi_max': 72, 'volume_ratio_min': 1.4, 'volume_ratio_max': 3.0, 'macd_buy_threshold': 0.018, 'macd_sell_threshold': -0.018, 'stop_loss_pct': 0.04, 'take_profit_pct': 0.09, 'type': 'aggressive'},
                
                # ê· í˜• ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 35, 'rsi_max': 65, 'volume_ratio_min': 1.1, 'volume_ratio_max': 2.2, 'macd_buy_threshold': 0.01, 'macd_sell_threshold': -0.01, 'stop_loss_pct': 0.025, 'take_profit_pct': 0.05, 'type': 'balanced'},
                {'rsi_min': 33, 'rsi_max': 67, 'volume_ratio_min': 1.05, 'volume_ratio_max': 2.1, 'macd_buy_threshold': 0.008, 'macd_sell_threshold': -0.008, 'stop_loss_pct': 0.02, 'take_profit_pct': 0.048, 'type': 'balanced'},
                {'rsi_min': 36, 'rsi_max': 64, 'volume_ratio_min': 1.15, 'volume_ratio_max': 2.3, 'macd_buy_threshold': 0.012, 'macd_sell_threshold': -0.012, 'stop_loss_pct': 0.022, 'take_profit_pct': 0.052, 'type': 'balanced'},
                
                # ë‹¨ê¸° ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 20, 'rsi_max': 80, 'volume_ratio_min': 1.5, 'volume_ratio_max': 3.0, 'macd_buy_threshold': 0.02, 'macd_sell_threshold': -0.02, 'stop_loss_pct': 0.03, 'take_profit_pct': 0.08, 'type': 'short_term'},
                {'rsi_min': 22, 'rsi_max': 78, 'volume_ratio_min': 1.6, 'volume_ratio_max': 3.2, 'macd_buy_threshold': 0.022, 'macd_sell_threshold': -0.022, 'stop_loss_pct': 0.035, 'take_profit_pct': 0.085, 'type': 'short_term'},
                {'rsi_min': 18, 'rsi_max': 82, 'volume_ratio_min': 1.4, 'volume_ratio_max': 2.8, 'macd_buy_threshold': 0.018, 'macd_sell_threshold': -0.018, 'stop_loss_pct': 0.04, 'take_profit_pct': 0.09, 'type': 'short_term'},
                
                # ì¥ê¸° ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 38, 'rsi_max': 62, 'volume_ratio_min': 0.8, 'volume_ratio_max': 1.8, 'macd_buy_threshold': 0.005, 'macd_sell_threshold': -0.005, 'stop_loss_pct': 0.015, 'take_profit_pct': 0.04, 'type': 'long_term'},
                {'rsi_min': 40, 'rsi_max': 60, 'volume_ratio_min': 0.9, 'volume_ratio_max': 1.9, 'macd_buy_threshold': 0.006, 'macd_sell_threshold': -0.006, 'stop_loss_pct': 0.018, 'take_profit_pct': 0.042, 'type': 'long_term'},
                {'rsi_min': 42, 'rsi_max': 58, 'volume_ratio_min': 0.85, 'volume_ratio_max': 1.7, 'macd_buy_threshold': 0.004, 'macd_sell_threshold': -0.004, 'stop_loss_pct': 0.012, 'take_profit_pct': 0.038, 'type': 'long_term'},
                
                # í‰ê·  íšŒê·€ ì „ëµë“¤ (3ê°œ)
                {'rsi_min': 15, 'rsi_max': 85, 'volume_ratio_min': 0.9, 'volume_ratio_max': 1.5, 'macd_buy_threshold': -0.005, 'macd_sell_threshold': 0.005, 'stop_loss_pct': 0.04, 'take_profit_pct': 0.08, 'type': 'mean_reversion'},
                {'rsi_min': 12, 'rsi_max': 88, 'volume_ratio_min': 1.0, 'volume_ratio_max': 1.8, 'macd_buy_threshold': -0.008, 'macd_sell_threshold': 0.008, 'stop_loss_pct': 0.045, 'take_profit_pct': 0.085, 'type': 'mean_reversion'},
                {'rsi_min': 18, 'rsi_max': 82, 'volume_ratio_min': 0.85, 'volume_ratio_max': 1.6, 'macd_buy_threshold': -0.006, 'macd_sell_threshold': 0.006, 'stop_loss_pct': 0.035, 'take_profit_pct': 0.075, 'type': 'mean_reversion'},
            ]
            
            # ğŸ’° ì‹œì¥ ë ˆì§ë³„ ì „ë¬¸ ì „ëµ ì¶”ê°€ (6ê°œ)
            regime_pro_strategies = []
            for regime, strategies in regime_strategies.items():
                for strategy in strategies:
                    strategy['type'] = regime
                    regime_pro_strategies.append(strategy)
            
            # ëª¨ë“  ì „ëµ í•©ì¹˜ê¸° (ê³ ë“±ê¸‰ ë² ì´ìŠ¤ + ë ˆì§ë³„ + ê¸°ë³¸)
            all_strategy_types = []
            
            # 1. ê³ ë“±ê¸‰ ì „ëµ ë² ì´ìŠ¤ (ìµœìš°ì„ )
            if high_grade_base_strategies:
                all_strategy_types.extend(high_grade_base_strategies)
                logger.info(f"  âœ… ê³ ë“±ê¸‰ ë² ì´ìŠ¤ ì „ëµ {len(high_grade_base_strategies)}ê°œ ì¶”ê°€")
            
            # 2. ë ˆì§ë³„ ì „ë¬¸ ì „ëµ
            all_strategy_types.extend(regime_pro_strategies)
            
            # 3. ê¸°ë³¸ ì „ëµ
            all_strategy_types.extend(basic_strategies)
            
            default_strategies = []
            for i, strategy_params in enumerate(all_strategy_types):
                # ê³ ë“±ê¸‰ ì „ëµ ë² ì´ìŠ¤ì¸ì§€ í™•ì¸
                is_evolved = strategy_params.get('type', '').startswith('evolved_')
                
                if is_evolved:
                    # ê³ ë“±ê¸‰ ì „ëµ ë² ì´ìŠ¤: ìµœì†Œí•œì˜ ë³€ë™ (ê¸°ì¡´ ì„±ê³¼ ìœ ì§€í•˜ë˜ ë¯¸ì„¸ ì¡°ì •)
                    rsi_min = strategy_params['rsi_min'] + random.randint(-1, 1)
                    rsi_max = strategy_params['rsi_max'] + random.randint(-1, 1)
                    volume_ratio_min = max(0.3, strategy_params['volume_ratio_min'] + random.uniform(-0.05, 0.05))
                    volume_ratio_max = min(6.0, strategy_params['volume_ratio_max'] + random.uniform(-0.1, 0.1))
                    macd_buy = strategy_params['macd_buy_threshold'] + random.uniform(-0.001, 0.001)
                    macd_sell = strategy_params['macd_sell_threshold'] + random.uniform(-0.001, 0.001)
                    stop_loss = max(0.008, strategy_params['stop_loss_pct'] + random.uniform(-0.001, 0.001))
                    take_profit = max(0.015, strategy_params['take_profit_pct'] + random.uniform(-0.002, 0.002))
                else:
                    # ê¸°ë³¸/ë ˆì§ë³„ ì „ëµ: í° ë³€ë™ (ë‹¤ì–‘ì„± í™•ë³´)
                    rsi_min = max(5, strategy_params['rsi_min'] + random.randint(-3, 3))
                    rsi_max = min(95, strategy_params['rsi_max'] + random.randint(-3, 3))
                    volume_ratio_min = max(0.3, strategy_params['volume_ratio_min'] + random.uniform(-0.15, 0.15))
                    volume_ratio_max = min(6.0, strategy_params['volume_ratio_max'] + random.uniform(-0.2, 0.2))
                    macd_buy = strategy_params['macd_buy_threshold'] + random.uniform(-0.003, 0.003)
                    macd_sell = strategy_params['macd_sell_threshold'] + random.uniform(-0.003, 0.003)
                    stop_loss = max(0.008, strategy_params['stop_loss_pct'] + random.uniform(-0.003, 0.003))
                    take_profit = max(0.015, strategy_params['take_profit_pct'] + random.uniform(-0.008, 0.008))
                
                strategy = {
                    'strategy_id': f'{coin}_{interval}_default_{i+1:03d}',
                    'coin': coin,
                    'interval': interval,
                    'rsi_min': rsi_min,
                    'rsi_max': rsi_max,
                    'volume_ratio_min': volume_ratio_min,
                    'volume_ratio_max': volume_ratio_max,
                    'macd_buy_threshold': macd_buy,
                    'macd_sell_threshold': macd_sell,
                    'stop_loss_pct': stop_loss,
                    'take_profit_pct': take_profit,
                    'profit': random.uniform(-0.05, 0.1),
                    'win_rate': random.uniform(0.3, 0.7),
                    'trades_count': random.randint(5, 50),
                    'max_drawdown': random.uniform(0.05, 0.2),
                    'sharpe_ratio': random.uniform(0.5, 2.0),
                    'strategy_type': strategy_params.get('type', 'general'),
                    # ë¯¸ì‚¬ìš© ì»¬ëŸ¼ í™œì„±í™”: íŒ¨í„´ ì‹ ë¢°ë„/ì†ŒìŠ¤/ê°•í™” íƒ€ì…
                    'pattern_confidence': random.uniform(0.4, 0.8),
                    'pattern_source': 'evolved_base' if is_evolved else 'template',
                    'enhancement_type': 'selfplay_base' if is_evolved else 'standard'
                }
                default_strategies.append(strategy)
            
            logger.info(f"ğŸ“Š ê¸°ë³¸ ì „ëµ ìƒì„± ì™„ë£Œ: {len(default_strategies)}ê°œ (ë‹¤ì–‘í•œ íƒ€ì… + ë ˆì§ë³„ ì „ë¬¸ì „ëµ)")
            return default_strategies
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _update_strategies_from_selfplay(self, coin: str, interval: str, selfplay_result: Dict[str, Any], evolved_strategies: List[Dict[str, Any]] = None):
        """Self-play ê²°ê³¼ë¡œ coin_strategies í…Œì´ë¸” ì„±ê³¼ ì§€í‘œ ë° ë“±ê¸‰ ì—…ë°ì´íŠ¸"""
        try:
            from rl_pipeline.db.writes import update_strategy_performance
            from rl_pipeline.db.connection_pool import get_optimized_db_connection
            
            # ğŸ”¥ evolved_strategiesì—ì„œ ë“±ê¸‰ ì •ë³´ ë§¤í•‘ ìƒì„± (ì „ëµ ID -> quality_grade)
            # ì›ë³¸ strategiesì˜ ìˆœì„œì™€ evolved_strategiesì˜ ìˆœì„œê°€ ì¼ì¹˜í•œë‹¤ê³  ê°€ì •
            quality_grade_map = {}
            strategy_index_map = {}  # evolved_strategies ì¸ë±ìŠ¤ -> ì›ë³¸ strategy_id
            all_strategy_ids = []  # ğŸ”¥ ëª¨ë“  ì „ëµ ID ë¦¬ìŠ¤íŠ¸ (ìˆœì„œ ë³´ì¡´)
            
            if evolved_strategies:
                # ì›ë³¸ strategiesëŠ” selfplay í˜¸ì¶œ ì „ì— ì „ë‹¬ë˜ì—ˆìœ¼ë¯€ë¡œ, 
                # evolved_strategiesì˜ ìˆœì„œë¡œ ë§¤í•‘ ê°€ëŠ¥ (ìˆœì„œê°€ ë³´ì¡´ë¨)
                for idx, evolved_strategy in enumerate(evolved_strategies):
                    strategy_id = evolved_strategy.get('id')
                    quality_grade = evolved_strategy.get('quality_grade')
                    
                    if strategy_id:
                        all_strategy_ids.append(strategy_id)  # ìˆœì„œ ë³´ì¡´
                        
                        if quality_grade:
                            quality_grade_map[strategy_id] = quality_grade
                            strategy_index_map[idx] = strategy_id
                            
                            # _evolved ì ‘ë¯¸ì‚¬ ì œê±°ëœ ì›ë³¸ IDë„ ë§¤í•‘
                            if strategy_id.endswith('_evolved'):
                                original_id = strategy_id[:-8]  # '_evolved' ì œê±°
                                quality_grade_map[original_id] = quality_grade
                        else:
                            strategy_index_map[idx] = strategy_id
            
            # Self-play ê²°ê³¼ì—ì„œ ì„±ê³¼ ë°ì´í„° ì¶”ì¶œ
            cycle_results = selfplay_result.get('cycle_results', [])
            if not cycle_results:
                # traditional_resultë‚˜ predictive_resultì—ì„œë„ ì‹œë„
                cycle_results = []
                if selfplay_result.get('traditional_result', {}).get('cycle_results'):
                    cycle_results.extend(selfplay_result['traditional_result']['cycle_results'])
                if selfplay_result.get('predictive_result', {}).get('cycle_results'):
                    cycle_results.extend(selfplay_result['predictive_result']['cycle_results'])
            
            # ğŸ”¥ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ì²˜ë¦¬ ì¶”ê°€ (ì˜¨ë¼ì¸ ê²°ê³¼ê°€ ì•„ì§ ë³€í™˜ë˜ì§€ ì•Šì€ ê²½ìš°)
            if not cycle_results:
                # online_resultì—ì„œ segment_results ì¶”ì¶œ ë° ë³€í™˜
                try:
                    from rl_pipeline.hybrid.online_data_converter import (
                        extract_online_selfplay_result,
                        convert_online_segments_to_cycle_results
                    )
                    
                    online_segments = extract_online_selfplay_result(selfplay_result)
                    if online_segments:
                        summary = selfplay_result.get('summary', {})
                        # ì˜¨ë¼ì¸ ê²°ê³¼ê°€ online_resultì— ì§ì ‘ ìˆëŠ” ê²½ìš°
                        if not online_segments and selfplay_result.get('online_result'):
                            online_result = selfplay_result.get('online_result', {})
                            online_segments = online_result.get('segment_results', [])
                            summary = online_result.get('summary', {})
                        
                        if online_segments:
                            cycle_results = convert_online_segments_to_cycle_results(online_segments, summary)
                            logger.debug(f"âœ… {coin}-{interval}: ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì™„ë£Œ ({len(cycle_results)}ê°œ cycle)")
                except ImportError:
                    logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ ì—†ìŒ (ë¬´ì‹œ)")
                except Exception as e:
                    logger.debug(f"âš ï¸ ì˜¨ë¼ì¸ Self-play ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            if not cycle_results:
                logger.debug(f"âš ï¸ {coin}-{interval}: Self-play ê²°ê³¼ì— cycle_results ì—†ìŒ")
                return
            
            updated_count = 0
            skipped_count = 0
            
            # ğŸ”¥ ì²« ë²ˆì§¸ cycleì—ì„œ agent_id -> strategy_id ë§¤í•‘ ìƒì„±
            agent_to_strategy_map = {}
            if cycle_results and len(cycle_results) > 0:
                first_cycle = cycle_results[0]
                first_results = first_cycle.get('results', {})
                agent_ids_sorted = sorted(first_results.keys())
                
                # ğŸ”¥ predictive_strategy_* í˜•íƒœì˜ agent_idë¥¼ ì‹¤ì œ ì „ëµ IDë¡œ ë§¤í•‘
                for idx, agent_id in enumerate(agent_ids_sorted):
                    # 1. ì¸ë±ìŠ¤ ê¸°ë°˜ ë§¤í•‘ (ìš°ì„ ìˆœìœ„ 1)
                    if idx < len(all_strategy_ids):
                        agent_to_strategy_map[agent_id] = all_strategy_ids[idx]
                    elif idx in strategy_index_map:
                        agent_to_strategy_map[agent_id] = strategy_index_map[idx]
                    # 2. agent_* í˜•íƒœ ì²˜ë¦¬
                    elif agent_id.startswith('agent_'):
                        try:
                            agent_idx = int(agent_id.split('_')[1]) - 1
                            if 0 <= agent_idx < len(all_strategy_ids):
                                agent_to_strategy_map[agent_id] = all_strategy_ids[agent_idx]
                            elif agent_idx in strategy_index_map:
                                agent_to_strategy_map[agent_id] = strategy_index_map[agent_idx]
                        except (ValueError, IndexError):
                            pass
                    # 3. predictive_strategy_* í˜•íƒœ ì²˜ë¦¬ (ìˆ«ì ì¶”ì¶œ)
                    elif agent_id.startswith('predictive_strategy_'):
                        try:
                            # predictive_strategy_1 -> 0, predictive_strategy_3 -> 2 ë“±
                            pred_idx = int(agent_id.split('_')[2]) - 1
                            if 0 <= pred_idx < len(all_strategy_ids):
                                agent_to_strategy_map[agent_id] = all_strategy_ids[pred_idx]
                                logger.debug(f"âœ… {agent_id} â†’ {all_strategy_ids[pred_idx]} ë§¤í•‘ ì„±ê³µ")
                        except (ValueError, IndexError):
                            pass
                    # 4. agent_idê°€ ì´ë¯¸ strategy_idì¸ ê²½ìš°
                    if agent_id in quality_grade_map:
                        agent_to_strategy_map[agent_id] = agent_id
                
                logger.debug(f"ğŸ” {coin}-{interval}: agent_to_strategy ë§¤í•‘ {len(agent_to_strategy_map)}ê°œ ìƒì„±")
            
            # ğŸ”¥ ë°°ì¹˜ ì—…ë°ì´íŠ¸ë¡œ ë³€ê²½: ëª¨ë“  ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ í›„ í•œ ë²ˆì— ì—…ë°ì´íŠ¸
            batch_updates = []  # (strategy_id, performance_data) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            
            # ëª¨ë“  cycleì—ì„œ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘
            for cycle in cycle_results:
                results = cycle.get('results', {})
                
                for agent_id, performance in results.items():
                    try:
                        # ğŸ”¥ agent_id -> strategy_id ë§¤í•‘ ì‚¬ìš©
                        strategy_id = agent_to_strategy_map.get(agent_id, agent_id)
                        
                        # ë§¤í•‘ì´ ì—†ìœ¼ë©´ agent_idë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (agent_idê°€ strategy_idì¸ ê²½ìš°)
                        if strategy_id == agent_id and agent_id not in quality_grade_map:
                            # quality_grade_mapì— ì—†ìœ¼ë©´ agent_idë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            pass
                        
                        # ğŸ”¥ ì „ëµ IDê°€ 'predictive_strategy_*' í˜•íƒœë©´ ê±´ë„ˆë›°ê¸° (ì‹¤ì œ ì „ëµ IDê°€ ì•„ë‹˜)
                        if strategy_id and strategy_id.startswith('predictive_strategy_'):
                            logger.debug(f"âš ï¸ {agent_id} (ë§¤í•‘: {strategy_id})ëŠ” ì‹¤ì œ ì „ëµ IDê°€ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœ€")
                            skipped_count += 1
                            continue
                        
                        # ì„±ê³¼ ì§€í‘œ ì¶”ì¶œ ë° ë³€í™˜
                        # performanceëŠ” agent.get_performance_metrics()ì˜ ê²°ê³¼
                        total_pnl = performance.get('total_pnl', 0.0)
                        win_rate = performance.get('win_rate', 0.0)
                        trades_count = performance.get('total_trades', 0)
                        max_drawdown = performance.get('max_drawdown', 0.0)
                        sharpe_ratio = performance.get('sharpe_ratio', 0.0)
                        
                        # profit_factor ê³„ì‚° (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê³„ì‚°)
                        profit_factor = performance.get('profit_factor', 0.0)
                        if profit_factor == 0.0 and trades_count > 0:
                            # ê°„ë‹¨í•œ profit_factor ê³„ì‚°: ì´ ìˆ˜ìµ / ì´ ì†ì‹¤
                            total_profit = performance.get('total_profit', 0.0)
                            total_loss = performance.get('total_loss', 0.0)
                            if total_loss > 0:
                                profit_factor = abs(total_profit / total_loss)
                        
                        # avg_profit_per_trade ê³„ì‚°
                        avg_profit_per_trade = 0.0
                        if trades_count > 0:
                            avg_profit_per_trade = total_pnl / trades_count
                        
                        # profitì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜ (total_pnlì´ ì´ë¯¸ í¼ì„¼íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ)
                        # ì¼ë°˜ì ìœ¼ë¡œ Self-playì—ì„œ total_pnlì€ ê¸ˆì•¡ì´ë¯€ë¡œ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                        initial_capital = 10000.0  # Self-play ì´ˆê¸° ìë³¸
                        profit_pct = (total_pnl / initial_capital) * 100 if total_pnl != 0 else 0.0
                        
                        # ğŸ”¥ quality_grade ì¶”ê°€ (evolved_strategiesì—ì„œ ê°€ì ¸ì˜¨ ë“±ê¸‰)
                        performance_data = {
                            'profit': profit_pct,  # í¼ì„¼íŠ¸ë¡œ ì €ì¥
                            'win_rate': win_rate,
                            'trades_count': trades_count,
                            'max_drawdown': max_drawdown,
                            'sharpe_ratio': sharpe_ratio,
                            'profit_factor': profit_factor,
                            'avg_profit_per_trade': avg_profit_per_trade,
                        }
                        
                        # ğŸ”¥ quality_grade ì¶”ê°€ (evolved_strategiesì—ì„œ ê³„ì‚°ëœ ë“±ê¸‰)
                        if strategy_id in quality_grade_map:
                            performance_data['quality_grade'] = quality_grade_map[strategy_id]
                        elif strategy_id.endswith('_evolved') and strategy_id[:-8] in quality_grade_map:
                            # _evolved ì ‘ë¯¸ì‚¬ê°€ ìˆëŠ” ê²½ìš° ì›ë³¸ IDë¡œ ë§¤í•‘
                            original_id = strategy_id[:-8]
                            performance_data['quality_grade'] = quality_grade_map[original_id]
                        
                        batch_updates.append((strategy_id, performance_data))
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ ì „ëµ {agent_id} ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                        skipped_count += 1
                        continue
            
            # ğŸ”¥ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰ (í•œ ë²ˆì˜ ì—°ê²°ë¡œ ëª¨ë“  ì „ëµ ì—…ë°ì´íŠ¸)
            if batch_updates:
                try:
                    import time
                    import sqlite3
                    
                    with get_optimized_db_connection("strategies") as conn:
                        cursor = conn.cursor()
                        
                        # updated_at ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (í•œ ë²ˆë§Œ)
                        cursor.execute("PRAGMA table_info(coin_strategies)")
                        columns = [col[1] for col in cursor.fetchall()]
                        has_updated_at = 'updated_at' in columns
                        
                        # ğŸ”¥ ì¡´ì¬í•˜ëŠ” ì „ëµ IDë§Œ í•„í„°ë§ (ë°°ì¹˜ ì¿¼ë¦¬ë¡œ í™•ì¸)
                        strategy_ids = [sid for sid, _ in batch_updates]
                        placeholders = ','.join(['?' for _ in strategy_ids])
                        
                        cursor.execute(f"""
                            SELECT id FROM coin_strategies 
                            WHERE id IN ({placeholders}) AND coin = ? AND interval = ?
                        """, strategy_ids + [coin, interval])
                        
                        existing_ids = {row[0] for row in cursor.fetchall()}
                        
                        # ì¡´ì¬í•˜ëŠ” ì „ëµë§Œ ì—…ë°ì´íŠ¸
                        valid_updates = [(sid, data) for sid, data in batch_updates if sid in existing_ids]
                        
                        if not valid_updates:
                            logger.warning(f"âš ï¸ {coin}-{interval}: ì¡´ì¬í•˜ëŠ” ì „ëµì´ ì—†ì–´ ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€")
                            return
                        
                        # ğŸ”¥ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                        max_retries = 3
                        retry_delay = 1.0
                        
                        for attempt in range(max_retries):
                            try:
                                # íŠ¸ëœì­ì…˜ ì‹œì‘
                                for strategy_id, performance_data in valid_updates:
                                    set_clauses = []
                                    values = []
                                    
                                    for key, value in performance_data.items():
                                        if key in ['profit', 'win_rate', 'max_drawdown', 'sharpe_ratio', 
                                                  'profit_factor', 'quality_grade', 'trades_count', 
                                                  'avg_profit_per_trade']:
                                            set_clauses.append(f"{key} = ?")
                                            values.append(value)
                                    
                                    if has_updated_at:
                                        set_clauses.append("updated_at = datetime('now')")
                                    
                                    values.extend([strategy_id, coin, interval])
                                    
                                    query = f"""
                                        UPDATE coin_strategies 
                                        SET {', '.join(set_clauses)} 
                                        WHERE id = ? AND coin = ? AND interval = ?
                                    """
                                    
                                    cursor.execute(query, tuple(values))
                                
                                # ëª¨ë“  ì—…ë°ì´íŠ¸ ì„±ê³µ ì‹œ ì»¤ë°‹
                                conn.commit()
                                updated_count = len(valid_updates)
                                logger.info(f"âœ… {coin}-{interval}: {updated_count}ê°œ ì „ëµ ì„±ê³¼ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                                break
                                
                            except sqlite3.OperationalError as db_locked_error:
                                if "database is locked" in str(db_locked_error) and attempt < max_retries - 1:
                                    wait_time = retry_delay * (attempt + 1)
                                    logger.warning(f"âš ï¸ {coin}-{interval} ë°°ì¹˜ ì—…ë°ì´íŠ¸ DB ì ê¸ˆ, {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„ ({attempt+1}/{max_retries})")
                                    time.sleep(wait_time)
                                    conn.rollback()  # ë¡¤ë°± í›„ ì¬ì‹œë„
                                    continue
                                else:
                                    logger.error(f"âŒ {coin}-{interval} ë°°ì¹˜ ì—…ë°ì´íŠ¸ ìµœì¢… ì‹¤íŒ¨: {db_locked_error}")
                                    conn.rollback()
                                    raise
                                    
                except Exception as db_error:
                    logger.error(f"âŒ {coin}-{interval}: ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {db_error}")
                    # ê°œë³„ ì—…ë°ì´íŠ¸ë¡œ í´ë°± (ì„±ëŠ¥ì€ ëŠë¦¬ì§€ë§Œ ë™ì‘)
                    for strategy_id, performance_data in batch_updates:
                        try:
                            fallback_data = {k: v for k, v in performance_data.items() if k != 'quality_grade'}
                            if fallback_data:
                                update_strategy_performance(strategy_id, fallback_data)
                                updated_count += 1
                        except Exception:
                            skipped_count += 1
            
            if updated_count > 0:
                logger.info(f"âœ… {coin}-{interval}: {updated_count}ê°œ ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ (Self-play ê²°ê³¼ ë°˜ì˜)")
            if skipped_count > 0:
                logger.warning(f"âš ï¸ {coin}-{interval}: {skipped_count}ê°œ ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€")
                
        except Exception as e:
            logger.error(f"âŒ {coin}-{interval}: Self-play ê²°ê³¼ë¡œ ì „ëµ ì„±ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise
    
    def _sync_strategy_grades_to_coin_strategies(self, coin: str, interval: str):
        """strategy_grades í…Œì´ë¸”ì˜ ë“±ê¸‰ì„ coin_strategies.quality_gradeì— ë™ê¸°í™”"""
        try:
            from rl_pipeline.db.connection_pool import get_optimized_db_connection
            
            with get_optimized_db_connection("strategies") as conn:
                cursor = conn.cursor()
                
                # ğŸ”¥ strategy_gradesì—ì„œ ë“±ê¸‰ ì¡°íšŒ (ëª¨ë“  ë“±ê¸‰ í¬í•¨)
                cursor.execute("""
                    SELECT strategy_id, grade, predictive_accuracy
                    FROM strategy_grades
                    WHERE coin = ? AND interval = ?
                    ORDER BY strategy_id
                """, (coin, interval))
                
                grade_results = cursor.fetchall()
                
                if not grade_results:
                    logger.debug(f"âš ï¸ {coin}-{interval}: ë™ê¸°í™”í•  ë“±ê¸‰ ë°ì´í„° ì—†ìŒ")
                    return
                
                logger.debug(f"ğŸ” {coin}-{interval}: strategy_gradesì—ì„œ {len(grade_results)}ê°œ ë“±ê¸‰ ë°ì´í„° ë°œê²¬")
                
                updated_count = 0
                skipped_count = 0
                not_found_count = 0
                
                # updated_at ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                from rl_pipeline.core.utils import table_exists
                cursor.execute("PRAGMA table_info(coin_strategies)")
                columns = [col[1] for col in cursor.fetchall()]
                has_updated_at = 'updated_at' in columns
                
                # coin_strategiesì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì „ëµ ID í™•ì¸ (ë””ë²„ê¹…ìš©)
                cursor.execute("""
                    SELECT id FROM coin_strategies 
                    WHERE coin = ? AND interval = ?
                """, (coin, interval))
                existing_ids = {row[0] for row in cursor.fetchall()}
                logger.debug(f"ğŸ” {coin}-{interval}: coin_strategiesì— ì¡´ì¬í•˜ëŠ” ì „ëµ ìˆ˜: {len(existing_ids)}")
                
                # ğŸ” strategy_id ìƒ˜í”Œ ìˆ˜ì§‘ (ë””ë²„ê¹…ìš©)
                sample_not_found_ids = []
                
                for strategy_id, grade, predictive_accuracy in grade_results:
                    try:
                        # ì „ëµì´ coin_strategiesì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        if strategy_id not in existing_ids:
                            not_found_count += 1
                            # ìƒ˜í”Œ ID ìˆ˜ì§‘ (ìµœëŒ€ 5ê°œ)
                            if len(sample_not_found_ids) < 5:
                                sample_not_found_ids.append(strategy_id)
                            skipped_count += 1
                            continue
                        
                        # coin_strategies í…Œì´ë¸” ì—…ë°ì´íŠ¸ (updated_at ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í¬í•¨)
                        if has_updated_at:
                            cursor.execute("""
                                UPDATE coin_strategies
                                SET quality_grade = ?, updated_at = datetime('now')
                                WHERE id = ? AND coin = ? AND interval = ?
                            """, (grade, strategy_id, coin, interval))
                        else:
                            cursor.execute("""
                                UPDATE coin_strategies
                                SET quality_grade = ?
                                WHERE id = ? AND coin = ? AND interval = ?
                            """, (grade, strategy_id, coin, interval))
                        
                        if cursor.rowcount > 0:
                            updated_count += 1
                            if updated_count <= 5:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                logger.debug(f"âœ… {strategy_id} ë“±ê¸‰ ë™ê¸°í™”: {grade} (ì •í™•ë„: {predictive_accuracy:.2%})")
                        else:
                            # ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ ê²½ìš°: ì´ë¯¸ ê°™ì€ ë“±ê¸‰ì´ê±°ë‚˜ ì¡°ê±´ ë¶ˆì¼ì¹˜
                            skipped_count += 1
                            if skipped_count <= 3:
                                # í˜„ì¬ ë“±ê¸‰ í™•ì¸
                                cursor.execute("""
                                    SELECT quality_grade FROM coin_strategies 
                                    WHERE id = ? AND coin = ? AND interval = ?
                                """, (strategy_id, coin, interval))
                                current_grade = cursor.fetchone()
                                if current_grade:
                                    logger.debug(f"âš ï¸ {strategy_id} ë“±ê¸‰ ë³€ê²½ ì—†ìŒ: í˜„ì¬={current_grade[0]}, ìƒˆ={grade}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ {strategy_id} ë“±ê¸‰ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
                
                if updated_count > 0:
                    logger.info(f"âœ… {coin}-{interval} ë“±ê¸‰ ë™ê¸°í™” ì™„ë£Œ: {updated_count}ê°œ ì „ëµ ì—…ë°ì´íŠ¸ "
                               f"(ê±´ë„ˆëœ€: {skipped_count}ê°œ, coin_strategiesì— ì—†ìŒ: {not_found_count}ê°œ)")
                else:
                    if not_found_count > 0:
                        # ğŸ” ë” ìì„¸í•œ ë””ë²„ê¹… ì •ë³´ ì œê³µ
                        sample_ids_str = ", ".join(sample_not_found_ids) if sample_not_found_ids else "ì—†ìŒ"
                        
                        # ğŸ”§ 'unknown'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” IDëŠ” ì‹œë®¬ë ˆì´ì…˜ self-play ê²°ê³¼ë¡œ, coin_strategiesì— ì—†ìŒì´ ì •ìƒ
                        unknown_count = sum(1 for sid in sample_not_found_ids if isinstance(sid, str) and sid.startswith('unknown'))
                        if unknown_count > 0:
                            logger.debug(
                                f"âš ï¸ {coin}-{interval}: ë“±ê¸‰ ë™ê¸°í™” ëŒ€ìƒ ì—†ìŒ "
                                f"(strategy_grades: {len(grade_results)}ê°œ, coin_strategiesì— ì—†ìŒ: {not_found_count}ê°œ)\n"
                                f"   ğŸ“‹ ëˆ„ë½ëœ strategy_id ìƒ˜í”Œ: {sample_ids_str}\n"
                                f"   ğŸ’¡ ì›ì¸: ì‹œë®¬ë ˆì´ì…˜ self-play ê²°ê³¼ì˜ strategy_id (unknown_*)ëŠ” coin_strategiesì— ì €ì¥ë˜ì§€ ì•ŠìŒ (ì •ìƒ ë™ì‘)"
                            )
                        else:
                            # ğŸ”§ Self-playë¡œ í…ŒìŠ¤íŠ¸ëœ ëª¨ë“  ì „ëµì´ coin_strategiesì— ì €ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì •ìƒ ë™ì‘
                            # ë¡¤ì—…ì€ rl_episode_summaryì˜ ëª¨ë“  ì „ëµì— ëŒ€í•´ ê³„ì‚°í•˜ì§€ë§Œ,
                            # coin_strategiesì—ëŠ” ì§„í™”ëœ ì „ëµë§Œ ì €ì¥ë˜ë¯€ë¡œ ì¼ë¶€ strategy_idê°€ ì—†ì„ ìˆ˜ ìˆìŒ
                            if not_found_count == len(grade_results):
                                # ëª¨ë“  ì „ëµì´ ì—†ëŠ” ê²½ìš°: Self-play ì „ëµë“¤ì´ coin_strategiesì— ì €ì¥ë˜ì§€ ì•Šì€ ê²½ìš°
                                logger.debug(
                                    f"â„¹ï¸ {coin}-{interval}: ë“±ê¸‰ ë™ê¸°í™” ëŒ€ìƒ ì—†ìŒ "
                                    f"(strategy_grades: {len(grade_results)}ê°œ, coin_strategiesì— ì—†ìŒ: {not_found_count}ê°œ)\n"
                                    f"   ğŸ“‹ ëˆ„ë½ëœ strategy_id ìƒ˜í”Œ: {sample_ids_str}\n"
                                    f"   ğŸ’¡ ì›ì¸: Self-playë¡œ í…ŒìŠ¤íŠ¸ëœ ì „ëµë“¤ì´ coin_strategiesì— ì €ì¥ë˜ì§€ ì•ŠìŒ (ì •ìƒ ë™ì‘)\n"
                                    f"   â„¹ï¸ ë¡¤ì—…ì€ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì „ëµì— ëŒ€í•´ ê³„ì‚°í•˜ì§€ë§Œ, coin_strategiesì—ëŠ” ì§„í™”ëœ ì „ëµë§Œ ì €ì¥ë¨"
                                )
                            else:
                                # ì¼ë¶€ë§Œ ì—†ëŠ” ê²½ìš°: ê²½ê³  ìœ ì§€
                                logger.warning(
                                    f"âš ï¸ {coin}-{interval}: ë“±ê¸‰ ë™ê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨ "
                                    f"(strategy_grades: {len(grade_results)}ê°œ, coin_strategiesì— ì—†ìŒ: {not_found_count}ê°œ)\n"
                                    f"   ğŸ“‹ ëˆ„ë½ëœ strategy_id ìƒ˜í”Œ: {sample_ids_str}\n"
                                    f"   ğŸ’¡ ì›ì¸: ì¼ë¶€ ë¡¤ì—… ë°ì´í„°ì˜ strategy_idê°€ coin_strategiesì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ "
                                    f"(ì´ì „ ì‹¤í–‰ ë°ì´í„° ë˜ëŠ” Self-play í…ŒìŠ¤íŠ¸ ì „ëµì¼ ìˆ˜ ìˆìŒ)"
                                )
                    else:
                        logger.debug(f"âš ï¸ {coin}-{interval}: ë“±ê¸‰ ë™ê¸°í™” ëŒ€ìƒ ì—†ìŒ "
                                     f"(ëª¨ë‘ ì´ë¯¸ ë™ê¸°í™”ë¨ ë˜ëŠ” ì¡°ê±´ ë¶ˆì¼ì¹˜, skipped: {skipped_count}ê°œ)")
                
        except Exception as e:
            logger.error(f"âŒ ë“±ê¸‰ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _filter_strategies_by_direction(
        self,
        strategies: List[Dict[str, Any]],
        coin: str,
        interval: str,
        candle_data: pd.DataFrame
    ) -> List[Dict[str, Any]]:
        """
        ì‹¤ì œ ìº”ë“¤ ë°ì´í„°ë¡œ ë¹ ë¥¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸í•˜ì—¬ ë°©í–¥ì„±ì´ ìˆëŠ” ì „ëµë§Œ í•„í„°ë§
        
        Args:
            strategies: í•„í„°ë§í•  ì „ëµ ë¦¬ìŠ¤íŠ¸
            coin: ì½”ì¸ ì‹¬ë³¼
            interval: ì¸í„°ë²Œ
            candle_data: ì‹¤ì œ ìº”ë“¤ ë°ì´í„°
            
        Returns:
            ë°©í–¥ì„±ì´ ìˆëŠ” ì „ëµë§Œ í•„í„°ë§ëœ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í™˜ê²½ë³€ìˆ˜ë¡œ í•„í„°ë§ í™œì„±í™” ì—¬ë¶€ ì œì–´ (ê¸°ë³¸ê°’: false - ë‹¤ì–‘ì„± í™•ë³´)
            enable_filtering = os.getenv('ENABLE_STRATEGY_DIRECTION_FILTERING', 'false').lower() == 'true'
            
            if not enable_filtering:
                logger.debug(f"ğŸ“Š ë°©í–¥ì„± í•„í„°ë§ ë¹„í™œì„±í™”, ëª¨ë“  ì „ëµ ì‚¬ìš© (ë‹¤ì–‘ì„± í™•ë³´)")
                return strategies
            
            # ğŸ†• ì²« ìƒì„± ì—¬ë¶€ í™•ì¸ (ê¸°ì¡´ ì „ëµì´ ìˆìœ¼ë©´ í•„í„°ë§, ì—†ìœ¼ë©´ ì™„í™”)
            try:
                from rl_pipeline.db.connection_pool import get_optimized_db_connection
                with get_optimized_db_connection("strategies") as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT COUNT(*) FROM coin_strategies 
                        WHERE coin = ? AND interval = ?
                    """, (coin, interval))
                    existing_count = cursor.fetchone()[0]
                    
                    if existing_count == 0:
                        # ì²« ìƒì„± ì‹œ í•„í„°ë§ ì™„í™” (50% ì´ìƒ í†µê³¼í•˜ë©´ ì‚¬ìš©)
                        logger.info(f"ğŸ“Š {coin}-{interval} ì²« ì „ëµ ìƒì„±, í•„í„°ë§ ì™„í™” ëª¨ë“œ")
                        strict_mode = False
                    else:
                        # ê¸°ì¡´ ì „ëµì´ ìˆìœ¼ë©´ ì—„ê²©í•œ í•„í„°ë§
                        logger.debug(f"ğŸ“Š {coin}-{interval} ê¸°ì¡´ ì „ëµ {existing_count}ê°œ ì¡´ì¬, ì—„ê²©í•œ í•„í„°ë§")
                        strict_mode = True
            except Exception as e:
                logger.debug(f"âš ï¸ ê¸°ì¡´ ì „ëµ ìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}, ì—„ê²©í•œ í•„í„°ë§ ì‚¬ìš©")
                strict_mode = True
            
            # ìº”ë“¤ ë°ì´í„° ìœ íš¨ì„± ì²´í¬ (DataFrame ë¹„êµ ì•ˆì „í•˜ê²Œ)
            try:
                if candle_data is None:
                    logger.warning(f"âš ï¸ ìº”ë“¤ ë°ì´í„°ê°€ Noneì´ë¯€ë¡œ í•„í„°ë§ ê±´ë„ˆëœ€")
                    return strategies
                if isinstance(candle_data, pd.DataFrame):
                    if candle_data.empty or len(candle_data) < 10:
                        logger.warning(f"âš ï¸ ìº”ë“¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í•„í„°ë§ ê±´ë„ˆëœ€")
                        return strategies
                else:
                    logger.warning(f"âš ï¸ ìº”ë“¤ ë°ì´í„° íƒ€ì…ì´ DataFrameì´ ì•„ë‹˜, í•„í„°ë§ ê±´ë„ˆëœ€")
                    return strategies
            except Exception as e:
                logger.warning(f"âš ï¸ ìº”ë“¤ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}, í•„í„°ë§ ê±´ë„ˆëœ€")
                return strategies

            # ğŸ”¥ ìˆ˜ì •: prediction_generator ì„ íƒì  import
            try:
                from rl_pipeline.engine.prediction_generator import PredictionGenerator
                prediction_generator = PredictionGenerator()
            except ImportError:
                logger.debug("âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ë¯¸ì‚¬ìš© (PredictionGenerator ë¯¸êµ¬í˜„), ë°©í–¥ì„± í•„í„°ë§ ê±´ë„ˆëœ€")
                return strategies
            
            # ìº”ë“¤ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ (ìµœê·¼ 10ê°œ ìº”ë“¤ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
            sample_candles = candle_data.tail(10).copy()
            
            filtered_strategies = []
            skipped_count = 0
            
            # ë””ë²„ê¹…: ì²« ëª‡ ê°œ ì „ëµì˜ íŒŒë¼ë¯¸í„° í™•ì¸
            if strategies:
                sample_params = self._extract_strategy_params_for_prediction(strategies[0])
                logger.debug(f"ğŸ“Š í•„í„°ë§ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ íŒŒë¼ë¯¸í„°: RSI={sample_params.get('rsi_min', 'N/A')}-{sample_params.get('rsi_max', 'N/A')}, "
                           f"MACD_buy={sample_params.get('macd_buy_threshold', 'N/A')}, MACD_sell={sample_params.get('macd_sell_threshold', 'N/A')}")
            
            for strategy in strategies:
                try:
                    # ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    strategy_params = self._extract_strategy_params_for_prediction(strategy)
                    
                    # ìƒ˜í”Œ ìº”ë“¤ë¡œ ë¹ ë¥¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ë” ë§ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸)
                    has_direction = False
                    test_count = min(10, len(sample_candles))  # ìµœëŒ€ 10ê°œë¡œ ì¦ê°€
                    
                    for idx in range(test_count):
                        candle = sample_candles.iloc[idx]
                        
                        # ì‹œì¥ ìƒíƒœ ì¶”ì¶œ (ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ ê°’ ì¶”ì¶œ)
                        def safe_get(candle, key, default):
                            """ì•ˆì „í•˜ê²Œ ë‹¨ì¼ ê°’ ì¶”ì¶œ"""
                            try:
                                val = candle[key]
                                # Seriesë‚˜ DataFrameì´ë©´ ì²« ë²ˆì§¸ ê°’ ì¶”ì¶œ
                                if isinstance(val, (pd.Series, pd.DataFrame)):
                                    val = val.iloc[0] if len(val) > 0 else default
                                # numpy arrayë©´ ì²« ë²ˆì§¸ ê°’
                                elif hasattr(val, 'item'):
                                    try:
                                        val = val.item()
                                    except (ValueError, AttributeError):
                                        pass
                                # NaN ì²´í¬ (pd.isna ëŒ€ì‹  ì§ì ‘ ì²´í¬)
                                if val is None:
                                    return default
                                try:
                                    val_float = float(val)
                                    # NaN, inf ì²´í¬
                                    import math
                                    if math.isnan(val_float) or math.isinf(val_float):
                                        return default
                                    return val_float
                                except (ValueError, TypeError):
                                    return default
                            except (KeyError, IndexError, AttributeError, TypeError, ValueError):
                                return default
                        
                        market_state = {
                            'rsi': safe_get(candle, 'rsi', 50.0),
                            'macd': safe_get(candle, 'macd', 0.0),
                            'macd_signal': safe_get(candle, 'macd_signal', 0.0),
                            'volume_ratio': safe_get(candle, 'volume_ratio', 1.0),
                            'mfi': safe_get(candle, 'mfi', 50.0),
                            'atr': safe_get(candle, 'atr', 0.02),
                            'adx': safe_get(candle, 'adx', 25.0),
                            'price': safe_get(candle, 'close', 0.0)
                        }
                        
                        # ì˜ˆì¸¡ ìƒì„±
                        prediction = prediction_generator.generate_prediction(
                            strategy=strategy_params,
                            market_state=market_state,
                            interval=interval,
                            entry_price=market_state['price'],
                            state_key=f"{coin}_{interval}_{idx}"
                        )
                        
                        # ë°©í–¥ì„±ì´ ìˆìœ¼ë©´ í†µê³¼ (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)
                        if prediction.predicted_dir != 0:
                            logger.debug(f"âœ… ì „ëµ {strategy.get('id', 'unknown')[:30]} dir={prediction.predicted_dir} í†µê³¼")
                            has_direction = True
                            break
                        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì „ëµì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¡œê·¸
                        elif strategy == strategies[0] and idx == 0:
                            logger.debug(f"ğŸ” ì²« ì „ëµ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸: dir={prediction.predicted_dir}, conf={prediction.predicted_conf:.3f}, "
                                       f"RSI={market_state['rsi']:.1f}, MACD={market_state['macd']:.6f}")
                    
                    if has_direction:
                        filtered_strategies.append(strategy)
                    else:
                        skipped_count += 1
                        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì „ëµë§Œ ìƒì„¸ ë¡œê·¸
                        if strategy == strategies[0]:
                            logger.debug(f"âŒ ì²« ì „ëµ í•„í„°ë§ ì œì™¸: dir=0ë§Œ ë‚˜ì˜´, íŒŒë¼ë¯¸í„°={strategy_params}")
                        
                except Exception as e:
                    # ì˜ˆì™¸ ë°œìƒ ì‹œ ì „ëµ í¬í•¨ (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
                    logger.debug(f"âš ï¸ ì „ëµ {strategy.get('id', 'unknown')} í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}, í¬í•¨")
                    filtered_strategies.append(strategy)
            
            if skipped_count > 0:
                logger.info(f"ğŸ“Š ë°©í–¥ì„± í•„í„°ë§: {skipped_count}ê°œ ì „ëµ ì œì™¸ (dir=0ë§Œ ë‚˜ì˜´)")
            
            # ğŸ†• ì²« ìƒì„± ì‹œ ì™„í™” ëª¨ë“œ: í•„í„°ë§ í›„ ì „ëµì´ ì ì–´ë„ ì¼ì • ë¹„ìœ¨ ì´ìƒ ìˆìœ¼ë©´ ì‚¬ìš©
            if not strict_mode:
                # ì²« ìƒì„± ì‹œ: 30% ì´ìƒ í†µê³¼í–ˆìœ¼ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ì›ë³¸ ì‚¬ìš©
                if len(filtered_strategies) >= len(strategies) * 0.3:
                    logger.info(f"ğŸ“Š ì²« ìƒì„± ì™„í™” ëª¨ë“œ: {len(filtered_strategies)}ê°œ ì „ëµ í†µê³¼ ({len(filtered_strategies)/len(strategies)*100:.1f}%), ì‚¬ìš©")
                    return filtered_strategies
                else:
                    logger.info(f"ğŸ“Š ì²« ìƒì„± ì™„í™” ëª¨ë“œ: í•„í„°ë§ í›„ {len(filtered_strategies)}ê°œë§Œ ë‚¨ìŒ (ì „ì²´ì˜ {len(filtered_strategies)/len(strategies)*100:.1f}%), ì›ë³¸ ì „ëµ ì‚¬ìš©")
                    return strategies
            else:
                # ì—„ê²©í•œ ëª¨ë“œ: í•„í„°ë§ í›„ ì „ëµì´ ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš© (ì•ˆì „ì¥ì¹˜)
                if len(filtered_strategies) == 0:
                    logger.warning(f"âš ï¸ ë°©í–¥ì„± í•„í„°ë§ í›„ ì „ëµì´ ì—†ì–´ì„œ ì›ë³¸ ì „ëµ ì‚¬ìš©")
                    return strategies
            
            return filtered_strategies
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë°©í–¥ì„± í•„í„°ë§ ì‹¤íŒ¨: {e}, ì›ë³¸ ì „ëµ ì‚¬ìš©")
            return strategies
    
    def _extract_strategy_params_for_prediction(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ëµì—ì„œ ì˜ˆì¸¡ ìƒì„±ì— í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë§Œ ì¶”ì¶œ"""
        try:
            # strategy_conditionsì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (JSON ë¬¸ìì—´ì´ë©´ íŒŒì‹±)
            import json
            strategy_conditions = strategy.get('strategy_conditions', {})
            
            if isinstance(strategy_conditions, str):
                try:
                    strategy_conditions = json.loads(strategy_conditions) if strategy_conditions else {}
                except json.JSONDecodeError:
                    strategy_conditions = {}
            
            # ì „ëµ íŒŒë¼ë¯¸í„° êµ¬ì„± (ìš°ì„ ìˆœìœ„: strategy_conditions > strategy ì§ì ‘ í•„ë“œ > ê¸°ë³¸ê°’)
            # None ì²´í¬ë¥¼ í¬í•¨í•˜ì—¬ ì‹¤ì œ ê°’ì´ ìˆì„ ë•Œë§Œ ì‚¬ìš©
            def get_param(key, default):
                # strategy_conditionsì—ì„œ ë¨¼ì € ì°¾ê¸°
                val = strategy_conditions.get(key) if strategy_conditions else None
                if val is not None:
                    return float(val)
                # strategy ì§ì ‘ í•„ë“œì—ì„œ ì°¾ê¸°
                val = strategy.get(key)
                if val is not None:
                    return float(val)
                return default
            
            params = {
                'rsi_min': get_param('rsi_min', 30.0),
                'rsi_max': get_param('rsi_max', 70.0),
                'volume_ratio_min': get_param('volume_ratio_min', 1.0),
                'volume_ratio_max': get_param('volume_ratio_max', 2.0),
                'macd_buy_threshold': get_param('macd_buy_threshold', 0.01),
                'macd_sell_threshold': get_param('macd_sell_threshold', -0.01),
                'stop_loss_pct': get_param('stop_loss_pct', 0.02),
                'take_profit_pct': get_param('take_profit_pct', 0.05),
            }
            
            return params
            
        except Exception as e:
            logger.debug(f"âš ï¸ ì „ëµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return {
                'rsi_min': 30.0,
                'rsi_max': 70.0,
                'volume_ratio_min': 1.0,
                'volume_ratio_max': 2.0,
                'macd_buy_threshold': 0.01,
                'macd_sell_threshold': -0.01,
                'stop_loss_pct': 0.02,
                'take_profit_pct': 0.05,
            }
    
    def _create_default_analysis_result(self, coin: str, interval: str) -> Any:
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„± - ë” í˜„ì‹¤ì ì¸ ê²°ê³¼"""
        try:
            import random
            
            # ê°„ë‹¨í•œ ë¶„ì„ ê²°ê³¼ í´ë˜ìŠ¤ ì •ì˜
            class SimpleAnalysisResult:
                def __init__(self, coin: str, interval: str):
                    self.coin = coin
                    self.interval = interval
                    self.regime = random.choice(['bullish', 'bearish', 'neutral', 'sideways'])
                    self.fractal_score = random.uniform(0.3, 0.8)
                    self.multi_timeframe_score = random.uniform(0.4, 0.9)
                    self.indicator_cross_score = random.uniform(0.2, 0.7)
                    self.ensemble_score = random.uniform(0.3, 0.8)
                    self.ensemble_confidence = random.uniform(0.5, 0.9)
                    
                    # ìµœì¢… ì‹œê·¸ë„ ì ìˆ˜ ê³„ì‚°
                    self.final_signal_score = (self.fractal_score + self.multi_timeframe_score + 
                                             self.indicator_cross_score + self.ensemble_score) / 4
                    
                    # ì‹œê·¸ë„ ì•¡ì…˜ ê²°ì •
                    if self.final_signal_score > 0.7:
                        self.signal_action = "BUY"
                    elif self.final_signal_score < 0.3:
                        self.signal_action = "SELL"
                    else:
                        self.signal_action = "HOLD"
                    
                    self.signal_confidence = self.ensemble_confidence
                    self.created_at = datetime.now().isoformat()
            
            result = SimpleAnalysisResult(coin, interval)
            logger.info(f"ğŸ“Š ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„±: {result.signal_action} (ì ìˆ˜: {result.final_signal_score:.3f})")

            # Dictë¡œ ë³€í™˜ (validator í˜¸í™˜ì„±)
            return {
                'coin': result.coin,
                'interval': result.interval,
                'regime': result.regime,
                'fractal_score': result.fractal_score,
                'multi_timeframe_score': result.multi_timeframe_score,
                'indicator_cross_score': result.indicator_cross_score,
                'ensemble_score': result.ensemble_score,
                'ensemble_confidence': result.ensemble_confidence,
                'signal_score': result.final_signal_score,
                'signal_action': result.signal_action,
                'signal_confidence': result.signal_confidence,
                'created_at': result.created_at
            }
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ê²°ê³¼ë¼ë„ ë°˜í™˜ (dict)
            return {
                'coin': coin,
                'interval': interval,
                'regime': 'neutral',
                'fractal_score': 0.5,
                'multi_timeframe_score': 0.5,
                'indicator_cross_score': 0.5,
                'ensemble_score': 0.5,
                'ensemble_confidence': 0.5,
                'signal_score': 0.5,
                'signal_action': 'HOLD',
                'signal_confidence': 0.5,
                'created_at': datetime.now().isoformat()
            }

# ============================================================================
# í†µí•©ëœ Learning Results DB ê´€ë¦¬
# ============================================================================

@contextmanager
def run_integrated_pipeline(coin: str, interval: str, candle_data: pd.DataFrame) -> PipelineResult:
    """í†µí•©ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    orchestrator = IntegratedPipelineOrchestrator()
    return orchestrator.run_complete_pipeline(coin, interval, candle_data)
# ê¸°ë³¸ê°’ì€ ëª¨ë‘ falseë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì„œ ì¤‘ìš”í•œ ë¡œê·¸ë§Œ ì¶œë ¥ë¨

