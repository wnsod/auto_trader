"""
Absolute Zero ì‹œìŠ¤í…œ - í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (ê²€ì¦ ì‹œìŠ¤í…œ í†µí•© ë²„ì „)
ëª¨ë“  íŒŒì´í”„ë¼ì¸ ê¸°ëŠ¥ì„ í†µí•©í•œ ë‹¨ì¼ ì‹œìŠ¤í…œ + ë°ì´í„° ê²€ì¦
"""

import sys
import os
import logging
import sqlite3
import json
import numpy as np
import warnings
from datetime import datetime
from typing import Dict, List, Any, Optional

# NumPy overflow/underflow ê²½ê³  ìˆ¨ê¹€
warnings.filterwarnings('ignore', category=RuntimeWarning, module='numpy')

# TensorFlow Protobuf ë²„ì „ ê²½ê³  ìˆ¨ê¹€ (JAX ë¡œë“œ ì‹œ ë°œìƒí•˜ëŠ” ê²½ê³ , ê¸°ëŠ¥ ì˜í–¥ ì—†ìŒ)
warnings.filterwarnings('ignore', message='.*Protobuf gencode version.*', category=UserWarning)
warnings.filterwarnings('ignore', message='.*Sharding info not provided.*', category=UserWarning)

# JAX TPU/ROCm ë°±ì—”ë“œ ë°©ì§€ ë° CUDA ê°•ì œ ì‚¬ìš©
import os
# TensorFlow ê²½ê³  ì™„ì „ ì–µì œ (JAXê°€ TensorFlow ì—†ì´ë„ ì‘ë™ ê°€ëŠ¥)
os.environ.setdefault('TF_CPP_MIN_LOG_LEVEL', '3')
# CUDAë§Œ ì‚¬ìš©í•˜ë„ë¡ ëª…ì‹œ (ROCm ì œì™¸)
os.environ.setdefault('JAX_PLATFORMS', 'cuda,cpu')  # CUDAë§Œ ì‚¬ìš©, ROCm ì œì™¸

# Python warnings í•„í„°ë§ (TensorFlow ê´€ë ¨)
warnings.filterwarnings('ignore', category=Warning, message='.*Tensorflow.*')
warnings.filterwarnings('ignore', category=Warning, message='.*TensorFlow.*')

# JAX ë¡œê±° ë ˆë²¨ ì¡°ì • (TensorFlow ê²½ê³  ì–µì œ)
import logging as std_logging
std_logging.getLogger('jax._src.xla_bridge').setLevel(std_logging.ERROR)
std_logging.getLogger('jax._src.lib').setLevel(std_logging.ERROR)
std_logging.getLogger('absl').setLevel(std_logging.ERROR)

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# ğŸ”¥ logger ì´ˆê¸°í™” (import ì „ì— ì„¤ì •)
logger = logging.getLogger(__name__)

# ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡° import
try:
    # ì§ì ‘ import ì‹œë„
    import rl_pipeline.core.env as core_env
    import rl_pipeline.core.errors as core_errors
    import rl_pipeline.strategy.manager as strategy_manager
    import rl_pipeline.simulation.selfplay as selfplay
    import rl_pipeline.routing.regime_router as regime_router
    import rl_pipeline.analysis.integrated_analyzer as integrated_analyzer
    import rl_pipeline.db.schema as db_schema
    import rl_pipeline.db.connection_pool as db_pool

    # ğŸ”¥ ë””ë²„ê·¸ ì‹œìŠ¤í…œ import
    from rl_pipeline.monitoring import SessionManager

    # ğŸ†• ê²€ì¦ ì‹œìŠ¤í…œ import
    from rl_pipeline.validation import (
        create_validation_orchestrator,
        validate_absolute_zero_stage
    )

    config = core_env.config
    AZError = core_errors.AZError
    create_run_record = strategy_manager.create_run_record
    update_run_record = strategy_manager.update_run_record
    create_strategies = strategy_manager.create_strategies
    create_global_strategies = strategy_manager.create_global_strategies
    run_self_play_test = selfplay.run_self_play_test
    RegimeRouter = regime_router.RegimeRouter
    create_regime_routing_strategies = regime_router.create_regime_routing_strategies
    IntegratedAnalyzer = integrated_analyzer.IntegratedAnalyzer
    analyze_strategies = integrated_analyzer.analyze_strategies
    analyze_global_strategies = integrated_analyzer.analyze_global_strategies
    ensure_indexes = db_schema.ensure_indexes
    setup_database_tables = db_schema.setup_database_tables
    create_strategies_table = db_schema.create_strategies_table
    get_optimized_db_connection = db_pool.get_optimized_db_connection

    NEW_PIPELINE_AVAILABLE = True

except ImportError as e:
    logger.error(f"ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    config = None
    AZError = Exception
    NEW_PIPELINE_AVAILABLE = False

# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
# ğŸ”¥ pipelines í´ë”ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì„¤ì • íŒŒì¼ ì°¾ê¸°
base_dir = os.path.dirname(os.path.dirname(__file__))
env_path = os.path.join(base_dir, 'rl_pipeline_config.env')
load_dotenv(env_path)

# í™˜ê²½ ë³€ìˆ˜
AZ_DEBUG = os.getenv('AZ_DEBUG', 'false').lower() == 'true'
# ğŸ”¥ pipelines í´ë”ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
# base_dirëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨
AZ_LOG_FILE = os.getenv('AZ_LOG_FILE', os.path.join(base_dir, 'absolute_zero_debug.log'))
AZ_SIMULATION_VERBOSE = os.getenv('AZ_SIMULATION_VERBOSE', 'false').lower() == 'true'
AZ_CANDLE_DAYS = int(os.getenv('AZ_CANDLE_DAYS', '30'))
AZ_INTERVALS = os.getenv('AZ_INTERVALS', '')

# ğŸ†• ê²€ì¦ ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜
ENABLE_VALIDATION = os.getenv('ENABLE_VALIDATION', 'true').lower() == 'true'
ENABLE_AUTO_FIX = os.getenv('ENABLE_AUTO_FIX', 'true').lower() == 'true'

# ğŸ†• ì „ì—­ ê²€ì¦ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
validation_orchestrator = None
if ENABLE_VALIDATION:
    try:
        validation_orchestrator = create_validation_orchestrator(enable_auto_fix=ENABLE_AUTO_FIX)
        logger.info("âœ… ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        ENABLE_VALIDATION = False

# ë¶„ë¦¬ëœ ëª¨ë“ˆ imports
from rl_pipeline.pipelines.orchestrator import (
    PipelineResult,
    IntegratedPipelineOrchestrator,
)
from rl_pipeline.db.learning_results import (
    create_learning_results_tables,
    save_pipeline_execution_log,
    save_regime_routing_results,
    get_pipeline_performance_summary,
)
from rl_pipeline.data.candle_loader import (
    get_available_coins_and_intervals,
    load_candle_data_for_coin,
)

def _configure_logging():
    try:
        root_logger = logging.getLogger()
        if AZ_DEBUG:
            root_logger.setLevel(logging.DEBUG)
        else:
            root_logger.setLevel(logging.INFO)
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
        if not any(isinstance(h, logging.StreamHandler) for h in root_logger.handlers):
            sh = logging.StreamHandler()
            sh.setLevel(logging.DEBUG if AZ_DEBUG else logging.INFO)
            fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
            sh.setFormatter(fmt)
            root_logger.addHandler(sh)
        if AZ_DEBUG and not any(isinstance(h, logging.FileHandler) for h in root_logger.handlers):
            try:
                fh = logging.FileHandler(AZ_LOG_FILE, encoding='utf-8')
                fh.setLevel(logging.DEBUG)
                fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
                fh.setFormatter(fmt)
                root_logger.addHandler(fh)
                logger.debug(f"ğŸ“ ë””ë²„ê·¸ ë¡œê·¸ íŒŒì¼: {AZ_LOG_FILE}")
            except Exception as e:
                logger.warning(f"âš ï¸ íŒŒì¼ ë¡œê±° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"[LOGGING_INIT_ERROR] {e}")

# Docker í™˜ê²½ ê²½ë¡œ ì„¤ì •
# ğŸ”¥ pipelines í´ë”ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
# base_dirëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨
CANDLES_DB_PATH = os.path.join(base_dir, 'data', 'rl_candles.db')
STRATEGIES_DB_PATH = os.path.join(base_dir, 'data', 'learning_strategies.db')
# learning_results.dbëŠ” ì´ì œ learning_strategies.dbë¡œ í†µí•©ë¨ (core/env.py ì°¸ì¡°)
LEARNING_RESULTS_DB_PATH = STRATEGIES_DB_PATH

def ensure_storage_ready():
    """ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ì‚¬ì „ ë³´ì¥"""
    try:
        # ğŸ”¥ pipelines í´ë”ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
        # base_dirëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨
        data_dir = os.path.join(base_dir, 'data')
        os.makedirs(data_dir, exist_ok=True)

        def _ensure_file_exists(path):
            if not os.path.exists(path):
                open(path, 'a').close()
                logger.info(f"âœ… íŒŒì¼ ìƒì„±: {path}")

        # LEARNING_RESULTS_DB_PATHëŠ” ì´ì œ STRATEGIES_DB_PATHì™€ ë™ì¼í•˜ë¯€ë¡œ ì¤‘ë³µ ì œê±°
        for path in (CANDLES_DB_PATH, STRATEGIES_DB_PATH):
            _ensure_file_exists(path)
    except Exception as e:
        logger.error(f"âŒ ì €ì¥ì†Œ ì‚¬ì „ ì¤€ë¹„ ì‹¤íŒ¨: {e}")

def run_absolute_zero(coin: Optional[str] = None, interval: str = "15m", n_strategies: int = 300, intervals: Optional[List[str]] = None) -> Dict[str, Any]:
    """Absolute Zero ì‹œìŠ¤í…œ ì‹¤í–‰ - ê²€ì¦ ì‹œìŠ¤í…œ í†µí•©"""
    try:
        start_time = datetime.now()
        validation_results = {}  # ğŸ†• ê²€ì¦ ê²°ê³¼ ì €ì¥

        # ğŸ”¥ ë””ë²„ê·¸ ì„¸ì…˜ ìƒì„±
        session_manager = SessionManager()
        session_id = None
        try:
            # ì¸í„°ë²Œ ë¦¬ìŠ¤íŠ¸ ë¯¸ë¦¬ ì¤€ë¹„ (ì„¸ì…˜ ìƒì„±ìš©)
            if intervals and len(intervals) > 0:
                intervals_for_session = intervals
            elif AZ_INTERVALS:
                intervals_for_session = [i.strip() for i in AZ_INTERVALS.split(',')]
            else:
                intervals_for_session = [interval]

            # ì½”ì¸ ê²°ì • (ì„¸ì…˜ ìƒì„±ìš©)
            coin_for_session = coin
            if coin_for_session is None:
                try:
                    available = get_available_coins_and_intervals()
                    coins = sorted(list({c for c, _ in available}))
                    if coins:
                        coin_for_session = coins[0]
                except:
                    coin_for_session = "UNKNOWN"

            session_id = session_manager.create_session(
                coins=[coin_for_session] if coin_for_session else ["UNKNOWN"],
                intervals=intervals_for_session,
                config={
                    "n_strategies": n_strategies,
                    "candle_days": AZ_CANDLE_DAYS
                }
            )
            logger.info(f"âœ… ë””ë²„ê·¸ ì„¸ì…˜ ìƒì„±: {session_id}")
        except Exception as session_err:
            logger.warning(f"âš ï¸ ë””ë²„ê·¸ ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {session_err}")
            session_id = None

        # ë‹¤ì¤‘ ì¸í„°ë²Œ ì§€ì› ìš°ì„ ìˆœìœ„: í•¨ìˆ˜ ì¸ì intervals > AZ_INTERVALS í™˜ê²½ë³€ìˆ˜ > ë‹¨ì¼ interval
        if intervals and len(intervals) > 0:
            intervals_raw = intervals
        elif AZ_INTERVALS:
            intervals_raw = [i.strip() for i in AZ_INTERVALS.split(',')]
        else:
            intervals_raw = [interval]

        # ì¸í„°ë²Œ ìˆœì„œ ì •ë ¬
        def sort_intervals(interval_list):
            """ì¸í„°ë²Œì„ ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬"""
            def get_order_in_minutes(iv):
                iv_lower = iv.lower().strip()
                try:
                    if iv_lower.endswith('m'):
                        minutes = int(iv_lower[:-1])
                        return minutes
                    elif iv_lower.endswith('h'):
                        hours = int(iv_lower[:-1])
                        return hours * 60
                    elif iv_lower.endswith('d'):
                        days = int(iv_lower[:-1])
                        return days * 1440
                    else:
                        return 999999
                except (ValueError, AttributeError):
                    return 999999

            return sorted(interval_list, key=lambda x: (get_order_in_minutes(x), x))

        intervals_to_use = sort_intervals(intervals_raw)

        # ì½”ì¸ ê¸°ë³¸ê°’: DBì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì¸ ëª©ë¡ ìš°ì„  ì‚¬ìš©
        if coin is None:
            try:
                available = get_available_coins_and_intervals()
                coins = sorted(list({c for c, _ in available}))
                if not coins:
                    raise ValueError("âŒ DBì— ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                coin = coins[0]
            except Exception as e:
                logger.error(f"âŒ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                raise ValueError("âŒ ì½”ì¸ì„ ì§€ì •í•˜ê±°ë‚˜ DBì— ìº”ë“¤ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.") from e

        logger.info(f"ğŸš€ Absolute Zero ì‹œìŠ¤í…œ ì‹œì‘: {coin} {intervals_to_use}")
        logger.info(f"ğŸ—“ï¸ ìº”ë“¤ íˆìŠ¤í† ë¦¬ ì¼ìˆ˜: {AZ_CANDLE_DAYS}ì¼")
        logger.info(f"ğŸ” ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ: {'í™œì„±í™”' if ENABLE_VALIDATION else 'ë¹„í™œì„±í™”'}")

        if not NEW_PIPELINE_AVAILABLE:
            logger.error("âŒ ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {"error": "ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€"}

        # ì‹¤í–‰ ë©”íƒ€ë°ì´í„° ìƒì„±
        run_id = f"abs_zero_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        dataset_span = f"{datetime.now().strftime('%Y-%m-%d')}"

        # ì‹¤í–‰ ê¸°ë¡ ìƒì„±
        try:
            interval_str = intervals_to_use[0] if intervals_to_use else interval
            if len(intervals_to_use) > 1:
                interval_str = ','.join(intervals_to_use)
            create_run_record(run_id, "Absolute Zero System ì‹¤í–‰", coin=coin, interval=interval_str)
            logger.info(f"âœ… ì‹¤í–‰ ê¸°ë¡ ìƒì„± ì™„ë£Œ: {run_id} (coin={coin}, intervals={interval_str})")
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹¤í–‰ ê¸°ë¡ ìƒì„± ì‹¤íŒ¨: {e}")

        # ìº”ë“¤ ë°ì´í„° ë¡œë“œ
        logger.info(f"ğŸ“Š {coin} ìº”ë“¤ ë°ì´í„° ë¡œë“œ ì‹œì‘ (ëª©í‘œ: {AZ_CANDLE_DAYS}ì¼)...")
        all_candle_data = load_candle_data_for_coin(coin, intervals_to_use)

        if not all_candle_data:
            logger.error(f"âŒ {coin} ìº”ë“¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return {"error": f"{coin} ìº”ë“¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨"}

        # ë°ì´í„° ì¶©ë¶„ì„± ì²´í¬
        total_candles = sum(len(df) for df in all_candle_data.values())
        if total_candles == 0:
            logger.error(f"âŒ {coin}: ì‚¬ìš© ê°€ëŠ¥í•œ ìº”ë“¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {"error": f"{coin}: ìº”ë“¤ ë°ì´í„° ì—†ìŒ"}

        # í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        logger.info(f"ğŸ”„ {coin} í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘...")

        # íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
        orchestrator = IntegratedPipelineOrchestrator(session_id=session_id)

        # ê° ì¸í„°ë²Œë³„ë¡œ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_results = []
        for idx, interval in enumerate(intervals_to_use):
            try:
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“Š {coin}-{interval} í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...")
                logger.info(f"{'='*60}")

                candle_data = all_candle_data.get((coin, interval))
                if candle_data is None or candle_data.empty:
                    logger.warning(f"âš ï¸ {coin}-{interval} ìº”ë“¤ ë°ì´í„° ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue

                # 1-3ë‹¨ê³„ ì‹¤í–‰: ì „ëµìƒì„± â†’ Self-play â†’ ë ˆì§ë¼ìš°íŒ…
                result = orchestrator.run_partial_pipeline(coin, interval, candle_data)
                pipeline_results.append(result)

                # ğŸ†• ê²€ì¦ ì‹œìŠ¤í…œ ì‹¤í–‰
                if ENABLE_VALIDATION and validation_orchestrator:
                    logger.info(f"\nğŸ” {coin}-{interval} íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ê²€ì¦ ì‹œì‘...")

                    # 1. ì „ëµ ìƒì„± ê²€ì¦
                    if result.strategies_created > 0:
                        strategy_validation = validation_orchestrator.validate_pipeline_stage(
                            'strategy_generation',
                            {
                                'strategies': getattr(result, 'strategies', []),
                                'count': result.strategies_created,
                                'saved_count': result.strategies_created,
                                'coin': coin,
                                'interval': interval
                            },
                            coin, interval, pipeline_run_id=run_id
                        )
                        validation_results[f"{coin}_{interval}_strategy"] = strategy_validation

                        if not strategy_validation.is_successful():
                            logger.warning(f"âš ï¸ ì „ëµ ìƒì„± ê²€ì¦ ì´ìŠˆ: {strategy_validation.get_success_rate():.1%} ì„±ê³µë¥ ")
                            if strategy_validation.has_critical_issues():
                                logger.error(f"âŒ Critical ì´ìŠˆ ë°œê²¬!")

                    # 2. Self-play ê²€ì¦
                    if result.selfplay_result and result.selfplay_episodes > 0:
                        selfplay_validation = validation_orchestrator.validate_pipeline_stage(
                            'selfplay',
                            {
                                'episodes': result.selfplay_result.get('episodes', []),
                                'total_episodes': result.selfplay_episodes,
                                'evolved_strategies': result.selfplay_result.get('evolved_strategies', []),
                                'prediction_accuracy': result.selfplay_result.get('prediction_accuracy', 0),
                                'average_return': result.selfplay_result.get('average_return', 0),
                                'win_rate': result.selfplay_result.get('win_rate', 0),
                                'coin': coin,
                                'interval': interval
                            },
                            coin, interval, pipeline_run_id=run_id
                        )
                        validation_results[f"{coin}_{interval}_selfplay"] = selfplay_validation

                        if not selfplay_validation.is_successful():
                            logger.warning(f"âš ï¸ Self-play ê²€ì¦ ì´ìŠˆ: {selfplay_validation.get_success_rate():.1%} ì„±ê³µë¥ ")

                    # 3. ë¼ìš°íŒ… ê²€ì¦
                    if result.routing_results > 0:
                        routing_validation = validation_orchestrator.validate_pipeline_stage(
                            'routing',
                            {
                                'routing_results': getattr(result, 'routing_data', []),
                                'regime': result.regime_detected,
                                'selected_strategies': getattr(result, 'selected_strategies', []),
                                'backtest_results': getattr(result, 'backtest_results', {}),
                                'signal_scores': [result.signal_score],
                                'coin': coin,
                                'interval': interval
                            },
                            coin, interval, pipeline_run_id=run_id
                        )
                        validation_results[f"{coin}_{interval}_routing"] = routing_validation

                        if not routing_validation.is_successful():
                            logger.warning(f"âš ï¸ ë¼ìš°íŒ… ê²€ì¦ ì´ìŠˆ: {routing_validation.get_success_rate():.1%} ì„±ê³µë¥ ")

                logger.info(f"âœ… {coin}-{interval} íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ë ˆì§ë¼ìš°íŒ…ê¹Œì§€ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"âŒ {coin}-{interval} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ğŸ†• ì „ì²´ ê²€ì¦ ìš”ì•½
        if ENABLE_VALIDATION and validation_orchestrator and validation_results:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½ - {coin}")
            logger.info(f"{'='*60}")

            total_checks = 0
            total_passed = 0
            critical_issues = []

            for key, val_result in validation_results.items():
                total_checks += val_result.total_checks
                total_passed += val_result.passed_checks

                logger.info(f"  {key}: {val_result.overall_status.value} "
                          f"({val_result.get_success_rate():.1%} ì„±ê³µë¥ )")

                if val_result.has_critical_issues():
                    critical_issues.append(key)

            overall_rate = (total_passed / total_checks * 100) if total_checks > 0 else 0
            logger.info(f"\n  ì „ì²´ ì„±ê³µë¥ : {overall_rate:.1f}%")
            logger.info(f"  ì´ ê²€ì¦: {total_checks}ê°œ (âœ… {total_passed}ê°œ)")

            if critical_issues:
                logger.warning(f"  âš ï¸ Critical ì´ìŠˆ ë°œê²¬: {', '.join(critical_issues)}")

            # ê²€ì¦ í†µê³„ ì¡°íšŒ
            val_stats = validation_orchestrator.get_validation_stats()
            logger.info(f"\n  ëˆ„ì  ê²€ì¦ í†µê³„:")
            logger.info(f"    - ì´ ê²€ì¦: {val_stats['total_validations']}íšŒ")
            logger.info(f"    - ì„±ê³µ: {val_stats['successful_validations']}íšŒ")
            logger.info(f"    - ìë™ ë³µêµ¬: {val_stats['auto_fixed']}íšŒ")

        # ê¸€ë¡œë²Œ ì „ëµ ìƒì„± (í•„ìš”ì‹œ)
        # ... (ê¸°ì¡´ ì½”ë“œ)

        execution_time = (datetime.now() - start_time).total_seconds()

        logger.info(f"\nğŸ‰ Absolute Zero ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
        logger.info(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")

        return {
            "status": "success",
            "coin": coin,
            "intervals": intervals_to_use,
            "pipeline_results": len(pipeline_results),
            "execution_time": execution_time,
            "validation_enabled": ENABLE_VALIDATION,
            "validation_summary": {
                "total_validations": len(validation_results),
                "overall_success_rate": overall_rate if validation_results else 100.0,
                "critical_issues": len(critical_issues) if validation_results else 0
            } if ENABLE_VALIDATION else None
        }

    except Exception as e:
        logger.error(f"âŒ Absolute Zero ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"error": str(e)}

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ëª¨ë“  ì½”ì¸/ì¸í„°ë²Œ ì¡°í•©ì— ëŒ€í•´ ì‹¤í–‰"""
    try:
        _configure_logging()
        logger.info("ğŸš€ Absolute Zero ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ ì‹œì‘ (ê²€ì¦ ì‹œìŠ¤í…œ í™œì„±í™”)")

        # ì €ì¥ ê²½ë¡œ ë° DB íŒŒì¼ ì‚¬ì „ ë³´ì¥
        ensure_storage_ready()

        # ğŸ†• ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        try:
            logger.info("ğŸ”§ ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
            setup_database_tables()
            create_learning_results_tables()

            # í•„ìˆ˜ í…Œì´ë¸” ë³´ê°• ìƒì„± (ë°©ì–´ì )
            try:
                create_strategies_table()
            except Exception as se:
                logger.warning(f"âš ï¸ strategies ë³´ê°• ìƒì„± ì‹¤íŒ¨(ë¬´ì‹œ ê°€ëŠ¥): {se}")

            # ì¸ë±ìŠ¤ ìƒì„± (í•œ ë²ˆë§Œ)
            try:
                logger.info("ğŸ”§ ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘...")
                ensure_indexes()
                logger.info("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            except Exception as ie:
                logger.warning(f"âš ï¸ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨(ë¬´ì‹œ ê°€ëŠ¥): {ie}")

            logger.info("âœ… ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return {"error": f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"}

        # ğŸ†• ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì¸/ì¸í„°ë²Œ ì¡°í•© ê°€ì ¸ì˜¤ê¸°
        coin_interval_combinations = get_available_coins_and_intervals()
        logger.info(f"ğŸ“Š ë°œê²¬ëœ ì½”ì¸/ì¸í„°ë²Œ ì¡°í•©: {len(coin_interval_combinations)}ê°œ")

        # ì½”ì¸ë³„ ì „ì²´ ì¸í„°ë²Œë¡œ ê·¸ë£¹í•‘
        coin_to_intervals: Dict[str, List[str]] = {}
        for c, itv in coin_interval_combinations:
            coin_to_intervals.setdefault(c, [])
            if itv not in coin_to_intervals[c]:
                coin_to_intervals[c].append(itv)

        # ì¸í„°ë²Œ ì •ë ¬
        def sort_intervals_for_main(interval_list):
            """ì¸í„°ë²Œì„ ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬"""
            def get_order_in_minutes(iv):
                iv_lower = iv.lower().strip()
                try:
                    if iv_lower.endswith('m'):
                        minutes = int(iv_lower[:-1])
                        return minutes
                    elif iv_lower.endswith('h'):
                        hours = int(iv_lower[:-1])
                        return hours * 60
                    elif iv_lower.endswith('d'):
                        days = int(iv_lower[:-1])
                        return days * 1440
                    else:
                        return 999999
                except (ValueError, AttributeError):
                    return 999999

            return sorted(interval_list, key=lambda x: (get_order_in_minutes(x), x))

        for c in coin_to_intervals:
            try:
                coin_to_intervals[c] = sort_intervals_for_main(coin_to_intervals[c])
            except Exception:
                pass

        if not coin_interval_combinations:
            logger.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì¸/ì¸í„°ë²Œ ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
            logger.error("âŒ ìº”ë“¤ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•˜ì„¸ìš”: python candles_collector.py")
            return {"error": "no coin/interval combinations found", "message": "ìº”ë“¤ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•˜ì„¸ìš”"}

        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²« ë²ˆì§¸ ì½”ì¸ë§Œ ì‹¤í–‰ (ì „ì²´ ì‹¤í–‰ ì›í•˜ë©´ ì´ ë¶€ë¶„ ì œê±°)
        logger.info("âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²« ë²ˆì§¸ ì½”ì¸ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        first_coin = list(coin_to_intervals.keys())[0] if coin_to_intervals else None
        if first_coin:
            coin_to_intervals = {first_coin: coin_to_intervals[first_coin]}

        # ê° ì¡°í•©ì— ëŒ€í•´ ì‹¤í–‰
        results = []
        failed_runs = []

        for coin, intervals in coin_to_intervals.items():
            try:
                logger.info(f"\nğŸª™ {coin} {', '.join(intervals)} ì²˜ë¦¬ ì‹œì‘")
                result = run_absolute_zero(coin, interval=intervals[0], n_strategies=200, intervals=intervals)
                results.append(result)

                if result.get("status") == "success":
                    logger.info(f"âœ… {coin} ì²˜ë¦¬ ì„±ê³µ")
                else:
                    logger.error(f"âŒ {coin} ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('message', 'Unknown error')}")
                    failed_runs.append(f"{coin}_{','.join(intervals)}")

            except Exception as e:
                logger.error(f"âŒ {coin} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                failed_runs.append(f"{coin}_{','.join(intervals)}")
                continue

        # ê²°ê³¼ ìš”ì•½
        successful_runs = len([r for r in results if r.get("status") == "success"])
        total_runs = len(coin_to_intervals)

        logger.info(f"\nğŸ‰ Absolute Zero ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ì´ ì‹¤í–‰: {total_runs}ê°œ, ì„±ê³µ: {successful_runs}ê°œ, ì‹¤íŒ¨: {len(failed_runs)}ê°œ")

        if failed_runs:
            logger.warning(f"âš ï¸ ì‹¤íŒ¨í•œ ì¡°í•©: {failed_runs}")

        # ğŸ†• ê²€ì¦ ì‹œìŠ¤í…œ ìµœì¢… ë¦¬í¬íŠ¸
        if ENABLE_VALIDATION and validation_orchestrator:
            logger.info("\nğŸ“Š ê²€ì¦ ì‹œìŠ¤í…œ ìµœì¢… ë¦¬í¬íŠ¸:")
            final_report = validation_orchestrator.generate_report()

            if 'total_validations' in final_report:
                logger.info(f"  - ì˜¤ëŠ˜ ì´ ê²€ì¦: {final_report['total_validations']}íšŒ")
                logger.info(f"  - í‰ê·  ì„±ê³µë¥ : {final_report.get('average_success_rate', 0):.1%}")
                logger.info(f"  - Critical ì´ìŠˆ: {final_report.get('critical_issues', 0)}ê±´")
                logger.info(f"  - ìë™ ë³µêµ¬: {final_report.get('auto_fixed_issues', 0)}ê±´")

            # ì‹ ë¢°ë„ í˜„í™©
            trust_stats = validation_orchestrator.trust_manager.get_global_stats()
            logger.info(f"\n  ì‹œìŠ¤í…œ ê±´ê°•ë„: {trust_stats.get('system_health', 'Unknown')}")

            if 'problematic_components' in trust_stats and trust_stats['problematic_components']:
                logger.warning(f"  âš ï¸ ë¬¸ì œ ì»´í¬ë„ŒíŠ¸: {trust_stats['problematic_components']}")

        return {
            "status": "success",
            "total_runs": total_runs,
            "successful_runs": successful_runs,
            "failed_runs": len(failed_runs)
        }

    except Exception as e:
        logger.error(f"âŒ ë©”ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"error": str(e)}

if __name__ == "__main__":
    main()