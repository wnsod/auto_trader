"""
Phase 4 í…ŒìŠ¤íŠ¸: ml_runner.py ì˜ˆì¸¡ í”¼ë“œë°± ëª¨ë“ˆ ê²€ì¦

ì‹¤í–‰ ë°©ë²•:
    docker exec -it auto_trader_coin bash
    cd /workspace
    python rl_pipeline/tests/test_phase4_ml_runner.py
"""

import sys
import os
import logging
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
workspace_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(workspace_root))

from rl_pipeline.hybrid.ml_runner import (
    PredictionFeedbackRunner,
    WeightedEpisodeData,
    PredictionRecord,
    process_prediction_feedback,
    PREDICTION_ERROR_THRESHOLD_LOW,
    PREDICTION_ERROR_THRESHOLD_HIGH,
    PREDICTION_WEIGHT_HIGH,
    PREDICTION_WEIGHT_LOW,
    PREDICTION_WEIGHT_DEFAULT
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_prediction_error_calculation():
    """ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ 1: ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚°")
    logger.info("=" * 60)
    
    try:
        runner = PredictionFeedbackRunner()
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        test_cases = [
            {
                "name": "ì •í™•í•œ ì˜ˆì¸¡ (ë°©í–¥/í¬ê¸° ëª¨ë‘ ë§ìŒ)",
                "predicted_target": 0.01,  # 1%
                "actual_move_pct": 0.01,
                "predicted_dir": 1,
                "actual_dir": 1,
                "expected_low": True
            },
            {
                "name": "ë°©í–¥ ë§ìŒ, í¬ê¸° ë‹¤ë¦„",
                "predicted_target": 0.02,  # 2%
                "actual_move_pct": 0.01,  # 1%
                "predicted_dir": 1,
                "actual_dir": 1,
                "expected_low": None  # í¬ê¸° ì˜¤ì°¨ëŠ” ì¤‘ê°„
            },
            {
                "name": "ë°©í–¥ í‹€ë¦¼",
                "predicted_target": 0.01,
                "actual_move_pct": -0.01,
                "predicted_dir": 1,
                "actual_dir": -1,
                "expected_low": False  # í° ì˜¤ì°¨
            }
        ]
        
        for case in test_cases:
            error = runner.calculate_prediction_error(
                case["predicted_target"],
                case["actual_move_pct"],
                case["predicted_dir"],
                case["actual_dir"]
            )
            
            logger.info(f"  {case['name']}: error={error:.4f}")
            
            if case["expected_low"] is not None:
                if case["expected_low"]:
                    if error > PREDICTION_ERROR_THRESHOLD_LOW:
                        logger.warning(f"  âš ï¸ ì˜ˆìƒ: ë‚®ì€ ì˜¤ì°¨, ì‹¤ì œ: {error:.4f}")
                else:
                    if error < PREDICTION_ERROR_THRESHOLD_HIGH:
                        logger.warning(f"  âš ï¸ ì˜ˆìƒ: ë†’ì€ ì˜¤ì°¨, ì‹¤ì œ: {error:.4f}")
        
        logger.info("âœ… ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚° í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_feedback_weights():
    """ê°€ì¤‘ì¹˜ ë¶€ì—¬ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ 2: ê°€ì¤‘ì¹˜ ë¶€ì—¬")
    logger.info("=" * 60)
    
    try:
        runner = PredictionFeedbackRunner()
        
        # í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ë°ì´í„°
        episodes_data = [
            {'state': [1.0], 'action': 1, 'reward': 0.5},
            {'state': [1.0], 'action': 1, 'reward': 0.3},
            {'state': [1.0], 'action': 1, 'reward': -0.2},
        ]
        
        # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ì˜¤ì°¨
        prediction_errors = [
            PREDICTION_ERROR_THRESHOLD_LOW * 0.5,  # ë‚®ì€ ì˜¤ì°¨ â†’ ë†’ì€ ê°€ì¤‘ì¹˜
            PREDICTION_ERROR_THRESHOLD_LOW * 1.5,  # ì¤‘ê°„ ì˜¤ì°¨ â†’ ê¸°ë³¸ ê°€ì¤‘ì¹˜
            PREDICTION_ERROR_THRESHOLD_HIGH * 1.5,  # ë†’ì€ ì˜¤ì°¨ â†’ ë‚®ì€ ê°€ì¤‘ì¹˜
        ]
        
        weighted_episodes = runner.apply_feedback_weights(episodes_data, prediction_errors)
        
        if len(weighted_episodes) != len(episodes_data):
            logger.error(f"âŒ ê°€ì¤‘ì¹˜ ë¶€ì—¬ëœ ì—í”¼ì†Œë“œ ìˆ˜ ë¶ˆì¼ì¹˜: {len(weighted_episodes)} != {len(episodes_data)}")
            return False
        
        logger.info("  ê°€ì¤‘ì¹˜ ë¶€ì—¬ ê²°ê³¼:")
        for i, episode in enumerate(weighted_episodes):
            weight = episode.get('prediction_weight', 0.0)
            error = episode.get('prediction_error', 0.0)
            logger.info(f"    ì—í”¼ì†Œë“œ {i+1}: weight={weight:.2f}, error={error:.4f}")
            
            # ê°€ì¤‘ì¹˜ ê²€ì¦
            if error < PREDICTION_ERROR_THRESHOLD_LOW:
                if weight != PREDICTION_WEIGHT_HIGH:
                    logger.error(f"âŒ ë‚®ì€ ì˜¤ì°¨ì¸ë° ê°€ì¤‘ì¹˜ê°€ HIGHê°€ ì•„ë‹˜: {weight}")
                    return False
            elif error > PREDICTION_ERROR_THRESHOLD_HIGH:
                if weight != PREDICTION_WEIGHT_LOW:
                    logger.error(f"âŒ ë†’ì€ ì˜¤ì°¨ì¸ë° ê°€ì¤‘ì¹˜ê°€ LOWê°€ ì•„ë‹˜: {weight}")
                    return False
        
        logger.info("âœ… ê°€ì¤‘ì¹˜ ë¶€ì—¬ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_convert_to_training_data():
    """í•™ìŠµ ë°ì´í„° ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ 3: í•™ìŠµ ë°ì´í„° ë³€í™˜")
    logger.info("=" * 60)
    
    try:
        runner = PredictionFeedbackRunner()
        
        # í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ë°ì´í„°
        weighted_episodes = [
            {
                'state': [1.0, 2.0, 3.0],
                'action': 1,
                'reward': 0.5,
                'prediction_weight': 1.5,
                'prediction_error': 0.001
            },
            {
                'state': [2.0, 3.0, 4.0],
                'action': -1,
                'reward': -0.2,
                'prediction_weight': 0.3,
                'prediction_error': 0.025
            },
            {
                'state': [3.0, 4.0, 5.0],
                'action': 0,
                'reward': 0.1,
                'prediction_weight': 1.0,
                'prediction_error': 0.01
            }
        ]
        
        training_data = runner.convert_to_training_data(weighted_episodes)
        
        if training_data is None:
            logger.error("âŒ í•™ìŠµ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨")
            return False
        
        logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ë³€í™˜ ì„±ê³µ:")
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ê¸¸ì´ í™•ì¸
        states_len = len(training_data.states) if hasattr(training_data.states, '__len__') else 0
        actions_len = len(training_data.actions) if hasattr(training_data.actions, '__len__') else 0
        rewards_len = len(training_data.rewards) if hasattr(training_data.rewards, '__len__') else 0
        weights_len = len(training_data.weights) if hasattr(training_data.weights, '__len__') else 0
        errors_len = len(training_data.prediction_errors) if hasattr(training_data.prediction_errors, '__len__') else 0
        
        logger.info(f"  - ìƒíƒœ ìƒ˜í”Œ ìˆ˜: {states_len}")
        logger.info(f"  - í–‰ë™ ìƒ˜í”Œ ìˆ˜: {actions_len}")
        logger.info(f"  - ë³´ìƒ ìƒ˜í”Œ ìˆ˜: {rewards_len}")
        logger.info(f"  - ê°€ì¤‘ì¹˜ ìƒ˜í”Œ ìˆ˜: {weights_len}")
        logger.info(f"  - ì˜ˆì¸¡ ì˜¤ì°¨ ìƒ˜í”Œ ìˆ˜: {errors_len}")
        
        # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
        if not (states_len == actions_len == rewards_len == weights_len == errors_len):
            logger.error(f"âŒ ë°ì´í„° ê¸¸ì´ ë¶ˆì¼ì¹˜: states={states_len}, actions={actions_len}, rewards={rewards_len}, weights={weights_len}, errors={errors_len}")
            return False
        
        if states_len == 0:
            logger.error("âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return False
        
        # ê°€ì¤‘ì¹˜ ë²”ìœ„ í™•ì¸
        weights_array = np.array(training_data.weights) if not isinstance(training_data.weights, np.ndarray) else training_data.weights
        if np.any(weights_array < 0):
            logger.error("âŒ ìŒìˆ˜ ê°€ì¤‘ì¹˜ ë°œê²¬")
            return False
        
        errors_array = np.array(training_data.prediction_errors) if not isinstance(training_data.prediction_errors, np.ndarray) else training_data.prediction_errors
        
        logger.info(f"  - ê°€ì¤‘ì¹˜ ë²”ìœ„: {np.min(weights_array):.2f} ~ {np.max(weights_array):.2f}")
        logger.info(f"  - ì˜ˆì¸¡ ì˜¤ì°¨ ë²”ìœ„: {np.min(errors_array):.4f} ~ {np.max(errors_array):.4f}")
        
        logger.info("âœ… í•™ìŠµ ë°ì´í„° ë³€í™˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_integration():
    """í†µí•© í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ 4: í†µí•© í…ŒìŠ¤íŠ¸ (ì˜ˆì¸¡ ê²€ì¦ â†’ ì˜¤ì°¨ ê³„ì‚° â†’ ê°€ì¤‘ì¹˜ ë¶€ì—¬ â†’ ë³€í™˜)")
    logger.info("=" * 60)
    
    try:
        # ì˜¨ë¼ì¸ Self-Play ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
        online_results = {
            'status': 'success',
            'segment_results': [
                [
                    type('Segment', (), {
                        'strategy_id': 'test_strategy_1',
                        'profit': 100.0,
                        'trades_count': 5
                    })()
                ]
            ]
        }
        
        # ì˜ˆì¸¡ ê¸°ë¡ ì‹œë®¬ë ˆì´ì…˜
        predictions = [
            {
                'timestamp': 1000,
                'predicted_dir': 1,
                'predicted_target': 0.01,
                'predicted_horizon': 10,
                'predicted_conf': 0.8,
                'actual_dir': 1,
                'actual_move_pct': 0.012,
                'actual_horizon': 8
            },
            {
                'timestamp': 2000,
                'predicted_dir': -1,
                'predicted_target': -0.015,
                'predicted_horizon': 12,
                'predicted_conf': 0.7,
                'actual_dir': 1,  # ë°©í–¥ í‹€ë¦¼
                'actual_move_pct': 0.005,
                'actual_horizon': 10
            },
            {
                'timestamp': 3000,
                'predicted_dir': 1,
                'predicted_target': 0.02,
                'predicted_horizon': 15,
                'predicted_conf': 0.6,
                'actual_dir': 1,
                'actual_move_pct': 0.018,
                'actual_horizon': 14
            }
        ]
        
        # í†µí•© ì²˜ë¦¬
        training_data = process_prediction_feedback(online_results, predictions)
        
        if training_data is None:
            logger.error("âŒ í†µí•© ì²˜ë¦¬ ì‹¤íŒ¨")
            return False
        
        # ë°ì´í„° ê²€ì¦
        if len(training_data.states) == 0:
            logger.error("âŒ ìƒíƒœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return False
        
        logger.info(f"âœ… í†µí•© ì²˜ë¦¬ ì„±ê³µ:")
        logger.info(f"  - ìƒ˜í”Œ ìˆ˜: {len(training_data.states)}")
        
        # NumPy ë°°ì—´ì¸ì§€ í™•ì¸
        if isinstance(training_data.states, np.ndarray):
            logger.info(f"  - ìƒíƒœ ì°¨ì›: {training_data.states.shape if training_data.states.size > 0 else 'N/A'}")
        else:
            logger.info(f"  - ìƒíƒœ íƒ€ì…: {type(training_data.states)}")
        
        if len(training_data.weights) > 0:
            logger.info(f"  - ê°€ì¤‘ì¹˜ í‰ê· : {np.mean(training_data.weights):.3f}")
            logger.info(f"  - ê°€ì¤‘ì¹˜ ë²”ìœ„: {np.min(training_data.weights):.2f} ~ {np.max(training_data.weights):.2f}")
        
        if len(training_data.prediction_errors) > 0:
            logger.info(f"  - ì˜ˆì¸¡ ì˜¤ì°¨ í‰ê· : {np.mean(training_data.prediction_errors):.4f}")
        
        # ê°€ì¤‘ì¹˜ ë¶„í¬ í™•ì¸
        if len(training_data.weights) > 0:
            high_weight_count = np.sum(training_data.weights == PREDICTION_WEIGHT_HIGH)
            default_weight_count = np.sum(training_data.weights == PREDICTION_WEIGHT_DEFAULT)
            low_weight_count = np.sum(training_data.weights == PREDICTION_WEIGHT_LOW)
            
            logger.info(f"  - ê°€ì¤‘ì¹˜ ë¶„í¬: HIGH={high_weight_count}, DEFAULT={default_weight_count}, LOW={low_weight_count}")
        
        logger.info("âœ… í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("=" * 60)
    logger.info("Phase 4: ml_runner.py ì˜ˆì¸¡ í”¼ë“œë°± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    tests = [
        ("ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚°", test_prediction_error_calculation),
        ("ê°€ì¤‘ì¹˜ ë¶€ì—¬", test_feedback_weights),
        ("í•™ìŠµ ë°ì´í„° ë³€í™˜", test_convert_to_training_data),
        ("í†µí•© í…ŒìŠ¤íŠ¸", test_integration),
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\nâ–¶ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
        try:
            result = test_func()
            results.append((test_name, result))
            if result:
                logger.info(f"âœ… {test_name} í†µê³¼\n")
            else:
                logger.error(f"âŒ {test_name} ì‹¤íŒ¨\n")
        except Exception as e:
            logger.error(f"âŒ {test_name} ì˜ˆì™¸ ë°œìƒ: {e}")
            results.append((test_name, False))
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"{status}: {test_name}")
    
    logger.info(f"\nì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed == total:
        logger.info("=" * 60)
        logger.info("ğŸ‰ Phase 4 í…ŒìŠ¤íŠ¸ ëª¨ë‘ í†µê³¼!")
        logger.info("=" * 60)
        return True
    else:
        logger.error("=" * 60)
        logger.error("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        logger.error("=" * 60)
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

