import sys
import os
sys.path.insert(0, "/workspace")

import sqlite3
import asyncio
import aiohttp
import pandas as pd
import os
import time
from datetime import datetime, timedelta, timezone
from threading import Thread
from queue import Queue
from collections import defaultdict

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì • (envì—ì„œ ê°€ì ¸ì˜¤ê¸° - í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
from rl_pipeline.core.env import config
DB_PATH = os.getenv('RL_DB_PATH', config.RL_DB)

# ì¸í„°ë²Œ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ í•„ìˆ˜)
env_intervals = os.getenv('CANDLE_INTERVALS')
if not env_intervals:
    print("âŒ ì˜¤ë¥˜: CANDLE_INTERVALS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    INTERVALS = []
else:
    INTERVALS = [i.strip() for i in env_intervals.split(',')]

# ì¸í„°ë²Œë³„ ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ í•„ìˆ˜ - ë™ì  ìƒì„±)
INTERVAL_DAYS_BACK = {}
for interval in INTERVALS:
    env_key = f"DAYS_BACK_{interval.upper()}"
    days_back = os.getenv(env_key)
    
    if days_back:
        INTERVAL_DAYS_BACK[interval] = int(days_back)
    else:
        print(f"âš ï¸ ê²½ê³ : {interval}ì— ëŒ€í•œ ìˆ˜ì§‘ ê¸°ê°„({env_key})ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ê¸°ë³¸ê°’ 90ì¼ ì ìš©)")
        INTERVAL_DAYS_BACK[interval] = 90  # ìµœì†Œí•œì˜ ì•ˆì „ì¥ì¹˜

UTC = timezone.utc  # ëª¨ë“  ì‹œê°„ ê¸°ì¤€ì„ UTCë¡œ í†µì¼

# ğŸ§ª ì¢…ëª© ëª©ë¡ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ TARGET_COINS/TARGET_SYMBOLSê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©)
env_target_symbols = os.getenv('TARGET_COINS', '')
IS_ALL_TARGET = False  # ì „ì²´ ìˆ˜ì§‘ í”Œë˜ê·¸

if env_target_symbols.upper() == 'ALL':
    TEST_SYMBOLS = None
    IS_ALL_TARGET = True
    print("ğŸ¯ íƒ€ê²Ÿ ì„¤ì •: ì „ì²´ ì¢…ëª© ìˆ˜ì§‘ ëª¨ë“œ (ALL)")
elif env_target_symbols:
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì¢…ëª© ëª©ë¡ íŒŒì‹± (ì‰¼í‘œ êµ¬ë¶„)
    TEST_SYMBOLS = [c.strip() for c in env_target_symbols.split(',')]
    print(f"ğŸ¯ ì„¤ì •ëœ íƒ€ê²Ÿ ì¢…ëª©: {len(TEST_SYMBOLS)}ê°œ ({TEST_SYMBOLS[:5]}...)")
else:
    # ê¸°ë³¸ê°’ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ - ì„¤ì • íŒŒì¼ í•„ìˆ˜)
    TEST_SYMBOLS = []
    print("âš ï¸ ê²½ê³ : TARGET_COINS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ğŸš€ ìµœì í™”ëœ ë™ì‹œì„± ì œì–´ ì„¤ì •
MAX_CONCURRENT_REQUESTS = 50  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì¦ê°€
REQUEST_TIMEOUT = 15  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
RETRY_ATTEMPTS = 2  # ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 0.5  # ì¬ì‹œë„ ê°„ê²©
RATE_LIMIT_DELAY = 1.0  # 429 ì—ëŸ¬ ì‹œ ëŒ€ê¸° ì‹œê°„
MAX_RATE_LIMIT_RETRIES = 3  # 429 ì—ëŸ¬ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

# ğŸš€ ìŠ¤ë§ˆíŠ¸ í•„ë“œ ê°ì§€ ì„¤ì • (ê±°ë˜ì†Œë³„ ë‹¤ë¥¸ ì»¬ëŸ¼ëª… ëŒ€ì‘)
FIELD_CANDIDATES = {
    'open': ['opening_price', 'open', 'o', 'price_open', 'high'], # highê°€ ì˜ëª» ë“¤ì–´ê°€ì§€ ì•Šë„ë¡ ìˆœì„œ ì£¼ì˜ (ì¼ë°˜ì ì¸ ìš°ì„ ìˆœìœ„)
    'high': ['high_price', 'high', 'h', 'price_high'],
    'low': ['low_price', 'low', 'l', 'price_low'],
    'close': ['trade_price', 'close', 'c', 'price_close', 'price'],
    'volume': ['candle_acc_trade_price', 'volume', 'v', 'vol', 'acc_trade_price'],
    'timestamp': ['candle_date_time_utc', 'timestamp_utc', 'date_utc', 'time_utc']
}

def get_value_from_candidates(data_dict, field_name, default=0.0):
    """ì—¬ëŸ¬ í›„ë³´ í‚¤ ì¤‘ ì¡´ì¬í•˜ëŠ” ê°’ì„ ì°¾ì•„ ë°˜í™˜"""
    for candidate in FIELD_CANDIDATES.get(field_name, []):
        if candidate in data_dict:
            return float(data_dict[candidate])
    return default

def get_timestamp_from_candidates(data_dict):
    """UTC ì‹œê°„ í•„ë“œë¥¼ ì°¾ì•„ Unix Timestampë¡œ ë³€í™˜ (UTC ê¸°ì¤€ í†µì¼)"""
    try:
        # UTC ì‹œê°„ ì‹œë„
        for key in FIELD_CANDIDATES['timestamp']:
            if key in data_dict:
                ts_str = data_dict[key]
                if isinstance(ts_str, str):
                    return int(datetime.strptime(ts_str, '%Y-%m-%dT%H:%M:%S').replace(tzinfo=UTC).timestamp()), ts_str
                    
    except Exception:
        pass
    return None, None
REQUEST_TIMEOUT = 15  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
RETRY_ATTEMPTS = 2  # ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 0.5  # ì¬ì‹œë„ ê°„ê²©
RATE_LIMIT_DELAY = 1.0  # 429 ì—ëŸ¬ ì‹œ ëŒ€ê¸° ì‹œê°„
MAX_RATE_LIMIT_RETRIES = 3  # 429 ì—ëŸ¬ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

# ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
save_queue = asyncio.Queue(maxsize=3000)  # í í¬ê¸° ì¦ê°€

# 429 rate limit ë¡œê·¸ ìš”ì•½ìš©
rate_limit_counter = defaultdict(int)
rate_limit_last_print = defaultdict(float)

# ğŸš€ ì‹¤íŒ¨í•œ ìš”ì²­ ì¶”ì ìš© (ê°„ì†Œí™”)
failed_requests = set()  # (coin, interval) íŠœí”Œë¡œ ì €ì¥
failed_requests_lock = asyncio.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½

# ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
class PerformanceMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        self.total_candles = 0
        self.last_progress_time = time.time()
        self.progress_interval = 10  # 10ì´ˆë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
        
    def log_request(self, success: bool, candle_count: int = 0):
        self.request_count += 1
        if success:
            self.success_count += 1
            self.total_candles += candle_count
        else:
            self.error_count += 1
        
        # ì§„í–‰ë¥  ì¶œë ¥
        current_time = time.time()
        if current_time - self.last_progress_time >= self.progress_interval:
            self._print_progress()
            self.last_progress_time = current_time
    
    def _print_progress(self):
        elapsed = time.time() - self.start_time
        if elapsed > 0:
            rps = self.request_count / elapsed
            cps = self.total_candles / elapsed
            success_rate = self.success_count / self.request_count if self.request_count > 0 else 0
            print(f"ğŸ“ˆ ì§„í–‰ë¥ : {self.request_count:,} ìš”ì²­, {self.total_candles:,} ìº”ë“¤, "
                  f"{rps:.1f} req/s, {cps:.0f} ìº”ë“¤/s, ì„±ê³µë¥ : {success_rate:.1%}")
    
    def get_stats(self):
        elapsed = time.time() - self.start_time
        return {
            'elapsed_time': elapsed,
            'requests_per_second': self.request_count / elapsed if elapsed > 0 else 0,
            'success_rate': self.success_count / self.request_count if self.request_count > 0 else 0,
            'total_candles': self.total_candles,
            'candles_per_second': self.total_candles / elapsed if elapsed > 0 else 0
        }

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
performance_monitor = PerformanceMonitor()

# ğŸš€ Rate limitingì„ ìœ„í•œ ë”œë ˆì´ ê´€ë¦¬
class RateLimiter:
    def __init__(self):
        self.last_request_time = 0
        self.min_interval = 0.02  # 20ms ê°„ê²© (ì´ˆë‹¹ 50 ìš”ì²­) - ìµœì í™”ë¨
        self.rate_limit_until = 0
    
    async def wait_if_needed(self):
        current_time = time.time()
        
        # Rate limit ëŒ€ê¸°
        if current_time < self.rate_limit_until:
            wait_time = self.rate_limit_until - current_time
            print(f"â³ Rate limit ëŒ€ê¸°: {wait_time:.1f}ì´ˆ")
            await asyncio.sleep(wait_time)
            current_time = time.time()
        
        # ìµœì†Œ ê°„ê²© ëŒ€ê¸°
        time_since_last = current_time - self.last_request_time
        if time_since_last < self.min_interval:
            await asyncio.sleep(self.min_interval - time_since_last)
        
        self.last_request_time = time.time()
    
    def set_rate_limit(self, retry_after=None):
        """429 ì—ëŸ¬ ì‹œ rate limit ì„¤ì •"""
        if retry_after:
            self.rate_limit_until = time.time() + retry_after
        else:
            self.rate_limit_until = time.time() + RATE_LIMIT_DELAY

# ì „ì—­ rate limiter
rate_limiter = RateLimiter()

# í…Œì´ë¸” ìƒì„±
def create_table():
    # ê¸°ì¡´ DB íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
    if os.path.exists(DB_PATH):
        os.remove(DB_PATH)
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„± (ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ)
    cursor.execute("""
    CREATE TABLE candles (
        -- ğŸ·ï¸ ê¸°ë³¸ ì‹ë³„ì (3ê°œ)
        symbol TEXT,
        interval TEXT,
        timestamp INTEGER,
        -- ğŸ’° ê¸°ë³¸ OHLCV (4ê°œ)
        open REAL,
        high REAL,
        low REAL,
        close REAL,
        volume REAL,
        -- ğŸ“‰ í•µì‹¬ ì˜¤ì‹¤ë ˆì´í„° (2ê°œ)
        rsi REAL,
        mfi REAL,
        -- ğŸ“Š í•µì‹¬ íŠ¸ë Œë“œ (2ê°œ)
        macd REAL,
        macd_signal REAL,
        -- ğŸŒ í•µì‹¬ ë³¼ë¦°ì €ë°´ë“œ (5ê°œ)
        bb_upper REAL,
        bb_middle REAL,
        bb_lower REAL,
        bb_position REAL,
        bb_width REAL,
        -- ğŸ“ˆ í•µì‹¬ ì¶”ì„¸/ë³€ë™ì„± (3ê°œ)
        atr REAL,
        ma20 REAL,
        adx REAL,
        -- ğŸ“Š í•µì‹¬ ê±°ë˜ëŸ‰ (1ê°œ)
        volume_ratio REAL,
        -- âš ï¸ í•µì‹¬ ë¦¬ìŠ¤í¬ (1ê°œ)
        risk_score REAL,
        -- ğŸ§  í•µì‹¬ íŒŒë™ (2ê°œ)
        wave_phase TEXT,
        confidence REAL,
        -- ğŸ”„ í•µì‹¬ íŒŒë™ ë¶„ì„ (3ê°œ)
        zigzag_direction REAL,
        zigzag_pivot_price REAL,
        wave_progress REAL,
        -- ğŸ¯ í•µì‹¬ íŒ¨í„´ ë¶„ì„ (2ê°œ)
        pattern_type TEXT,
        pattern_confidence REAL,
        -- ğŸ§  í•µì‹¬ í†µí•© ë¶„ì„ (3ê°œ)
        volatility_level TEXT,
        risk_level TEXT,
        integrated_direction TEXT,
        -- ğŸš€ êµ¬ì¡° ì ìˆ˜ (1ê°œ)
        structure_score REAL,
        -- ğŸš€ ì‹¬ë¦¬ë„ ë¶„ì„ (2ê°œ)
        sentiment REAL,
        sentiment_label TEXT,
        PRIMARY KEY (symbol, interval, timestamp)
    )
    """)
    
    # ğŸš€ ì¸ë±ìŠ¤ ì¶”ê°€ë¡œ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_interval ON candles(symbol, interval)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON candles(timestamp)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_timestamp ON candles(symbol, timestamp)')
    
    conn.commit()
    conn.close()

# ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ (ë¹„ë™ê¸° ë²„ì „) - ìµœê·¼ 100ê°œë§Œ ìœ ì§€
async def candle_saver_worker(save_queue):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ì €ì¥ ì›Œì»¤ - ìµœê·¼ 100ê°œë§Œ ìœ ì§€"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    total_saved = 0
    batch_data = []
    batch_size = 1000  # ë°°ì¹˜ í¬ê¸° ì¦ê°€

    while True:
        try:
            item = await save_queue.get()
            if item is None:
                # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
                if batch_data:
                    cursor.executemany('''
                        INSERT OR REPLACE INTO candles (
                            symbol, interval, timestamp, open, high, low, close, volume
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    ''', batch_data)
                    conn.commit()
                    total_saved += len(batch_data)
                print(f"ğŸ’¾ ì´ ì €ì¥ëœ ìº”ë“¤: {total_saved:,}ê°œ")
                break

            symbol, interval, candles = item

            # ë°°ì¹˜ ë°ì´í„° ì¶”ê°€
            for c in candles:
                # ì´ë¯¸ fetch_candlesì—ì„œ UTC ì²˜ë¦¬ ë° ì¤‘ë³µ ì œê±°ë¨
                # c['timestamp']ëŠ” ISO í¬ë§· ë¬¸ìì—´ì´ê±°ë‚˜ ì´ë¯¸ ì²˜ë¦¬ëœ ê°’ì¼ ìˆ˜ ìˆìŒ.
                # fetch_candlesì—ì„œ ë°˜í™˜í•  ë•Œ timestampë¥¼ Unix timestamp integerë¡œ ë°˜í™˜í•˜ë©´ ë” ê¹”ë”í•¨.
                # í˜„ì¬ ë¡œì§ì€ fetch_candlesì—ì„œ list of dict ë°˜í™˜.
                
                # fetch_candles ìˆ˜ì •ë³¸ì— ë§ì¶°ì„œ ì²˜ë¦¬:
                # c['timestamp']ê°€ ì–´ë–¤ í˜•íƒœì¸ì§€ í™•ì¸ í•„ìš”.
                # fetch_candles ìˆ˜ì • ì½”ë“œì—ì„œëŠ” 'timestamp' í‚¤ì— dt.isoformat() ë˜ëŠ” ì›ë³¸ ë¬¸ìì—´ì„ ë„£ì—ˆìŒ.
                # í•˜ì§€ë§Œ DB ì €ì¥ì‹œì—ëŠ” integer timestampê°€ í•„ìš”í•¨.
                
                val = c['timestamp']
                if isinstance(val, int):
                    timestamp = val
                else:
                    # ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹± (UTC ê°€ì •)
                    try:
                        dt = pd.to_datetime(val).replace(tzinfo=UTC)
                        timestamp = int(dt.timestamp())
                    except:
                        # fallback
                        timestamp = int(pd.to_datetime(val).timestamp())

                batch_data.append((
                    symbol, interval, timestamp,
                    c['open'], c['high'], c['low'], c['close'], c['volume']
                ))

            # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ DBì— ì €ì¥
            if len(batch_data) >= batch_size:
                cursor.executemany('''
                    INSERT OR REPLACE INTO candles (
                        symbol, interval, timestamp, open, high, low, close, volume
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', batch_data)
                conn.commit()
                total_saved += len(batch_data)
                batch_data.clear()

        except Exception as e:
            print(f"âš ï¸ ì €ì¥ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            continue

    conn.close()
    
def build_url(interval):
    # í™˜ê²½ë³€ìˆ˜ í‚¤ ìƒì„± (ì˜ˆ: API_URL_15M)
    env_key = f"API_URL_{interval.upper()}"
    url = os.getenv(env_key)
    
    if not url:
        print(f"âŒ ì˜¤ë¥˜: {interval}ì— ëŒ€í•œ API URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ({env_key})")
        return None
        
    return url

async def get_all_symbols(session: aiohttp.ClientSession):
    """ğŸš€ ìµœì í™”ëœ ì¢…ëª© ëª©ë¡ ì¡°íšŒ"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ Ticker URL ê°€ì ¸ì˜¤ê¸°
    url = os.getenv('API_TICKER_URL')
    if not url:
        print("âŒ ì˜¤ë¥˜: API_TICKER_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    data = await response.json()
                    # ë°ì´í„° íŒŒì‹± (ê±°ë˜ì†Œë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ - í˜„ì¬ëŠ” ë¹—ì¸ ê¸°ì¤€)
                    # ë²”ìš©ì„±ì„ ìœ„í•´ ì¶”í›„ íŒŒì‹± ë¡œì§ ë¶„ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ
                    if "data" in data:
                        symbols = [s for s in data["data"] if s != "date"]
                        print(f"âœ… ì¢…ëª© ëª©ë¡ ì¡°íšŒ ì„±ê³µ: {len(symbols)}ê°œ")
                        return symbols
                    else:
                        print(f"âš ï¸ ì¢…ëª© ëª©ë¡ í˜•ì‹ ë¶ˆì¼ì¹˜ (data í‚¤ ì—†ìŒ)")
                        return []

                elif response.status == 429:
                    # Rate limit ì²˜ë¦¬
                    retry_after = None
                    try:
                        retry_after_header = response.headers.get('Retry-After')
                        if retry_after_header:
                            retry_after = int(retry_after_header)
                    except:
                        pass
                    
                    rate_limiter.set_rate_limit(retry_after)
                    print(f"âš ï¸ ì¢…ëª© ëª©ë¡ ì¡°íšŒ Rate limit (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS})")
                    
                    if attempt < RETRY_ATTEMPTS - 1:
                        backoff_delay = RETRY_DELAY * (2 ** attempt)
                        await asyncio.sleep(backoff_delay)
                        await rate_limiter.wait_if_needed()
                    continue
                else:
                    print(f"âš ï¸ ì¢…ëª© ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ (HTTP {response.status})")
        except Exception as e:
            print(f"âš ï¸ ì¢…ëª© ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS}): {e}")
            if attempt < RETRY_ATTEMPTS - 1:
                backoff_delay = RETRY_DELAY * (2 ** attempt)
                await asyncio.sleep(backoff_delay)
    
    return []

async def fetch_candles(session: aiohttp.ClientSession, symbol: str, interval: str, from_ts: int, to_ts: int):
    """ğŸš€ ìµœì í™”ëœ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨) - ê³¼ê±° ìˆ˜ì§‘ ì§€ì›"""
    url = build_url(interval)
    if not url:
        return []

    to_dt = datetime.fromtimestamp(to_ts, tz=UTC)
    
    # ì‹¬ë³¼ ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì²˜ë¦¬ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
    prefix = os.getenv('SYMBOL_PREFIX', '')
    suffix = os.getenv('SYMBOL_SUFFIX', '')
    market_code = f"{prefix}{symbol}{suffix}"
    
    params = {
        "market": market_code,
        "count": 200,
        "to": to_dt.strftime("%Y-%m-%dT%H:%M:%S")
    }
    
    key = f"{symbol}/{interval}"

    for attempt in range(RETRY_ATTEMPTS):
        try:
            # Rate limit ëŒ€ê¸°
            await rate_limiter.wait_if_needed()
            
            timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            async with session.get(url, params=params, timeout=timeout) as response:
                if response.status == 429:
                    rate_limit_counter[key] += 1
                    now = time.time()
                    if rate_limit_counter[key] % 10 == 1 or now - rate_limit_last_print[key] > 10:
                        rate_limit_last_print[key] = now
                    # Rate Limit ëŒ€ì‘: ë” ê¸´ ëŒ€ê¸° ì‹œê°„ ì ìš©
                    wait_time = min(3.0, rate_limit_counter[key] * 1.5)  # ìµœëŒ€ 3ì´ˆê¹Œì§€ ì¦ê°€
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    rate_limit_counter[key] = 0  # ì •ìƒ ì‘ë‹µì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
                
                if response.status == 200:
                    data = await response.json()
                    if not isinstance(data, list):
                        performance_monitor.log_request(False)
                        return []

                    candles = []
                    seen_timestamps = set()
                    
                    for candle in data:
                        try:
                            # ğŸš€ ìŠ¤ë§ˆíŠ¸ í•„ë“œ ë§¤í•‘ ì ìš©
                            timestamp, ts_iso = get_timestamp_from_candidates(candle)
                            
                            if timestamp is None:
                                continue
                            
                            if timestamp in seen_timestamps:
                                continue
                            seen_timestamps.add(timestamp)

                            candles.append({
                                'timestamp': ts_iso,
                                'open': get_value_from_candidates(candle, 'open'),
                                'high': get_value_from_candidates(candle, 'high'),
                                'low': get_value_from_candidates(candle, 'low'),
                                'close': get_value_from_candidates(candle, 'close'),
                                'volume': round(get_value_from_candidates(candle, 'volume'), 4)
                            })
                        except (ValueError, KeyError) as e:
                            continue

                    performance_monitor.log_request(True, len(candles))
                    return candles
                else:
                    pass
                    
        except asyncio.TimeoutError:
            pass
        except Exception as e:
            pass
        
        if attempt < RETRY_ATTEMPTS - 1:
            # ì§€ìˆ˜ ë°±ì˜¤í”„
            backoff_delay = RETRY_DELAY * (2 ** attempt)
            await asyncio.sleep(backoff_delay)
    
    performance_monitor.log_request(False)
    
    # ì‹¤íŒ¨í•œ ìš”ì²­ ê¸°ë¡
    async with failed_requests_lock:
        failed_requests.add((symbol, interval))
    
    return []

interval_minutes = {'15m': 15, '30m': 30, '240m': 240, '1d': 1440}

def split_into_chunks(from_ts, to_ts, gap_sec):
    chunks = []
    while to_ts > from_ts:
        end = to_ts
        start = max(from_ts, to_ts - gap_sec * 200)
        chunks.append((start, end))
        to_ts = start
    return chunks

# ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
async def fetch_all(save_queue):
    """ğŸš€ ìµœì í™”ëœ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""

    connector = aiohttp.TCPConnector(
        limit=MAX_CONCURRENT_REQUESTS * 3,
        limit_per_host=MAX_CONCURRENT_REQUESTS * 2,
        ttl_dns_cache=300,
        use_dns_cache=True,
        keepalive_timeout=30,
        enable_cleanup_closed=True
    )

    timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={'User-Agent': 'Mozilla/5.0 (compatible; TradingBot/2.0)'}
    ) as session:
        symbols = await get_all_symbols(session)
        if not symbols:
            return
        
        # ğŸ§ª í…ŒìŠ¤íŠ¸ìš© ì¢…ëª© í•„í„°ë§
        if TEST_SYMBOLS is not None:
            # TEST_SYMBOLSì— ì§€ì •ëœ ì¢…ëª©ë§Œ í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
            symbols_dict = {s.upper(): s for s in symbols}  # ì›ë³¸ ì‹¬ë³¼ëª… ìœ ì§€
            filtered_symbols = []
            not_found = []
            
            for test_sym in TEST_SYMBOLS:
                test_sym_upper = test_sym.upper()
                if test_sym_upper in symbols_dict:
                    filtered_symbols.append(symbols_dict[test_sym_upper])
                else:
                    not_found.append(test_sym)
            
            symbols = filtered_symbols
            if not_found:
                print(f"âš ï¸ ë‹¤ìŒ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(not_found)}")
            print(f"ğŸ§ª ì§€ì • ëª¨ë“œ: ì„ íƒëœ ì¢…ëª© {len(symbols)}ê°œë§Œ ìˆ˜ì§‘ ({', '.join(symbols[:5])}...)")
            
        elif IS_ALL_TARGET:
            # ALL ëª¨ë“œ: í•„í„°ë§ ì—†ì´ ì „ì²´ ì¢…ëª© ìˆ˜ì§‘
            print(f"ğŸš€ ì „ì²´ ëª¨ë“œ: ê±°ë˜ì†Œ ì „ì²´ ì¢…ëª© {len(symbols)}ê°œ ìˆ˜ì§‘ ì‹œì‘")
            
        elif len(symbols) > 10:
            # TEST_SYMBOLSê°€ Noneì´ê³  ì¢…ëª©ì´ ë§ìœ¼ë©´ ì²˜ìŒ 10ê°œë§Œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            symbols = symbols[:10]
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì¢…ëª© 10ê°œë¡œ ì œí•œ ({', '.join(symbols)})")


        # ê³¼ê±° ìˆ˜ì§‘ ê¸°ê°„: ì§€í‘œ ê³„ì‚° ë²„í¼ í¬í•¨ (ìµœì†Œ 70~90ì¼)
        total_tasks = 0

        end_time_global = datetime.now(UTC)
        for interval in INTERVALS:
            gap_sec = interval_minutes[interval] * 60
            print(f"\nâ° {interval} ìº”ë“¤ ìˆ˜ì§‘ ì¤‘...")

            interval_tasks = []
            # ì¸í„°ë²Œë³„ ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (ì§€í‘œ ë²„í¼ í¬í•¨)
            days_back = INTERVAL_DAYS_BACK.get(interval, 70)
            start_time = end_time_global - timedelta(days=days_back)
            start_ts = int(start_time.timestamp())
            end_ts = int(end_time_global.timestamp()) - 300
            for coin in symbols:
                chunks = split_into_chunks(start_ts, end_ts, gap_sec)
                
                for start, end in chunks:
                    task = limited_fetch(session, coin, interval, start, end, save_queue)
                    interval_tasks.append(task)

            total_tasks += len(interval_tasks)
            print(f"ğŸ“‹ {interval}: {len(interval_tasks):,}ê°œ íƒœìŠ¤í¬ ìƒì„±")

            # ğŸš€ ë” í° ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹¤í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            batch_size = 200  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            completed_tasks = 0

            for i in range(0, len(interval_tasks), batch_size):
                batch = interval_tasks[i:i + batch_size]
                results = await asyncio.gather(*batch, return_exceptions=True)

                # ê²°ê³¼ ì²˜ë¦¬
                for result in results:
                    if isinstance(result, Exception):
                        print(f"âš ï¸ íƒœìŠ¤í¬ ì‹¤í–‰ ì˜¤ë¥˜: {result}")
                    elif result:
                        pass  # ì„±ê³µí•œ ê²½ìš° (ì´ë¯¸ íì— ì¶”ê°€ë¨)

                completed_tasks += len(batch)
                if completed_tasks % (batch_size * 5) == 0:  # 5ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
                    print(f"ğŸ“ˆ {interval} ì§„í–‰ë¥ : {completed_tasks:,}/{len(interval_tasks):,} ({completed_tasks/len(interval_tasks)*100:.1f}%)")


        # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ì²˜ë¦¬
        if failed_requests:
            # logger ëŒ€ì‹  print ì‚¬ìš©
            print(f"âš ï¸ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ({len(failed_requests)}ê°œ): {list(failed_requests)[:5]}...")
        else:
            print("âœ… ëª¨ë“  ìš”ì²­ ì„±ê³µ!")

        stats = performance_monitor.get_stats()

        # ğŸš€ ì„±ëŠ¥ í‰ê°€
        if stats['requests_per_second'] > 50:
            pass
        elif stats['requests_per_second'] > 35:
            pass
        else:
            pass
            
async def limited_fetch(session: aiohttp.ClientSession, coin: str, interval: str, start_ts: int, end_ts: int, save_queue):
    """ğŸš€ ìµœì í™”ëœ ì œí•œëœ í˜ì¹˜ (ì„¸ë§ˆí¬ì–´ ì œì–´)"""
    async with semaphore:  # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
        candles = await fetch_candles(session, coin, interval, start_ts, end_ts)
        await asyncio.sleep(0.02)  # ìµœì†Œ ì§€ì—° ì‹œê°„ (50 ë™ì‹œ ìš”ì²­ ëŒ€ì‘)
        if candles:
            await save_queue.put((coin, interval, candles))
        return candles

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë¹„ë™ê¸° ë²„ì „)
async def main():
    
    # í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ DB íŒŒì¼ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)
    create_table()
    
    
    # ğŸš€ ì„±ëŠ¥ ì˜ˆì¸¡
    estimated_symbols = 400  # ì˜ˆìƒ ì¢…ëª© ìˆ˜
    estimated_requests = estimated_symbols * len(INTERVALS) * 8
    estimated_time = estimated_requests / 50

    # ğŸ§ª ì´ë²¤íŠ¸ ë£¨í”„ì— ë°”ì¸ë”©ëœ save_queue ìƒì„±
    save_queue = asyncio.Queue(maxsize=3000)

    # ğŸš€ ì €ì¥ ì›Œì»¤ ì‹œì‘
    worker = asyncio.create_task(candle_saver_worker(save_queue))

    try:
        # ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        await fetch_all(save_queue)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    # ğŸš€ ì›Œì»¤ ì¢…ë£Œ ì‹ í˜¸
    await save_queue.put(None)
    await worker

if __name__ == "__main__":
    asyncio.run(main())