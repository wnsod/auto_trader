import json
from abc import ABC, abstractmethod
from typing import Dict, Any
from llm_factory.utils.llm_client import get_openai_client

class BaseAgent(ABC):
    """ëª¨ë“  LLM ì—ì´ì „íŠ¸ì˜ ë¶€ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self, agent_name: str, model_name: str = "gpt-4o-mini"):
        self.agent_name = agent_name
        self.model_name = model_name
        self.client = get_openai_client()

    @abstractmethod
    def process(self, input_data: Any) -> Dict:
        """ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ë¶„ì„ ê²°ê³¼(JSON)ë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""
        pass

    def call_llm(self, prompt: str, system_role: str = "You are a financial analyst.") -> str:
        """ì‹¤ì œ LLM í˜¸ì¶œ"""
        if not self.client:
            return None # Mock ëª¨ë“œë¡œ Fallback

        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            # print(f"âŒ [LLM Error] {e}")
            print(f"[LLM Error] {e}")
            return None

    def _mock_llm_inference(self, prompt: str, mock_response: Dict) -> Dict:
        """LLM í˜¸ì¶œì„ í‰ë‚´ë‚´ëŠ” ë©”ì„œë“œ (API ì—°ê²° ì „ í…ŒìŠ¤íŠ¸ìš©)"""
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ OpenAI API ë“±ì„ í˜¸ì¶œ
        # print(f"ğŸ¤– [{self.agent_name}] Thinking...\nPrompt: {prompt[:50]}...")
        return mock_response

