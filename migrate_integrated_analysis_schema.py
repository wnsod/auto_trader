#!/usr/bin/env python3
"""
integrated_analysis_results í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ:
  id, coin, interval, signal_action, signal_score, confidence, created_at

ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ:
  id, coin, interval, regime, fractal_score, multi_timeframe_score,
  indicator_cross_score, ensemble_score, ensemble_confidence,
  final_signal_score, signal_confidence, signal_action, created_at

ë§ˆì´ê·¸ë ˆì´ì…˜ ë°©ë²•:
1. ê¸°ì¡´ ë°ì´í„°ë¥¼ ì„ì‹œ í…Œì´ë¸”ë¡œ ë°±ì—…
2. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
3. ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆë¡œ í…Œì´ë¸” ì¬ìƒì„±
4. ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆ í…Œì´ë¸”ë¡œ ë³µì‚¬ (ì»¬ëŸ¼ ë§¤í•‘)
5. ì„ì‹œ í…Œì´ë¸” ì‚­ì œ
"""

import sqlite3
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def migrate_integrated_analysis_results(db_path: str) -> bool:
    """integrated_analysis_results í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    try:
        # DB íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(db_path).exists():
            logger.error(f"âŒ DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_path}")
            return False

        logger.info(f"ğŸš€ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘: {db_path}")

        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()

            # 1. ê¸°ì¡´ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='table' AND name='integrated_analysis_results'
            """)
            if not cursor.fetchone():
                logger.info("â„¹ï¸ integrated_analysis_results í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                create_new_table(cursor)
                conn.commit()
                logger.info("âœ… ìƒˆ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                return True

            # 2. ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ í™•ì¸
            cursor.execute("PRAGMA table_info(integrated_analysis_results)")
            existing_columns = {row[1] for row in cursor.fetchall()}
            logger.info(f"ğŸ“Š ê¸°ì¡´ ì»¬ëŸ¼: {existing_columns}")

            # 3. ì´ë¯¸ ìƒˆ ìŠ¤í‚¤ë§ˆì¸ì§€ í™•ì¸
            required_columns = {
                'regime', 'fractal_score', 'multi_timeframe_score',
                'indicator_cross_score', 'ensemble_score', 'ensemble_confidence',
                'final_signal_score', 'signal_confidence'
            }
            if required_columns.issubset(existing_columns):
                logger.info("âœ… í…Œì´ë¸”ì´ ì´ë¯¸ ìƒˆ ìŠ¤í‚¤ë§ˆë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš”.")
                return True

            # 4. ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM integrated_analysis_results")
            data_count = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜: {data_count}ê°œ")

            # 5. ê¸°ì¡´ ë°ì´í„°ë¥¼ ì„ì‹œ í…Œì´ë¸”ë¡œ ë°±ì—…
            logger.info("ğŸ’¾ ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì¤‘...")
            cursor.execute("""
                CREATE TABLE integrated_analysis_results_backup AS
                SELECT * FROM integrated_analysis_results
            """)
            logger.info(f"âœ… {data_count}ê°œ ë°ì´í„° ë°±ì—… ì™„ë£Œ")

            # 6. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
            logger.info("ğŸ—‘ï¸ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ ì¤‘...")
            cursor.execute("DROP TABLE integrated_analysis_results")
            logger.info("âœ… ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ")

            # 7. ìƒˆ ìŠ¤í‚¤ë§ˆë¡œ í…Œì´ë¸” ìƒì„±
            logger.info("ğŸ—ï¸ ìƒˆ í…Œì´ë¸” ìƒì„± ì¤‘...")
            create_new_table(cursor)
            logger.info("âœ… ìƒˆ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

            # 8. ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆ í…Œì´ë¸”ë¡œ ë³µì‚¬
            logger.info("ğŸ“¥ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")

            # ê¸°ì¡´ ë°ì´í„°ì˜ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸
            cursor.execute("PRAGMA table_info(integrated_analysis_results_backup)")
            backup_columns = [row[1] for row in cursor.fetchall()]

            if data_count > 0:
                # ì»¬ëŸ¼ ë§¤í•‘ (êµ¬ ìŠ¤í‚¤ë§ˆ â†’ ìƒˆ ìŠ¤í‚¤ë§ˆ)
                # signal_score â†’ final_signal_score
                # confidence â†’ signal_confidence
                if 'signal_score' in backup_columns and 'confidence' in backup_columns:
                    cursor.execute("""
                        INSERT INTO integrated_analysis_results
                        (coin, interval, regime, fractal_score, multi_timeframe_score,
                         indicator_cross_score, ensemble_score, ensemble_confidence,
                         final_signal_score, signal_confidence, signal_action, created_at)
                        SELECT
                            coin,
                            interval,
                            'neutral' AS regime,
                            0.0 AS fractal_score,
                            0.0 AS multi_timeframe_score,
                            0.0 AS indicator_cross_score,
                            0.0 AS ensemble_score,
                            0.0 AS ensemble_confidence,
                            signal_score AS final_signal_score,
                            confidence AS signal_confidence,
                            signal_action,
                            created_at
                        FROM integrated_analysis_results_backup
                    """)
                    logger.info(f"âœ… {data_count}ê°œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ ê¸°ì¡´ ë°ì´í„° êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

            # 9. ë°±ì—… í…Œì´ë¸” ì‚­ì œ
            logger.info("ğŸ—‘ï¸ ë°±ì—… í…Œì´ë¸” ì‚­ì œ ì¤‘...")
            cursor.execute("DROP TABLE integrated_analysis_results_backup")
            logger.info("âœ… ë°±ì—… í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ")

            # 10. ìƒˆ í…Œì´ë¸” ë°ì´í„° ê°œìˆ˜ í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM integrated_analysis_results")
            new_data_count = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ë°ì´í„° ê°œìˆ˜: {new_data_count}ê°œ")

            conn.commit()
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")

            # 11. ê²°ê³¼ ê²€ì¦
            if new_data_count == data_count:
                logger.info("âœ… ë°ì´í„° ë¬´ê²°ì„± í™•ì¸ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ ë°ì´í„° ê°œìˆ˜ ë¶ˆì¼ì¹˜: {data_count} â†’ {new_data_count}")

            return True

    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
        return False


def create_new_table(cursor: sqlite3.Cursor):
    """ìƒˆ ìŠ¤í‚¤ë§ˆë¡œ í…Œì´ë¸” ìƒì„±"""
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS integrated_analysis_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            coin TEXT NOT NULL,
            interval TEXT NOT NULL,
            regime TEXT NOT NULL DEFAULT 'neutral',

            -- ë¶„ì„ ê²°ê³¼
            fractal_score REAL DEFAULT 0.0,
            multi_timeframe_score REAL DEFAULT 0.0,
            indicator_cross_score REAL DEFAULT 0.0,

            -- JAX ì•™ìƒë¸” ê²°ê³¼
            ensemble_score REAL DEFAULT 0.0,
            ensemble_confidence REAL DEFAULT 0.0,

            -- ìµœì¢… ì‹œê·¸ë„ ì ìˆ˜
            final_signal_score REAL DEFAULT 0.0,
            signal_confidence REAL DEFAULT 0.0,
            signal_action TEXT DEFAULT 'hold',

            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # ì¸ë±ìŠ¤ ìƒì„±
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_integrated_analysis_coin_interval
        ON integrated_analysis_results(coin, interval)
    """)
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_integrated_analysis_final_signal_score
        ON integrated_analysis_results(final_signal_score DESC)
    """)
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_integrated_analysis_created_at
        ON integrated_analysis_results(created_at DESC)
    """)
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_integrated_analysis_regime
        ON integrated_analysis_results(regime)
    """)


if __name__ == "__main__":
    import sys

    # DB ê²½ë¡œ (ê¸°ë³¸ê°’: rl_pipeline/data_storage/rl_strategies.db)
    if len(sys.argv) > 1:
        db_path = sys.argv[1]
    else:
        # ë„ì»¤ ë‚´ë¶€ ê²½ë¡œ
        db_path = "/workspace/data_storage/rl_strategies.db"

        # ë¡œì»¬ ê²½ë¡œë¡œ ëŒ€ì²´ (íŒŒì¼ì´ ì—†ìœ¼ë©´)
        if not Path(db_path).exists():
            db_path = "./data_storage/rl_strategies.db"

    logger.info(f"ğŸ¯ ëŒ€ìƒ DB: {db_path}")

    success = migrate_integrated_analysis_results(db_path)

    if success:
        logger.info("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ!")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨!")
        sys.exit(1)
