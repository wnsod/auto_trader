"""
US ì£¼ì‹ ì‹œì¥ ë¶„ì„ ìœ í‹¸ë¦¬í‹° (market_analyzer.py)

ê¸°ëŠ¥:
1. S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (Wikipedia/Slickcharts ì†ŒìŠ¤ ë˜ëŠ” yfinance)
2. í€ë”ë©˜íƒˆ ë°ì´í„°(PER, Market Cap, Sector ë“±) ì¡°íšŒ ë° ë¶„ì„
3. ë°¸ë¥˜ì—ì´ì…˜ í‰ê°€ ë° ë¦¬ìŠ¤í¬ ë ˆë²¨ ì‚°ì¶œ
4. í˜ë‹ˆì£¼(Penny Stock) ë“± ìœ ì˜ ì¢…ëª© í•„í„°ë§

ë°ì´í„° ì†ŒìŠ¤:
- yfinance (Yahoo Finance)
- Wikipedia (S&P 500 List)
"""

import os
import json
import time
import requests
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from typing import Dict, List, Optional

# ======================
# ê²½ë¡œ ì„¤ì •
# ======================
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
DATA_DIR = os.path.join(BASE_DIR, 'data_storage')
os.makedirs(DATA_DIR, exist_ok=True)

# ë°ì´í„° ìºì‹œ íŒŒì¼
SP500_TICKER_CACHE = os.path.join(DATA_DIR, 'sp500_tickers.json')
FUNDAMENTAL_CACHE_JSON = os.path.join(DATA_DIR, 'us_fundamentals.json')

CACHE_EXPIRE_HOURS = 24  # í•˜ë£¨ í•œ ë²ˆ ê°±ì‹ 

# ======================
# 1. S&P 500 í‹°ì»¤ ì¡°íšŒ
# ======================

def fetch_sp500_tickers(use_cache=True) -> List[str]:
    """
    S&P 500 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (Wikipedia -> GitHub dataset fallback)
    """
    if use_cache and os.path.exists(SP500_TICKER_CACHE):
        try:
            with open(SP500_TICKER_CACHE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # í•˜ë£¨ ì§€ë‚œ ìºì‹œëŠ” ê°±ì‹  ì‹œë„
                if 'timestamp' in data:
                    last_update = datetime.fromisoformat(data['timestamp'])
                    if datetime.now() - last_update < timedelta(hours=CACHE_EXPIRE_HOURS):
                        return data['tickers']
        except:
            pass

    # 1) Wikipedia ì‹œë„
    print("ğŸ“¥ S&P 500 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘ (Wikipedia)...")
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        tables = pd.read_html(url)
        df = tables[0]
        tickers = df['Symbol'].tolist()
        tickers = [t.replace('.', '-') for t in tickers]  # BRK.B -> BRK-B
        with open(SP500_TICKER_CACHE, 'w', encoding='utf-8') as f:
            json.dump({'timestamp': datetime.now().isoformat(), 'tickers': tickers}, f)
        print(f"âœ… S&P 500 í‹°ì»¤ {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return tickers
    except Exception as e:
        print(f"âŒ Wikipedia ì‹¤íŒ¨: {e}")

    # 2) GitHub dataset fallback (datasets/s-and-p-500-companies)
    print("ğŸ“¥ GitHub datasetì—ì„œ S&P 500 í‹°ì»¤ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    try:
        url = "https://raw.githubusercontent.com/datasets/s-and-p-500-companies/master/data/constituents.csv"
        df = pd.read_csv(url)
        tickers = df['Symbol'].tolist()
        tickers = [t.replace('.', '-') for t in tickers]
        with open(SP500_TICKER_CACHE, 'w', encoding='utf-8') as f:
            json.dump({'timestamp': datetime.now().isoformat(), 'tickers': tickers}, f)
        print(f"âœ… S&P 500 í‹°ì»¤ {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ (GitHub)")
        return tickers
    except Exception as e:
        print(f"âŒ GitHub fallback ì‹¤íŒ¨: {e}")

    # 3) ìµœì¢… ë¹„ìƒ ë¦¬ìŠ¤íŠ¸
    print("âš ï¸ ë¹„ìƒìš© í•˜ë“œì½”ë”© ë¦¬ìŠ¤íŠ¸ë¡œ ì§„í–‰")
    return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA', 'META', 'BRK-B', 'V', 'JNJ']

def get_all_us_symbols() -> List[str]:
    """ì „ì²´ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (S&P 500)"""
    return fetch_sp500_tickers()

def get_korean_name(ticker: str) -> str:
    """ë¯¸êµ­ ì£¼ì‹ì€ í•œê¸€ëª…ì´ ì—†ìœ¼ë¯€ë¡œ í‹°ì»¤ ë°˜í™˜ (í•„ìš” ì‹œ ë³„ë„ ë§¤í•‘ ê°€ëŠ¥)"""
    return ticker

# ======================
# 2. í€ë”ë©˜íƒˆ ë°ì´í„° (yfinance)
# ======================

def fetch_us_fundamentals(tickers: List[str] = None, force_refresh=False) -> Dict:
    """
    S&P 500 í€ë”ë©˜íƒˆ ì§€í‘œ ì¡°íšŒ (yfinance Ticker ê°ì²´ í™œìš©)
    """
    # 1. ìºì‹œ í™•ì¸
    cached_data = {}
    if not force_refresh and os.path.exists(FUNDAMENTAL_CACHE_JSON):
        try:
            with open(FUNDAMENTAL_CACHE_JSON, 'r', encoding='utf-8') as f:
                cached = json.load(f)
                if 'timestamp' in cached:
                    last_update = datetime.fromisoformat(cached['timestamp'])
                    if datetime.now() - last_update < timedelta(hours=CACHE_EXPIRE_HOURS):
                        cached_data = cached.get('data', {})
        except:
            pass

    if tickers is None:
        tickers = fetch_sp500_tickers()

    # ìºì‹œì— ì—†ëŠ” í‹°ì»¤ë§Œ ì„ ë³„
    target_tickers = [t for t in tickers if t not in cached_data]
    
    if not target_tickers:
        return {t: cached_data[t] for t in tickers if t in cached_data}

    print(f"ğŸŒ US í€ë”ë©˜íƒˆ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(target_tickers)}ê°œ ì¢…ëª©)...")
    
    # yfinanceëŠ” ëŒ€ëŸ‰ ì¡°íšŒ ì‹œ Tickers ê°ì²´ ì‚¬ìš©ì´ ë¹ ë¦„
    # í•˜ì§€ë§Œ ìƒì„¸ infoëŠ” ê°œë³„ ì ‘ê·¼ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” 50ê°œì”© ëŠì–´ì„œ ì²˜ë¦¬ ê¶Œì¥
    
    new_data = {}
    chunk_size = 50
    
    for i in range(0, len(target_tickers), chunk_size):
        chunk = target_tickers[i:i+chunk_size]
        try:
            # ë°°ì¹˜ ë¡œë”©ì€ infoë¥¼ í•œ ë²ˆì— ì£¼ì§€ ì•Šìœ¼ë¯€ë¡œ, ë£¨í”„ ëŒë©° ì ‘ê·¼
            # ì†ë„ ê°œì„ ì„ ìœ„í•´ í•„ìš”í•œ í•„ë“œë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¤ëŠ” ë°©ë²• ê³ ë ¤
            # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì„±ì„ ìœ„í•´ ê°œë³„ Ticker ì ‘ê·¼ (ëŠë¦¬ì§€ë§Œ í™•ì‹¤)
            for t in chunk:
                try:
                    stock = yf.Ticker(t)
                    info = stock.info
                    
                    data = {
                        'symbol': t,
                        'name': info.get('shortName', t),
                        'sector': info.get('sector', 'Unknown'),
                        'industry': info.get('industry', 'Unknown'),
                        'market_cap': info.get('marketCap', 0),
                        'per': info.get('trailingPE'),
                        'forward_per': info.get('forwardPE'),
                        'pbr': info.get('priceToBook'),
                        'eps': info.get('trailingEps'),
                        'div_yield': (info.get('dividendYield', 0) or 0) * 100, # % ë‹¨ìœ„ ë³€í™˜
                        'beta': info.get('beta'),
                        'current_price': info.get('currentPrice', 0),
                        'volume': info.get('averageVolume', 0)
                    }
                    new_data[t] = data
                except Exception as e:
                    print(f"âš ï¸ {t} info ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    new_data[t] = {'symbol': t, 'error': str(e)}
            
            print(f"   ... {i + len(chunk)}/{len(target_tickers)} ì™„ë£Œ")
            time.sleep(1) # API ë¶€í•˜ ì¡°ì ˆ
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # ë°ì´í„° ë³‘í•© ë° ì €ì¥
    merged_data = {**cached_data, **new_data}
    
    try:
        with open(FUNDAMENTAL_CACHE_JSON, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'data': merged_data
            }, f, indent=2)
    except Exception as e:
        print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    return {t: merged_data[t] for t in tickers if t in merged_data}

def get_fundamental_data(ticker: str) -> Optional[Dict]:
    """íŠ¹ì • ì¢…ëª© í€ë”ë©˜íƒˆ ì¡°íšŒ"""
    # ë‹¨ì¼ ì¡°íšŒ ì‹œ ì „ì²´ ë¡œë“œ ë°©ì§€ë¥¼ ìœ„í•´ ìºì‹œ ì§ì ‘ ì½ê¸° ê¶Œì¥
    # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ì „ì²´ ë¡œë“œ í•¨ìˆ˜ í˜¸ì¶œ
    data = fetch_us_fundamentals([ticker])
    return data.get(ticker)

# ======================
# 3. í‰ê°€ ë° ë¶„ì„ ë¡œì§
# ======================

def get_stock_tier(info: Dict) -> str:
    """ì‹œê°€ì´ì•¡ ê¸°ì¤€ í‹°ì–´ ë¶„ë¥˜ (USD)"""
    cap = info.get('market_cap', 0)
    
    # ë‹¨ìœ„: USD
    if cap >= 200_000_000_000: # 200B (Mega Cap) - ì• í”Œ, ë§ˆì†Œ ë“±
        return 'MEGA'
    elif cap >= 10_000_000_000: # 10B (Large Cap)
        return 'LARGE'
    elif cap >= 2_000_000_000: # 2B (Mid Cap)
        return 'MID'
    else:
        return 'SMALL'

def calculate_value_score(info: Dict) -> int:
    """ê°€ì¹˜íˆ¬ì ì ìˆ˜ ê³„ì‚° (0~100)"""
    score = 50
    
    per = info.get('per')
    pbr = info.get('pbr')
    div = info.get('div_yield', 0)
    beta = info.get('beta')
    
    # PER í‰ê°€ (ë¯¸êµ­ì¥ì€ í•œêµ­ë³´ë‹¤ PERê°€ ë†’ìŒ)
    if per:
        if 0 < per < 15: score += 15
        elif 15 <= per < 25: score += 5
        elif per > 50: score -= 10
        
    # PBR í‰ê°€
    if pbr:
        if pbr < 3: score += 10
        elif pbr > 10: score -= 5
        
    # ë°°ë‹¹ í‰ê°€
    if div > 2.0: score += 10
    
    # ë³€ë™ì„±(Beta) í‰ê°€
    if beta:
        if 0.8 < beta < 1.2: score += 5 # ì‹œì¥ ì¶”ì¢… ì•ˆì •ì 
        elif beta > 2.0: score -= 10 # ê³ ë³€ë™ì„±
        
    return max(0, min(100, score))

def evaluate_fundamental(info: Dict, warning_list: List[str] = None) -> Dict:
    """ì¢…ëª© ì¢…í•© í‰ê°€"""
    ticker = info.get('symbol')
    price = info.get('current_price', 0)
    cap = info.get('market_cap', 0)
    
    reasons = []
    passed = True
    
    # 1. í˜ë‹ˆì£¼ í•„í„° (5ë‹¬ëŸ¬ ë¯¸ë§Œì€ ê¸°ê´€ ìˆ˜ê¸‰ ë¶€ì¡± ê°€ëŠ¥ì„±)
    if price < 5.0 and price > 0: 
        # S&P 500 í¸ì… ì¢…ëª©ì´ë¼ë©´ 5ë‹¬ëŸ¬ ë¯¸ë§Œì´ì–´ë„ ê´œì°®ì„ ìˆ˜ ìˆìœ¼ë‚˜ ì£¼ì˜
        reasons.append(f"ì €ê°€ì£¼ (${price})")
        # passed = False # S&P 500ì´ë¼ë©´ ì¼ë‹¨ í†µê³¼ì‹œí‚¬ ìˆ˜ë„ ìˆìŒ
        
    # 2. ì‹œê°€ì´ì•¡ í•„í„° (S&P 500ì´ë¼ë„ ë„ˆë¬´ ì‘ì•„ì§„ ê²½ìš°)
    if cap < 5_000_000_000: # 5B ë¯¸ë§Œ
        # passed = False
        reasons.append(f"ì‹œì´ ê°ì†Œ (${cap/1e9:.1f}B)")

    if warning_list and ticker in warning_list:
        passed = False
        reasons.append("ìœ ì˜ ì¢…ëª© ì§€ì •")

    score = calculate_value_score(info)
    tier = get_stock_tier(info)
    
    risk = 'MEDIUM'
    if score < 40: risk = 'HIGH'
    if score > 70: risk = 'LOW'
    
    return {
        'pass': passed,
        'score': score,
        'weight': score / 50.0,
        'risk_level': risk,
        'tier': tier,
        'reasons': reasons if not passed else ['í•„í„° í†µê³¼']
    }

# ======================
# 4. ìœ ì˜ ì¢…ëª© ì¡°íšŒ
# ======================

def get_market_warning_list_extended() -> List[str]:
    """
    ìœ ì˜ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ë¯¸ì¥ìš©)
    - ìƒì¥íì§€ ì˜ˆì •, íŒŒì‚° ì‹ ì²­ ë“± (ìˆ˜ë™ ê´€ë¦¬ ë˜ëŠ” ë³„ë„ ì†ŒìŠ¤ í•„ìš”)
    - ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ í˜ë‹ˆì£¼ë‚˜ ë¬¸ì œ ì¢…ëª© í•˜ë“œì½”ë”© ì˜ˆì‹œ
    """
    # ì˜ˆì‹œ: íŒŒì‚° ì´ìŠˆê°€ ìˆëŠ” ì¢…ëª©ë“¤
    warning_list = ['BBBYQ', 'SIVBQ'] 
    return warning_list

# ======================
# 5. ë¶„ì„ ì‹¤í–‰ê¸° (Main)
# ======================

def analyze_multiple_coins(tickers: List[str]) -> Dict:
    """ë‹¤ì¤‘ ì¢…ëª© ë¶„ì„"""
    print(f"\nğŸ“Š {len(tickers)}ê°œ ì£¼ì‹ í€ë”ë©˜íƒˆ ë¶„ì„ ì‹œì‘...")
    
    # í€ë”ë©˜íƒˆ ë°ì´í„° ë¡œë“œ (í•„ìš”ì‹œ ê°±ì‹ )
    all_funds = fetch_us_fundamentals(tickers)
    warnings = get_market_warning_list_extended()
    
    results = {}
    for ticker in tickers:
        if ticker in all_funds:
            info = all_funds[ticker]
            if 'error' in info:
                evaluation = {'pass': False, 'score': 0, 'reasons': [f"ë°ì´í„° ì˜¤ë¥˜: {info['error']}"]}
            else:
                evaluation = evaluate_fundamental(info, warnings)
                
            results[ticker] = {
                'fundamental': info,
                'evaluation': evaluation
            }
        else:
            results[ticker] = {
                'fundamental': None,
                'evaluation': {
                    'pass': False, 'score': 0, 'reasons': ['ë°ì´í„° ì—†ìŒ']
                }
            }
    return results

if __name__ == '__main__':
    print("ğŸ§ª US ë§ˆì¼“ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸")
    
    test_tickers = ['AAPL', 'TSLA', 'NVDA', 'F'] # ì• í”Œ, í…ŒìŠ¬ë¼, ì—”ë¹„ë””ì•„, í¬ë“œ
    res = analyze_multiple_coins(test_tickers)
    
    for t, data in res.items():
        print(f"\nğŸ“Œ {t}")
        fund = data['fundamental']
        if fund and 'current_price' in fund:
            print(f"  Price: ${fund['current_price']}, PER: {fund['per']}, PBR: {fund['pbr']}")
            print(f"  í‰ê°€: {data['evaluation']}")
        else:
            print(f"  ë°ì´í„° ì—†ìŒ: {fund}")
